#include "sae_par.h"
#include "ndf.h"
#include <math.h>

#define MXSTK 100    /* Size of stack for recursive calls */

void CGEN_FUNCTION( kpg1Qntl )( int usewt, int interp, CGEN_TYPE fract,
                              int el, const CGEN_TYPE x[], const
                              CGEN_TYPE w[], int ip[], CGEN_TYPE *q,
                              int *status ){
/*
*+
*  Name:
*     kpg1Qntl<T>

*  Purpose:
*     Finds a quantile in a (possibly weighted) set of data.

*  Synopsis:
*     void kpg1Qntl<T>( int usewt, int interp, CGEN_TYPE fract, int el,
*                       const CGEN_TYPE x[], const CGEN_TYPE w[], int ip[],
*                       CGEN_TYPE *q, int *status )

*  Description:
*     This function calculates the value of a specified quantile in a set
*     of data values, which may be weighted.  In concept (although not in
*     practice) it sorts the supplied data values into ascending order
*     along with their associated positive weights, if supplied. It then
*     finds a quantile "q" such that the sum of the weights associated with
*     all data values less than "q" is a specified fraction "fract" of the
*     sum of all the weights supplied.  If no weights are supplied, then
*     each data value is assigned unit weight.  There are two main
*     applications of this algorithm:
*
*     a) To find specified quantiles of a distribution of data values for
*     statistical purposes.  In this case, the weights may optionally be
*     used to represent the number of times each data value occurs.  In
*     such cases, it may be useful to regard the distribution as
*     continuous, and therefore to interpolate linearly between data values
*     when obtaining the result.
*
*     b) Alternatively, the values may represent residuals from some fitted
*     function.  In this case, by setting "fract" to 0.5, the "weighted
*     median residual" may be found.  This has the property that if it is
*     subtracted from all the original residuals, then the weighted sum of
*     the absolute values of the corrected residuals will be minimised.
*     Thus, it may be used as the basis for iteratively finding an `L1"
*     fit.  In such cases, the required result will be equal to one of the
*     data values (or may lie mid-way between two of them) and
*     interpolation between values is not normally required.

*  Parameters:
*     usewt
*        Whether or not the data have associated weights.
*     interp
*        Whether or not interpolation between data values should be
*        performed when obtaining the result.
*     fract
*        The fraction specifying the required quantile, in the range 0.0 to
*        1.0.
*     el
*        Number of data values.
*     x
*        Array of data values.
*     w
*        Array of associated positive weights (if required). This parameter
*        will only be referenced if "usewt" is non-zero.
*     ip
*        On entry, an array of pointers identifying which elements of "x"
*        (and "w" if supplied) are to be considered. On exit, these
*        pointers will have been permuted to access the specified data
*        elements in an order which is more nearly sorted than before
*        (although in general it will not represent a complete sort of the
*        data). The supplied "ip" array should have at least "el" elements.
*     *q
*        Returned holding the value of the requested quantile.
*     *status
*        The global status.

*  Notes:
*     -  There are versions of this function for processing both REAL and
*     DOUBLE PRECISION data; replace the "x" in the function name by "r" or
*     D as appropriate. The types of the FACT, "x", "w" and "q" arguments
*     should match the function being used.
*     -  This function is optimised for use when the number of data values
*     is large. In general, only a partial sort of the data will be
*     performed, so this function will perform better than most other
*     methods of finding quantiles, which typically require a complete
*     sort.
*     -  The order in which the input pointers are supplied in the array
*     "ip" is arbitrary, but there will often be an efficiency advantage in
*     supplying them so that they access the data in nearly-sorted order.
*     Thus, re-supplying the array of pointers generated by a previous
*     invocation of this function (for the same or similar data) may be
*     worthwhile.

*  Timing:
*     Details of the asymptotic time required to execute the original
*     SELECT algorithm are not altogether clear from the published papers.
*     It appears that this algorithm may have better average performance
*     than other methods and the time required may approximate to "el" *
*     LOG( MIN( "k", "el" - "k" + 1 ) ) where "k" is the rank of the
*     largest data value which is smaller than the quantile being sought.
*     However, Sedgewick (see References) indicates that such algorithms
*     should, in general, complete in time proportional to "el", so the
*     above formula may be incorrect.  When using weighted data, the time
*     will be multiplied by a further factor reflecting the non-linearity
*     of the cumulative weight versus rank function and the difficulty of
*     inverting it.

*  References:
*     -  Comm. of the ACM, vol 18, no. 3 (March 1975), p165.
*     -  Also see page 173.
*     -  In addition, see the algorithm assessment by "t". Brown in
*     Collected Algorithms of the ACM, (algorithm no. 489).
*     -  Sedgwick, "r"., 1988, "Algorithms" (Addison-Wesley).

*  Copyright:
*     Copyright (C) 2022 East Asian Observatory
*     All rights reserved.

*  Licence:
*     This program is free software; you can redistribute it and/or modify
*     it under the terms of the GNU General Public License as published by
*     the Free Software Foundation; either Version 2 of the License, or (at
*     your option) any later version.
*
*     This program is distributed in the hope that it will be useful, but
*     WITHOUT ANY WARRANTY; without even the implied warranty of
*     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
*     General Public License for more details.
*
*     You should have received a copy of the GNU General Public License
*     along with this program; if not, write to the Free Software
*     Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
*     02110-1301, USA.

*  Authors:
*     FR: R.W.Floyd and R.L Rivest (CACM)
*     RFWS: R.F. Warren-Smith (STARLINK, RAL)
*     DSB: David S. Berry (STARLINK)
*     DSB: David S. Berry (EAO)

*  History:
*     25-APR-2022 (DSB):
*        Original version, based on equivalent Fortran function by FR et
*        al.

*-
*/

/* Local variables: */
   CGEN_TYPE alpha;      /* Interpolation fraction */
   CGEN_TYPE extra;      /* Extra cumulative weight required */
   CGEN_TYPE t;          /* Target value when partitioning */
   CGEN_TYPE wl;         /* Sum of `left' weights for iteration */
   CGEN_TYPE wleft;      /* Sum of `left' sorted weights */
   CGEN_TYPE wmid;       /* Sum of weights of unsorted data */
   CGEN_TYPE wr;         /* Sum of `right' weights for iteration */
   CGEN_TYPE wright;     /* Sum of `right' sorted weights */
   CGEN_TYPE wtarg;      /* Target weight for quantile */
   int i;                /* General index for array elements */
   int i1;               /* Index of lower neighbouring element */
   int i2;               /* Index of upper neighbouring element */
   int itmp;             /* Temporary store for swapping pointers */
   int j;                /* General index for array elements */
   int k;                /* Target rank for SELECT algorithm */
   int kzero;            /* Initial estimate of target rank */
   int l;                /* Left (first) array element to sort */
   int ll;               /* Left (first) array element to sort */
   int lstk[ MXSTK ];    /* Stack of left array element indices */
   int n;                /* Number of elements to be partitioned */
   int r;                /* Right (last) array element to sort */
   int rr;               /* Right (last) array element to sort */
   int rstk[ MXSTK ];    /* Stack of right array element indices */
   int s;                /* Used for estimating sample size */
   int sd;               /* Used for estimating sample size */
   int stk;              /* Stack pointer */
   float z;              /* Used for estimating sample size */

/* Check the inherited global status. */
   if( *status != SAI__OK ) return;

/* Initialise pointers to the left and right array elements to be
   sorted. */
   l = 1;
   r = el;

/* Initialise sums of weights for those elements which have already
   been sorted (i.e. those lying to the left and right of the un-sorted
   region). */
   wleft = 0.0;
   wright = 0.0;

/* Calculate, or estimate (using linear interpolation), the rank of the
   largest element such that the sum of weights for this and all
   smaller elements will not exceed the required fraction of the total
   sum of weights.  Initialise the target rank to this value. */
   kzero = round( el*NDF_MIN( NDF_MAX( 0.0, fract ), 1.0 ) );
   k = kzero;

/* Initialise the pointer to the recursive call stack. */
   stk = 0;

/* A recursive invocation of the basic algorithm starts here.
   ========================================================= */
L1:

/* Within each invocation, return to this point after each iteration,
   until convergence is achieved.  Confine the target rank for the next
   iteration to the search range to be used. */
L2:                      /* Start of 'DO WHILE' loop */
   k = NDF_MIN( NDF_MAX( l, k ), r );

/* If there are enough elements still to be sorted to make it
   worthwhile, then estimate the size of sample needed to get an
   approximate indication of the target value (i.e. the data value with
   the target rank).  Do not perform this step if the stack will
   overflow.  (This is unlikely to happen, but if it does it simply
   results in a slight loss of efficiency due to not reaching the
   optimum depth of recursion. The results will still be OK.) */
   if( ( ( r - l ) > 60 ) && ( stk < MXSTK ) ) {
      n = r - l + 1;
      i = k - l + 1;

/* (The object here is to estimate the target value in such a way that
   when "ip"("l":"r") is permuted to partition "x"("ip"("l":"r")) about this value,
   any error due to statistical uncertainty results in the true value
   of the K"th ranked data value being pointed at by an element of "ip"
   lying in the smaller part of the partitioned search range.  The cost
   of the next partitioning step is then minimised. The trick is to
   balance the cost of estimating the target value - determined by the
   sub-sample size - against the cost of getting it wrong. The original
   paper should be consulted for details.) */
      z = log( (float)( n ) );
      s = (int)( 0.5*exp( ( 2.0/3.0 )*z ) );

/* This is a modification recommended by the algorithm assessor: */

/* Original:
   sd = INT( 0.5*SQRT( z*REAL( s*( n - s ) / n ) )*SIGN( 1, i - n / 2) ) */

/* Modified to: */
      sd = (int)( 0.1*sqrt( z*(float)( s*( n - s )/n ) )*( 2*i/n - 1 ) );

/* Set the bounds of the sub-sample of "ip" to be partitioned. */
      ll = NDF_MAX( l, k - i*s/n + sd );
      rr = NDF_MIN( r, k + ( n - i )*s/n + sd );

/* The basic algorithm now invokes itself recursively to get an
   estimate of the target value from the smaller sub-sample it has
   identified, before partitioning the entire sample it was given about
   this value. Values which must be retained between recursive
   invocations are pushed on to the stack. */
      stk++;
      lstk[ stk - 1 ] = l;
      rstk[ stk - 1 ] = r;

/* Branch back to the start of the algorithm with the appropriate
   sub-sample defined. */
      l = ll;
      r = rr;
      goto L1;

/* Return from a recursive invocation to this point. */
L3:;
   }

/* Partition the data.
   ==================
   The code above implements the recursive invocation of the algorithm.
   The following performs the actual sorting, based on an appropriate
   iterative partitioning scheme. Two schemes are used; one for
   unweighted data (and for recursive invocations, where the weights
   are not relevant), and a second for the top-level invocation in the
   case where weights are present (and the cumulative weight versus
   rank function must be inverted at the same time). */

/* Implement an "unweighted" sort.
   ==============================
   This is used for recursive invocations or when there are no weights
   present; we are simply involved in sorting pointers to data values
   without associated weights.  Our aim is to get "ip"("k") to point at the
   K"th ranked data value, and (in the case of a top-level invocation)
   to get "ip"("k"+1) to point at the ("k"+1)"th ranked value. */
   if( ( !usewt ) || ( stk > 0 ) ) {

/* We assume we have an estimate of the target value (i.e. that "ip"("k")
   has been assigned a value so that it points to an approximation to
   the K"th ranked data value).  The "ip" array is then partitioned so
   that all values smaller than "x"("ip"("k")) are pointed at by elements of
   "ip" lying to one side of "ip"("k") and all larger values are pointed at
   by elements on the other side.  We hope that the original value
   "x"("ip"("k")) will end up still being pointed at by "ip"("k") (in which case
   the sort is complete), or by an element of "ip" pretty close to it
   (preferably lying in the smaller part of the partitioned region).
   The algorithm which follows is the basic QUICKSORT partitioning
   sequence.  Initialise the target value and the range of elements to
   partition. */
      t = x[ ip[ k - 1 ] - 1 ];
      i = l;
      j = r;

/* Initialise for partitioning, including a pointer to a `sentinel"
   value at the end of the array.  This allows the main part of the
   partitioning algorithm to execute rapidly without having to check
   against the array bounds. */
      itmp = ip[ l - 1 ];
      ip[ l - 1 ] = ip[ k - 1 ];
      ip[ k - 1 ] = itmp;

      if( x[ ip[ r - 1 ] - 1 ] > t ) {
         itmp = ip[ r - 1 ];
         ip[ r - 1 ] = ip[ l - 1 ];
         ip[ l - 1 ] = itmp;
      }

/* Move inwards from either end of the array region being partitioned
   ("i" and "j" mark the array elements being considered at each end) until
   there are no more elements to process. */
      while( i < j ){

/* Interchange pairs of elements which are out of order. */
         itmp = ip[ i - 1 ];
         ip[ i - 1 ] = ip[ j - 1 ];
         ip[ j - 1 ] = itmp;
         i++;
         j--;

/* Move the end pointers in towards the centre until an exchange of
   values is indicated. */
         while( x[ ip[ i - 1 ] - 1 ] < t ){
            i++;
         }

         while( x[ ip[ j - 1 ] - 1 ] > t ){
            j--;
         }

      }

/* Tidy up, ensuring that "ip"("j") points at the value we have just
   partitioned about. */
      if( x[ ip[ l - 1 ] - 1 ] == t ) {
         itmp = ip[ l - 1 ];
         ip[ l - 1 ] = ip[ j - 1 ];
         ip[ j - 1 ] = itmp;
      } else {
         j++;
         itmp = ip[ j - 1 ];
         ip[ j - 1 ] = ip[ r - 1 ];
         ip[ r - 1 ] = itmp;
      }

/* If this is a recursive invocation, then we are simply trying to
   correctly set the value of "ip"("k").  Update the left and right search
   range so that this element lies between the closest elements of "ip"
   so far correctly determined (of which the latest is "ip"("j")).  Allow
   the range to collapse to a single point if "j" equals "k", in which case
   the value of "ip"("k") has been found. */
      if( stk > 0 ) {
         if( j <= k ) l = j + 1;
         if( k <= j ) r = j - 1;

/* Continue iterating until only a single element (the K"th one)
   remains to be found.  Since its neighbours will have been found by
   this point, it must now have the correct value. */
         if( r > l ) goto L2;

/* If this is a top-level invocation (not recursive), then we are
   trying to correctly set two elements in the "ip" array ("ip"("kzero") and
   "ip"("kzero"+1)) so that they point at the correspondingly ranked data
   values. Adjust the search range to exclude the element "ip"("j"), which
   has just been evaluated.  Do this such that elements which point to
   data values ranked "kzero" and smaller get excluded to the left and
   those pointing to values ranked ("kzero"+1) and larger get excluded to
   the right.  (Note that we test against "kzero", because "k" may depart
   from the required rank on the final iteration in order to stay
   within the search range.) */
      } else {
         if( j <= kzero ) {
            l = j + 1;
         } else {
            r = j - 1;
         }

/* Iterations continue until no elements of "ip" remain in the search
   range.  The required elements ("ip"("kzero") and "ip"("kzero"+1)) then
   correspond with elements "ip"("l"-1) and "ip"("r"+1). */
         if( r >= l ) goto L2;

/* When a solution has been found, obtain the indices of the data
   elements lying immediately below and above the quantile and
   calculate the fractional position of the target weight between these
   elements. */
         i1 = NDF_MAX( 1, l - 1 );
         i2 = NDF_MIN( r + 1, el );
         alpha = el*NDF_MIN( NDF_MAX( 0.0, fract ), 1.0 ) - i1 + 0.5;
         alpha = NDF_MIN( NDF_MAX( 0.0, alpha ), 1.0 );

/* To obtain the result, either interpolate between the adjacent
   values... */
         if( interp ) {
            *q = ( 1.0 - alpha )*x[ ip[ i1 - 1 ] - 1 ] + alpha*x[ ip[
                 i2 - 1 ] - 1 ];

/* ...or pick the nearer one, as required. */
         } else {
            if( alpha < 0.5 ) {
               *q = x[ ip[ i1 - 1 ] - 1 ];
            } else if( alpha == 0.5 ) {
               *q = 0.5*( x[ ip[ i1 - 1 ] - 1 ] + x[ ip[ i2 - 1 ] - 1 ] );
            } else {
               *q = x[ ip[ i2 - 1 ] - 1 ];
            }
         }
      }

/* Implement a top-level sort with weights.
   ========================================
   If this is a top-level invocation of the algorithm (not recursive)
   and weights have been supplied, then we must iteratively evaluate
   two elements of the "ip" array ("ip"("k") and "ip"("k"+1)), so that (a) they
   point at the K"th and ("k"-1)"th ranked elements of "x", and (b) these
   values lie immediately below and above the required quantile.  The
   value of "k" is initially only a guess at its true final value, so
   this must also be refined during the iterations. */
   } else {

/* We start by partitioning the "ip" array on the value "x"("ip"("k")). As a
   result of previous recursive invocations (if performed), this is the
   current best estimate of the value of the K"th ranked data element
   (using the current approximate value of "k").  The algorithm which
   follows is the basic QUICKSORT partitioning sequence. Initialise the
   target value, the range of elements to partition and sums for the
   weights of elements which lie to the left and right of the
   partition. */
      t = x[ ip[ k - 1 ] - 1 ];
      i = l;
      j = r;
      wl = 0.0;
      wr = 0.0;

/* Initialise for partitioning, including a pointer to a `sentinel"
   value at the end of the array. This allows the main part of the
   partitioning algorithm to execute rapidly without having to check
   aganst the array bounds. */
      itmp = ip[ l - 1 ];
      ip[ l - 1 ] = ip[ k - 1 ];
      ip[ k - 1 ] = itmp;

      if( x[ ip[ r - 1 ] - 1 ] > t ) {
         itmp = ip[ r - 1 ];
         ip[ r - 1 ] = ip[ l - 1 ];
         ip[ l - 1 ] = itmp;
      }

/* Move inwards from either end of the array region being partitioned
   ("i" and "j" mark the array elements being considered at each end) until
   there are no more elements to process. */
      while( i < j ){

/* Interchange pairs of elements which are out of order and sum their
   weights. */
         itmp = ip[ i - 1 ];
         ip[ i - 1 ] = ip[ j - 1 ];
         ip[ j - 1 ] = itmp;
         wl += w[ ip[ i - 1 ] - 1 ];
         wr += w[ ip[ j - 1 ] - 1 ];
         i++;
         j--;

/* Move the end pointers in towards the centre until an exchange of
   values is indicated, again summing the weights of elements on each
   side of the partition as they are encountered. */
         while( x[ ip[ i - 1 ] - 1 ] < t ){
            wl += w[ ip[ i - 1 ] - 1 ];
            i++;
         }

         while( x[ ip[ j - 1 ] - 1 ] > t ){
            wr += w[ ip[ j - 1 ] - 1 ];
            j--;
         }

      }

/* Tidy up, ensuring that "ip"("j") points to the value we have just
   partitioned about and that all weights have been correctly allocated
   to left or right (the weight "w"("ip"("j")) itself is allocated to the
   left). */
      if( i == j ) wl += w[ ip[ i - 1 ] - 1 ];
      if( x[ ip[ l - 1 ] - 1 ] == t ) {
         itmp = ip[ l - 1 ];
         ip[ l - 1 ] = ip[ j - 1 ];
         ip[ j - 1 ] = itmp;
      } else {
         j++;
         itmp = ip[ j - 1 ];
         ip[ j - 1 ] = ip[ r - 1 ];
         ip[ r - 1 ] = itmp;

         wl += w[ ip[ j - 1 ] - 1 ];
         wr += -w[ ip[ j - 1 ] - 1 ];
      }

/* At this point, "j" contains an approximation to "k" (itself only an
   approximation to its true final value, which is unknown) and
   "x"("ip"("j")) has the current partition value "t" (which is now known to be
   the J"th ranked data value so that "ip"("j") has its correct value).
   "wleft" contains the sum of weights for elements "x"("ip"(1:"l"-1)), "wl"
   contains the sum for elements "x"("ip"("l":"j")), "wr" contains the sum for
   elements "x"("ip"("j"+1:"r")) and "wright" contains the sum for elements
   "x"("ip"("r"+1:"el")).  Using these results, we must now form a new estimate
   of "k" and update the search range for the next iteration. */

/* Calculate the cumulative `target weight" which the sum of weights
   for all elements smaller than the final result should have. */
      wtarg = NDF_MIN( NDF_MAX( 0.0, fract ), 1.0 )*( wleft + wl + wr + wright );

/* Test whether the sum of elements lying to the `left" of "ip"("j"), and
   therefore smaller than "x"("ip"("j")), plus the weight of element "ip"("j")
   itself, lies above or below this target. In doing this, use only
   half the weight of element "ip"("j").  This reflects the fact that each
   element is `centred"" in its weight bin. */
      if( ( wleft + wl - 0.5*w[ ip[ j - 1 ] - 1 ] ) < wtarg ) {

/* If it lies below, then elements "x"("ip"(1:"j")) can now be regarded as
   sorted (not literally, but in the sense that we need not consider
   them again).  Absorb the `left sum" of weights for this iteration
   into the overall left sum of sorted weights and set the sum of
   weights for the remaining unsorted elements ("wmid") to the `right
   sum" obtained on this iteration.  Update the left boundary of the
   unsorted region to exclude the newly-sorted elements. */
         wleft += wl;
         wmid = wr;
         l = j + 1;

/* Otherwise, perform a similar operation to exclude elements to the
   right, which can now be regarded as sorted.  Ensure that the weight
   of element "ip"("j") itself is transferred to the right and removed from
   "wmid" during this process. */
      } else {
         wright += wr + w[ ip[ j - 1 ] - 1 ];
         wmid = wl - w[ ip[ j - 1 ] - 1 ];
         r = j - 1;
      }

/* We now use linear interpolation to estimate (or guess) a better
   value of "k" for the next iteration.  (Note that before the next
   iteration actually occurs, the new "ip"("k") will be updated via
   recursive calls to the SELECT algorithm so that it points at an
   improved estimate of the K"th ranked data value.)  First calculate
   the `extra cumulative weight" needed over and above the sum of
   weights for all elements so far sorted to the left. */
      extra = wtarg - wleft;

/* Adjust the weight values to remove half the weight of the largest
   sorted left element and add half the weight of the smallest sorted
   right element. This accounts for the elements being centred in their
   weight bins. */
      if( l > 1 ) {
         extra += 0.5*w[ ip[ l - 2 ] - 1 ];
         wmid += 0.5*w[ ip[ l - 2 ] - 1 ];
      }
      if( r < el ) wmid += 0.5*w[ ip[ r ] - 1 ];

/* Make a new estimate of "k" by linear interpolation. Since the search
   range has been reduced, this will be a more accurate estimate than
   on the previous iteration.  Allow an extra half element at each end
   for accurate interpolation (weight bin centring again). Note that
   the new value of "k" will be restricted to lie within the new search
   range at the start of the next iteration.  Use the central unsorted
   element if there are no weights left in this region. */
      if( wmid != 0.0 ) {
         k = round( ( r - l + 2 )*( extra/wmid ) ) + l - 1;
      } else {
         k = ( l + r )/2;
      }

/* Iterations continue until there are no more elements of "ip" left to
   sort.  Since we repeatedly exclude elements pointing to values below
   the quantile to the left, and exclude those pointing to values above
   the quantile to the right, we eventually end up with the two
   elements lying adjacent to the desired quantile being pointed at by
   "ip"("l"-1) and "ip"("r"+1). */
      if( r >= l ) goto L2;

/* When a solution has been found, obtain the indices of the data
   elements lying immediately below and above the quantile and
   calculate the fractional position of the target weight between the
   cumulative sum of weights for each element. */
      i1 = NDF_MAX( 1, l - 1 );
      i2 = NDF_MIN( r + 1, el );
      alpha = ( wtarg - wleft + 0.5*w[ ip[ i1 - 1 ] - 1 ] )/( 0.5*( w[ ip[ i1 - 1 ] - 1 ] + w[ ip[
                                                                      i2 - 1 ] - 1 ] ) );
      alpha = NDF_MIN( NDF_MAX( 0.0, alpha ), 1.0 );

/* To obtain the result, either interpolate between the adjacent
   values... */
      if( interp ) {
         *q = ( 1.0 - alpha )*x[ ip[ i1 - 1 ] - 1 ] + alpha*x[ ip[ i2
              - 1 ] - 1 ];

/* ...or pick the nearer one, as required. */
      } else {
         if( alpha < 0.5 ) {
            *q = x[ ip[ i1 - 1 ] - 1 ];
         } else if( alpha == 0.5 ) {
            *q = 0.5*( x[ ip[ i1 - 1 ] - 1 ] + x[ ip[ i2 - 1 ] - 1 ] );
         } else {
            *q = x[ ip[ i2 - 1 ] - 1 ];
         }
      }
   }

/*  Pop the stack and return from a recursive invocation of the
    algorithm. This stage is omitted if the stack is empty, in which
    case the return is from the top-level invocation so the sort is
    complete. */
   if( stk > 0 ) {
      l = lstk[ stk - 1 ];
      r = rstk[ stk - 1 ];
      stk--;
      goto L3;
   }

}

