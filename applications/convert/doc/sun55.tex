\documentstyle[11pt,epsf,twoside]{article}
\pagestyle{myheadings}

% -----------------------------------------------------------------------------
% ? Document identification
\newcommand{\stardoccategory}  {Starlink User Note}
\newcommand{\stardocinitials}  {SUN}
\newcommand{\stardocsource}    {sun55.8}
\newcommand{\stardocnumber}    {55.8}
\newcommand{\stardocauthors}   {Malcolm J. Currie\\
                                G.J.Privett\\
                                A.J.Chipperfield}
\newcommand{\stardocdate}      {1997 December 3}
\newcommand{\stardoctitle}     {CONVERT\\
                                A Format-conversion Package}
\newcommand{\stardocversion}   {Version 1.1}
\newcommand{\stardocmanual}    {User's Manual}
% ? End of document identification
% -----------------------------------------------------------------------------

\newcommand{\stardocname}{\stardocinitials /\stardocnumber}
\markright{\stardocname}
\setlength{\textwidth}{160mm}
\setlength{\textheight}{230mm}
\setlength{\topmargin}{-2mm}
\setlength{\oddsidemargin}{0mm}
\setlength{\evensidemargin}{0mm}
\setlength{\parindent}{0mm}
\setlength{\parskip}{\medskipamount}
\setlength{\unitlength}{1mm}

% -----------------------------------------------------------------------------
%  Hypertext definitions.
%  ======================
%  These are used by the LaTeX2HTML translator in conjunction with star2html.

%  Comment.sty: version 2.0, 19 June 1992
%  Selectively in/exclude pieces of text.
%
%  Author
%    Victor Eijkhout                                      <eijkhout@cs.utk.edu>
%    Department of Computer Science
%    University Tennessee at Knoxville
%    104 Ayres Hall
%    Knoxville, TN 37996
%    USA

%  Do not remove the %\begin{rawtex} and %\end{rawtex} lines (used by 
%  star2html to signify raw TeX that latex2html cannot process).
%\begin{rawtex}
\makeatletter
\def\makeinnocent#1{\catcode`#1=12 }
\def\csarg#1#2{\expandafter#1\csname#2\endcsname}

\def\ThrowAwayComment#1{\begingroup
    \def\CurrentComment{#1}%
    \let\do\makeinnocent \dospecials
    \makeinnocent\^^L% and whatever other special cases
    \endlinechar`\^^M \catcode`\^^M=12 \xComment}
{\catcode`\^^M=12 \endlinechar=-1 %
 \gdef\xComment#1^^M{\def\test{#1}
      \csarg\ifx{PlainEnd\CurrentComment Test}\test
          \let\html@next\endgroup
      \else \csarg\ifx{LaLaEnd\CurrentComment Test}\test
            \edef\html@next{\endgroup\noexpand\end{\CurrentComment}}
      \else \let\html@next\xComment
      \fi \fi \html@next}
}
\makeatother

\def\includecomment
 #1{\expandafter\def\csname#1\endcsname{}%
    \expandafter\def\csname end#1\endcsname{}}
\def\excludecomment
 #1{\expandafter\def\csname#1\endcsname{\ThrowAwayComment{#1}}%
    {\escapechar=-1\relax
     \csarg\xdef{PlainEnd#1Test}{\string\\end#1}%
     \csarg\xdef{LaLaEnd#1Test}{\string\\end\string\{#1\string\}}%
    }}

%  Define environments that ignore their contents.
\excludecomment{comment}
\excludecomment{rawhtml}
\excludecomment{htmlonly}
%\end{rawtex}

%  Hypertext commands etc. This is a condensed version of the html.sty
%  file supplied with LaTeX2HTML by: Nikos Drakos <nikos@cbl.leeds.ac.uk> &
%  Jelle van Zeijl <jvzeijl@isou17.estec.esa.nl>. The LaTeX2HTML documentation
%  should be consulted about all commands (and the environments defined above)
%  except \xref and \xlabel which are Starlink specific.

\newcommand{\htmladdnormallinkfoot}[2]{#1\footnote{#2}}
\newcommand{\htmladdnormallink}[2]{#1}
\newcommand{\htmladdimg}[1]{}
\newenvironment{latexonly}{}{}
\newcommand{\hyperref}[4]{#2\ref{#4}#3}
\newcommand{\htmlref}[2]{#1}
\newcommand{\htmlimage}[1]{}
\newcommand{\htmladdtonavigation}[1]{}
%  Starlink cross-references and labels.
\newcommand{\xref}[3]{#1}
\newcommand{\xlabel}[1]{}

%  LaTeX2HTML symbol.
\newcommand{\latextohtml}{{\bf LaTeX}{2}{\tt{HTML}}}

%  Define command to re-centre underscore for Latex and leave as normal
%  for HTML (severe problems with \_ in tabbing environments and \_\_
%  generally otherwise).
\newcommand{\latex}[1]{#1}
\newcommand{\setunderscore}{\renewcommand{\_}{{\tt\symbol{95}}}}
\latex{\setunderscore}

%  Redefine the \tableofcontents command. This procrastination is necessary 
%  to stop the automatic creation of a second table of contents page
%  by latex2html.
\newcommand{\latexonlytoc}[0]{\tableofcontents}

% -----------------------------------------------------------------------------
%  Debugging.
%  =========
%  Remove % on the following to debug links in the HTML version using Latex.

% \newcommand{\hotlink}[2]{\fbox{\begin{tabular}[t]{@{}c@{}}#1\\\hline{\footnotesize #2}\end{tabular}}}
% \renewcommand{\htmladdnormallinkfoot}[2]{\hotlink{#1}{#2}}
% \renewcommand{\htmladdnormallink}[2]{\hotlink{#1}{#2}}
% \renewcommand{\hyperref}[4]{\hotlink{#1}{\S\ref{#4}}}
% \renewcommand{\htmlref}[2]{\hotlink{#1}{\S\ref{#2}}}
% \renewcommand{\xref}[3]{\hotlink{#1}{#2 -- #3}}
% -----------------------------------------------------------------------------
% ? Document-specific \newcommand or \newenvironment commands.

\newcommand{\dqt}[1]{{\tt{"#1"}}}
\newcommand{\hash}{\dqt{\#}}

% centre an asterisk
\newcommand{\lsk}{\raisebox{-0.4ex}{\rm *}}

\begin{htmlonly}
  \renewcommand{\hash}{\dqt{#}}
\end{htmlonly}

% conditional text
\newcommand{\latexelsehtml}[2]{#1}
\begin{htmlonly}
  \renewcommand{\latexelsehtml}[2]{#2}
\end{htmlonly}

% A kind of list item, like description, but with an easily adjustable
% item separation.  Note that the paragraph and fount-size change are
% needed to make the revised \baselinestretch work.
\newlength{\menuwidth}
\newlength{\menuindent}
\newcommand{\menuitem}[2]
  {{\bf #1} \settowidth{\menuwidth}{{\bf #1} }
  \setlength{\menuindent}{-0.5em}
  \addtolength{\menuwidth}{-2\menuwidth}
  \addtolength{\menuwidth}{\textwidth}
  \addtolength{\menuwidth}{\menuindent}
  \hspace{\menuindent}\parbox[t]{\menuwidth}{
  \renewcommand{\baselinestretch}{0.75}\small
  #2 \par \vspace{0.6ex}
  \renewcommand{\baselinestretch}{1.0}\normalsize} \\ }
\begin{htmlonly}
\newcommand{\menuitem}[2]
  {\item [\htmlref{#1}{#1}] #2}
\end{htmlonly}

\newcommand{\classitem}[1]{\item [\htmlref{#1}{#1}]}

% an environment for references (for the SST sstdiytopic command).
\newenvironment{refs}{\vspace{-4ex} % normally 3ex
                      \begin{list}{}{\setlength{\topsep}{0mm}
                                     \setlength{\partopsep}{0mm}
                                     \setlength{\itemsep}{0mm}
                                     \setlength{\parsep}{0mm}
                                     \setlength{\leftmargin}{1.5em}
                                     \setlength{\itemindent}{-\leftmargin}
                                     \setlength{\labelsep}{0mm}
                                     \setlength{\labelwidth}{0mm}}
                    }{\end{list}}

% Shorthands for hypertext links.
% -------------------------------
\newcommand{\CONVERT}{{\footnotesize CONVERT}}
\newcommand{\BCONVERT}{{\footnotesize \bf CONVERT}}
\newcommand{\Figaroref}{\xref{{\footnotesize FIGARO}}{sun86}{}}
\newcommand{\FITSref}{\htmladdnormallink{FITS}{http://www.gsfc.nasa.gov/astro/fits/fits\_{}home.html}}
\newcommand{\HDSref}{\xref{HDS}{sun92}{}}
\newcommand{\ICLref}{\xref{{\footnotesize ICL}}{sg5}{}}
\newcommand{\IRAF}{{\footnotesize IRAF}}
\newcommand{\IRAFref}{\htmladdnormallink{{\footnotesize IRAF}}{http://iraf.noao.edu/iraf-homepage.html}}
\newcommand{\KAPPA}{{\footnotesize KAPPA}}
\newcommand{\IRAFURL}{http://iraf.noao.edu/iraf-homepage.html}
\newcommand{\IDLURL}
           {http://sslab.colorado.edu:2222/projects/IDL/idl\_ssl\_home.html}
\newcommand{\IDLAULURL}{http://idlastro.gsfc.nasa.gov/homepage.html}
\newcommand{\NDFref}[1]{\htmlref{#1}{ap:NDFformat}}
\newcommand{\SPECDRE}{\xref{{\footnotesize SPECDRE}}{sun140}{}}

% SST definitions
% ---------------

% +
%  Name:
%     SST.TEX

%  Purpose:
%     Define LaTeX commands for laying out Starlink routine descriptions.

%  Language:
%     LaTeX

%  Type of Module:
%     LaTeX data file.

%  Description:
%     This file defines LaTeX commands which allow routine documentation
%     produced by the SST application PROLAT to be processed by LaTeX and
%     by LaTeX2html. The contents of this file should be included in the
%     source prior to any statements that make of the sst commands.

%  Notes:
%     The commands defined in the style file html.sty provided with LaTeX2html 
%     are used. These should either be made available by using the appropriate
%     sun.tex (with hypertext extensions) or by putting the file html.sty 
%     on your TEXINPUTS path (and including the name as part of the  
%     documentstyle declaration).

%  Authors:
%     RFWS: R.F. Warren-Smith (STARLINK)
%     PDRAPER: P.W. Draper (Starlink - Durham University)
%     MJC: Malcolm J. Currie (STARLINK)

%  History:
%     10-SEP-1990 (RFWS):
%        Original version.
%     10-SEP-1990 (RFWS):
%        Added the implementation status section.
%     12-SEP-1990 (RFWS):
%        Added support for the usage section and adjusted various spacings.
%     8-DEC-1994 (PDRAPER):
%        Added support for simplified formatting using LaTeX2html.
%     1995 October 4 (MJC):
%        Added goodbreaks and pagebreak[3] in various places to improve
%        pages breaking before headings, not immediately after.
%        Corrected banner width.
%     {enter_further_changes_here}

%  Bugs:
%     {note_any_bugs_here}

% -

%  Define length variables.
\newlength{\sstbannerlength}
\newlength{\sstcaptionlength}
\newlength{\sstexampleslength}
\newlength{\sstexampleswidth}

%  Define a \tt font of the required size.
\newfont{\ssttt}{cmtt10 scaled 1095}

%  Define a command to produce a routine header, including its name,
%  a purpose description and the rest of the routine's documentation.
\newcommand{\sstroutine}[3]{
   \goodbreak
   \markboth{{\stardocname}~ --- #1}{{\stardocname}~ --- #1}
   \rule{\textwidth}{0.5mm}
   \vspace{-7ex}
   \newline
   \settowidth{\sstbannerlength}{{\Large {\bf #1}}}
   \setlength{\sstcaptionlength}{\textwidth}
   \setlength{\sstexampleslength}{\textwidth}
   \addtolength{\sstbannerlength}{0.5em}
   \addtolength{\sstcaptionlength}{-2.0\sstbannerlength}
   \addtolength{\sstcaptionlength}{-4.9pt}
   \settowidth{\sstexampleswidth}{{\bf Examples:}}
   \addtolength{\sstexampleslength}{-\sstexampleswidth}
   \parbox[t]{\sstbannerlength}{\flushleft{\Large {\bf #1}}}
   \parbox[t]{\sstcaptionlength}{\center{\Large #2}}
   \parbox[t]{\sstbannerlength}{\flushright{\Large {\bf #1}}}
   \begin{description}
      #3
   \end{description}
}

%  Format the description section.
\newcommand{\sstdescription}[1]{\item[Description:] #1}

%  Format the usage section.
\newcommand{\sstusage}[1]{\pagebreak[3] \item[Usage:] \mbox{} \\[1.3ex] {\ssttt #1}}

%  Format the invocation section.
\newcommand{\sstinvocation}[1]{\sloppy \item[Invocation:]\hspace{0.4em}{\tt #1}}

%  Format the arguments section.
\newcommand{\sstarguments}[1]{
   \item[Arguments:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Format the returned value section (for a function).
\newcommand{\sstreturnedvalue}[1]{
   \item[Returned Value:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Format the parameters section (for an application).
\newcommand{\sstparameters}[1]{
   \goodbreak 
   \item[Parameters:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Format the output results parameters section (for an application).
\newcommand{\sstresparameters}[1]{
   \goodbreak 
   \item[Results Parameters:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Format the graphics style parameters section (for an application).
\newcommand{\sstgraphparameters}[1]{
   \goodbreak 
   \item[Graphics-style Parameters:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Format the examples section.
\newcommand{\sstexamples}[1]{
   \goodbreak
   \item[Examples:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Define the format of a subsection in a normal section.
\newcommand{\sstsubsection}[1]{ \item[{#1}] \mbox{} \\}

%  Define the format of a subsection in the examples section.
%\newcommand{\sstexamplesubsection}[2]{\sloppy
%\item[\parbox{\sstexampleslength}{\ssttt #1}] \mbox{} \\ #2 }
\newcommand{\sstexamplesubsection}[2]{\sloppy \item{\ssttt #1} \mbox{} \\ #2 }

%  Define the format of a long-example subsection in the examples section.
%\newcommand{\sstlongexamplesubsection}[3]{\sloppy
%\item[\ssttt \hspace{-0.5em}#1] {\ssttt #2} \mbox{} \\ #3}
\newcommand{\sstlongexamplesubsection}[3]{\sloppy \item{\ssttt #1} {\ssttt #2} \mbox{} \\ #3}

%  Format the notes section.
\newcommand{\sstnotes}[1]{\pagebreak[3] \item[Notes:] \mbox{} \\[1.3ex] #1}

%  Provide a general-purpose format for additional (DIY) sections.
\newcommand{\sstdiytopic}[2]{\goodbreak \item[{\hspace{-0.35em}#1\hspace{-0.35em}:}] \mbox{} \\[1.3ex] #2}

%  Format the implementation status section.
\newcommand{\sstimplementationstatus}[1]{
   \pagebreak[3] \item[{Implementation Status:}] \mbox{} \\[1.3ex] #1}

%  Format the bugs section.
\newcommand{\sstbugs}[1]{\item[Bugs:] #1}

%  Specify a variant of the itemize environment where the top separation
%  is reduced.  It is needed because a \vspace is ignored in the
%  \sstitemlist command.
\newenvironment{sstitemize}{%
  \vspace{-4.3ex}\begin{itemize}}{\end{itemize}}

%  Format a list of items while in paragraph mode.
\newcommand{\sstitemlist}[1]{
  \mbox{} \\
  \vspace{-3.5ex}
  \begin{sstitemize}
     #1
  \end{sstitemize}
}

%  Format a list of items while in paragraph mode, and where there
%  is a heading, thus the negative vertical space is not needed.
\newcommand{\ssthitemlist}[1]{
  \mbox{} \\
  \vspace{-3.5ex}
  \begin{itemize}
     #1
  \end{itemize}
}

%  Define the format of an item.
\newcommand{\sstitem}{\item}

%  Now define html equivalents of those already set. These are used by
%  latex2html and are defined in the html.sty files.
\begin{htmlonly}

%  Re-define \ssttt.
   \newcommand{\ssttt}{\tt}

%  sstroutine.
   \renewcommand{\sstroutine}[3]{
      \subsection{#1\xlabel{#1}-\label{#1}#2}
      \begin{description}
         #3
      \end{description}
   }

%  sstdescription
   \renewcommand{\sstdescription}[1]{\item[Description:]
      \begin{description}
         #1
      \end{description}
   }

%  sstusage
   \renewcommand{\sstusage}[1]{\htmlref{\item[Usage:]}{app_usage} \mbox{} \\ {\ssttt #1}}

%  sstinvocation
   \renewcommand{\sstinvocation}[1]{\item[Invocation:]
      \begin{description}
         {\ssttt #1}
      \end{description}
   }

%  sstarguments
   \renewcommand{\sstarguments}[1]{
      \item[Arguments:]
      \begin{description}
         #1
      \end{description}
   }

%  sstreturnedvalue
   \renewcommand{\sstreturnedvalue}[1]{
      \item[Returned Value:]
      \begin{description}
         #1
      \end{description}
   }

%  sstparameters
   \renewcommand{\sstparameters}[1]{
      \xref{\item[Parameters:]}{sun95}{se_param}
      \begin{description}
         #1
      \end{description}
   }

%  sstexamples
   \renewcommand{\sstexamples}[1]{
      \htmlref{\item[Examples:]}{app_example}
      \begin{description}
         #1
      \end{description}
   }

%  sstsubsection
   \renewcommand{\sstsubsection}[1]{\item[{#1}]}

%  sstexamplesubsection
   \renewcommand{\sstexamplesubsection}[2]{\item[{\ssttt #1}] \\ #2}

%  sstnotes
   \renewcommand{\sstnotes}[1]{\item[Notes:]
      \begin{description}
         #1
      \end{description}
   }

%  sstdiytopic
   \renewcommand{\sstdiytopic}[2]{\item[{#1}]
      \begin{description}
         #2
      \end{description}
   }

%  sstimplementationstatus
   \renewcommand{\sstimplementationstatus}[1]{\item[Implementation Status:] 
      \begin{description}
         #1
      \end{description}
   }

%  sstitemlist
   \newcommand{\sstitemlist}[1]{
      \begin{itemize}
         #1
      \end{itemize}
   }
\end{htmlonly}

%  End of sst.tex layout definitions.
%.

% End of SST definitions
% ----------------------
% ? End of document specific commands
% -----------------------------------------------------------------------------
%  Title Page.
%  ===========
\renewcommand{\thepage}{\roman{page}}
\begin{document}
\thispagestyle{empty}

%  Latex document header.
%  ======================
\begin{latexonly}
   CCLRC / {\sc Rutherford Appleton Laboratory} \hfill {\bf \stardocname}\\
   {\large Particle Physics \& Astronomy Research Council}\\
   {\large Starlink Project\\}
   {\large \stardoccategory\ \stardocnumber}
   \begin{flushright}
   \stardocauthors\\
   \stardocdate
   \end{flushright}
   \vspace{-4mm}
   \rule{\textwidth}{0.5mm}
   \vspace{5mm}
   \begin{center}
   {\Huge\bf  \stardoctitle \\ [2.5ex]}
   {\LARGE\bf \stardocversion \\ [4ex]}
   {\Huge\bf  \stardocmanual}
   \end{center}
   \vspace{5mm}

% ? Heading for abstract if used.
   \vspace{10mm}
   \begin{center}
      {\Large\bf Abstract}
   \end{center}
% ? End of heading for abstract.
\end{latexonly}

%  HTML documentation header.
%  ==========================
\begin{htmlonly}
   \xlabel{}
   \begin{rawhtml} <H1> \end{rawhtml}
      \stardoctitle\\
      \stardocversion\\
      \stardocmanual
   \begin{rawhtml} </H1> \end{rawhtml}

% ? Add picture here if required.
% ? End of picture

   \begin{rawhtml} <P> <I> \end{rawhtml}
   \stardoccategory \stardocnumber \\
   \stardocauthors \\
   \stardocdate
   \begin{rawhtml} </I> </P> <H3> \end{rawhtml}
      \htmladdnormallink{CCLRC}{http://www.cclrc.ac.uk} /
      \htmladdnormallink{Rutherford Appleton Laboratory}
                        {http://www.cclrc.ac.uk/ral} \\
      \htmladdnormallink{Particle Physics \& Astronomy Research Council}
                        {http://www.pparc.ac.uk} \\
   \begin{rawhtml} </H3> <H2> \end{rawhtml}
      \htmladdnormallink{Starlink Project}{http://star-www.rl.ac.uk/}
   \begin{rawhtml} </H2> \end{rawhtml}
   \htmladdnormallink{\htmladdimg{source.gif} Retrieve hardcopy}
      {http://star-www.rl.ac.uk/cgi-bin/hcserver?\stardocsource}\\

%  HTML document table of contents. 
%  ================================
%  Add table of contents header and a navigation button to return to this 
%  point in the document (this should always go before the abstract \section). 
  \label{stardoccontents}
  \begin{rawhtml} 
    <HR>
    <H2>Contents</H2>
  \end{rawhtml}
  \renewcommand{\latexonlytoc}[0]{}
  \htmladdtonavigation{\htmlref{\htmladdimg{contents_motif.gif}}
        {stardoccontents}}

% ? New section for abstract if used.
  \section{\xlabel{abstract}Abstract}
% ? End of new section for abstract
\end{htmlonly}

% -----------------------------------------------------------------------------
% ? Document Abstract. (if used)
%   ==================
The \CONVERT\ package contains utilities for converting data files
between Starlink's Extensible {\em n}-dimensional Data Format
\xref{(NDF)}{sun33}{},
which is used by most Starlink applications, and a number of other common
data formats.
Using these utilities, astronomers can process their data selecting the best 
applications from a variety of Starlink or other packages.

The \CONVERT\ utilities may be run from the shell or \ICLref\ in the
normal way, or invoked automatically by the NDF library's `on-the-fly' 
data-conversion system.
% ? End of document abstract
% -----------------------------------------------------------------------------
% ? Latex document Table of Contents (if used).
%  ===========================================
 \newpage
 \begin{latexonly}
   \setlength{\parskip}{0mm}
   \latexonlytoc
   \setlength{\parskip}{\medskipamount}
   \markright{\stardocname}
 \end{latexonly}
% ? End of Latex document table of contents
% -----------------------------------------------------------------------------
\newpage
\renewcommand{\thepage}{\arabic{page}}
\setcounter{page}{1}

\section{Introduction}

If life were simple there would only be one data format, but in reality
there are numerous formats for storing {\em{n}}-dimensional astronomical data
associated with various software packages.   In Starlink we have not
been immune to this, having the original INTERIM BDF, HDS IMAGE format,
and \Figaroref\ DSTs to name but three.  However, Starlink is now taking the
novel approach of supporting different packages sharing a common data
format---the
\xref{NDF}{sun33}{}\latexonly{\footnote{
See SUN/33 for an introduction to the NDF.}}
(Extensible {\em{n}}-Dimensional-data format)---which most Starlink packages
are already using.

The purpose of \CONVERT\ is the interchange of data files
to and from the NDF.  Thus it enables astronomers to select the best
applications from a variety of packages, including those originating
abroad like 
\htmladdnormallink{IRAF}{\IRAFURL}. 
In addition it assists packages that wish to move to
using the NDF.

\CONVERT\ is available from all three UNIX platforms supported by
Starlink.  The supported conversions are currently as follows: 

\begin{latexonly}
\begin{center}
\begin{tabular}{l@{ -- }l}
\medskip
{\bf ASCII2NDF} &  Converts a text file to an NDF. \\ \medskip
{\bf DA2NDF} &  Converts a direct-access unformatted file to an NDF. \\ \medskip
{\bf DST2NDF} &  Converts a Figaro (Version 2) DST file to an NDF. \\ \medskip
{\bf FITS2NDF} &  Converts FITS files into NDFs. \\ \medskip
{\bf GASP2NDF} &  Converts an image in GASP format to an NDF. \\ \medskip
{\bf GIF2NDF} &  Converts an image in GIF format to an NDF. \\ \medskip
{\bf IRAF2NDF} &  Converts an IRAF image to an NDF. \\ \medskip
{\bf IRCAM2NDF} &  Converts an IRCAM data file to a series of NDFs. \\ \medskip
{\bf NDF2ASCII} &  Converts an NDF to a text file. \\ \medskip
{\bf NDF2DA} & Converts an NDF to a direct-access unformatted file. \\ \medskip
{\bf NDF2DST} & Converts an NDF to a Figaro (Version 2) DST file. \\ \medskip
{\bf NDF2FITS} & Converts an NDF to a FITS file. \\ \medskip
{\bf NDF2GASP} & Converts a two-dimensional NDF into a GASP image. \\ \medskip
{\bf NDF2GIF} & Converts a two-dimensional NDF into a GIF file. \\ \medskip
{\bf NDF2IRAF} & Converts an NDF to an IRAF image. \\ \medskip
{\bf NDF2PGM} & Converts an NDF to PBMPLUS PGM format. \\ \medskip
{\bf NDF2TIFF} & Converts a two-dimensional NDF into a TIFF file. \\ \medskip
{\bf NDF2UNF} &  Converts an NDF to a sequential unformatted file. \\ \medskip
{\bf TIFF2NDF} &  Converts an image in TIFF format to an NDF. \\ \medskip
{\bf UNF2NDF} &  Converts a sequential unformatted file to an NDF. \\
\end{tabular}
\end{center}
\end{latexonly}
\begin{htmlonly}
{\bf \htmlref{ASCII2NDF}{ASCII2NDF}}
 -- Converts a text file to an NDF. \\ \medskip
{\bf \htmlref{DA2NDF}{DA2NDF}}
 -- Converts a direct-access unformatted file to an NDF. \\ \medskip
{\bf \htmlref{DST2NDF}{DST2NDF}}
 -- Converts a Figaro (Version 2) DST file to an NDF. \\ \medskip
{\bf \htmlref{FITS2NDF}{FITS2NDF}}
 -- Converts FITS files into NDFs. \\ \medskip
{\bf \htmlref{GASP2NDF}{GASP2NDF}}
 -- Converts an image in GASP format to an NDF. \\ \medskip
{\bf \htmlref{GIF2NDF}{GIF2NDF}}
 -- Converts an image in GIF format to an NDF. \\ \medskip
{\bf \htmlref{IRAF2NDF}{IRAF2NDF}}
 -- Converts an IRAF image to an NDF. \\ \medskip
{\bf \htmlref{IRCAM2NDF}{IRCAM2NDF}}
 -- Converts an IRCAM data file to a series of NDFs. \\ \medskip
{\bf \htmlref{NDF2ASCII}{NDF2ASCII}}
 -- Converts an NDF to a text file. \\ \medskip
{\bf \htmlref{NDF2DA}{NDF2DA}}
 -- Converts an NDF to a direct-access unformatted file. \\ \medskip
{\bf \htmlref{NDF2DST}{NDF2DST}}
 -- Converts an NDF to a Figaro (Version 2) DST file. \\ \medskip
{\bf \htmlref{NDF2FITS}{NDF2FITS}}
 -- Converts an NDF to a FITS file. \\ \medskip
{\bf \htmlref{NDF2GASP}{NDF2GASP}}
 -- Converts a two-dimensional NDF into a GASP image. \\ \medskip
{\bf \htmlref{NDF2GIF}{NDF2GIF}}
 -- Converts an NDF to a GIF file. \\ \medskip
{\bf \htmlref{NDF2IRAF}{NDF2IRAF}}
 -- Converts an NDF to an IRAF image. \\ \medskip
{\bf \htmlref{NDF2PGM}{NDF2PGM}}
 -- Converts an NDF to a PGM format. \\ \medskip
{\bf \htmlref{NDF2TIFF}{NDF2TIFF}}
 -- Converts an NDF to a TIFF file. \\ \medskip
{\bf \htmlref{NDF2UNF}{NDF2UNF}}
 -- Converts an NDF to a sequential unformatted file. \\ \medskip
{\bf \htmlref{TIFF2NDF}{TIFF2NDF}}
 -- Converts an image in TIFF format to an NDF. \\ \medskip
{\bf \htmlref{UNF2NDF}{UNF2NDF}}
 -- Converts a sequential unformatted file to an NDF. \\
\end{htmlonly}

In addition there are FITS readers within 
\xref{\KAPPA\ }{sun95} \latexonly{ (see SUN/95)}
which will convert FITS files and tapes to NDFs.
These are more tolerant of `almost FITS' files, but lack support for
IMAGE and BINTABLE extensions.

and notes on converting 
\htmlref{NDFs to IDL}{app_idl}
format in 
\latexonly{Appendix~\ref{app_idl} of} this document.

The following converters are available on VMS (on STADAT) but not on UNIX
(see 
\htmlref{`\CONVERT\ on VMS'}{app_vms}\latexonly{ (Appendix \ref{app_vms})}.
\begin{latexonly}
\begin{center}
\begin{tabular}{l@{ -- }l}
\medskip
{\bf BDF2NDF} &  Converts a Starlink Interim BDF file to an NDF. \\ \medskip
{\bf DIPSO2NDF} & Converts a DIPSO-format file to an NDF. \\ \medskip
{\bf NDF2BDF} &  Converts an NDF to a Starlink Interim BDF file. \\ \medskip
{\bf NDF2DIPSO} &  Converts an NDF to a DIPSO-format file. \\
\end{tabular}
\end{center}
\end{latexonly}
\begin{htmlonly}
{\bf BDF2NDF}
 --  Converts a Starlink Interim BDF file to an NDF. \\ \medskip
{\bf DIPSO2NDF}
 -- Converts a DIPSO-format file to an NDF. \\ \medskip
{\bf NDF2BDF}
 --  Converts an NDF to a Starlink Interim BDF file. \\ \medskip
{\bf NDF2DIPSO}
 --  Converts an NDF to a DIPSO-format file. \\
\end{htmlonly}

Starting up the \CONVERT\ package will also set up defaults for the
\htmlref{automatic NDF conversion facilities}{sect_auto}
\latexonly{ (described in Section \ref{sect_auto})} to enable applications 
which use the NDF library to read and write most of the file formats handled 
by the \CONVERT\ package, and some others.

The various formats supported by \CONVERT\ do not have
one-to-one correspondence and therefore in general it is not possible to
apply a forward and reverse conversion and finish with a duplicate of
the initial data file.  This hysteresis is particularly likely when
starting with an NDF, since many simpler formats have no way of storing
certain NDF data items, like variance and axis widths.  However, if you
are dealing with a simple file containing just a data array and linear
axis centres, then it should be possible to avoid loss of information except
with GIF and TIFF formats which will reduce the absolute data values to 256
greyscale levels.

{\sl Note -- the input data file is not deleted or altered in any way.}

\newpage 
\section{Running \BCONVERT}

\subsection{Starting \CONVERT\ from the UNIX shell}

The command {\tt convert} defines \CONVERT\ commands from
the UNIX shell.

\small
\begin{verbatim}
      % convert
\end{verbatim}
\normalsize 
Note that the {\tt \%} is the UNIX shell's prompt which you do not type.

A message similar to:
\small
\begin{verbatim}

   CONVERT commands are now available -- (Version 1.0, 1997 August)

   Defaults for automatic NDF conversion are set.

   Type conhelp for help on CONVERT commands.
   Type "showme sun55" to browse the hypertext documentation.

\end{verbatim}
\normalsize 
will be displayed. You will then be able to mix \CONVERT\ and UNIX commands.

The {\tt convert} command is defined by the Starlink startup procedures to
`source' file {\tt convert} in the \CONVERT\ executables directory. 
Non-Starlink sites must make their own arrangements.

\subsection{Starting \CONVERT\ from ICL}
To start ICL, type:
\small
\begin{verbatim}
     % icl
\end{verbatim}
\normalsize
You will see any messages produced by system and user procedures, followed
by the {\tt ICL>} prompt, something like the following.

\small
\begin{quote} \begin{verbatim}
ICL (UNIX) Version 3.1-5 20/05/97

Loading installed package definitions...

  - Type HELP package_name for help on specific Starlink packages
  -   or HELP PACKAGES for a list of all Starlink packages
  - Type HELP [command] for help on ICL and its commands

ICL>
\end{verbatim} \end{quote}
\normalsize
Then, to make the \CONVERT\ commands known to the command language, type:
\small
\begin{quote} \begin{verbatim}
ICL> CONVERT
\end{verbatim} \end{quote}
\normalsize
This will produce a \CONVERT\ startup message similar to:
\small
\begin{quote} \begin{verbatim}
CONVERT commands are now available -- (Version 1.0, 1997 August)

Defaults for automatic NDF conversion are set.

Type CONHELP or HELP CONVERT for help on CONVERT commands.
Type "showme sun55" to browse the hypertext documentation.
\end{verbatim} \end{quote}
\normalsize

The ICL command {\tt CONVERT} is defined by the standard Starlink ICL login
files to {\tt LOAD} file {\tt convert.icl} in the \CONVERT\ executables 
directory. Non-Starlink sites must make their own arrangements.

\subsection{Issuing \CONVERT\ Commands}
Having initialised \CONVERT\ you are now ready to issue a
\CONVERT\ command. To run an application you can just give
its name (or its name preceded by {\tt con\_}\footnote{The {\tt con\_<name>}
form is defined for use where there may be confusion between commands of the
same name from different packages.})---you will be prompted for any required 
{\em parameters}. 
Alternatively, you may enter parameter values on the command line
specified by position or by keyword.  If you want to override any
defaulted parameters, then you specify the parameter's value on the
command line.  Note that {\em from UNIX the commands are in lowercase}, whereas
from {\footnotesize ICL} the case does not matter.

Most \CONVERT\ applications can be run as simply as:

\small
\begin{verbatim}
     <application> <in> <out>
\end{verbatim}
\normalsize
where {\tt $<$application$>$} is the application's name, {\tt $<$in$>$}
is the input file, and {\tt $<$out$>$} is the output
file following the conversion.  For instance, from the UNIX shell,

\small
\begin{verbatim}
     % dst2ndf old new
\end{verbatim}
\normalsize
or, from ICL,

\small
\begin{verbatim}
     ICL> DST2NDF old new
\end{verbatim}
\normalsize
both instruct the application \htmlref{DST2NDF}{DST2NDF} to convert the
DST file called {\tt old.dst} to the NDF called {\tt new.sdf}.  
Note that for UNIX, the case of the filename is significant.

The following example has the same effect as those immediately above,
only this time you are prompted for the filenames needed by DST2NDF. 

\small
\begin{verbatim}
     ICL> DST2NDF
     IN - Name of Figaro (.DST) file to be converted /' '/ > old
     OUT - Name of output NDF /@f1/ > new
\end{verbatim}
\normalsize
The value between the {\tt / /} delimiters is a suggested default.  You
can choose to accept the suggestion by pressing carriage return. 

The exceptions to the simple usage ({\tt{<application> <in> <out>}}) are
as follows.
\begin{itemize}
\item \htmlref{ASCII2NDF}{ASCII2NDF} and \htmlref{UNF2NDF}{UNF2NDF},
where you give the shape of the dataset,
either directly or from a FITS-like header.  UNF2NDF also requires
the number of records per value.

\item \htmlref{DA2NDF}{DA2NDF}, where you also give the shape of the
dataset, and the number of records per value.

\item \htmlref{IRCAM2NDF}{IRCAM2NDF} where you select which observations
to convert and give the prefix of the names of the output NDFs.
\end{itemize}

See
\latexelsehtml{Section~4 of SUN/95}{\xref{here}{sun95}{se_param}}
or Section~8 of \xref{SG/4}{sg4}{}
for details of how to use parameters for controlling these and other
options.  However, you should be able to get along using intuition
alone, or, perhaps by consulting the examples given in the 
\htmlref{application specifications}{app_full} 
\latexonly{in Appendix~\ref{app_full}} which includes its usage, parameters 
and details of the conversion process.

In most cases, one invocation of a \CONVERT\ application is required for each 
file conversion but in some cases, inputs may be defined as 
\xref{`GROUPS'}{sun150}{} of names, including wildcards (see the 
\htmlref{application specifications}{app_full} for details).

\subsection{Obtaining Help}
You can get the top-level help information for \CONVERT\  by typing:

\small
\begin{verbatim}
     % conhelp
\end{verbatim}
\normalsize
from the UNIX shell, or:
\small
\begin{verbatim}
     ICL> CONHELP
\end{verbatim}
\normalsize
from ICL. (You can also access \CONVERT\ help from ICL by using the ICL command,
HELP.)

The help topics are mostly detailed descriptions of the applications
but also include global information on matters such as using parameters. 
{\em{e.g.}}\ the following command gives help on the application
\htmlref{UNF2NDF}{UNF2NDF}.

\small
\begin{verbatim}
     % conhelp unf2ndf
\end{verbatim}
\normalsize

If you have commenced running an application you can still access the
help library whenever you are prompted for a parameter; you enter {\tt ?}.
Here is an example.

\small
\begin{verbatim}
     NOPEREC - Number of data values per output record /512/ > ?

     NDF2UNF

       Parameters

         NOPEREC = _INTEGER (Read)
            The number of data values per record of the output file.  It
            should be in the range 1 to 8191, unless the array is double
            precision, when the upper limit is 4095.  The suggested
            default is the current value. [The first dimension of the NDF]

     NOPEREC - Number of data values per output record /512/ > 
\end{verbatim}
\normalsize

\subsection{\xlabel{sun55_se_hypertext}Hypertext Help\label{se_hypertext}}

A modified version of this document exists in hypertext form.  One way
to access it is to use the
\xref{{\tt showme}}{sun188}{displaying_parts_of_documents} command

\small
\begin{verbatim}
     % showme sun55
\end{verbatim}
\normalsize
and a Web browser will appear, presenting the index to the hypertext
form of this document.  The hypertext permits easy location of
referenced documents and applications.

\newpage 
\section{\label{sect_auto}\xlabel{sect_auto}Automatic Format Conversion with
the NDF Library}
\xref{SSN/20}{ssn20}{} describes a system incorporated into the 
\xref{NDF library}{sun33}{}
routines which enables applications written to read or write NDFs to handle
any arbitrary `foreign' format for which a conversion utility can be defined.
The system operates via environment variables which define the set of permitted 
conversions and the commands required to do them.

\subsection{The Default Conversion Commands}
\CONVERT\ startup will define defaults for the NDF-conversion environment 
variables which permit automatic conversion of files in the formats handled by 
\CONVERT\ (except for IRCAM and PGM).
It also allows data compression. 

\begin{htmlonly}
The list of format names and associated filename extensions defined by 
\CONVERT\ is set out in the table below---the filename extensions tell the 
system which format the file is in.
\end{htmlonly}
\begin{latexonly}
The list of format names and associated filename extensions
defined by \CONVERT\ is set out in Table~\ref{tab:formats}---the filename 
extensions tell the system which format the file is in. For the unformatted 
and ASCII conversions the format names and extensions are somewhat arbitrary.
\end{latexonly}
This list will nullify any existing list so private conversions must be added
{\em after\/} CONVERT startup.

For the unformatted and ASCII conversions the format names and
extensions are somewhat arbitrary.  The FITS and STREAM formats have
synonym file extensions for the conversion to NDF.  The standard file
extension is required for the conversion to the foreign format.

\begin{table}[hb]
\begin{center}
\begin{tabular}{|llp{32mm}l|}
\hline
Format & Extension & Extension & Description \\
       &           & Synonyms  & \\
\hline
FITS        & .fit & .fits .fts .FITS .FIT
                     .lilo .lihi .silo .sihi
                     .mxlo .rilo .rihi .vdlo .vdhi & FITS \\
FIGARO      & .dst & & Figaro (Version 2) DST \\
IRAF        & .imh & & IRAF \\
STREAM      & .das & .str & Unformatted direct-access or stream \\
UNFORMATTED & .unf & & Unformatted with FITS header \\
UNF0        & .dat & & Unformatted without FITS header \\
ASCII       & .asc & & ASCII with FITS header \\
TEXT        & .txt & & ASCII without FITS header \\
GIF         & .gif & & Graphics Interchange Format \\
TIFF        & .tif & & Tag Image File Format \\
GASP        & .hdr & & GASP \\
COMPRESSED  & .sdf.Z & & Compressed NDF \\
GZIP        & .sdf.gz & & {\bf gzip} compressed NDF \\
\hline
\end{tabular}
\caption{\label{tab:formats}Defined Formats and Extensions}
\end{center}
\end{table}

\begin{htmlonly}
The table below lists the utilities used to perform the conversions.
In general the default parameter values are used---non-default parameters 
(other than the input and output filenames) are listed in the table.
\end{htmlonly}
\begin{latexonly}
Table \ref{tab:conversions} lists the utilities used to perform the conversions.
In general the default parameter values are used---non-default parameters 
(other than the input and output filenames) are listed in the table.
\end{latexonly}

\begin{table}[ht]
\begin{center}
\begin{tabular}{|llllc|}
\hline
FORMAT & In/out & Utility & Non-default parameters & Variable \\
\hline
FITS & in & \htmlref{FITS2NDF}{FITS2NDF} & & \\
& out & \htmlref{NDF2FITS}{NDF2FITS} & bitpix=-1 proexts=t & \\
FIGARO & in & \htmlref{DST2NDF}{DST2NDF} & & \\
& out & \htmlref{NDF2DST}{NDF2DST} & & $\times$ \\
IRAF & in & \htmlref{IRAF2NDF}{IRAFNDF} & & \\
& out & \htmlref{NDF2IRAF}{NDF2IRAF} & & \\
STREAM & in & \htmlref{DA2NDF}{DA2NDF} & noperec=! & \\
& out & \htmlref{NDF2DA}{NDF2DA} & & \\
UNFORMATTED & in & \htmlref{UNF2NDF}{UNF2NDF} & fits=t noperec=! & \\
& out & \htmlref{NDF2UNF}{NDF2UNF} & fits=t & \\
UNF0 & in & \htmlref{UNF2NDF}{UNF2NDF} & fits=f noperec=! &  $\surd$ \\
& out & \htmlref{NDF2UNF}{NDF2UNF} & fits=f & \\
ASCII & in & \htmlref{ASCII2NDF}{ASCII2NDF} & fits=t & \\
& out & \htmlref{NDF2ASCII}{NDF2ASCII} & fits=t reclen=80 & \\
TEXT & in & \htmlref{ASCII2NDF}{ASCII2NDF} & fits=f &  $\surd$ \\
& out & \htmlref{NDF2ASCII}{ASCII2NDF} & fits=f reclen=80 & \\
GIF & in & \htmlref{GIF2NDF}{GIF2NDF} & & $\times$ \\
& out & \htmlref{NDF2GIF}{NDF2GIF} & & $\times$ \\
TIF & in & \htmlref{TIF2NDF}{TIF2NDF} & & $\times$ \\
& out & \htmlref{NDF2TIF}{NDF2TIF} & & $\times$ \\
GASP & in & \htmlref{GASP2NDF}{GASP2NDF} & & \\
& out & \htmlref{NDF2GASP}{NDF2GASP} & fillbad=0 & \\
COMPRESSED & in & {\bf uncompress} & & $\times$ \\
& out & {\bf compress} & & $\times$ \\
GZIP & in & {\bf gzip} & & $\times$ \\
& out & {\bf gunzip} & & $\times$ \\
\hline
\end{tabular}
\caption{\label{tab:conversions}Conversion Commands.}
\end{center}
\end{table}

\begin{latexonly}
Table~\ref{tab:conversions} also contains a column headed `Variable'.
Most of the command lines issued to do the automatic conversion will include 
the translation of an environment variable named NDF\_FROM\_\-{\em fmt}\_\-PARS or 
NDF\_TO\_{\em fmt}\_PARS as appropriate (where {\em fmt} is the format name).
This may be used to give additional parameters to the command if you do not
want to define a completely new command for yourself. 
\end{latexonly}
\begin{htmlonly}
The table also contains a column headed `Variable'.
Most of the command lines issued to do the automatic conversion will include 
the translation of an environment variable named NDF\_FROM\_{\em fmt}\_PARS or 
NDF\_TO\_{\em fmt}\_PARS as appropriate (where {\em fmt} is the format name).
This may be used to give additional parameters to the command if you do not
want to define a completely new command for yourself. 
\end{htmlonly}
Where the `Variable' column contains a tick, the variable {\em must} be used 
to supply the SHAPE parameter; where it contains a cross, additional parameters
cannot be specified.

For example, suppose application {\tt rdndf} uses the NDF library to read
one NDF (named by the first parameter) and write another (named by the second
parameter). This application could be made to read a TEXT file ({\tt{data.txt}})
containing the required values for a 50 $\times$ 10 data array, and write its 
results as a FITS file ({\tt{output.fit}}) as follows:

\small
\begin{quote} \begin{verbatim}
% convert
CONVERT commands are now available -- (Version 1.0, 1997 August)

Defaults for automatic NDF conversion are set.

Type conhelp for help on CONVERT commands.
Type "showme sun55" to browse the hypertext documentation.

% setenv NDF_FROM_TEXT_PARS 'SHAPE=[50,10]'
% rdndf data.txt output.fit
\end{verbatim} \end{quote}
\normalsize
\bigskip

The order of the formats in the tables also defines a search path.  If
you omit the file extension, the system will search for an NDF of that
name.  If that is absent, it will try a {\tt .fit} FITS file.  If neither
are present it tries an IRAF file, and so on. The recognised formats and
their order is defined through the environment variable
NDF\_FORMATS\_IN.  The shell {\tt convert} startup defines
NDF\_FORMATS\_IN as given below.

\small
\begin{verbatim}
     'FITS(.fit),FIGARO(.dst),IRAF(.imh),STREAM(.das),UNFORMATTED(.unf),UNF0(.dat),
     ASCII(.asc),TEXT(.txt),GIF(.gif),TIFF(.tif),GASP(.hdr),COMPRESSED(.sdf.Z),
     GZIP(.sdf.gz),FITS(.fits),FITS(.fts),FITS(.FTS),FITS(.FITS),FITS(.FIT),
     FITS(.lilo),FITS(.lihi),FITS(.silo),FITS(.sihi),FITS(.mxlo),FITS(.rilo),
     FITS(.rihi),FITS(.vdlo),FITS(.vdhi),STREAM(.str)'
\end{verbatim}
\normalsize

but from ICL the {\tt CONVERT} command does not define the synonyms due 
to a limitation of ICL.  Thus NDF\_FORMATS\_IN is defined to be the
following. 

\small
\begin{verbatim}
     'FITS(.fit),FIGARO(.dst),IRAF(.imh),STREAM(.das),UNFORMATTED(.unf),UNF0(.dat),
     ASCII(.asc),TEXT(.txt),GIF(.gif),TIFF(.tif),GASP(.hdr),COMPRESSED(.sdf.Z),
     GZIP(.sdf.gz)'
\end{verbatim}
\normalsize

When creating an output file, there is a similar list of recognised
formats.  The \CONVERT\ startup procedures define NDF\_FORMATS\_OUT
as follows.

\small
\begin{verbatim}
     '.,FITS(.fit),FIGARO(.dst),IRAF(.imh),STREAM(.das),UNFORMATTED(.unf),
     UNF0(.dat),ASCII(.asc),TEXT(.txt),GIF(.gif),TIFF(.tif),GASP(.hdr),
     COMPRESSED(.sdf.Z),GZIP(.sdf.gz)'
\end{verbatim}
\normalsize

The leading dot indicates that if you omit the file extension, the
output file will be an NDF.

There are some examples of the automatic system in action and use of
NDF\_FORMATS\_IN and NDF\_FORMATS\_OUT in
\latexelsehtml{SUN/95, Section~15.1.}{\xref{Automatic
Conversion.}{sun95}{se_autoconvert}}

\section{Acknowledgements}
Jo Murray wrote the original versions of the applications that convert
between DSTs or DIPSO files and NDFs.  Alan Chipperfield produced the
original STARIN and STAROUT upon which BDF2NDF and NDF2BDF are based.
Rhys Morris wrote the original versions of IRAF2NDF, NDF2IRAF, GASP2NDF
and NDF2GASP. Grant Privett wrote the TIFF and contributed to the GIF
conversion utilities.

Rodney Warren-Smith devised the format-conversion facilities for the NDF 
data access library.

\newpage
\appendix

\section{\label{app_full}Specifications of \BCONVERT\ applications}
\subsection{Explanatory Notes}
The specification of parameters has the following format.

\begin{verbatim}
     name  =  type (access)
        description
\end{verbatim}
This format also includes a {\em Usage\/} entry.   \label{app_usage}
This shows how the  application is invoked from the command line.   It
lists the positional parameters in order followed by any prompted
keyword parameters using  a {\mbox ``KEYWORD=?''} syntax.  Defaulted
keyword parameters do not appear.  Positional parameters that are
normally defaulted are indicated by being enclosed in square brackets.  
Keyword ({\it i.e.}\ not positional) parameters are needed where the
number of parameters are large, and usually occur because they depend on
the value of another parameter.  An example should clarify.
\bigskip

{\ssttt \hspace*{1.0em}
        ndf2ascii in out [comp] [reclen] noperec=?
}
\bigskip

IN, OUT, COMP, and RECLEN are all positional
parameters.  Only IN, and OUT would be prompted if not given
on the command line. The remaining parameter, NOPEREC, depends on the
value of another parameter (it is FIXED), and will be prompted for when
FIXED is {\tt TRUE}. 

There is also an {\em Examples\/} section.  \label{app_example}  This
shows how to run the application from the command line.  More often
you'll enter the command name and just some of the parameters, and be
prompted for the rest. 

Examples give command lines as accepted by the tasks themselves.  From
the UNIX shell, {\em metacharacters\/} (notably {\tt{[}}, {\tt{]}} and {\tt{"}})
{\em must be escaped or enclosed in single quotes}.  For example:

\begin{quote} \begin{verbatim}
ascii2ndf ngc253q.dat ngc253 q shape='[100,60]'
fits2ndf '"abc.fit,def.fits"' 'fgh,ijk"' fmtcnv='"F,T"' noproexts
\end{verbatim} \end{quote}
\normalsize

The description entry has a notation scheme to indicate 
normally defaulted parameters, {\it i.e.}\ those for which there will
be no prompt.
For such parameters a matching pair of square brackets (\verb![]!)
terminates the description.  The content between the brackets mean
\begin{description}
\item[{\tt []}]
Empty brackets means that the default is created dynamically
by the application, and may depend on the values of other parameters.
Therefore, the default cannot be given explicitly.
\item[{\tt [,]}]
As above, but there are two default values that are created dynamically.
\item[{\tt [}{\rm default}{\tt ]}]
Occasionally, a description of the default is given in normal type.
\item[{\tt [default]}]
If the brackets contain a value in teletype-fount, this is the explicit
default value.
\end{description}

\newpage
\sstroutine{
   ASCII2NDF
}{
   Converts a text file to an NDF
}{
   \sstdescription{
      This application converts a text file to an NDF.  Only one of
      the array components may be created from the input file.
      Preceding the input data there may be an optional header.  This
      header may be skipped, or may consist of a simple FITS header.
      In the former case the shape of the NDF has be to be supplied.
   }
   \sstusage{
      ascii2ndf in out [comp] [skip] shape [type]
   }
   \sstparameters{
      \sstsubsection{
         COMP = LITERAL (Read)
      }{
         The NDF component to be copied.  It may be {\tt "Data"},
         {\tt "Quality"} or {\tt "Variance"}.  To create a variance or
         quality array the NDF must already exist. {\tt ["Data"]}
      }
      \sstsubsection{
         FITS = \_LOGICAL (Read)
      }{
         If {\tt TRUE}, the initial records of the formatted file are
         interpreted as a FITS header (with one card image per record)
         from which the shape, data type, and axis centres are derived.
         The last record of the FITS-like header must be terminated by
         an END keyword; subsequent records in the input file are
         treated as an array component given by COMP.  {\tt [FALSE]}
      }
      \sstsubsection{
         IN = FILENAME (Read)
      }{
         Name of the input text Fortran file.  The file will normally
         have variable-length records when there is a header, but
         always fixed-length records when there is no header.  The
         maximum record length allowed is 512 bytes.
      }
      \sstsubsection{
         MAXLEN = INTEGER (Read)
      }{
         The maximum record length in bytes of records within the input
         text file.  Unless the records are longer than 512 bytes, you
         can use the default value.  The suggested value is the current
         value.  {\tt [512]}
      }
      \sstsubsection{
         OUT = NDF (Read and Write)
      }{
         Output NDF data structure.  When COMP is not {\tt "Data"} the NDF
         is modified rather than a new NDF created.
         It becomes the new current NDF.
      }
      \sstsubsection{
         SHAPE = \_INTEGER (Read)
      }{
         The shape of the NDF to be created.  For example, {\tt [40,30,20]}
         would create 40 columns by 30 lines by 10 bands.  It is only
         accessed when FITS is {\tt FALSE}.
      }
      \sstsubsection{
         SKIP = INTEGER (Read)
      }{
         The number of header records to be skipped at the start of the
         input file before finding the data array or FITS-like header.
         {\tt [0]}
      }
      \sstsubsection{
         TYPE = LITERAL (Read)
      }{
         The data type of the output NDF.  It must be one of the
         following HDS types: {\tt "\_BYTE"}, {\tt "\_WORD"}, {\tt "\_REAL"},
         {\tt "\_INTEGER"}, {\tt "\_DOUBLE"}, {\tt "\_UBYTE"},
         {\tt "\_UWORD"} corresponding to signed byte,
         signed word, real, integer, double precision, unsigned byte,
         and unsigned word.  See \xref{SUN/92}{sun92}{} for further details.  An
         unambiguous abbreviation may be given.  TYPE is ignored when
         COMP = {\tt "Quality"} since the QUALITY component must comprise
         unsigned bytes (equivalent to TYPE = {\tt "\_UBYTE"}) to be a valid
         NDF. The suggested default is the current value.  TYPE is only
         accessed when FITS is {\tt FALSE}.  {\tt ["\_REAL"]}
       }
   }
   \sstexamples{
      \sstexamplesubsection{
         ascii2ndf ngc253.dat ngc253 shape=[100,60]
      }{
         This copies a data array from the text file {\tt ngc253.dat} to the
         NDF called ngc253.  The input file does not contain a header
         section.  The NDF is two-dimensional: 100 elements in $x$ by 60
         in $y$.  Its data array has type \_REAL.
      }
      \sstexamplesubsection{
         ascii2ndf ngc253q.dat ngc253 q shape=[100,60]
      }{
         This copies a quality array from the text file {\tt ngc253q.dat} to
         an existing NDF called ngc253 (such as created in the first
         example).  The input file does not contain a header section.  The
         NDF is two-dimensional: 100 elements in $x$ by 60 in $y$.  Its
         data array has type \_UBYTE.
      }
      \sstexamplesubsection{
         ascii2ndf ngc253.dat ngc253 fits
      }{
         This copies a data array from the text file {\tt ngc253.dat}
         to the NDF called ngc253.  The input file contains a FITS-like
         header section, which is copied to the FITS extension of the
         NDF.  The shape of the NDF is controlled by the mandatory FITS
         keywords NAXIS, AXIS1, \dots, AXIS{\em{n}}, and the data type by
         keywords BITPIX and UNSIGNED.
      }
      \sstexamplesubsection{
         ascii2ndf type="\_uword" in=ngc253.dat out=ngc253 maxlen=4000 $\backslash$
      }{
         This copies a data array from the text file {\tt ngc253.dat} to the
         NDF called ngc253.  The input file does not contain a header
         section.  The NDF has the current shape and data type is
         unsigned word.  The maximum record length is 4000 bytes.
      }
      \sstexamplesubsection{
         ascii2ndf spectrum ZZ skip=2 shape=200
      }{
         This copies a data array from the text file {\tt spectrum} to
         the NDF called ZZ.  The input file contains two header records
         that are ignored.  The NDF is one-dimensional comprising 200
         elements of type \_REAL.
      }
      \sstexamplesubsection{
         ascii2ndf spectrum.lis ZZ skip=1 fits
      }{
         This copies a data array from the text file {\tt spectrum.lis} to
         the NDF called ZZ.  The input file contains one header 
         record, that is ignored, followed by a FITS-like header section, which
         is copied to the FITS extension of the NDF.  The shape of the
         NDF is controlled by the mandatory FITS keywords NAXIS, AXIS1,
         \dots, AXIS{\em{n}}, and the data type by keywords BITPIX and UNSIGNED.
      }
   }
   \sstnotes{
      The details of the conversion are as follows:
      \ssthitemlist{

         \sstitem
            the ASCII-file array is written to the NDF array as
            selected by COMP.  When the NDF is being modified, the shape
            of the new component must match that of the NDF.

         \sstitem
            If the input file contains a FITS-like header, and a new
            NDF is created, {\it i.e.}\ COMP = {\tt "Data"}, the header records are
            placed within the NDF's FITS extension.  This enables more
            than one array (input file) to be used to form an NDF.  Note
            that the data array must be created first to make a valid NDF,
            and it's the FITS structure associated with that array that is
            wanted.  Indeed the application prevents you from doing
            otherwise.

         \sstitem
            The FITS-like header defines the properties of the NDF as
            follows:
            \begin{itemize}
            \item BITPIX defines the data type: 8 gives \_BYTE, 16 produces
            \_WORD, 32 makes \_INTEGER, $-$32 gives \_REAL, and $-$64 generates
            \_DOUBLE.  For the first two, if there is an extra header
            record with the keyword UNSIGNED and logical value T, these
            types become \_UBYTE and \_UWORD respectively.  UNSIGNED is
            non-standard, since unsigned integers would not follow in a
            proper FITS file.  However, here it is useful to enable
            unsigned types to be input into an NDF.  UNSIGNED may be
            created by this application's sister, NDF2ASCII.  BITPIX is
            ignored for QUALITY data; type \_UBYTE is used.
            \item NAXIS, and NAXIS{\em{n}} define the shape of the NDF.
            \item The TITLE, LABEL, and BUNIT are copied to the NDF
            TITLE, LABEL, and UNITS NDF components respectively.
            \item The CDELT{\em{n}}, CRVAL{\em{n}}, CTYPE{\em{n}}, and CUNIT{\em{n}} keywords make
            linear axis structures within the NDF.  CUNIT{\em{n}} define the
            axis units, and the axis labels are assigned to CTYPE{\em{n}}. 
            If some are missing, pixel co-ordinates are used for those
            axes.
            \item BSCALE and BZERO in a FITS extension are ignored.
            \item BLANK is not used to indicate which input array values
            should be assigned to a standard bad value.
            \item END indicates the last header record unless it
            terminates a dummy header, and the actual data is in an
            extension.
            \end{itemize}

         \sstitem
            Other data item such as HISTORY, data ORIGIN, and axis
            widths are not supported, because the text file has a simple
            structure to enable a diverse set of input files to be
            converted to NDFs, and to limitations of the standard FITS
            header.
      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{NDF2ASCII}{NDF2ASCII};
      \KAPPA: \xref{TRANDAT}{sun95}{TRANDAT};
      \SPECDRE: \xref{ASCIN}{sun140}{ASCIN} and
      \xref{ASCOUT}{sun140}{ASCOUT}.
   }
}

\newpage
\sstroutine{
   DA2NDF
}{
   Converts a direct-access unformatted file to an NDF
}{
   \sstdescription{
      This application converts a direct-access (fixed-length records)
      unformatted file to an NDF.  It can therefore also process
      unformatted data files generated by C routines.  Only one of the
      array components may be created from the input file.   The shape
      of the NDF has be to be supplied.
   }
   \sstusage{
      da2ndf in out [comp] noperec shape [type]
   }
   \sstparameters{
      \sstsubsection{
         COMP = LITERAL (Read)
      }{
         The NDF component to be copied.  It may be {\tt "Data"},
         {\tt "Quality"}
         or {\tt "Variance"}.  To create a variance or quality array the NDF
         must already exist. {\tt ["Data"]}
      }
      \sstsubsection{
         IN = FILENAME (Read)
      }{
         Name of the input direct-access unformatted file.
      }
      \sstsubsection{
         NOPEREC = \_INTEGER (Read)
      }{
         The number of data values per record of the input file.  It
         must be positive.  The suggested default is the size of the
         first dimension of the array.  A null ({\tt{!}}) value for NOPEREC
         causes the size of first dimension to be used.
      }
      \sstsubsection{
         OUT = NDF (Read and Write)
      }{
         Output NDF data structure.  When COMP is not {\tt "Data"} the NDF
         is modified rather than a new NDF created.  It becomes the new
         current NDF.  Unusually for an output NDF, there is a suggested
         default---the current value---to facilitate the inclusion of
         variance and quality arrays.
      }
      \sstsubsection{
         SHAPE = \_INTEGER (Read)
      }{
         The shape of the NDF to be created.  For example, {\tt [40,30,20]}
         would create 40 columns by 30 lines by 10 bands.
      }
      \sstsubsection{
         TYPE = LITERAL (Read)
      }{
         The data type of the direct-access file and the NDF.  It must
         be one of the following HDS types: {\tt "\_BYTE"}, {\tt"\_WORD"},
         {\tt "\_REAL"}, {\tt "\_INTEGER"}, {\tt "\_DOUBLE"},
         {\tt "\_UBYTE"}, {\tt "\_UWORD"} corresponding to
         signed byte, signed word, real, integer, double precision,
         unsigned byte, and unsigned word respectively.  See
         \xref{SUN/92}{sun92}{} for further details.  An unambiguous
         abbreviation may be given.
         TYPE is ignored when COMP = {\tt "Quality"} since the QUALITY
         component must comprise unsigned bytes (equivalent to TYPE =
         {\tt "\_UBYTE"}) to be a valid NDF. The suggested default is the
         current value. {\tt ["\_REAL"]}
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         da2ndf ngc253.dat ngc253 shape=[100,60] noperec=8
      }{
         This copies a data array from the direct-access file {\tt ngc253.dat}
         to the NDF called ngc253.  The NDF is two-dimensional: 100
         elements in $x$ by 60 in $y$.  Its data array has type \_REAL.  The
         data records each have 8 real values.
      }
      \sstexamplesubsection{
         da2ndf ngc253q.dat ngc253 q 100 [100,60]
      }{
         This copies a quality array from the direct-access file
         {\tt ngc253q.dat} to an existing NDF called ngc253 (such as created
         in the first example).  The NDF is two-dimensional: 100
         elements in $x$ by 60 in $y$.  Its data array has type \_UBYTE.
         The data records each have 100 unsigned-byte values.
      }
      \sstexamplesubsection{
         da2ndf type="\_uword" in=ngc253.dat out=ngc253 $\backslash$
      }{
         This copies a data array from the direct-access file
         {\tt ngc253.dat}
         to the NDF called ngc253.  The NDF has the current shape and
         data type is unsigned word.  The current number of values per
         record is used.
      }
   }
   \sstnotes{
      The details of the conversion are as follows:
      \ssthitemlist{

         \sstitem
            the direct-access file's array is written to the NDF array
            as selected by COMP.  When the NDF is being modified, the
            shape of the new component must match that of the NDF.  This
            enables more than one array (input file) to be used to form an
            NDF.  Note that the data array must be created first to make a
            valid NDF.  Indeed the application prevents you from doing
            otherwise.

         \sstitem
            Other data items such as axes are not supported, because of
            the direct-access file's simple structure.
      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{NDF2DA}{NDF2DA}.
   }
}

\newpage
\sstroutine{
   DST2NDF
}{
   Converts a Figaro (Version 2) DST file to an NDF
}{
   \sstdescription{
      This application converts a Figaro Version-2 DST file to a
      Version-3 file, {\it i.e.}\ to an NDF.  The rules for converting the
      various components of a DST are listed in the notes.  Since
      both are hierarchical formats most files can be be converted with
      little or no information lost.
   }
   \sstusage{
      dst2ndf in out
   }
   \sstparameters{
      \sstsubsection{
         FORM = LITERAL (Read)
      }{
         The storage form of the NDF's data and variance arrays.
         FORM = {\tt "Simple"} gives the simple form, where the array of data
         and variance values is located in an ARRAY structure.  Here it
         can have ancillary data like the origin.  This is the normal
         form for an NDF.  FORM = {\tt "Primitive"} offers compatibility with
         earlier formats, such as IMAGE.  In the primitive form the
         data and variance arrays are primitive components at the top
         level of the NDF structure, and hence it cannot have
         ancillary information. {\tt ["Simple"]}
      }
      \sstsubsection{
         IN = Figaro file (Read)
      }{
         The file name of the version 2 file.  A file extension must
         not be given after the name, since {\tt ".dst"} is appended by the
         application.  The file name is limited to 80 characters.
      }
      \sstsubsection{
         OUT = NDF (Write)
      }{
         The file name of the output NDF file.  A file extension must
         not be given after the name, since {\tt ".sdf"} is appended by the
         application.  Since the NDF\_ library is not used, a section
         definition may not be given following the name.  The file
         name is limited to 80 characters.
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         dst2ndf old new
      }{
         This converts the Figaro file {\tt old.dst} to the NDF called new
         (in file {\tt new.sdf}).  The NDF has the simple form.
      }
      \sstexamplesubsection{
         dst2ndf horse horse p
      }{
         This converts the Figaro file {\tt horse.dst} to the NDF called
         horse (in file {\tt horse.sdf}).  The NDF has the primitive form.
      }
   }
   \sstnotes{
      The rules for the conversion of the various components are as
      follows:
      \vspace{-\parskip}
      \begin{center}
      \begin{tabular}{|lcl|p{43mm}|}
      \hline 
      \multicolumn{1}{|c}{Figaro file} & & \multicolumn{1}{c}{NDF} &
      \multicolumn{1}{|c|}{Comments} \\ \hline
      .Z.DATA   & $\Rightarrow$ & .DATA\_ARRAY.DATA & when FORM = {\tt "SIMPLE"}\\
      .Z.DATA   & $\Rightarrow$ & .DATA\_ARRAY & when FORM = {\tt "PRIMITIVE"} \\
      .Z.ERRORS & $\Rightarrow$ & .VARIANCE.DATA & after processing when FORM = {\tt "SIMPLE"} \\
      .Z.ERRORS & $\Rightarrow$ & .VARIANCE & after processing when FORM = {\tt "PRIMITIVE"} \\
      .Z.QUALITY & $\Rightarrow$ & .QUALITY.QUALITY & must be BYTE array
                                  (see Bad-pixel handling below) \\
      & $\Rightarrow$ & .QUALITY.BADBITS = 255 & \\
      .Z.LABEL  & $\Rightarrow$ & .LABEL & \\
      .Z.UNITS  & $\Rightarrow$ & .UNITS & \\
      .Z.IMAGINARY & $\Rightarrow$ & .DATA\_ARRAY.IMAGINARY\_DATA & \\
      .Z.MAGFLAG & $\Rightarrow$ & .MORE.FIGARO.MAGFLAG & \\
      .Z.RANGE  & $\Rightarrow$ & .MORE.FIGARO.RANGE & \\
      .Z.xxxx   & $\Rightarrow$ & .MORE.FIGARO.Z.xxxx & \\ 
      & & & \\
      .X.DATA   & $\Rightarrow$ & .AXIS(1).DATA\_ARRAY & \\ 
      .X.ERRORS & $\Rightarrow$ & .AXIS(1).VARIANCE & after processing \\
      .X.WIDTH  & $\Rightarrow$ & .AXIS(1).WIDTH & \\
      .X.LABEL  & $\Rightarrow$ & .AXIS(1).LABEL & \\
      .X.UNITS  & $\Rightarrow$ & .AXIS(1).UNITS & \\
      .X.LOG    & $\Rightarrow$ & .AXIS(1).MORE.FIGARO.LOG & \\
      .X.xxxx   & $\Rightarrow$ & .AXIS(1).MORE.FIGARO.xxxx & \\
      & & & (Similarly for .Y .T .U .V or .W structures which are
             renamed to AXIS(2), \ldots, AXIS(6) in the NDF.) \\
      & & & \\
      .OBS.OBJECT & $\Rightarrow$ & .TITLE & \\
      .OBS.SECZ & $\Rightarrow$ & .MORE.FIGARO.SECZ & \\
      .OBS.TIME & $\Rightarrow$ & .MORE.FIGARO.TIME & \\
      .OBS.xxxx & $\Rightarrow$ & .MORE.FIGARO.OBS.xxxx & \\
      & & & \\
      .FITS.xxxx& $\Rightarrow$ & .MORE.FITS.xxxx & into value part of
         the string \\
      .COMMENTS.xxxx  & $\Rightarrow$ & .MORE.FITS($n$) & into comment part of
         the string \\
      .FITS.xxxx.DATA & $\Rightarrow$ & .MORE.FITS($n$) & into value part of
         the string \\
      .FITS.xxxx.DESCRIPTION & $\Rightarrow$ & .MORE.FITS($n$) & into comment
         part of the string \\
      .FITS.xxxx.yyyy & $\Rightarrow$ & .MORE.FITS($n$) & into blank-keyword
         comment containing {\tt yyyy=value} \\
      & & & \\ \hline
      \end{tabular}
      \end{center}

      \vspace{-\parskip}
      \begin{center}
      \begin{tabular}{|lcl|p{43mm}|}
      \hline 
      \multicolumn{1}{|c}{Figaro file} & & \multicolumn{1}{c}{NDF} &
      \multicolumn{1}{|c|}{Comments} \\ \hline
      .MORE.xxxx& $\Rightarrow$ & .MORE.xxxx & \\
      & & & \\
      .TABLE    & $\Rightarrow$ & .MORE.FIGARO.TABLE & \\
      .xxxx     & $\Rightarrow$ & .MORE.FIGARO.xxxx & \\ \hline
      \end{tabular}
      \end{center}

      Axis arrays with dimensionality greater than one are not
      supported by the NDF.  Therefore, if the application encounters
      such an axis array, it processes the array using the following
      rules, rather than those given above.
      \begin{center}
      \begin{tabular}{|lcl|p{48mm}|}
      \hline 
      \multicolumn{1}{|c}{Figaro file} & & \multicolumn{1}{c}{NDF} &
      \multicolumn{1}{|c|}{Comments} \\ \hline
      .X.DATA   & $\Rightarrow$ & .AXIS(1).MORE.FIGARO.DATA\_ARRAY &
            AXIS(1).DATA\_ARRAY is filled with pixel co-ordinates \\
      .X.ERRORS & $\Rightarrow$ & .AXIS(1).MORE.FIGARO.VARIANCE & after
            processing \\
      .X.WIDTH  & $\Rightarrow$ & .AXIS(1).MORE.FIGARO.WIDTH & \\ \hline
      \end{tabular}
      \end{center}

      In addition to creating a blank-keyword NDF FITS-extension
      header for each component of a non-standard DST FITS structure
      (.FITS.xxxx.yyyy where yyyy is not DATA or DESCRIPTION), this set
      of related headers are bracketed by blank lines and a comment
      containing the name of the structure ({\it i.e.}\ xxxx).
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{NDF2DST}{NDF2DST}.
   }
   \sstdiytopic{
   Bad-pixel handling
   }{
   The QUALITY array is only copied if the bad-pixel flag
   (.Z.FLAGGED) is false or absent.  A simple NDF with the bad-pixel
   flag set to false (meaning that there are no bad-pixels present)
   is created when .Z.FLAGGED is absent or false and FORM = {\tt "SIMPLE"}.
   }
   \sstimplementationstatus{
      The maximum number of dimensions is 6.
   }
}

\newpage
\sstroutine{
   FITS2NDF
}{
   Converts FITS files into NDFs
}{
   \sstdescription{
      This application converts one or more files in the FITS format
      into NDFs.  It can process an arbitrary FITS file to produce an
      NDF, using NDF extensions to store information conveyed in table
      and image components of the FITS file.  While no information is
      lost, in many common cases this would prove inconvenient
      especially as no meaning is attached to the NDF extension
      components.  Therefore, FITS2NDF recognises certain data products
      (currently IUE Final Archive, ISO, and 2dF), and provides
      tailored conversions that map the FITS data better on to the NDF
      components.  For instance, a FITS IMAGE extension storing data
      errors will have its data array transferred to the NDF's VARIANCE
      (after being squared).  In addition, FITS2NDF can restore
      NDFs converted to FITS by the sister task NDF2FITS.

      Details of the supported special formats and rules for processing
      them are given in topic {\tt "Special Formats"}; the general-case
      processing rules are described in the {\tt "Notes"}.
   }
   \sstusage{
      fits2ndf in out
   }
   \sstparameters{
      \sstsubsection{
         FMTCNV = LITERAL (Read)
      }{
         This specifies whether or not format conversion will occur.
         The conversion applies the values of the FITS keywords BSCALE
         and BZERO to the FITS data to generate the {\tt "}true{\tt "} data values.
         This applies to IMAGE extensions, as well as the primary data
         array.  If BSCALE and BZERO are not given in the FITS header,
         they are taken to be 1.0 and 0.0 respectively.

         If FMTCNV={\tt FALSE}, the HDS type of the data array in the NDF
         will be the equivalent of the FITS data format on tape
         ({\em{e.g.}}\ BITPIX = 16 creates a \_WORD array).  If {\tt TRUE},
         the data array in the NDF will be converted from the FITS data
         type on tape to \_REAL or \_DOUBLE in the NDF.  The choice of
         floating-point data type depends on the number of significant
         digits in the BSCALE and BZERO keywords.

         FMTCNV must be enclosed in double quotes and may be a list of
         comma-separated values to be applied to each conversion in
         turn.  An error results if more values than the number of
         input FITS files are supplied.  If too few are given, the last
         value in the list applied to all the conversions; thus a
         single value is applied to all the input files.  If more than
         one line is required to enter the information at a prompt then
         place a {\tt "-"} at the end of each line where a continuation line
         is desired.  {\tt ["TRUE"]}
      }
      \sstsubsection{
         IN = LITERAL (Read)
      }{
         The names of the FITS-format files to be converted to NDFs.
         It may be a list of file names or direction specifications
         separated by commas and enclosed in double quotes.  FITS file
         names may include the regular expressions ({\tt "$*$"},
         {\tt "?"}, {\tt "[a-z]"} {\em etc.}).  Indirection may occur
         through text files (nested up to seven deep).  The indirection
         character is {\tt "$\wedge$"}.  If extra prompt lines are
         required, append the continuation character {\tt "-"} to the
         end of the line.  Comments
         in the indirection file begin with the character {\tt "\#"}.
      }
      \sstsubsection{
         OUT = LITERAL (Write)
      }{
         The names for the output NDFs.  These may be enclosed in
         double quotes and specified as a list of comma-separated names,
         OR, using modification elements to specify output NDF names
         based on the input filenames.  Indirection may be used if
         required.

         The simplest modification element is the asterisk {\tt "$*$"}, which
         means call the output NDF files the same name (without any
         directory specification) as the corresponding input FITS file,
         but with file extension {\tt ".sdf"}.

         Other types of modification can also occur so OUT = {\tt "x$*$"} would
         mean that the output files would have the same name as the
         input FITS files except for an {\tt "x"} prefix.  You can also
         replace a specified string in the output filename, for example
         OUT={\tt "x$*$/cal/Starlink/"} replaces the string
         {\tt "cal"} with {\tt "Starlink"} in any of the output names
         {\tt "x$*$"}.
      }
      \sstsubsection{
         PROEXTS = \_LOGICAL (Read)
      }{
         This governs how any extension (here called a sub-file) within
         the FITS file are processed in the general case.  If {\tt TRUE}, any
         FITS sub-file is propagated to the NDF as an NDF extension
         called NDF\_EXT\_$n$, where $n$ is the number of the extension.  If
         {\tt FALSE}, any FITS-file extensions are ignored.  The {\tt "Notes"} of
         the general conversion contain details of where and in what
         form the various FITS extensions are stored in the NDF.

         This parameter is ignored when the supplied FITS file is one
         of the special formats, but excluding NDF2FITS-created files,
         whose structure in terms of multiple FITS objects is defined.
         Specialist NDF extensions may be created in this case.  See
         topic {\tt "Special Formats"} for details.  {\tt [TRUE]}
      }
      \sstsubsection{
         PROFITS = \_LOGICAL (Read)
      }{
         If TRUE, the primary headers of the FITS file are written
         verbatim to the NDF's FITS extension.  {\tt [TRUE]}
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         fits2ndf 256.fit f256 fmtcnv=f
      }{
         This converts the FITS file called {\tt 256.fit} to the NDF called
         f256.  The data type of the NDF's data array matches that of
         the FITS primary data array.  A FITS extension is created in
         f256, and FITS sub-files are propagated to NDF extensions.
      }
      \sstexamplesubsection{
         fits2ndf 256.fit f256 noprofits noproexts
      }{
         As the previous example except there will be a format conversion
         from a FITS integer data type to floating point in the NDF
         using the BSCALE and BZERO keywords, and there will be no
         extensions written within f256.
      }
      \sstexamplesubsection{
         fits2ndf "$*$.fit,p$*$.fits" $*$
      }{
         This converts a set of FITS files given by the list
         {\tt "$*$.fit,p$*$.fits"}, where {\tt $*$} is the match-any-character wildcard.
         The resultant NDFs take the filenames of the FITS files, so if
         one of the FITS files was {\tt parker.fits}, the resultant NDF would
         be called parker.  Format conversion is performed on integer
         data types.  A FITS extension is created in each NDF and any
         FITS sub-files present are propagated to NDF extensions.
      }
      \sstexamplesubsection{
         fits2ndf swp25000.mxlo mxlo25000
      }{
         This converts the IUE MXLO FITS file called {\tt swp25000.mxlo} to
         the NDF called mxlo25000.
      }
      \sstexamplesubsection{
         fits2ndf "data/$*$.silo" "silo$*$$|$swp$|$$|$" noprofits
      }{
         This converts all the IUE SILO FITS files with file extension
         {\tt .silo} in directory data to NDFs in the current directory.
         Each name of an NDF is derived from the corresponding FITS
         filename; the original name has the {\tt "swp"} removed and
         {\tt "silo"} is prefixed.  So for example, {\tt swp25000.silo}
         would become an NDF called silo25000.  No FITS extension is created.
      }
      \sstexamplesubsection{
         fits2ndf "abc.fit,def.fts" "fgh,ijk" fmtcnv="F,T" noproexts
      }{
         This converts the FITS files {\tt abc.fit} and {\tt def.fts} to the NDFs
         called fgh and ijk respectively.  Format conversion is applied
         to {\tt abc.fit} but not to {\tt def.fts}.  FITS extensions are created
         in the NDFs but there are no extensions for any FITS sub-files
         that may be present.
      }
   }
   \sstnotes{
      Some sources of FITS files that require special conversion
      rules, particularly because they use binary tables, are
      recognised.  Details of the processing for these is given within
      topic {\tt "Special Formats"}.  Both NDF and FITS use the term
      extension, and they mean different things.  Thus to avoid
      confusion in the descriptions below, the term `sub-file' is used
      to refer to a FITS IMAGE, TABLE or BINTABLE extension.

      The general rules for the conversion are as follows.

      \sstitemlist{

         \sstitem
         The primary data array of the FITS file becomes the NDF's data
         array.  There is an option using parameter FMTCNV to convert
         integer data to floating point using the values of FITS keywords
         BSCALE and BZERO.

         \sstitem
         Any integer array elements with value equal to the FITS
         keyword BLANK become bad values in the NDF data array.  Likewise
         any floating-point data set to an IEEE not-a-number value also
         become bad values in the NDF's data array.  The BAD\_PIXEL flag is
         set appropriately.

         \sstitem
         NDF quality and variance arrays are not created.

         \sstitem
         A verbatim copy of the FITS primary header is placed in the
         NDF's FITS extension when parameter PROFITS is {\tt TRUE}.

         \sstitem
         Here are details of the processing of standard items from the
         the FITS header, listed by FITS keyword.

         \ssthitemlist{

            \sstitem
            CRVAL$n$, CDELT$n$, CRPIX$n$, CTYPE$n$, CUNIT$n$ --- define
            the NDF's AXIS structure along the $n^{\rm th}$ axis.  For
            a given axis CRVAL$n$, CRPIX$n$, and CDELT$n$ must all
            be present to define the axis
            centres.  Where one or more of these is absent, the axis
            centres become pixel co-ordinates, and if this applies to all
            dimensions in a multiple-axis dataset, no NDF AXIS structure
            is made.  CTYPE$n$ defines the label and CUNIT$n$ the units for
            the $n^{\rm th}$ axis.

            \sstitem
            OBJECT, LABEL, BUNIT --- if present are equated to the NDF's
            title, label, and units components respectively.

            \sstitem
            LBOUND$n$ --- if present, this specifies the pixel origin for
            the $n^{\rm th}$ dimension.
         }

         \sstitem
         Additional sub-files within the FITS files are converted into
         extensions within the NDF if parameter PROEXTS is {\tt TRUE}.  These
         extensions are named FITS\_EXT\_$m$ for the $m^{\rm th}$ sub-file.

         \sstitem
         An IMAGE sub-file is treated like the primary data array, and
         follows the rules give above.  However, the resultant NDF is an
         extension of the main NDF.

         \sstitem
         A BINTABLE or TABLE sub-file are converted into a structure
         of type TABLE.  This has a NROWS component specifying the
         number of rows, and a COLUMNS structure containing a series of
         further structures, each of which has has the name of the
         corresponding column in the FITS table.  These COLUMN structures
         contain a column of table data values in component DATA,
         preserving the original data type; and optional UNITS and COMMENT
         components which specify the column's units and the meaning of
         the column.  Thus for example, for the third sub-file of NDF
         called ABC, the data for column called RA would be located in
         ABC.MORE.NDF\_EXT\_3.COLUMNS.RA.DATA.

         \sstitem
         A random-group FITS file creates an NDF for each group.  As
         they are related observations the series of NDFs are stored in a
         single HDS container file whose name is still given by parameter
         OUT.  Each group NDF has component name FITS\_G$n$, where $n$ is the
         group number.

         Each group NDF contains the full header in the FITS extension,
         appended by the set of group parameters.  The group parameters
         are evaluated using their scales and offsets, and made to look
         like FITS cards.  The keywords of these FITS cards are derived
         from the values of PTYPE$m$ in the main header, where $m$ is the
         number of the group parameter.
      }
   }
   \sstdiytopic{
      Special Formats
   }{
      \sstitemlist{

         \sstitem
         NDF2FITS

         \ssthitemlist{

            \sstitem
            This is recognised by the presence of an HDUCLAS1 keyword set
            to {\tt 'NDF'}.  The conversion is similar to the general case, except
            the processing of FITS sub-files and HISTORY headers.

            \sstitem
            An IMAGE sub-file converts to an NDF variance-array component,
            provided the keyword HDUCLAS2 is present and has a value that is
            either {\tt 'VARIANCE'} or {\tt 'ERROR'}.

            \sstitem
            An IMAGE sub-file converts to an NDF quality-array component,
            provided the keyword HDUCLAS2 is present and has value
            {\tt 'QUALITY'}.

            \sstitem
            FITS ASCII and binary tables become NDF extensions, however,
            the original structure path and data type are restored using
            the values of the EXTNAME and EXTTYPE keywords respectively.
            An extension may be an array of structures, the shape being stored
            in the EXTSHAPE keyword.  The shapes of multi-dimensional arrays
            within the extensions are also restored.

            \sstitem
            HISTORY cards in a special format created by NDF2FITS are
            converted back into NDF history records.  This will only work
            provided the HISTORY headers have not been tampered.  Such
            headers are not transferred to the FITS airlock, when
            PROFITS={\tt TRUE}.
         }
         \newpage

         \sstitem
         IUE Final Archive LILO, LIHI, SILO, SIHI

         \ssthitemlist{

            \sstitem
            This converts an IUE LI or SI product stored as a FITS primary
            data array and IMAGE extension containing the quality into an
            NDF.  Other FITS headers are used to create AXIS structures (SI
            products only), and character components.

            \sstitem
            Details of the conversion are:

            \ssthitemlist{

               \sstitem
               The primary data array of the FITS file becomes NDF main
               data array.  The value of parameter FMTCNV controls whether
               keywords BSCALE and BZERO are applied to scale the data;
               FMTCNV along with the number of significant characters in the
               keywords decide the data type of the array.  It is expected
               that this will be \_REAL if FMTCNV is TRUE, and \_WORD
               otherwise.

               \sstitem
               The quality array comes from the IMAGE extension of the
               FITS file.  The twos complement values are divided by $-$128 to
               obtain the most-significant 8 bits of the 14 in use.  There is
               no check that the dimension and axis-defining FITS headers in
               this extension match those of the main data array.  The
               standard indicates that they will be the same.

               \sstitem
               The FILENAME header value becomes the NDF's TITLE component.

               \sstitem
               The BUNIT header value becomes the NDF's UNITS component.

               \sstitem
               The CDELT$n$, CRPIX$n$, and CRVAL$n$ define the axis centres.
               CTYPE$n$ defines the axis labels.  Axis information is only
               available for the SILO and SIHI products.

               \sstitem
               The primary headers may be written to the NDF's FITS
               extension when parameter PROFITS is {\tt TRUE}.
            }
         }
         \bigskip

         \sstitem
         IUE Final Archive MXLO

         \ssthitemlist{

            \sstitem
            This will usually be a single 1-dimensional NDF, however, if
            the binary table contains more than one row, a series of NDFs are
            stored in a single HDS container file whose name is specified by
            parameter OUT.  The name of each NDF is the row number.  Thus for
            OUT=ABC, the second observation will be in NDF ABC.2.

            \sstitem
            Only the most-significant 8 bits of the quality flags are
            transferred to the NDF.

            \sstitem
            The primary headers may be written to the standard FITS
            airlock extension when PROFITS is {\tt TRUE}.

            \sstitem
            The conversion from binary-table columns and headers to NDF
            objects is as follows:
            \medskip

            \begin{tabular}{lp{100mm}}
            NPOINTS            &   Number of elements \\
            WAVELENGTH         &   Start wavelength, axis label and units \\
            DELTAW             &   Incremental wavelength \\
            FLUX               &   Data array, label, units, bad-pixel flag \\
            SIGMA              &   Data-error array \\
            QUALITY            &   Quality array \\
            remaining columns  &   Component in IUE\_MX extension (NET and
                                   BACKGROUND are NDFs) \\
            \end{tabular}
         }
         \bigskip

         \sstitem
         ISO CAM auto-analysis (CMAP, CMOS)

         \ssthitemlist{

            \sstitem
            The CAM auto-analysis FITS products have a binary table
            using the {\tt "}Green Bank{\tt "} convention, where rows
            of the table represent a series of observations, and each
            row is equivalent to a normal simple header and data unit.  Thus
            most of the columns have the same names as
            the standard FITS keywords.

            \sstitem
            If there is only one observation, a normal NDF is produced; if
            there are more than one, the HDS container file of the supplied
            NDF is used to store a series of NDFs---one for each
            observation---called OBS$n$, where $n$ is the observation number.
            Each observation comprises three rows in the binary table
            corrsponding to the flux, the r.m.s. errors, and the integration
            times.

            \sstitem
            The conversion from binary-table columns to NDF objects is as
            follows:
            \medskip

            \begin{tabular}{lp{100mm}}
            ARRAY              &   Data, error, exposure arrays depending
                                   on the value of column TYPE \\
            BLANK              &   Data blank ({\tt{i.e.}}\ undefined value) \\
            BUNIT              &   Data units \\
            BSCALE             &   Data scale factor \\
            BZERO              &   Data offset \\
            CDELT$n$           &   Pixel increment along axis $n$ \\
            CRPIX$n$           &   Axis $n$ reference pixel \\
            CRVAL$n$           &   Axis $n$ co-ordinate of reference pixel \\
            CTYPE$n$           &   Label for axis $n$ \\
            CUNIT$n$           &   Units for axis $n$ \\
            NAXIS              &   Number of dimensions \\
            NAXIS$n$           &   Dimension of axis $n$ \\
            remaining columns  &   keyword in FITS extension \\
            \end{tabular}
            \medskip

            Some of these remaining columns overwrite the (global) values
            in the primary headers.  The integration times are stored as
            an NDF within an extension called EXPOSURE.
            \medskip

            The creation of axis information and extensions does not occur
            for the error array, as these are already generated when the
            data-array row in the binary table is processed.
            \medskip

            The BITPIX column is ignored as the data type is determined
            through the use the TFORM$n$ keyword and the value of FMTCNV in
            conjunction with the BSCALE and BZERO columns.
         }
         \bigskip

         \sstitem
         ISO LWS auto-analysis (LWS AN)

         \ssthitemlist{
            \sstitem
            The conversion from binary-table columns to NDF objects is
            as follows:
            \medskip

            \begin{tabular}{ll}
               LSANFLX            &   Data array, label, and units \\
               LSANFLXU           &   Data errors, hence variance \\
               LSANDET            &   Quality (bits 1 to 4) \\
               LSANSDIR           &   Quality (bit 5) \\
               LSANRPID           &   Axis centres, labels, and units
                                      $x$-$y$ positions---dimensions 1 and 2) \\
               LSANSCNT           &   Axis centre, label, and unit (scan
                                      (count index---dimension 4) \\
               LSANWAV            &   Axis centre, label, and unit
                                      (wavelength---dimension 3) \\
               LSANWAVU           &   Axis errors (wavelength---dimension 3) \\
               LSANFILL           &   not copied \\
               remaining columns  &   column name in LWSAN extension \\
            \end{tabular}
         }
         \bigskip

         \sstitem
         ISO SWS auto-analysis (SWS AA)

         \ssthitemlist{
            \sstitem
            The conversion from binary-table columns to NDF objects is
            as follows:
            \medskip

            \begin{tabular}{ll}
               SWAAWAVE           &   Axis centres, label, and units \\
               SWAAFLUX           &   Data array, label, and units \\
               SWAASTDV           &   Data errors, hence variance \\
               SWAADETN           &   Quality \\
               SWAARPID           &   not copied \\
               SWAASPAR           &   not copied \\
               remaining columns  &   column name in SWSAA extension \\
            \end{tabular}
         }
         \bigskip

         \sstitem
         AAO 2dF

         \ssthitemlist{

            \sstitem
            The conversion is restricted to a 2dF archive FITS file
            created by task NDF2FITS.  FITS2NDF restores the original NDF.
            It creates the 2dF FIBRES extension and its constituent
            structures, and NDF\_CLASS extension.  In addition the variance,
            axes, and HISTORY records are converted.

            \sstitem
            The HISTORY propagation assumes that the FITS HISTORY headers
            have not been tampered.

            \sstitem
            Details of the conversion are:

            \ssthitemlist{

               \sstitem
               The primary data array becomes the NDF's data array.  Any
               NaN values present become bad values in the NDF.

               \sstitem
               The keywords CRVAL$n$, CDELT$n$, CRPIX$n$, CTYPE$n$, CUNIT$n$ are
               used to create the NDF axis centres, labels, and units.

               \sstitem
               The OBJECT, LABEL, BUNIT keywords define the NDF's title,
               label, and units components respectively, if they are defined.

               \sstitem
               HISTORY cards in a special format created by NDF2FITS are
               converted back into NDF history records.

               \sstitem
               The NDF variance is derived from the data array of an
               IMAGE extension (usually the first), if present, provided the
               IMAGE extension headers have an HDUCLAS2 keyword whose value
               is either {\tt 'VARIANCE'} or {\tt 'ERROR'}.

               \sstitem
               The NDF\_CLASS extension within the NDF is filled using the
               a FITS binary-table extension whose EXTNAME keyword's value is
               NDF\_CLASS.  Note: no error is reported if this extension does
               not exist within the FITS file.

               \sstitem
               The FIBRES extension is created from another FITS binary table
               whose EXTNAME keyword's value is FIBRES.  The OBJECT
               substructure's component names, data types, and values are
               taken from the binary-table columns themselves, and the
               components of the FIELD substructure are extracted from
               recognised keywords in the binary-table's header.  Note:
               no error is reported if this extension does not exist within
               the FITS file.

               \sstitem
               A FITS extension in the NDF may be written to store the
               primary data unit's headers when parameter PROFITS is
               {\tt TRUE}.  This FITS airlock will not contain any
               NDF-style HISTORY records.
            }
         }
      }
   }
   \sstdiytopic{
      References
   }{
      \begin{refs}
      \item Bailey, J.A. 1997, 2dF Software Report 14, version 0.5.
      \item NASA Office of Standards and Technology, 1994, {\it A User's Guide
       for the Flexible Image Transport System (FITS)}, version 3.1.
      \item NASA Office of Standards and Technology, 1995, {\it Definition of
       the Flexible Image Transport System (FITS)}, version 1.1.
      \end{refs}
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{NDF2FITS}{NDF2FITS};
      \KAPPA: \xref{FITSDIN}{sun95}{FITSDIN}, \xref{FITSIN}{sun95}{FITSIN}.
   }
}

\newpage
\sstroutine{
   GASP2NDF
}{
   Converts an image in GASP format to an NDF
}{
   \sstdescription{
      This application converts a GAlaxy Surface Photometry (GASP)
      format file into an NDF.
   }
   \sstusage{
      gasp2ndf in out shape=?
   }
   \sstparameters{
      \sstsubsection{
         IN = LITERAL (Read)
      }{
         A character string containing the name of GASP file to convert.
         The extension should not be given, since {\tt ".dat"} is assumed.
      }
      \sstsubsection{
         OUT = NDF (Write)
      }{
         The name of the output NDF.
      }
      \sstsubsection{
         SHAPE( 2 ) = \_INTEGER (Read)
      }{
         The dimensions of the GASP image (the number of columns
         followed by the number of rows).  Each dimension must be in the
         range 1 to 1024.  This parameter is only used if supplied on
         the command line, or if the header file corresponding to the
         GASP image does not exist or cannot be opened.
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         gasp2ndf m31\_gasp m31
      }{
         Convert a GASP file called {\tt m31\_gasp.dat} into an NDF called
         m31.  The dimensions of the image are taken from the header file
         {\tt m31\_gasp.hdr}.
      }
      \sstexamplesubsection{
         gasp2ndf n1068 ngc1068 shape=[256,512]
      }{
         Take the pixel values in the GASP file {\tt n1068.dat} and create
         the NDF {\tt ngc1068} with dimensions 256 columns by 512 rows.
      }
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         A GASP image is limited to a maximum of 1024 by 1024 elements.
         It must be two dimensional.

         \sstitem
         The GASP image is written to the NDF's data array.  The data
         array has type \_WORD. No other NDF components are created.

         \sstitem
         If the header file is corrupted, you must remove the offending
         {\tt ".hdr"} file or specify the shape of the GASP image on the
         command line, otherwise the application will continually abort.
      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{NDF2GASP}{NDF2GASP}.
   }
   \sstdiytopic{
      References
   }{
      GASP documentation (MUD/66).
   }
}

\newpage
\sstroutine{
   GIF2NDF
}{
   Converts a GIF file into an NDF. 
}{
   \sstdescription{
      This Bourne-shell script converts a Graphics Interchange Format
      (GIF) file into an unsigned-byte (256 grey-level) NDF format file.
      It handles one- or two-dimensional images.  The script uses
      various PBMPLUS utilities to produce a FITS file, flipped top
      to bottom, and then \htmlref{FITS2NDF}{FITS2NDF} to produce the final NDF. 
      Error messages are converted into Starlink style (preceded by {\tt{!}}).
   }
   \sstusage{
      gif2ndf in [out]
   }
   \sstparameters{
      \sstsubsection{
         IN = FILENAME (Read)
      }{
         The name of the GIF file to be converted (without the {\tt .gif}
         extension, which is assumed).
      }
      \sstsubsection{
         OUT = NDF (Write)
      }{
         The name of the NDF to be generated (without the {\tt .sdf} extension).
         If the OUT parameter is omitted, the value of the IN parameter
         is used.
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         gif2ndf old new
      }{
         This converts the GIF file {\tt old.gif} into an NDF called new
         (in file {\tt new.sdf}).
      }
      \sstexamplesubsection{
         gif2ndf horse
      }{
         This converts the GIF file {\tt horse.gif} into an NDF called horse
         (in file {\tt horse.sdf}).
      }
   }

   \sstnotes{ 
      The following points should be remembered:
      \ssthitemlist{ 

         \sstitem
            This initial version of the script generates images with at most
            256 grey levels.  It does not use the image colour lookup table.

         \sstitem
            Input image filenames must have the file extension {\tt .gif}.

         \sstitem
            The PBMPLUS utilities {\tt giftopnm}, {\tt ppmtopgm} and
            {\tt pgmtofits} must be available on your PATH.
      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{NDF2GIF}{NDF2GIF}.
   }
}

\newpage
\sstroutine{
   IRAF2NDF
}{
   Converts an IRAF image to an NDF
}{
   \sstdescription{
      This application converts an IRAF image to an NDF.  See the Notes
      for details of the conversion.
   }
   \sstusage{
      iraf2ndf in out
   }
   \sstparameters{
      \sstsubsection{
         IN = LITERAL (Read)
      }{
         The name of the IRAF image.  Note that this excludes the
         {\tt ".imh"} file extension.
      }
      \sstsubsection{
         OUT = NDF (Write)
      }{
         The name of the NDF to be produced.
      }
      \sstsubsection{
         PROFITS = \_LOGICAL (Read)
      }{
         If {\tt TRUE}, the user headers of the IRAF file are written
         verbatim to the NDF's FITS extension.  Any IRAF history
         records are also appended to the FITS extension.  The FITS
         extension is not created if there are no user headers
         present in the IRAF file.  {\tt [TRUE]}
      }
      \sstsubsection{
         PROHIS = \_LOGICAL (Read)
      }{
         This parameter decides whether or not to create NDF HISTORY
         records.  Only the IRAF headers with keyword HISTORY, and
         which originated from NDF HISTORY records are used.  If
         PROHIS={\tt TRUE}, NDF HISTORY records are created.  {\tt [TRUE]}
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         iraf2ndf ell\_galaxy new\_galaxy
      }{
         Converts the IRAF image ell\_galaxy (comprising files
         {\tt ell\_galaxy.imh} and {\tt ell\_galaxy.pix}) to an NDF
         called new\_galaxy.
      }
      \sstexamplesubsection{
         iraf2ndf ell\_galaxy new\_galaxy noprofits noprohis
      }{
         As above, except no FITS extension is created, and NDF-style
         HISTORY lines in {\tt ell\_galaxy.imh} are not transferred to HISTORY
         records in NDF new\_galaxy.
      }
   }
   \sstnotes{
      The rules for the conversion are as follows:
      \ssthitemlist{

         \sstitem
         The NDF data array is copied from the {\tt ".pix"} file.

         \sstitem
         The title of the IRAF image (object i\_title in the {\tt ".imh"}
         header file) becomes the NDF title.  Likewise headers OBJECT and
         BUNIT become the NDF label and units respectively.

         \sstitem
         The pixel origin is set if any LBOUND$n$ headers are present.

         \sstitem
         Lines from the IRAF image header file may be transferred to
         the FITS extension of the NDF, when PROFITS={\tt TRUE}.  Any
         compulsory FITS keywords that are missing are added.  Certain
         other keywords are not propagated.  These are the IRAF ``Mini
         World Coordinate System'' (MWCS) keywords WCSDIM, DC\_FLAG,
         WAT$d$\_$nnn$ ($d$ is dimension, $nnn$ is the line number).
         Certain NDF-style HISTORY lines in the header are also
         be ignored when PROHIS={\tt TRUE} (see two notes below).

         \sstitem
         When PROFITS={\tt TRUE}, lines from the HISTORY section of the IRAF
         image are also extracted and added to the NDF's FITS extension as
         FITS HISTORY lines.  Two extra HISTORY lines are added to record
         the original name of the image and the date of the format
         conversion.

         \sstitem
         When PROHIS={\tt TRUE}, any HISTORY lines in the IRAF headers, which
         originated from an NDF2IRAF conversion of NDF HISTORY records.
         Such headers are not transferred to the FITS airlock, when
         PROFITS={\tt TRUE}.

         \sstitem
         Most axis information can be propagated either from standard
         FITS-like keywords, or certain MCWS headers.  Supported systems
         and formats are listed below.

         \sstitemlist{
            \medskip

            \sstitem
            FITS

            \ssthitemlist{
               \vspace*{-\bigskipamount}
               \sstitem
               linear

               \sstitem
               log-linear
            }
            \medskip

            \sstitem
            Equispec

            \ssthitemlist{
               \vspace*{-\bigskipamount}
               \sstitem
               linear

               \sstitem
               log-linear
            }
            \medskip

            \sstitem
            Multispec

            \ssthitemlist{
               \vspace*{-\bigskipamount}
               \sstitem
               linear

               \sstitem
               log-linear

               \sstitem
               Chebyshev and Legendre polynomials

               \sstitem
               Linear and cubic Spline

               \sstitem
               Explicit list of co-ordinates
               \vspace*{\medskipamount}
            }
         }

         However, for Multispec axes, only the first (spec1) axis
         co-ordinates are transferred to the NDF AXIS centres.  Any
         spec2 \dots spec$n$ co-ordinates, present when the data array is not
         one-dimensional or multiple fits have been stored, are ignored.
         The weights for multiple fits are thus also ignored.  The data
         type of the axis centres is \_REAL or \_DOUBLE depending on the
         number of significant digits in the co-ordinates or coefficients.

         The axis labels and units are also propagated, where present, to
         the NDF AXIS structure.  In the FITS system, these are derived
         from the CTYPE$n$ and CUNIT$n$ keywords.  In the MWCS, these
         components originate in the label and units parameters.

         The redshift correction, when present, is applied to the MCWS
         axis co-ordinates.

      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{NDF2IRAF}{NDF2IRAF}.
   }
   \sstdiytopic{
      Pitfalls
   }{
      \sstitemlist{

         \sstitem
         Bad pixels in the IRAF image are not replaced.

         \sstitem
         Some of the routines required for accessing the IRAF header
         file are written in SPP.  Macros are used to find the start of the
         header line section, this constitutes an `Interface violation' as
         these macros are not part of the IMFORT interface specification.
         It is possible that these may be changed in the future, so
         beware.
      }
   }
   \sstdiytopic{
      References
   }{
      IRAF User Handbook Volume 1A: ``A User's Guide to FORTRAN
      Programming in IRAF, the IMFORT Interface'', by Doug Tody.
   }
   \sstdiytopic{
      Keywords
   }{
      CONVERT, IRAF
   }
   \sstimplementationstatus{
      \sstitemlist{

         \sstitem
         Only handles one-, two-, and three-dimensional IRAF files.

         \sstitem
         The NDF produced has type \_WORD or \_REAL corresponding to the
         type of the IRAF image.  (The IRAF IMFORT FORTRAN subroutine
         library only supports these data types: signed words and real.)
         The pixel type of the image can be changed from within IRAF using
         the `chpixtype' task in the `images' package.
      }
   }
}

\newpage
\sstroutine{
   IRCAM2NDF
}{
   Converts an IRCAM data file to a series of NDFs
}{
   \sstdescription{
      This applications converts an HDS file in the IRCAM format listed
      in IRCAM User Note 11 to one or more NDFs.  See the Notes for a
      detailed list of the rules of the conversion.
   }
   \sstusage{
      ircam2ndf in prefix obs [config]
   }
   \sstparameters{
      \sstsubsection{
         CONFIG = LITERAL (Read)
      }{
         The choice of data array to place in the NDF.  It can have one
         of the following configuration values:
            \begin{itemize}
            \item {\tt "STARE"} --- the image of the object or sky;
            \item {\tt "CHOP"} --- the chopped image of the sky;
            \item {\tt "KTCSTARE"} --- the electronic pedestal or bias associated
                           with the stare image of the object or sky;
            \item{\tt "KTCCHOP"} --- the electronic pedestal or bias associated
                           with the chopped image of the sky.
            \end{itemize}
         Note that at the time of writing chopping has not been
         implemented for IRCAM.  For practical purposes CONFIG=\dqt{STARE}
         should be used.  The suggested default is the current value.
         {\tt ["STARE"]}
      }
      \sstsubsection{
         FMTCNV = \_LOGICAL (Read)
      }{
         This specifies whether or not format conversion may occur.
         If FMTCNV is {\tt FALSE}, the data type of the data array in the NDF
         will be the same as that in the IRCAM file, and there is no
         scale factor and offset applied.  If FMTCNV is {\tt TRUE}, whenever
         the IRCAM observation has non-null scale and offset values,
         the observation data array will be converted to type \_REAL in
         the NDF, and the scale and offset applied to the input data
         values to give the `true' data values.  A null scale factor is
         1 and a null offset is 0. {\tt [FALSE]}
      }
      \sstsubsection{
         IN = IRCAM (Read)
      }{
         The name of the input IRCAM file to convert to NDFs.  The
         suggested value is the current value.
      }
      \sstsubsection{
         OBS()  = LITERAL (Read)
      }{
         A list of the observation numbers to be converted into NDFs.
         Observations are numbered consecutively from 1 up to the
         actual number of observations in the IRCAM file.  Single
         observations or a set of adjacent observations may be
         specified, {\it e.g.}\ entering {\tt [4,6-9,12,14-16]} will read
         observations 4,6,7,8,9,12,14,15,16.  (Note that the brackets
         are required to distinguish this array of characters from a
         single string including commas.  The brackets are unnecessary
         when there is only one item.)

         If you wish to extract all the observations enter the wildcard
         {\tt $*$}.  {\tt 5-$*$} will read from 5 to the last observation.  The
         processing will continue until the last observation is
         converted.  The suggested value is the current value.
      }
      \sstsubsection{
         PREFIX = LITERAL (Read)
      }{
         The prefix of the output NDFs.  The name of an NDF is the
         prefix followed by the observation number.  The suggested
         value is the current value.
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         ircam2ndf ircam\_27aug89\_1cl rhooph obs=$*$
      }{
         This converts the IRCAM data file called {\tt ircam\_27aug89\_1cl} into
         a series of NDFs called rhooph1, rhooph2 {\it etc.}\  
         There is no format conversion applied.
      }
      \sstexamplesubsection{
         ircam2ndf ircam\_27aug89\_1cl rhooph [32,34-36] fmtcnv
      }{
         This converts four observations in the IRCAM data file called
         {\tt ircam\_27aug89\_1cl} into NDFs called rhooph32, 
         rhooph34, rhooph35, rhooph36.  The scale and offset
         are applied.
      }
      \sstexamplesubsection{
         ircam2ndf in=ircam\_04nov90\_1c config="KTC" obs=5 prefix=bias
      }{
         This converts the fifth observation in the IRCAM data file
         called {\tt ircam\_04nov90\_1c.sdf} into an NDF called bias5
         containing the electronic pedestal in its data array.  There is no 
         format conversion applied.
      }
   }
   \sstnotes{
      The rules for the conversion of the various components are as
      follows: \vspace*{-\medskipamount}
      \begin{center}
      \begin{tabular}{|lcl|p{37mm}|}
      \hline 
      \multicolumn{1}{|l}{IRCAM file} & & \multicolumn{1}{l}{NDF} &
      \multicolumn{1}{|c|}{Comments} \\ \hline
      .OBS.PHASEA.DATA\_ARRAY & $\Rightarrow$ &  .DATA\_ARRAY & 
          when parameter CONFIG={\tt "STARE"} \\
      .OBS.PHASEB.DATA\_ARRAY & $\Rightarrow$ &  .DATA\_ARRAY &
          when parameter CONFIG={\tt "CHOP"} \\
      .OBS.KTCA.DATA\_ARRAY   & $\Rightarrow$ &  .DATA\_ARRAY &
          when parameter CONFIG={\tt "KTCSTARE"} \\
      .OBS.KTCB.DATA\_ARRAY   & $\Rightarrow$ &  .DATA\_ARRAY &
          when parameter CONFIG={\tt "KTCCHOP"} \\
      & & & \\
      .OBS.DATA\_LABEL        & $\Rightarrow$ &  .LABEL & \\
      .OBS.DATA\_UNITS        & $\Rightarrow$ &  .UNITS & \\
      .OBS.TITLE              & $\Rightarrow$ &  .TITLE &
          If .OBS.TITLE is a blank string, OBS.DATA\_OBJECT is copied
          to the NDF title instead. \\
      .OBS.AXIS1\_LABEL       & $\Rightarrow$ &  .AXIS(1).LABEL & \\
      .OBS.AXIS2\_LABEL       & $\Rightarrow$ &  .AXIS(2).LABEL & \\
      .OBS.AXIS1\_UNITS       & $\Rightarrow$ &  .AXIS(1).UNITS & \\
      .OBS.AXIS2\_UNITS       & $\Rightarrow$ &  .AXIS(2).UNITS & \\ \hline
      \end{tabular}
      \end{center}

      \begin{center}
      \begin{tabular}{|lcl|p{35mm}|}
      \hline 
      \multicolumn{1}{|l}{IRCAM file} & & \multicolumn{1}{l}{NDF} &
      \multicolumn{1}{|c|}{Comments} \\ \hline
      \multicolumn{3}{|p{111mm}|}{
      .GENERAL.INSTRUMENT.PLATE\_SCALE 
          becomes the increment between the axis centres, with co-ordinate
          (0.0,0.0) located at the image centre.  The NDF axis units both
          become {\tt "arcseconds"}. } & \\
      & & & \\
      .GENERAL               & $\Rightarrow$ &  .MORE.IRCAM.GENERAL & \\
      .GENERAL.x             & $\Rightarrow$ &  .MORE.IRCAM.GENERAL.x & \\
      .GENERAL.x.y           & $\Rightarrow$ &  .MORE.IRCAM.GENERAL.x.y & \\
      & & & \\
      .OBS.x                 & $\Rightarrow$ &  .MORE.IRCAM.OBS.x &
          This excludes the components of OBS already listed above and
          DATA\_BLANK. \\ \hline
      \end{tabular}
      \end{center}

      \sstitemlist{

         \sstitem
         The data types of the IRCAM GENERAL structures have not been
         propagated to the NDF IRCAM extensions, because it would violate
         the rules of \xref{SGP/38}{sgp38}{}.  In the IRCAM file these all
         have the same type STRUCTURE.  The new data types are as follows:

      \begin{center}
      \begin{tabular}{|l|l|}
      \hline 
      \multicolumn{1}{|c|}{Extension Name} & \multicolumn{1}{c|}{Data Type} \\ \hline
      IRCAM.GENERAL & IRCAM\_GENERAL \\
      IRCAM.GENERAL.INSTRUMENT & IRCAM\_INSTRUM \\
      IRCAM.GENERAL.ID & IRCAM\_ID \\
      IRCAM.GENERAL.TELESCOPE & IRCAM\_TELESCOPE \\ \hline
      \end{tabular}
      \end{center}

         \sstitem
         Upon completion the number of observations
         successfully converted to NDFs is reported.
      }
   }
   \sstdiytopic{
      Bad-pixel Handling
   }{
      Elements of the data array equal to the IRCAM component
      .OBS.DATA\_BLANK are replaced by the standard bad value.
   }
   \sstimplementationstatus{
      \sstitemlist{

         \sstitem
         The data array in the NDF is in the primitive form.

         \sstitem
         The application aborts if the data array chosen by parameter
         CONFIG does not exist in the observation.
      }
   }
}

\newpage
\sstroutine{
   NDF2ASCII
}{
   Converts an NDF to a text file
}{
   \sstdescription{
      This application converts an NDF to a Fortran text file.  Only one of
      the array components may be copied to the output file.  Preceding
      the data there is an optional header consisting of either the
      FITS extension with the values of certain keywords replaced by
      information derived from the NDF, or a minimal FITS header also
      derived from the NDF.  The output file uses LIST carriagecontrol.
   }
   \sstusage{
      ndf2ascii in out [comp] [reclen] noperec=?
   }
   \sstparameters{
      \sstsubsection{
         COMP = LITERAL (Read)
      }{
         The NDF component to be copied.  It may be {\tt "Data"},
         {\tt "Quality"} or {\tt "Variance"}. {\tt ["Data"]}
      }
      \sstsubsection{
         FITS = \_LOGICAL (Read)
      }{
         If {\tt TRUE}, any FITS extension is written to start of the output
         file, unless there is no extension whereupon a minimal FITS
         header is written to the ASCII file. {\tt [FALSE]}
      }
      \sstsubsection{
         FIXED = \_LOGICAL (Read)
      }{
         When FIXED is {\tt TRUE}, the output file allocates a fixed number
         of characters per data value.  The number of characters chosen
         is the minimum that prevents any loss of precision, and hence
         is dependent on the data type of the NDF array.  These widths
         in characters for each HDS data type are as follows: \_UBYTE, 3;
         \_BYTE, 4; \_UWORD, 5; \_WORD, 6; \_INTEGER, 11; \_REAL, 16; and
         \_DOUBLE, 24.  The record length is the product of the number
         of characters per value plus one (for a delimiting space),
         times the number of values per record given by parameter
         NOPEREC, up to a maximum of 512.

         When FIXED is {\tt FALSE}, data values are packed as efficiently
         as possible within each record.  The length of each record is
         given by parameter RECLEN.  {\tt [FALSE]}
      }
      \sstsubsection{
         IN = NDF (Read)
      }{
         Input NDF data structure. The suggested default is the current
         NDF if one exists, otherwise it is the current value.
      }
      \sstsubsection{
         NOPEREC = \_INTEGER (Read)
      }{
         The number of data values per record of the output file, when
         FIXED is {\tt TRUE}.  It should be positive on UNIX platforms.
         The suggested default is the current value, or 8 when there
         is not one.  The upper limit is given by 512 divided by the
         number of characters per value plus 1 (see parameter FIXED).
      }
      \sstsubsection{
         OUT = FILENAME (Write)
      }{
         Name of the output formatted Fortran file.  The file will
         normally have variable-length records when there is a header,
         but always fixed-length records when there is no header.
      }
      \sstsubsection{
         RECLEN = \_INTEGER (Read)
      }{
         The maximum record length in bytes (characters) of the output
         file.  This has a maximum length of 512 (for efficiency
         reasons), and must be greater than 31 on UNIX systems.  The
         lower limit is further increased to 80 when there is a FITS
         header to be copied.  It is only used when FIXED is {\tt FALSE} and
         will default to the current value, or 132 if there is no
         current value.  {\tt []}
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         ndf2ascii cluster cluster.dat
      }{
         This copies the data array of the NDF called cluster to a text
         file called {\tt cluster.dat}.  The maximum recordlength of
         {\tt cluster.dat} is 132 bytes, and the data values are packed into
         these records as efficiently as possible.
      }
      \sstexamplesubsection{
         ndf2ascii cluster cluster.dat v
      }{
         This copies the variance of the NDF called cluster to a
         text file called {\tt cluster.dat}.  The maximum recordlength of
         {\tt cluster.dat} is 132 bytes, and the variance values are packed
         into these records as efficiently as possible.
      }
      \sstexamplesubsection{
         ndf2ascii cluster cluster.dat fixed noperec=12
      }{
         This copies the data array of the NDF called cluster to a
         text file called {\tt cluster.dat}.  There are twelve data values
         per record in {\tt cluster.dat}.
      }
      \sstexamplesubsection{
         ndf2ascii out=ndf234.dat fits reclen=80 in=@234
      }{
         This copies the data array of the NDF called 234 to a
         text file called {\tt ndf234.dat}.  The maximum recordlength of
         {\tt ndf234.dat} is 80 bytes, and the data values are packed into
         these records as efficiently as possible.  If there is a FITS
         extension, it is copied to {\tt ndf234.dat} with substitution of
         certain keywords, otherwise a minimal FITS header is produced.
      }
   }
   \sstnotes{
      The details of the conversion are as follows:
      \ssthitemlist{

         \sstitem
            the NDF array as selected by COMP is written to the ASCII
            file in records following an optional header.  When FIXED is
            {\tt FALSE} all records are padded out to the recordlength.

         \sstitem
            HISTORY is not propagated.

         \sstitem
            ORIGIN information is lost.

         \sstitem
            When a header is to be made, it is composed of FITS-like card
            images as follows:
      
         \sstitemlist{

            \sstitem
               The number of dimensions of the data array is written
               to the keyword NAXIS, and the actual dimensions to NAXIS1,
               NAXIS2 {\it etc.} as appropriate.

            \sstitem
               If the NDF contains any linear axis structures the
               information necessary to generate these structures is
               written to the FITS-like headers. For example, if a linear
               AXIS(1) structure exists in the input NDF the value of the
               first data point is stored with the keyword CRVAL1,
               and the incremental value between successive axis data is
               stored in keyword CDELT1.  By definition the reference pixel is
               1.0 and is stored in keyword CRPIX1.  If there is an axis label
               it is written to keyword CTYPE1, and axis unit is written to CUNIT1.
               (Similarly for AXIS(2) structures {\it etc.}) FITS does not have
               a standard method of storing axis widths and variances, so these
               NDF components will not be propagated to the header.
               Non-linear axis data arrays cannot be represented by CRVAL{\em{n}}
               and CDELT{\em{n}}, and must be ignored.

            \sstitem
               If the input NDF contains TITLE, LABEL or UNITS components
               these are stored with the keywords TITLE, LABEL or BUNIT
               respectively.

            \sstitem
               If the input NDF contains a FITS extension, the FITS items
               may be written to the FITS-like header, with the following
               exceptions:
               \begin{itemize}
               \item BITPIX is derived from the type of the NDF data array,
               and so it is not copied from the NDF FITS extension.
               \item NAXIS, and NAXIS{\em{n}} are derived from the dimensions of the
               NDF data array as described above, so these items are not
               copied from the NDF FITS extension.
               \item The TITLE, LABEL, and BUNIT descriptors are only copied
               if no TITLE, LABEL, and UNITS NDF components respectively
               have already been copied into these headers.
               \item The CDELT{\em{n}}, CRVAL{\em{n}}, CTYPE{\em{n}},
               CUNIT{\em{n}}, and CRTYPE{\em{n}} descriptors
               in the FITS extension are only copied if the input NDF
               contained no linear axis structures.
               \item The standard order of the FITS keywords is preserved,
               thus BITPIX, NAXIS and AXIS{\em{n}} appear immediately after the
               first card image, which should be SIMPLE.
               \item BSCALE and BZERO in a FITS extension are copied when
               BITPIX is positive, {\it i.e.} the array is not floating-point.
               \end{itemize}

            \sstitem
               An extra header record with keyword UNSIGNED and logical
               value T is added when the array data type is one of the HDS
               unsigned integer types.  This is done because standard FITS
               does not support unsigned integers, and allows (in conjunction
               with BITPIX) applications reading the unformatted file to
               determine the data type of the array.

            \sstitem
               The last header record card will be the standard FITS END.
         }

         \sstitem
            Other extensions are not propagated.
      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{ASCII2NDF}{ASCII2NDF};
      \KAPPA: \xref{TRANDAT}{sun95}{TRANDAT};
      \SPECDRE: \xref{ASCIN}{sun140}{ASCIN} and
      \xref{ASCOUT}{sun140}{ASCOUT}.
   }
   \sstimplementationstatus{
      \sstitemlist{

         \sstitem
         All non-complex numeric data types are supported.

         \sstitem
         The value of bad pixels is not written to a FITS-like header
         record with keyword BLANK.
      }
   }
}

\newpage
\sstroutine{
   NDF2DA
}{
   Converts an NDF to a direct-access unformatted file
}{
   \sstdescription{
      This application converts an NDF to a direct-access unformatted
      file, which is equivalent to fixed-length records, or a data
      stream suitable for reading by C routines.  Only one of the array
      components may be copied to the output file.
   }
   \sstusage{
      ndf2da in out [comp] [noperec]
   }
   \sstparameters{
      \sstsubsection{
         COMP = LITERAL (Read)
      }{
         The NDF component to be copied.  It may be {\tt "Data"},
         {\tt "Quality"} or {\tt "Variance"}. {\tt ["Data"]}
      }
      \sstsubsection{
         IN = NDF (Read)
      }{
         Input NDF data structure.  The suggested default is the current
         NDF if one exists, otherwise it is the current value.
      }
      \sstsubsection{
         NOPEREC = \_INTEGER (Read)
      }{
         The number of data values per record of the output file.  It
         must be positive.  The suggested default is the current value.
         {\tt{[}}The first dimension of the NDF{\tt{]}}
      }
      \sstsubsection{
         OUT = FILENAME (Write)
      }{
         Name of the output direct-access unformatted file.
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         ndf2da cluster cluster.dat
      }{
         This copies the data array of the NDF called cluster to a
         direct-access unformatted file called {\tt cluster.dat}.  The number
         of data values per record is equal to the size of the first
         dimension of the NDF.
      }
      \sstexamplesubsection{
         ndf2da cluster cluster.dat v
      }{
         This copies the variance of the NDF called cluster to a
         direct-access unformatted file called {\tt cluster.dat}.  The number
         of variance values per record is equal to the size of the
         first dimension of the NDF.
      }
      \sstexamplesubsection{
         ndf2da cluster cluster.dat noperec=12
      }{
         This copies the data array of the NDF called cluster to a
         direct-access unformatted file called cluster.dat.  There are
         twelve data values per record in {\tt cluster.dat}.
      }
   }
   \sstnotes{
      The details of the conversion are as follows:
      \ssthitemlist{

         \sstitem
            the NDF array as selected by COMP is written to the
            unformatted file in records.

         \sstitem
            all other NDF components are lost.
      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{DA2NDF}{DA2NDF}.
   }
}

\newpage
\sstroutine{
   NDF2DST
}{
   Converts an NDF to a Figaro (Version 2) DST file
}{
   \sstdescription{
      This application converts an NDF to a Figaro (Version 2) `DST'
      file.  The rules for converting the various components of a DST
      are listed in the notes.  Since both are hierarchical formats
      most files can be be converted with little or no information
      lost.
   }
   \sstusage{
      ndf2dst in out
   }
   \sstparameters{
      \sstsubsection{
         IN = NDF (Read)
      }{
         Input NDF data structure.  The suggested default is the
         current NDF if one exists, otherwise it is the current value.
      }
      \sstsubsection{
         OUT = Figaro (Write)
      }{
         Output Figaro file name. This excludes the file extension.
         The file created will be given extension {\tt ".dst"}.
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         ndf2dst old new
      }{
         This converts the NDF called old (in file {\tt old.sdf}) to the
         Figaro file {\tt new.dst}.
      }
      \sstexamplesubsection{
         ndf2dst spectre spectre
      }{
         This converts the NDF called spectre (in file {\tt spectre.sdf}) 
         to the Figaro file {\tt spectre.dst}.
      }
   }
   \sstnotes{
      The rules for the conversion are as follows:\vspace*{-\medskipamount}

      \begin{center}
      \begin{tabular}{|lcl|p{57mm}|}
      \hline 
      \multicolumn{1}{|c}{NDF} & & Figaro file &
      \multicolumn{1}{|c|}{Comments} \\ \hline
      Main data array  & $\Rightarrow$ & .Z.DATA & \\
      Imaginary array  & $\Rightarrow$ & .Z.IMAGINARY & \\
      Bad-pixel flag   & $\Rightarrow$ & .Z.FLAGGED & \\
      Units            & $\Rightarrow$ & .Z.UNITS & \\
      Label            & $\Rightarrow$ & .Z.LABEL & \\
      Variance         & $\Rightarrow$ & .Z.ERRORS & after processing \\
      Quality          & $\Rightarrow$ &  & It is not copied directly
                         though bad values indicated by QUALITY flags will
                         be flagged in .Z.DATA in addition to any flagged
                         values actually in the input main data array.
                         .Z.FLAGGED is set accordingly. \\ \hline
      \end{tabular}
      \end{center}

      \begin{center}
      \begin{tabular}{|lcl|p{54mm}|}
      \hline 
      \multicolumn{1}{|c}{NDF} & & Figaro file &
      \multicolumn{1}{|c|}{Comments} \\ \hline
      Title            & $\Rightarrow$ & .OBS.OBJECT & \\
      & & & \\
      AXIS(1) structure & $\Rightarrow$ & .X & \\
      AXIS(1) Data  & $\Rightarrow$ & .X.DATA\_ARRAY & unless there is a DATA
                          component of AXIS(1).MORE.FIGARO to allow for a 
                          non-1-dimensional array \\
      AXIS(1) Variance & $\Rightarrow$ & .X.VARIANCE & unless there is a
                          VARIANCE component of AXIS(1).MORE.FIGARO to
                          allow for a non-1-dimensional array \\
      AXIS(1) Width & $\Rightarrow$ & .X.WIDTH & unless there is a WIDTH
                          component of AXIS(1).MORE.FIGARO to
                          allow for a non-1-dimensional array \\
      AXIS(1) Units & $\Rightarrow$ & .X.UNITS & \\
      AXIS(1) Label & $\Rightarrow$ & .X.LABEL & \\
      AXIS(1).MORE.FIGARO.xxx & $\Rightarrow$ & .X.xxx & \\
      & & & Similarly for AXIS(2), \dots, AXIS(6) which are renamed to
           .Y .T .U .V or .W \\
      & & & \\
      FIGARO extension: & & & \\
      .MORE.FIGARO.MAGFLAG & $\Rightarrow$ & .Z.MAGFLAG & \\
      .MORE.FIGARO.RANGE & $\Rightarrow$ & .Z.RANGE & \\
      .MORE.FIGARO.SECZ & $\Rightarrow$ & .OBS.SECZ & \\
      .MORE.FIGARO.TIME & $\Rightarrow$ & .OBS.TIME & \\
      .MORE.FIGARO.xxx & $\Rightarrow$ & .xxx & recursively \\
      & & & \\
      FITS extension: & & & \\
      .MORE.FITS & & & \\
      Items  & $\Rightarrow$ & .FITS.xxx & \\
      Comments & $\Rightarrow$ & .COMMENTS.xxx & \\
      & & & \\
      Other extensions: & & & \\
      .MORE.other & $\Rightarrow$ & .MORE.other & \\ \hline
      \end{tabular}
      \end{center}
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{DST2NDF}{DST2NDF}.
   }
}

\newpage
\sstroutine{
   NDF2FITS
}{
   Converts NDFs into FITS files
}{
   \sstdescription{
      This application converts one or more NDF datasets into
      FITS-format files.  NDF2FITS stores any variance and quality
      information in IMAGE extensions (`sub-files') within the FITS
      file; and it uses binary tables to hold any NDF-extension data
      present, except for the FITS-airlock extension, which may be
      merged into the output FITS file's headers.

      You can select which NDF array components to export to the FITS
      file, and choose the data type of the data and variance arrays.
      You can control whether or not to propagate extensions and
      history information.
   }
   \sstusage{
      ndf2fits in out [comp] [bitpix] [origin]
   }
   \sstparameters{
      \sstsubsection{
         BITPIX = LITERAL (Read)
      }{
         The FITS bits-per-pixel (BITPIX) value for each conversion.
         This specifies the data type of the output FITS file.  Permitted
         values are: {\tt 8} for unsigned byte, {\tt 16} for signed word,
         {\tt 32} for integer, {\tt -32} for real, {\tt -64} for double
         precision.  There are two other special values.  BITPIX={\tt 0}
         will cause the output file to have the data type equivalent to
         that of the input NDF.  BITPIX={\tt -1} requests that the
         output file has the data type corresponding to the value of the
         BITPIX keyword in the NDF's FITS extension.  If the extension
         or BITPIX keyword is absent, the output file takes the data
         type of the input array.

         BITPIX values must be enclosed in double quotes and may be a list 
         of comma-separated values to be applied to each conversion in turn.
         An error results if more values than the number of input NDFs are
         supplied.  If too few are given, the last value in the list is
         applied to the remainder of the NDFs; thus a single value is 
         applied to all the conversions.  
         The given values must be in the same order as that of the input NDFs.
         Indirection through a text file may be used.
         If more than one line is required to enter the information at a prompt
         then type a {\tt "-"} at the end of each line where a
         continuation line is desired.
         {\tt [0]}
      }
      \sstsubsection{
         COMP = LITERAL (Read)
      }{
         The list of array components to attempt to transfer to each
         FITS file.  The acceptable values are {\tt "D"} for the main data
         array {\tt "V"} for variance, {\tt "Q"} for quality, or any permutation
         thereof.  The special value {\tt "A"} means all components,
         {\it i.e.}\ COMP=\dqt{DVQ}. Thus COMP=\dqt{VD} requests that 
         both the data array and variance are to be converted if present.  
         During processing at least one, if not all, of the requested
         components must be present, otherwise an error is reported and
         processing turns to the next input NDF.  If the data component
         is in the list, it will always be processed first into the
         FITS primary array.  The order of the variance and quality
         in COMP decides the order they will appear in the FITS file.

         COMP may be a list of comma-separated values to be applied to
         each conversion in turn.  The list must be enclosed in double quotes.
         An error results if more values than
         the number of input NDFs are supplied.  If too few are given,
         the last value in the list is applied to the remainder of the
         NDFs; thus a single value is applied to all the conversions.
         The given values must be in the same order as that of the
         input NDFs.  Indirection through a text file may be used.  If
         more than one line is required to enter the information at a prompt
         then type a {\tt "-"} at the end of each line where a continuation 
         line is desired.  {\tt ["A"]}
      }
      \sstsubsection{
         IN = LITERAL (Read)
      }{
         The names of the NDFs to be converted into FITS format.  It
         may be a list of NDF names or direction specifications
         separated by commas and enclosed in double quotes.  
         NDF names may include the regular
         expressions ({\tt "$*$"}, {\tt "?"}, {\tt "[a-z]"} {\it etc.}).
         Indirection may occur through text files (nested up to seven
         deep).  The indirection character is {\tt "$\wedge$"}.  If extra prompt
         lines are required, append the continuation character {\tt "-"} to
         the end of the line.  Comments in the indirection file begin
         with the character \hash.
      }
      \sstsubsection{
         ORIGIN = LITERAL (Read)
      }{
         The origin of the FITS files.  This becomes the value of the
         ORIGIN keyword in the FITS headers.  If a null value is given
         it defaults to {\tt "Starlink Project, U.K."}.
         {\tt [!]}
      }
      \sstsubsection{
         OUT = LITERAL (Write)
      }{
         The names for the output FITS files.  These may be enclosed in double
         quotes and specified as a list of comma-separated names, OR, using 
         modification elements to specify output filenames based on the input
         NDF filenames.  Indirection may be used if required. 

         The simplest modification element is the asterisk {\tt "$*$"}, which
         means call the output FITS files the same name (without any directory
         specification) as the corresponding input NDF, but with file 
         extension {\tt ".fit"} instead of the NDF's extension of {\tt ".sdf"}.

         Other types of modification can also occur so OUT=\dqt{x$*$}
         would mean that the output files would have the same name
         as the input NDFs except for an {\tt "x"} prefix and the
         file extension of {\tt ".fit"}.  You can also replace a specified
         string in the output filename, for example OUT=\dqt{x$*$|cal|Starlink|}
         replaces the string {\tt "cal"} with {\tt "Starlink"} in any of
         the output names {\tt "x$*$.fit"}.
      }
      \sstsubsection{
         PROEXTS = \_LOGICAL (Read)
      }{
         If {\tt TRUE}, the NDF extensions (other than the FITS extension)
         are propagated to the FITS files as FITS binary-table
         extensions, one per structure of the hierarchy. {\tt [FALSE]}
      }
      \sstsubsection{
         PROFITS = \_LOGICAL (Read)
      }{
         If {\tt TRUE}, the contents of the FITS extension of the NDF are
         merged with the header information derived from the standard
         NDF components.  See the Notes for details of the merger.
         {\tt [TRUE]}
      }
      \sstsubsection{
         PROHIS = \_LOGICAL (Read)
      }{
         If {\tt TRUE}, any NDF history records are written to the primary
         FITS header as HISTORY cards.  These follow the mandatory
         headers and any merged FITS-extension headers (see parameter
         PROFITS). {\tt [TRUE]}
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         ndf2fits horse logo.fit d
      }{
         This converts the NDF called horse to the FITS file called
         {\tt logo.fit}.  The data type of the FITS primary data array matches
         that of the NDF's data array.  The FITS extension in the NDF
         is merged into the FITS header of {\tt logo.fit}.
      }
      \sstexamplesubsection{
         ndf2fits horse logo.fit d proexts
      }{
         This converts the NDF called horse to the FITS file called
         {\tt logo.fit}.  The data type of the FITS primary data array matches
         that of the NDF's data array.  The FITS extension in the NDF
         is merged into the FITS header of {\tt logo.fit}.  In addition any
         NDF extensions (apart from FITS) are turned into binary tables
         that follow the primary header and data unit.
      }
      \sstexamplesubsection{
         ndf2fits horse logo.fit noprohis
      }{
         This converts the NDF called horse to the FITS file called
         {\tt logo.fit}.  The data type of the FITS primary data array matches
         that of the NDF's data array.  The FITS extension in the NDF
         is merged into the FITS header of {\tt logo.fit}.  Should horse
         contain variance and quality arrays, these are written in IMAGE
         extensions.  Any history information in the NDF is not relayed
         to the FITS file.
      }
      \sstexamplesubsection{
         ndf2fits "data/a$*$z" $*$ comp=v noprofits bitpix=-32
      }{
         This converts the NDFs with names beginning with {\tt "a"} and ending
         in {\tt "z"} in the directory called {\tt data} into FITS files of the
         same name and with a file extension of {\tt ".fit"}.  The variance
         array becomes the data array of each FITS file.  The data type
         of the FITS primary data array single-precision floating
         point.  Any FITS extension in the NDF is ignored.
      }
      \sstexamplesubsection{
         ndf2fits "abc,def" "jvp1.fit,jvp2.fit" comp=d  bitpix="16,-64"
      }{
         This converts the NDFs called abc and def into FITS files
         called {\tt jvp1.fit} and {\tt jvp2.fit} respectively.  
         The data type of the FITS primary data array is signed integer words
         in {\tt jvp1.fit}, and double-precision floating point in
         {\tt jvp2.fit}. The FITS extension in each NDFs is merged into the
         FITS header of the corresponding FITS file.
      }
   }
   \sstnotes{
      The rules for the conversion are as follows:
      \ssthitemlist{

         \sstitem
         The NDF main data array becomes the primary data array of the
         FITS file if it is in value of parameter COMP, otherwise the first
         array defined by parameter COMP will become the primary data
         array.  A conversion from floating point to integer or to a
         shorter integer type will cause the output array to be scaled and
         offset, the values being recorded in keywords BSCALE and BZERO.
         There is an offset (keyword BZERO) applied to signed byte and
         unsigned word types to make them unsigned-byte and signed-word
         values respectively in the FITS array (this is because FITS does
         not support these data types).

         \sstitem
         The FITS keyword BLANK records the bad values for integer
         output types.  Bad values in floating-point output arrays are
         denoted by IEEE not-a-number values.

         \sstitem
         The NDF's quality and variance arrays appear in individual
         FITS IMAGE extensions immediately following the primary header
         and data unit, unless that component already appears as the
         primary data array.  The quality array will always be written as
         an unsigned-byte array in the FITS file, regardless of the value
         of the parameter BITPIX.

         \sstitem
         Here are details of the processing of standard items from the
         NDF into the FITS header, listed by FITS keyword.

         \ssthitemlist{

            \sstitem
            SIMPLE, EXTEND, PCOUNT, GCOUNT -- all take their default
              values.

            \sstitem
            BITPIX, NAXIS, NAXISn -- are derived directly from the NDF
              data array;

            \sstitem
            CRVAL{\em{n}}, CDELT{\em{n}}, CRPIX{\em{n}}, CTYPE{\em{n}}, CUNIT{\em{n}} -- are derived from
              the NDF axis structures if possible.  If no linear NDF axis
              structures are present, the values in the NDF FITS extension
              are copied (when parameter PROFITS is {\tt TRUE}).  If any axes
              are non-linear, all FITS axis information is lost.

            \sstitem
            OBJECT, LABEL, BUNIT -- the values held in the NDF's title,
              label, and units components respectively are used if
              they are defined; otherwise any values found in the FITS
              extension are used (provided parameter PROFITS is {\tt TRUE}).

            \sstitem
            ORIGIN and DATE -- are created automatically.  However, the
              former may be overridden by an ORIGIN card in the NDF
              extension.

            \sstitem
            EXTNAME --- is the array-component name when the EXTNAME
              appears in the primary header or an IMAGE extension.  In a
              binary-table derived from an NDF extension, EXTNAME is the
              path of the extension within the NDF, the path separator
              being the usual dot.  The path includes the indices to
              elements of any array structures present; the indices are in
              a comma-separated list within parentheses.

            \sstitem
            EXTLEVEL --- is the level in the hierarchical structure of the
              extensions.  Thus a top-level extension has value 1,
              sub-components of this extension have value 2 and so on.

            \sstitem
            EXTTYPE --- is the data type of the NDF extension used to
              create a binary table.

            \sstitem
            EXTSHAPE --- is the shape of the NDF extension used to
            create a binary table.  It is a comma-separated list of the
            dimensions, and is 0 when the extension is not an array.

            \sstitem
            HDUCLAS1, HDUCLAS{\em{n}} -- {\tt "NDF"} and the
              array-component name respectively.

            \sstitem
            LBOUND{\em{n}} -- is the pixel origin for the $n^{\rm th}$ dimension
              when any of the pixel origins is not equal to 1.  (This is not a
              standard FITS keyword.)

            \sstitem
            XTENSION, BSCALE, BZERO, BLANK and END -- are not propagated
              from the NDF's FITS extension.  XTENSION will be set for
              any extension.  BSCALE and BZERO will be defined based on
              the chosen output data type in comparison with the NDF
              array's type, but cards with values 1.0 and 0.0 respectively
              are written to reserve places in the header section.  These
              `reservation' cards are for efficiency and they can always
              be deleted later.  BLANK is set to the Starlink standard bad
              value corresponding to the type specified by BITPIX, but only
              for integer types and not for the quality array.  It appears
              regardless of whether or not there are bad values actually
              present in the array; this is for the same efficiency reasons
              as before.  The END card terminates the FITS header.

           \sstitem
              HISTORY -- HISTORY headers are propagated from the FITS
              extension when PROFITS is {\tt TRUE}, and from the NDF
              history component when PROHIS is {\tt TRUE}.

         }

         \sstitem
         Extension information may be transferred to the FITS file when
         PROEXTS is {\tt TRUE}.  The whole hierarchy of extensions is propagated
         in order.  This includes substructures, and arrays of extensions
         and substructures.  However, at present, any extension structure
         containing only substructures is not propagated itself (as
         zero-column tables are not permitted), although its
         substructures may be converted.
 
         Each extension or substructure creates a one-row binary table,
         where the columns of the table correspond to the primitive
         (non-structure) components.  The name of each column is the
         component name.  The column order is the same as the component
         order.  The shapes of multi-dimensional arrays are recorded using
         the TDIM$n$ keyword, where $n$ is the column number.  The HEASARCH
         convention for specifying the width of character arrays (keyword
         TFORM$n$='$r$A$w$', where $r$ is the total number of characters in the
         column and $w$ is the width of an element) is used.  The EXTNAME,
         EXTTYPE, EXTSHAPE and EXTLEVEL keywords (see above) are written
         to the binary-table header.

      }
   }
   \sstdiytopic{
      Special Formats
   }{
      In the general case, NDF extensions (excluding the FITS extension)
      may be converted to one-row binary tables in the FITS file when
      parameter PROEXTS is {\tt TRUE}.  This preserves the information, but it
      may not be accessible to the recipient's FITS reader.  Therefore,
      in some cases it is desirable to understand the meanings of
      certain NDF extensions, and create standard FITS products for
      compatibility.

      At present only one product is supported, but others may be added
      as required.

      \sstitemlist{

         \sstitem
         AAO 2dF

         Standard processing is used except for the 2dF FIBRES extension
         and its constituent structures.  The NDF may be restored from the
         created FITS file using FITS2NDF.  The FIBRES extension converts
         to the second binary table in the FITS file (the NDF\_CLASS
         extension appears in the first).

         To propagate the OBJECT substructure, NDF2FITS creates a binary
         table of constant width (224 bytes) with one row per fibre.  The
         total number of rows is obtained from component NUM\_FIBRES.  If a
         possible OBJECT component is missing from the NDF, a null column
         is written for that component.  The columns inherit the data
         types of the OBJECT structure's components.  Column meanings and
         units are assigned based upon information in the reference given
         below.

         The FIELD structure components are converted into additional
         keywords of the same name in the binary-table header, with the
         exception that components with names longer than 8 characters
         have abbreviated keywords: UNALLOC$xxx$ become UNAL-$xxx$ ($xxx$=OBJ,
         GUI, or SKY), CONFIGMJD becomes CONFMJD, and $x$SWITCHOFF become
         $x$SWTCHOF ($x$=X or Y).  If any FIELD component is missing it is
         ignored.

         Keywords for the extension level, name, and type appear in the
         binary-table header.
      }
   }
   \sstdiytopic{
      References
   }{
      \begin{refs}
      \item Bailey, J.A. 1997, 2dF Software Report 14, version 0.5.
      \item NASA Office of Standards and Technology, 1994, {\it A User's Guide
       for the Flexible Image Transport System (FITS)}, version 3.1.
      \item NASA Office of Standards and Technology, 1995, {\it Definition of
       the Flexible Image Transport System (FITS)}, version 1.1.
      \end{refs}
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{FITS2NDF}{FITS2NDF};
      \KAPPA: \xref{FITSDIN}{sun95}{FITSDIN}, \xref{FITSIN}{sun95}{FITSIN}.
   }
   \sstimplementationstatus{
      \sstitemlist{

         \sstitem
         All NDF data types are supported.
      }
   }
}

\newpage
\sstroutine{
   NDF2GASP
}{
   Converts a two-dimensional NDF into a GASP image
}{
   \sstdescription{
      This application converts a two-dimensional NDF into the GAlaxy
      Surface Photometry (GASP) package's format.  See the Notes for the
      details of the conversion.
   }
   \sstusage{
      ndf2gasp in out [fillbad]
   }
   \sstparameters{
      \sstsubsection{
         IN = NDF (Read)
      }{
         The input NDF data structure. The suggested default is the
         current NDF if one exists, otherwise it is the current value.
      }
      \sstsubsection{
         FILLBAD = \_INTEGER (Read)
      }{
         The value used to replace bad pixels in the NDF's data array
         before it is copied to the GASP file.  The value must be in the
         range of signed words ($-$32768 to 32767).  A null value ({\tt{!}})
         means no replacements are to be made.  This parameter is
         ignored if there are no bad values.  {\tt [!]}
      }
      \sstsubsection{
         OUT = LITERAL (Write)
      }{
         The name of the output GASP image.  Two files are produced
         with the same name but different extensions.  The {\tt ".dat"} file
         contains the data array, and {\tt ".hdr"} is the associated header
         file that specifies the dimensions of the image.  The
         suggested default is the current value.
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         ndf2gasp abell1367 a1367
      }{
         Converts an NDF called abell1367 into the GASP image comprising
         the pixel file {\tt a1367.dat} and the header file {\tt a1367.hdr}.
         If there are any bad values present they are copied verbatim to
         the GASP image.
      }
      \sstexamplesubsection{
         ndf2gasp ngc253 ngc253 fillbad=-1
      }{
         Converts the NDF called ngc253 to a GASP image comprising the
         pixel file {\tt ngc253.dat} and the header file {\tt ngc253.hdr}.
         Any bad values in the data array are replaced by minus one.
      }
   }
   \sstnotes{
      The rules for the conversion are as follows:
      \ssthitemlist{

         \sstitem
         The NDF data array is copied to the {\tt ".dat"} file.

         \sstitem
         The dimensions of the NDF data array is written to the {\tt ".hdr"}
         header file.

         \sstitem
         All other NDF components are ignored.
      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{GASP2NDF}{GASP2NDF}.
   }
   \sstdiytopic{
      References
   }{
      GASP documentation (MUD/66).
   }
   \sstimplementationstatus{
      \sstitemlist{

         \sstitem
         The GASP image produced has by definition type SIGNED WORD.
         There is type conversion of the data array to this type.

         \sstitem
         Bad values may arise due to type conversion.  These too are
         substituted by the (non-null) value of FILLBAD.

         \sstitem
         For an NDF with an odd number of columns, the last column from
         the GASP image is trimmed.
      }
   }
}

\newpage
\sstroutine{
   NDF2GIF
}{
   Converts an NDF into a GIF file.
}{
   \sstdescription{
      This Bourne-shell script converts an NDF into a 256 grey-level
      Graphics Interchange Format (GIF) file.  One- or two-dimensional
      images can be handled.  The script uses the CONVERT utility
      \htmlref{NDF2TIFF}{NDF2TIFF} to produce a TIFF file and then
      various PBMPLUS utilities to convert the TIFF file into a GIF file. 

      Error messages are converted into Starlink style (preceded by {\tt{!}}).
   }
   \sstusage{
      ndf2gif in [out]
   }
   \sstparameters{
      \sstsubsection{
         IN = NDF (Read)
      }{
         The name of the input NDF (without the {\tt .sdf} extension).
      }
      \sstsubsection{
         OUT = FILENAME (Write)
      }{
         The name of the GIF file to be generated (without the {\tt .gif}
         extension, which is appended).
         If this is omitted, the value of the IN parameter is used.
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         ndf2gif old new
      }{
         This converts the NDF called old (in file {\tt old.sdf})
         into a GIF file {\tt new.gif}.
      }
   }
   \sstnotes{
      The following points should be remembered:
      \ssthitemlist{

         \sstitem
            This initial version of the script generates only 256 grey 
            levels and does not use the image colour lookup table so
            absolute data values may be lost.

         \sstitem
            The PBMPLUS utilities {\tt tifftopnm} and {\tt ppmtogif}
            must be available on your PATH.

         \sstitem
         At the time of writing, this utility uses a special Netpbm version
         of {\bf tifftopnm} on alpha OSF/1 due to a problem with {\bf tifftopnm}
         in the standard release of PBMPLUS.  Netpbm is based on PBMPLUS but
         contains many improvements and additions.
      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{GIF2NDF}{GIF2NDF}.
   }
}

\newpage
\sstroutine{
   NDF2IRAF
}{
   Converts an NDF to an IRAF image
}{
   \sstdescription{
      This application converts an NDF to an IRAF image.  See the Notes
      for details of the conversion.
   }
   \sstusage{
      ndf2iraf in out [fillbad]
   }
   \sstparameters{
      \sstsubsection{
         IN = NDF (Read)
      }{
         The input NDF data structure.  The suggested default is the
         current NDF if one exists, otherwise it is the current value.
      }
      \sstsubsection{
         FILLBAD = \_REAL (Read)
      }{
         The value used to replace bad pixels in the NDF's data array
         before it is copied to the IRAF file.  A null value ({\tt{!}}) means
         no replacements are to be made.  This parameter is ignored if
         there are no bad values.  {\tt [0]}
      }
      \sstsubsection{
         OUT = LITERAL (Write)
      }{
         The name of the output IRAF image.  Two files are produced
         with the same name but different extensions. The {\tt ".pix"} file
         contains the data array, and {\tt ".imh"} is the associated header
         file that may contain a copy of the NDF's FITS extension.
         The suggested default is the current value.
      }
      \sstsubsection{
         PROFITS = \_LOGICAL (Read)
      }{
         If {\tt TRUE}, the contents of the FITS extension of the NDF are
         merged with the header information derived from the standard
         NDF components.  See the Notes for details of the merger.
         {\tt [TRUE]}
      }
      \sstsubsection{
         PROHIS = \_LOGICAL (Read)
      }{
         If {\tt TRUE}, any NDF history records are written to the primary
         FITS header as HISTORY cards.  These follow the mandatory
         headers and any merged FITS-extension headers (see parameter
         PROFITS).  {\tt [TRUE]}
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         ndf2iraf abell119 a119
      }{
         Converts an NDF called abell119 into the IRAF image comprising
         the pixel file {\tt a119.pix} and the header file {\tt a119.imh}.  If there
         are any bad values present they are copied verbatim to the IRAF
         image.
      }
      \sstexamplesubsection{
         ndf2iraf abell119 a119 noprohis
      }{
         As the previous example, except that NDF HISTORY records are
         not transferred to the headers in {\tt a119.imh}.
      }
      \sstexamplesubsection{
         ndf2iraf qsospe qsospe fillbad=0
      }{
         Converts the NDF called qsospe to an IRAF image comprising the
         pixel file {\tt qsospe.imh} and the header file {\tt qsospe.pix}.  Any bad
         values in the data array are replaced by zero.
      }
      \sstexamplesubsection{
         ndf2iraf qsospe qsospe fillbad=0 profits=f
      }{
         As the previous example, except that any FITS airlock
         information in the NDF are not transferred to the headers in
         {\tt qsospe.imh}.
      }
   }
   \sstnotes{
      The rules for the conversion are as follows:
      \ssthitemlist{

         \sstitem
         The NDF data array is copied to the {\tt ".pix"} file.  Ancillary
         information listed below is written to the {\tt ".imh"} header file in
         FITS-like headers.

         \sstitem
         The IRAF ``Mini World Coordinate System'' (MWCS) is used to
         record axis information whenever one of the following criteria is
         satisfied:

         \begin{enumerate}
            \item the dataset has some linear axes (system=world);

            \item the dataset is one-dimensional with a non-linear axis, or is
            two-dimensional with the first axis non-linear and the
            second being some aperture number or index
            (system=multispec);

            \item the dataset has a linear spectral/dispersion axis along the
            first dimension and all other dimensions are pixel indices
            (system=equispec).
         \end{enumerate}

         \sstitem
         The NDF title, label, units are written to the header keywords
         TITLE, OBJECT, and BUNIT respectively if they are defined.
         Otherwise anys values for these keywords found in the FITS
         extension are used (provided parameter PROFITS is {\tt TRUE}).  There
         is a limit of twenty characters for each.

         \sstitem
         The NDF pixel origins are stored in keywords LBOUND$n$ for the
         nth dimension when any of the pixel origins is not equal to 1.

         \sstitem
         Keywords HDUCLAS1, HDUCLAS$n$ are set to {\tt "NDF"} and the
         array-component name respectively.

         \sstitem
         The BLANK keyword is set to the Starlink standard bad value,
         but only for the \_WORD data type and not for a quality array.  It
         appears regardless of whether or not there are bad values
         actually present in the array.

         \sstitem
         HISTORY headers are propagated from the FITS extension when
         PROFITS is {\tt TRUE}, and from the NDF history component when PROHIS
         is {\tt TRUE}.

         \sstitem
         If there is a FITS extension in the NDF, then the elements up
         to the first END keyword of this are added to the `user area' of
         the IRAF header file, when PROFITS={\tt TRUE}.  However, certain
         keywords are excluded: SIMPLE, NAXIS, NAXIS$n$, BITPIX, EXTEND,
         PCOUNT, GCOUNT, BSCALE, BZERO, END, and any already created from
         standard components of the NDF listed above.

         \sstitem
         A HISTORY record is added to the IRAF header file indicating
         that it originated in the named NDF and was converted by
         NDF2IRAF.

         \sstitem
         All other NDF components are not propagated.
      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{IRAF2NDF}{IRAF2NDF}.
   }
   \sstdiytopic{
      Pitfalls
   }{
      The IMFORT routines refuse to overwrite an IRAF image if an image
      with the same name exists.  The application then aborts.

      Some of the routines required for accessing the IRAF header image
      are written in SPP. Macros are used to find the start of the
      header line section, this constitutes an `Interface violation' as
      these macros are not part of the IMFORT interface specification.
      It is possible that these may be changed in the future, so
      beware.
   }
   \sstdiytopic{
      References
   }{
      IRAF User Handbook Volume 1A: ``A User's Guide to FORTRAN
      Programming in IRAF, the IMFORT Interface'', by Doug Tody.
    }
   \sstimplementationstatus{
      \sstitemlist{

         \sstitem
         Only handles one-, two-, and three-dimensional NDFs.

         \sstitem
         Of the NDF's array components only the data array may be
         copied.

         \sstitem
         The IRAF image produced has type SIGNED WORD or REAL dependent
         of the type of the NDF's data array.  (The IRAF IMFORT FORTRAN
         subroutine library only supports these data types.)  For \_BYTE,
         \_UBYTE, and \_WORD data arrays the IRAF image will have type
         SIGNED WORD; for all other data types of the NDF data array a
         REAL IRAF image is made.  The pixel type of the image can be
         changed from within IRAF using the `chpixtype' task in the
         `images' package.

         \sstitem
         Bad values may arise due to type conversion.  These too are
         substituted by the (non-null) value of FILLBAD.
      }
   }
}

\newpage
\sstroutine{
   NDF2PGM
}{
   Converts an NDF to a PBMPLUS-style PGM-format file.
}{
   \sstdescription{
      This application converts an NDF to a PBMPLUS PGM-format file.
      The programme first finds the brightest and darkest pixel values 
      in the image.  It then uses these to determine suitable scaling
      factors to convert the image into an 8-bit representation.  These
      are then output to a simple greyscale PBMPLUS PGM file.
   }
   \sstusage{
      ndf2pgm in out
   }
   \sstparameters{
      \sstsubsection{
         IN = NDF (Read)
      }{
         The name of the input NDF data structure (without the {\tt .sdf} 
         extension).  The suggested default is the current NDF if one exists,
         otherwise it is the current value.
      }
      \sstsubsection{
         OUT = \_CHAR (Read)
      }{
         The name of the PGM file be generated.
         The {\tt .pgm} name extension is added to any output filename that
         does not contain it.     
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         ndf2pgm old new
      }{
         This converts the NDF called old (in file {\tt old.sdf}) to the
         PGM file {\tt new.pgm}.
      }
      \sstexamplesubsection{
         ndf2pgm in=spectre out=spectre.pgm
      }{
         This converts the NDF called spectre (in file {\tt spectre.sdf}) 
         to the PGM file {\tt spectre.pgm}.
      }
   }
   \sstnotes{
      This programme was written for diagnostic purposes and is included just
      in case someone finds it useful.
   }
   \sstimplementationstatus{
      Bad values in the data array are replaced with zero in the output
      PGM file.
   }
}

\newpage
\sstroutine{
   NDF2TIFF
}{
   Converts an NDF to an 8-bit TIFF-6.0-format file.
}{
   \sstdescription{
      This application converts an NDF to a Tag Image File Format (TIFF).
      One- or two-dimensional arrays can be handled.

      The routine first finds the brightest and darkest pixel values in the 
      image.  It then uses these to determine suitable scaling factors to
      convert the image into an 8-bit representation.  These are then output 
      to a simple greyscale TIFF-6.0 file.
   }
   \sstusage{
      ndf2tiff in out
   }
   \sstparameters{
      \sstsubsection{
         IN = NDF (Read)
      }{
         The name of the input NDF data structure (without the {\tt .sdf} 
         extension).  The suggested default is the current NDF if one exists,
         otherwise it is the current value.
      }
      \sstsubsection{
         OUT = \_CHAR (Read)
      }{
         The name of the TIFF file to be generated.
         The {\tt .tif} name extension is added to any output filename that
         does not contain it.     
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         ndf2tiff old new
      }{
         This converts the NDF called old (in file {\tt old.sdf}) to the
         TIFF file called {\tt new.tif}.
      }
      \sstexamplesubsection{
         ndf2tiff in=spectre out=spectre.tif
      }{
         This converts the NDF called spectre (in file {\tt spectre.sdf}) 
         to the TIFF file called {\tt spectre.tif}.
      }
   }
   \sstnotes{
      This application generates only 256 grey levels and does not use 
      any image colour lookup table so absolute data values may be lost.

      No compression is applied.
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{TIFF2NDF}{TIFF2NDF}.
   }
   \sstimplementationstatus{
      Bad values in the data array are replaced with zero in the output
      TIFF file.
   }
}

\newpage
\sstroutine{
   NDF2UNF
}{
   Converts an NDF to a sequential unformatted file
}{
   \sstdescription{
      This application converts an NDF to a sequential unformatted
      Fortran file.  Only one of the array components may be copied to
      the output file.  Preceding the data there is an optional header
      consisting of either the FITS extension with the values of
      certain keywords replaced by information derived from the NDF, or
      a minimal FITS header also derived from the NDF.
   }
   \sstusage{
      ndf2unf in out [comp] [noperec]
   }
   \sstparameters{
      \sstsubsection{
         COMP = LITERAL (Read)
      }{
         The NDF component to be copied.  It may be {\tt "Data"},
         {\tt "Quality"} or {\tt "Variance"}. {\tt ["Data"]}
      }
      \sstsubsection{
         FITS = \_LOGICAL (Read)
      }{
         If {\tt TRUE}, any FITS extension is written to start of the output
         file, unless there is no extension whereupon a minimal FITS
         header is written to the unformatted file. {\tt [FALSE]}
      }
      \sstsubsection{
         IN = NDF (Read)
      }{
         Input NDF data structure. The suggested default is the current
         NDF if one exists, otherwise it is the current value.
      }
      \sstsubsection{
         NOPEREC = \_INTEGER (Read)
      }{
         The number of data values per record of the output file.  It
         must be positive.  The suggested default is the current value.
         {\tt{[}}The first dimension of the NDF{\tt{]}}
      }
      \sstsubsection{
         OUT = FILENAME (Write)
      }{
         Name of the output sequential unformatted file.  The file will
         but always fixed-length records when there is no header.
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         ndf2unf cluster cluster.dat
      }{
         This copies the data array of the NDF called cluster to an
         unformatted file called {\tt cluster.dat}.  The number of data values
         per record is equal to the size of the first dimension of the
         NDF.
      }
      \sstexamplesubsection{
         ndf2unf cluster cluster.dat v
      }{
         This copies the variance of the NDF called cluster to an
         unformatted file called {\tt cluster.dat}.  The number of variance
         values per record is equal to the size of the first dimension
         of the NDF.
      }
      \sstexamplesubsection{
         ndf2unf cluster cluster.dat noperec=12
      }{
         This copies the data array of the NDF called cluster to an
         unformatted file called {\tt cluster.dat}.  There are twelve data
         values per record in {\tt cluster.dat}.
      }
      \sstexamplesubsection{
         ndf2unf out=ndf234.dat fits in=@234
      }{
         This copies the data array of the NDF called 234 to an
         unformatted file called {\tt ndf234.dat}.  The number of data values
         per record is equal to the size of the first dimension of the
         NDF.  If there is a FITS extension, it is copied to {\tt ndf234.dat}
         with substitution of certain keywords, otherwise a minimal
         FITS header is produced.
      }
   }
   \sstnotes{
      The details of the conversion are as follows:
      \ssthitemlist{

         \sstitem
            the NDF array as selected by COMP is written to the
            unformatted file in records following an optional header.

         \sstitem
            HISTORY is not propagated.

         \sstitem
            ORIGIN information is lost.

         \sstitem
            When a header is to be made, it is composed of FITS-like card
            images as follows:
      
         \sstitemlist{

            \sstitem
               The number of dimensions of the data array is written
               to the keyword NAXIS, and the actual dimensions to NAXIS1,
               NAXIS2 {\it etc.} as appropriate.

            \sstitem
               If the NDF contains any linear axis structures the
               information necessary to generate these structures is
               written to the FITS-like headers. For example, if a linear
               AXIS(1) structure exists in the input NDF the value of the
               first data point is stored with the keyword CRVAL1,
               and the incremental value between successive axis data is
               stored in keyword CDELT1.  By definition the reference pixel is
               1.0 and is stored in keyword CRPIX1.  If there is an axis label
               it is written to keyword CTYPE1, and axis unit is written to CUNIT1.
               (Similarly for AXIS(2) structures {\it etc.}) FITS does not have
               a standard method of storing axis widths and variances, so these
               NDF components will not be propagated to the header.
               Non-linear axis data arrays cannot be represented by CRVAL{\em{n}}
               and CDELT{\em{n}}, and must be ignored.

            \sstitem
               If the input NDF contains TITLE, LABEL or UNITS components
               these are stored with the keywords TITLE, LABEL or BUNIT
               respectively.

            \sstitem
               If the input NDF contains a FITS extension, the FITS items
               may be written to the FITS-like header, with the following
               exceptions:
               \begin{itemize}
               \item BITPIX is derived from the type of the NDF data array,
               and so it is not copied from the NDF FITS extension.
               \item NAXIS, and NAXIS{\em{n}} are derived from the dimensions of the
               NDF data array as described above, so these items are not
               copied from the NDF FITS extension.
               \item The TITLE, LABEL, and BUNIT descriptors are only copied
               if no TITLE, LABEL, and UNITS NDF components respectively
               have already been copied into these headers.
               \item The CDELT{\em{n}}, CRVAL{\em{n}}, CTYPE{\em{n}},
               CUNIT{\em{n}}, and CRTYPE{\em{n}} descriptors
               in the FITS extension are only copied if the input NDF
               contained no linear axis structures.
               \item The standard order of the FITS keywords is preserved,
               thus BITPIX, NAXIS and NAXIS{\em{n}} appear immediately after the
               first card image, which should be SIMPLE.
               \item BSCALE and BZERO in a FITS extension are copied when
               BITPIX is positive, {\it i.e.} the array is not floating-point.
               \end{itemize}

            \sstitem
               An extra header record with keyword UNSIGNED and logical
               value T is added when the array data type is one of the HDS
               unsigned integer types.  This is done because standard FITS
               does not support unsigned integers, and allows (in conjunction
               with BITPIX) applications reading the unformatted file to
               determine the data type of the array.

            \sstitem
               The last header record card will be the standard FITS END.
         }

         \sstitem
            Other extensions are not propagated.
      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{UNF2NDF}{UNF2NDF}.
   }
   \sstimplementationstatus{
      \sstitemlist{

         \sstitem
         The value of bad pixels is not written to a FITS-like header
         record with keyword BLANK.
      }
   }
}

\newpage
\sstroutine{
   TIFF2NDF
}{
   Converts a TIFF file into an NDF. 
}{
   \sstdescription{
      This Bourne-shell script converts a 256 grey-level or
      black-and-white dithered Tag Image File Format (TIFF) into an
      unsigned-byte NDF file.  It handles one- or two-dimensional
      images.  The script uses various PBMPLUS utilities to produce a
      FITS file, flipped top to bottom, and then
      \htmlref{FITS2NDF}{FITS2NDF} to produce
      the final NDF.  Error messages are converted into Starlink style
      (preceded by {\tt !}).
   }
   \sstusage{
      tiff2ndf in [out]
   }
   \sstparameters{
      \sstsubsection{
         IN = FILENAME (Read)
      }{
         The name of the TIFF file to be converted (without the {\tt .tif}
         extension, which is assumed).
      }
      \sstsubsection{
         OUT = NDF (Write)
      }{
         The name of the NDF to be generated (without the {\tt .sdf} extension).
         If this is omitted, the value of the IN parameter is used.
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         tiff2ndf old new
      }{
         This converts the TIFF file {\tt old.tif} into an NDF called new
         (in file {\tt new.sdf}).
      }
      \sstexamplesubsection{
         tiff2ndf horse
      }{
         This converts the TIFF file {\tt horse.tif} into an NDF called horse
         (in file {\tt horse.sdf}).
      }
   }
   \sstnotes{
      The following points should be remembered:
      \ssthitemlist{

         \sstitem
            This initial version of the script handles only greyscale
            or b/w dithered images.  You are responsible for conversion
            of your images to this format prior to use, including 
            the conversion of RGB values to brightness values.

         \sstitem
            Input image file names must have the extension {\tt .tif}.

         \sstitem
            The PBMPLUS utilities {\bf tifftopnm}, {\bf ppmtopgm} and
            {\bf pgmtofits} must be available on your PATH.
      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{NDF2TIFF}{NDF2TIFF}.
   }
}

\newpage
\sstroutine{
   UNF2NDF
}{
   Converts a sequential unformatted file to an NDF
}{
   \sstdescription{
      This application converts a sequential unformatted Fortran file to
      an NDF.  Only one of the array components may be created from the
      input file.  Preceding the input data there may be an optional
      header.  This header may be skipped, or may consist of a simple
      FITS header.  In the former case the shape of the NDF has be to
      be supplied.
   }
   \sstusage{
      unf2ndf in out [comp] noperec [skip] shape [type]
   }
   \sstparameters{
      \sstsubsection{
         COMP = LITERAL (Read)
      }{
         The NDF component to be copied.  It may be {\tt "Data"},
         {\tt "Quality"} or {\tt "Variance"}.  To create a variance or
         quality array the NDF must already exist. {\tt ["Data"]}
      }
      \sstsubsection{
         FITS = \_LOGICAL (Read)
      }{
         If {\tt TRUE}, the initial records of the unformatted file are
         interpreted as a FITS header (with one card image per record)
         from which the shape, data type, and axis centres are derived.
         The last record of the FITS-like header must be terminated by
         an END keyword; subsequent records in the input file are
         treated as an array component given by COMP.  {\tt [FALSE]}
      }
      \sstsubsection{
         IN = FILENAME (Read)
      }{
         Name of the input sequential unformatted Fortran file.  The
         file will normally have variable-length records when there is
         a header, but always fixed-length records when there is no
         header.
      }
      \sstsubsection{
         NOPEREC = \_INTEGER (Read)
      }{
         The number of data values per record of the input file.
         It must be positive on UNIX systems.  The suggested default is the
         size of the first dimension of the array if there is no
         current value.  A null ({\tt{!}}) value for NOPEREC causes the size
         of first dimension to be used.
      }
      \sstsubsection{
         OUT = NDF (Read and Write)
      }{
         Output NDF data structure.  When COMP is not {\tt "Data"} the NDF
         is modified rather than a new NDF created.  It becomes the new
         current NDF.
      }
      \sstsubsection{
         SHAPE = \_INTEGER (Read)
      }{
         The shape of the NDF to be created.  For example, {\tt [40,30,20]}
         would create 40 columns by 30 lines by 10 bands.  It is only
         accessed when FITS is {\tt FALSE}.
      }
      \sstsubsection{
         SKIP = INTEGER (Read)
      }{
         The number of header records to be skipped at the start of the
         input file before finding the data array or FITS-like header.
         {\tt [0]}
      }
      \sstsubsection{
         TYPE = LITERAL (Read)
      }{
         The data type of the output NDF.  It must be one of the
         following HDS types: {\tt "\_BYTE"}, {\tt "\_WORD"}, {\tt "\_REAL"},
         {\tt "\_INTEGER"}, {\tt "\_DOUBLE"}, {\tt "\_UBYTE"},
         {\tt "\_UWORD"} corresponding to signed byte,
         signed word, real, integer, double precision, unsigned byte,
         and unsigned word.  See \xref{SUN/92}{sun92}{} for further details.  An
         unambiguous abbreviation may be given.  TYPE is ignored when
         COMP = {\tt "Quality"} since the QUALITY component must comprise
         unsigned bytes (equivalent to TYPE = {\tt "\_UBYTE"}) to be a valid
         NDF. The suggested default is the current value.  TYPE is only
         accessed when FITS is {\tt FALSE}. {\tt ["\_REAL"]}
      }
   }
   \sstexamples{
      \sstexamplesubsection{
         unf2ndf ngc253.dat ngc253 shape=[100,60] noperec=8
      }{
         This copies a data array from the unformatted file {\tt ngc253.dat}
         to the NDF called ngc253.  The input file does not contain a
         header section.  The NDF is two-dimensional: 100 elements in $x$
         by 60 in $y$.  Its data array has type \_REAL.  The data records
         each have 8 values.
      }
      \sstexamplesubsection{
         unf2ndf ngc253q.dat ngc253 q 100 shape=[100,60]
      }{
         This copies a quality array from the unformatted file
         {\tt ngc253q.dat} to an existing NDF called ngc253 (such as 
         created in the first example).  The input file does not contain a 
         header section.  The NDF is two-dimensional: 100 elements in $x$ by 60
         in $y$.  Its data array has type \_UBYTE.  The data records
         each have 100 values.
      }
      \sstexamplesubsection{
         unf2ndf ngc253.dat ngc253 fits noperec=!
      }{
         This copies a data array from the unformatted file ngc253.dat
         to the NDF called ngc253.  The input file contains a FITS-like
         header section, which is copied to the FITS extension of the
         NDF.  The shape of the NDF is controlled by the mandatory FITS
         keywords NAXIS, AXIS1, \ldots, AXIS{\em{n}}, and the data type by
         keywords BITPIX and UNSIGNED.  Each data record has AXIS1
         values (except perhaps for the last).
      }
      \sstexamplesubsection{
         unf2ndf type="\_uword" in=ngc253.dat out=ngc253 $\backslash$
      }{
         This copies a data array from the unformatted file {\tt ngc253.dat}
         to the NDF called ngc253.  The input file does not contain a
         header section.  The NDF has the current shape and data type
         is unsigned word.  The current number of values per record is
         used.
      }
      \sstexamplesubsection{
         unf2ndf spectrum zz skip=2 shape=200 noperec=!
      }{
         This copies a data array from the unformatted file {\tt spectrum}
         to the NDF called zz.  The input file contains two header
         records that are ignored.  The NDF is one-dimensional
         comprising 200 elements of type \_REAL.  There is one data
         record containing the whole array.
      }
      \sstexamplesubsection{
         unf2ndf spectrum.lis ZZ skip=1 fits noperec=20
      }{
         This copies a data array from the unformatted file {\tt spectrum.lis}
         to the NDF called ZZ.  The input file contains one header
         record, that is ignored, followed by a FITS-like header
         section, which is copied to the FITS extension of the NDF.
         The shape of the NDF is controlled by the mandatory FITS
         keywords NAXIS, AXIS1, \ldots, AXIS{\em{n}}, and the data type by
         keywords BITPIX and UNSIGNED.  Each data record has AXIS1
         values (except perhaps for the last).
      }
   }
   \sstnotes{
      The details of the conversion are as follows:
      \ssthitemlist{

         \sstitem
            the unformatted-file array is written to the NDF array as
            selected by COMP.  When the NDF is being modified, the shape
            of the new component must match that of the NDF.

         \sstitem
            If the input file contains a FITS-like header, and a new
            NDF is created, {\it i.e.}\ COMP = {\tt "Data"}, the header
            records are placed within the NDF's FITS extension.  This enables 
            more than one array (input file) to be used to form an NDF.  Note
            that the data array must be created first to make a valid NDF,
            and it's the FITS structure associated with that array that is
            wanted.  Indeed the application prevents you from doing
            otherwise.

         \sstitem
            The FITS-like header defines the properties of the NDF as
            follows:
            \begin{itemize}
            \item BITPIX defines the data type: 8 gives \_BYTE, 16 produces
            \_WORD, 32 makes \_INTEGER, $-$32 gives \_REAL, and $-$64 generates
            \_DOUBLE.  For the first two, if there is an extra header
            record with the keyword UNSIGNED and logical value T, these
            types become \_UBYTE and \_UWORD respectively.  UNSIGNED is
            non-standard, since unsigned integers would not follow in a
            proper FITS file.  However, here it is useful to enable
            unsigned types to be input into an NDF.  UNSIGNED may be
            created by this application's sister, NDF2UNF.  BITPIX is
            ignored for QUALITY data; type \_UBYTE is used.
            \item NAXIS, and NAXIS{\em{n}} define the shape of the NDF.
            \item The TITLE, LABEL, and BUNIT are copied to the NDF
            TITLE, LABEL, and UNITS NDF components respectively.
            \item The CDELT{\em{n}}, CRVAL{\em{n}}, CTYPE{\em{n}}, and CUNIT{\em{n}} keywords make
            linear axis structures within the NDF.  CUNIT{\em{n}} define the
            axis units, and the axis labels are assigned to CTYPE{\em{n}} If
            some are missing, pixel co-ordinates are used for those
            axes.
            \item BSCALE and BZERO in a FITS extension are ignored.
            \item BLANK is not used to indicate which input array values
            should be assigned to a standard bad value.
            \item END indicates the last header record unless it
            terminates a dummy header, and the actual data is in an
            extension.
            \end{itemize}

         \sstitem
            Other data item such as HISTORY, data ORIGIN, and axis
            widths are not supported, because the unformatted file has a
            simple structure to enable a diverse set of input files to be
            converted to NDFs, and to limitations of the standard FITS
            header.
      }
   }
   \sstdiytopic{
      Related Applications
   }{
      \CONVERT: \htmlref{NDF2UNF}{NDF2UNF}.
   }
}

\newpage
\normalsize
\section{\label{app_idl}Notes on creating 
\htmladdnormallink{IDL}{\IDLURL} files from NDFs}
\subsection{A simple route (but rather slow)}
The simplest route to use when generating data for IDL from NDFs is
to create an ASCII copy of the NDF you are interested in
using the \CONVERT\ package application 
\htmlref{NDF2ASCII}{NDF2ASCII} and then read 
the resulting file with IDL. The steps taken might be something like:

\begin{quote} \begin{verbatim}
% ndf2ascii in=imagein out=fileout  
\end{verbatim} \end{quote}
This will create a file, {\tt fileout}, containing the data component 
of the NDF called {\tt imagein}. If you want to store the variance or 
quality components you would use {\tt comp=v} or {\tt comp=q} respectively
as additional parameters.

You can then employ a simple IDL batch file such as:
\begin{quote} \begin{verbatim}
; Create IMAGE an 339x244 single precision floating point array.
IMAGE=FLTARR(339,244)

; Open the existing NDF2ASCII file "fileout" for read only access. 
OPENR, UNIT, 'fileout', /GET_LUN
  
; Read formatted input from the specified file unit and 
; place in the variable "IMAGE".
READF, UNIT, IMAGE
 
; Closes the file unit used.
CLOSE, UNIT

; Display the image after suitable scaling. 
TVSCL, IMAGE
\end{verbatim} \end{quote} 
The above example assumes image dimensions of 339$\times$244 pixels. 
If you are in any doubt as to the dimensions of your image you can
determine them using the \KAPPA\ application 
\xref{NDFTRACE}{sun95}{NDFTRACE}. 

One advantage of this route is that the ASCII data can instead be read
directly into byte, integer or double-precision arrays/structures by 
simply substituting {\tt INTARR}, {\tt DBLARR} or {\tt BYTARR} for 
{\tt FLTARR}. Clearly, it should be remembered that attempting to represent 
floating-point values 
within a byte array will not work properly, whereas a double-precision 
array will accommodate double-precision, floating-point, integer or byte 
values (though somewhat inefficiently in terms of memory consumption).


\subsection{A faster route (but a little more complicated)}
However, the NDF2ASCII routine is not fast and makes this route awkward
if time is important. Consequently, you may want to use
\htmlref{NDF2UNF}{NDF2UNF} to create an F77 unformatted sequential file thus:

\begin{quote} \begin{verbatim}
% ndf2unf in=imagein out=fileout noperec=339
\end{verbatim} \end{quote}
Where the {\tt noperec} number should be the size of the first axis of
the image.  

You can then read the created file using an IDL batch file similar to:

\begin{quote} \begin{verbatim}
; Supply the name of the image and its dimensions.
FNAME='fileout'
SD1=339
SD2=244
  
; Set up the main array and temporary array
; use NOZERO option to avoid initialisation 
IMAGE=INTARR(SD1,SD2,/NOZERO)
TEMP= INTARR(SD1,    /NOZERO)
 
; Display what is going on.
PRINT, "Converting file: ", FNAME
 
; Open the file generated by NDF2UNF for read access only.
OPENR, UNIT, fname, /GET_LUN, /F77_UNFORMATTED
 
; Read the image one record at a time.
FOR I=0,SD2-1  DO BEGIN  READU, UNIT, TEMP & $
  ; Transfer each line into the main image array.
  FOR J=0,SD1-1 DO BEGIN IMAGE(J,I)=TEMP(J) & $ 
ENDFOR & ENDFOR 
 
; Close the opened file unit.
CLOSE, 1
 
; Scale the image for display.
IMAGE=CONGRID(IMAGE,SD1,SD2,/INTERP)
WINDOW, 0,XSIZE=SD1,YSIZE=SD2
 
; Display the image.
TVSCL, IMAGE
\end{verbatim} \end{quote} 

The image is then contained in the integer array {\tt IMAGE} and may be 
manipulated by IDL. This would allow such operations as storing it as 
a UNIX unformatted file where the image might subsequently be read in 
from disc in one go.

It should be remembered that the data type of the F77 unformatted
file created by NDF2UNF may differ depending on the type of data stored 
in the original NDF. If this is the case you might need to change the 
type definition of the arrays {\tt image} and {\tt temp} to reflect this. 
The data type used within each component of an NDF may be determined using 
\xref{NDFTRACE}{sun95}{NDFTRACE}. 


\subsection{A fast and simple route using the IDL Astronomy Users' Library}

If this all seems a bit tedious, then those of you with with the IDL 
Astronomy Users' Library installed on your machines might choose to 
take advantage of its FITS conversion procedures to make life easier 
still. Users wishing to obtain a copy of the library can find it at 
\htmladdnormallink{{\tt \IDLAULURL}}{\IDLAULURL}.

The library contains IDL procedures from a number of sources that allow FITS 
format files to be read into IDL data structures. The routine chosen for the
example below was FXREAD which may be found in the {\tt /pro/bintable} 
sub-directory. It is part of a comprehensive suite of FITS conversion programs
that seems particularly easy to use.

So if you first convert your NDF into a FITS file using
\htmlref{NDF2FITS}{NDF2FITS} like this:

\begin{quote} \begin{verbatim}
% ndf2fits in=m42 out=m42.fit comp=d
\end{verbatim} \end{quote}
you can then use the following code from within IDL to place the image
into an IDL structure and display it. 

\begin{quote} \begin{verbatim}
; Read the FITS file 
fxread, 'm42.fit', DATA, HEADER
 
; Determine the size of the image
SIZEX=fxpar(header, 'NAXIS1')
SIZEY=fxpar(header, 'NAXIS2')
 
; Find the data type being read
DTYPE=fxpar(header, 'BITPIX')
 
; Scale the image for display
IMAGE=congrid(DATA,SIZEX,SIZEY,/INTERP)
window, 0,xsize=SIZEX,ysize=SIZEY
 
; Display the image
TVSCL, IMAGE
\end{verbatim} \end{quote}
As can be seen above, various values contained within the FITS header 
of the original can be obtained using the FXPAR procedure. 

You should bear in mind that a number of other procedures (such as 
IEEE\_TO\_HOST and GET\_DATE) from the Astronomy Users' Library 
are also needed by IDL when compiling this code. Consequently it is 
essential that the whole library should be obtained from the archive.

\newpage

\section{\label{app_vms}\BCONVERT\ on VMS}
The VMS release of \CONVERT\ is frozen at Version 0.5. For details of how to
use it, see SUN/55.5 from the VMS documentation set which is still available
on the residual Starlink VMS-service machine (STADAT).

BDF2NDF and NDF2BDF are only available on VMS because the Interim library 
has not been ported to UNIX.

DIPSO2NDF and NDF2DIPSO are not required on UNIX because UNIX DIPSO
processes NDFs.

\subsection{\xlabel{sun55_app_bdf}Converting BDFs to
NDFs\label{app_bdf}}

Some long-time Starlink users still have archive data in the form of BDF
files, which should be converted into an NDF or FITS.  Here are some
notes on how to go about converting such BDF files to NDF. 

First obtain an account on STADAT.  See your site manager to arrange
this.  Ensure that you have an adequate disk quota on DISK\$SCRATCH to
store your files.   Then follow the instructions below, substituting the
name of your BDF and NDF for {\tt MYBDF} and {\tt MYNDF} respectively. 
At the end use FTP in binary mode, to transfer the NDFs to your local
machine and delete your data files from STADAT.

\small
\begin{verbatim}
  $! Put this in your STADAT LOGIN.COM.  It defines the Starlink commands.
  $ @SSC:LOGIN

  $! This sets up the CONVERT definitions.  It need only be typed once
  $! per session.
  $ CONVERTSTART

  $! This is the basic command for running BDF2NDF.  There are a few
  $! other parameters.  Use the online help (CONHELP command) to obtain
  $! their details.
  $ BDF2NDF MYBDF MYNDF
\end{verbatim}
\normalsize

\newpage
\section{Release Notes -- V1.0}

\subsection{New applications}
There are three new applications:
\begin{description}

\item[\htmlref{DA2NDF}{DA2NDF}] -- This converts an unformatted stream file to
an NDF.  Such files will originate from C or Pascal unformatted
output (data streams), or from Fortran unformatted direct-access.

\item[\htmlref{FITS2NDF}{FITS2NDF}] -- This is a much improved reader compared
with \xref{FITSDIN}{sun95}{FITSDIN} of \KAPPA.  It has support for
binary table and image extensions in the FITS file.  It recognises
many special data products too.  FITS2NDF can regenerate most NDFs from
files made by its sister application, \htmlref{NDF2FITS}{NDF2FITS}.

\item[\htmlref{NDF2DA}{NDF2DA}] -- This provides the inverse operation to DA2NDF.
It permits you to process such files with standard packages through the
automatic-conversion system.

\end{description}

\subsection{Global changes}
\begin{description}

\item[Automatic Conversion]  There are two new formats
defined that operate within the \xref{NDF automatic format-conversion
system.}{ssn20}{} GZIP is similar to COMPRESSED, as it operates on
{\bf gzip} compressed NDFs with extension {\tt .sdf.gz}.  STREAM
operates on Fortran unformatted direct-access files or C unformatted
data whose file extension is {\tt .das}.
\htmlref{FITS2NDF}{FITS2NDF} is used for the forward conversion of FITS
data instead of \xref{FITSDIN}{sun95}{FITSDIN} from \KAPPA. There are
several file-extension synonyms, mostly for FITS, and {\tt .str} for
STREAM data.  The priority order in environment variables
NDF\_FORMATS\_IN and NDF\_FORMATS\_OUT has changed, with GASP
appearing later, and STREAM taking GASP's place.


\item[Documentation] The documentation has been updated to match this
version of the software.  Additional hyperlinks are introduced,
including ones for the related applications.  There are
\htmlref{additional notes}{app_bdf}
\latexonly{in Appendix~\ref{app_bdf}} on how to process BDF files on
STADAT.  The messages in the startup scripts mention how to obtain the
hypertext documentation.  Several application modules missing from
the online help are now present.

\item[FITS keywords] In several places, the CRTYPE$n$ and CTYPE$n$
keywords were confused.  Likewise, a BUNITS keywords was erroneously
recognised instead of BUNIT.  The standard header names are now used.
A new CUNIT$n$ keyword is added to store axis units.  Some tasks
omitted to write CRPIX$n$ for linear axis centres when trhe reference
position was located at the centre of the first element.  The origin
information is exported through LBOUND$n$ keywords.

\item[Linearity of axes]  The improved and more-robust \KAPPA\ subroutine
is now used to test whether or not the elements of axis-centre arrays
are equally spaced.

\end{description}

\subsection{Changed applications}
\begin{description}

\item[\htmlref{ASCII2NDF}{ASCII2NDF}]  Made far more efficient, mostly
due to a change in the CHR library, but also because the maximum
record length is now reduced to 512 bytes.  The default RECLEN is 132.

\item[\htmlref{DST2NDF}{DST2NDF}]  Allows for non-standard .FITS structures. 

\item[\htmlref{GIF2NDF}{GIF2NDF}]  Removed \KAPPA\ dependency.  It
uses one less conversion stage, so is more efficient.  The documentation
has been improved.

\item[\htmlref{IRAF2NDF}{IRAF2NDF}]  This has undergone a major upgrade
with support for axis propagation from eleven variants, control of the
creation of NDF HISTORY records and FITS extension from the headers in
the \IRAFref\ file.  The pixel origin is transferred to LBOUND$n$ headers.
The NDF label and units are created from OBJECT and BUNIT headers. 
The documentation has been corrected and improved.

\item[\htmlref{NDF2ASCII}{NDF2ASCII}]  Reduced the maximum record
length to 512 bytes.  The default RECLEN is 132.

\item[\htmlref{NDF2DST}{NDF2DST}]  Moves imaginary component of a
complex array to .Z.IMAGINARY.  There is a simplified error message
when the FITS file already exists.

There was a bug, now fixed, which could result in .OBS and .Z
structures of the FIGARO extension being lost.  This occurred when
FIGARO extension components SECZ or TIME (for OBS), and MAGFLAG or
RANGE (for Z) were present and were physically stored following their
respective structure.

\item[\htmlref{NDF2FITS}{NDF2FITS}]
BITPIX=$-$1 is allowed to enable the original FITS data type to be
restored during automatic conversion.  NDF2FITS use a better algorithm
to decide the required precision of floating-point header values.

Sensible defaults are used for the scale and offset when converting a
constant floating-point array to an integer array in the FITS file.

Extensions within 2dF NDFs are recognised, and appropriate binary tables
are created in the FITS file.

\item[\htmlref{NDF2GIF}{NDF2GIF}]
It is now available for alpha\_OSF1.

\item[\htmlref{NDF2IRAF}{NDF2IRAF}]  This has undergone a major upgrade
with support for axis propagation including a multispec format for
non-linear axis centres.  There is control of the export of NDF
HISTORY records and FITS extension information to the headers in the
\IRAFref\ file.  Header duplication is prevented.  The documentation
has been corrected and improved.  Parameter FILLBAD defaults to 0.
\IRAF\ filenames are no longer converted to lowercase.
The pixel origin is transferred from LBOUND$n$ headers.  The NDF
label and units are progagated to OBJECT and BUNIT headers.

\item[\htmlref{TIFF2NDF}{TIFF2NDF}]  Removed \KAPPA\ dependency.  It
uses one less conversion stage, so is more efficient.  It is now
available for alpha\_OSF1.  The documentation has been improved.

\end{description}  

\newpage
\section{Release Notes -- V1.1}

\subsection{Changed applications}
\begin{description}

\item[\htmlref{ASCII2NDF}{ASCII2NDF}] Added MAXLEN parameter to permit
long input records without impacting the efficiency of processing short
records.

\item[\htmlref{FITS2NDF}{FITS2NDF}] Filters out NDF-style history from
the FITS airlock.  Fixed bug which prevented the creation of NDF
extensions which are arrays of structures.  Processes the revised 2dF 
formats, and allows arbitrary additional extensions; all 2dF extensions can
now be an arbitrary order.  Fixed bug which occurred when replacing
negative errors in IUE MXLO data.  It recognises logical binary-table
columns.

\item[\htmlref{IRAF2NDF}{IRAF2NDF}] Sets the bounds of the NDF according
to LBOUND$n$ keywords, if present.  It no longer crashes when closing the
\IRAFref\ file, if there was a problem opening the IRAF file.  Propagates
all IRAF history records (including blanks) to the FITS airlock
when PROFITS={\tt TRUE}.  IRAF HISTORY lines which are too long for
a FITS header are truncated with an ellipsis.

\item[\htmlref{NDF2FITS}{NDF2FITS}] Modified to propagate the revised 2dF
extensions.  Thus the OBJECT extension generates wider binary tables
(from 210 to 224 bytes).  Now propagates primitive NDF extensions to binary
tables.  Does not transfer the LBOUND$n$ headers in the FITS airlock.

\item[\htmlref{NDF2IRAF}{NDF2IRAF}] Does not transfer the LBOUND$n$
headers in the FITS airlock.

\end{description}  

\end{document}
