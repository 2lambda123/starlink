# Number of iterations
#  postive number  = fixed number of iterations
#  negative number = maximum iterations if using chi^2 stopping criteria
numiter = -5

# chi^2 tolerance in negative-numiter case (requires noi model component)
chitol = 1e-3

# method of estimating variance map
#  0 = propagate from the time-domain noise (requires noi model component)
#  1 = sample variance of data that land in each pixel
varmapmethod = 1

# Perform iterations in memory?
memiter = 1

# Handle each subarray separately? Normally all data that were taken
# simultaneously at a given wavelength are handlded together.
#groupsubarray = 1

# Delete temporary .DIMM files if memiter=0?
deldimm = 1

# If performing iterations in memory, maximum length (seconds) for concatenated
# data. If 0 attempt to concatenate entire continuous chunks.
maxlen = 0

# Model components/order (comma separated list in brackets)
# Note: components specified AFTER 'ast' will not be calculated for the
# first time until the second iteration.
#  dks = fit and remove dark squid for the column
#  com = remove common-mode signal
#  gai = if com specified, fit gain/offset of common mode
#  ext = apply extinction correction
#  ast = estimate the map and astronomical signal
#  flt = apply filter to time streams
#  noi = estimate time-domain variance
#  smo = time series smoothing using a median or mean boxcar filter
#  pln = remove plane from each time slice
#  tmp = remove externally define template such as azimuth

modelorder = (com,gai,ext,flt,ast,noi)

# Export model files as NDF?

# Specify a value of 1 or 0 to export all or none of the components
# You can also specify an array of components to export using the same
# format as modelorder. Note that you can specify additional
# components 'res' and 'qua' to what may be provided to modelorder if
# you wish to export the residual model or quality arrays
# respectively. Exportation of 'res' is implied if 'noi' is specified
# as it becomes the variance components of the resulting NDF for
# 'res'. 'qua' will become the quality component of any full 3-dimensional
# model (e.g. 'res', 'ast', 'flt', 'ext'), but no quality will be
# written to model components with different dimensions.

exportndf = 0
#exportndf = (com,gai,ast,flt,dks,smo,pln,tmp,res,noi,qua)

# Normally all data points in exported model components are set to BAD values
# wherever there is a bad bolometer established during map-making. Set
# this flag to prevent this behaviour.

#noexportsetbad = 1

# Create .MORE.SMURF.ITERMAPS extensions after each iteration?
#itermap = 1

# Create .MORE.SMURF.BOLOMAPS single-beam map extensions?
#bolomap = 1

# Create .MORE.SMURF.SHORTMAPS extensions containing maps of every "shortmap"
# time slices? Alternatively, set to -1 to produce a map each time TCS_INDEX
# is incremented (i.e., each time a full pass through the scan pattern has
# been completed).
#shortmap=1000

# Create .MORE.SMURF.FLAGMAPS extensions? To enable this feature set flagmap
# to an array containing a subset of the following bit flags. Each flagmap
# will then contain a count of the number of samples with a quality bit
# matching at least one of these flags, for each continuous chunk:
#
# BADDA   : flagged bad by the DA system
# *BADBOL : entire bolometer is turned off
# SPIKE   : flagged as a spike
# DCJUMP  : location of a DC level step
# STAT    : telescope was not moving within flagslow to flagfast
# COM     : portion of data did not match the common-mode
# FILT    : filtered data did not have sufficient contributions from good data
# NOISE   : bolometer was flagged as being too noisy in general
#
# *Note: If BADBOL is set the behaviour is slightly different than expected;
#        the bolometer will be completely ignored when creating the flag map.
#
# The flagmap is mostly useful to verify whether the spike, jump, and
# common-mode rejection is correlated with features in the map (e.g. bright
# sources), for all of the detectors that were used to produce the map, e.g.
#
#flagmap = (BADBOL,SPIKE,DCJUMP,COM)

# Apply the flatfield if loading raw data? Default is 1 (true) -- you must
# explicitly set this to 0 if you want to produce a map in raw DAC units (and
# also supply raw data).

# ensureflat=0

# The gap (in time slices) between full calculations of the output map
# bolometer positions. Setting a larger value for this will speed up
# the map maker but will introduce larger spatial errors. The default
# value of 100 seems to produce spatial errors of under 0.1 arc-sec. This
# level of errors seems to cause about 1% of bolometers samples to be
# pushed into a neighouring map pixel. For tstep=100, the calculation of
# bolometer positions speeds up by about a factor of 60. Setting tstep to
# 1 (or zero) causes all bolometer positions to be calculated in full,
# without any approximation.
#tstep = 100

# If the telescope is scanning slowly the data may be safely down-sampled
# to save memory and time. This parameter controls the minimum angular
# scale on the sky. The new sample frequency is chosen such that this
# scale will be preserved taking into account the average slew speed and
# the sample rate of the input files. The following defaults are to downsample
# to the same angular scale as the default map pixel sizes in each band
# which works out to slightly smaller than the FWHM/3:

#450.downsampscale = 2
#850.downsampscale = 4

# To test the response of the map-maker to different known
# astronomical sources, an external "fakemap" can be specified to
# provide an image of the sky that will produce additional
# astronomical signal to the time series. At present, the dimensions
# of this map must be identical to that of the real map. If the pixel
# ranges are not the same makemap will hault. A typical procedure may
# involve: (i) produce a map withe makemap; (ii) produce an image with
# simulated data with the same pixel dimensions; (iii) specify this
# new map for the "fakemap" parameter below. Note that this is a
# fully-parsed ndf identifier, so you can do things like:
#
# fakemap = fakesky.sdf
# fakemap = fakesky[1:300,100:450]
#
# Additionally, you can specify a scalar scale factor, "fakescale", by
# which each pixel in the fakemap will be multiplied before adding to
# the data.
#
# fakescale = 23.5

# ----------------------------------------------------------------------------
# The following parameters control data-cleaning before iterations start
# ----------------------------------------------------------------------------

# set this to 0 to turn off all of the pre-mapmaking data cleaning

#doclean = 0

# Export the data immediately after data cleaning / before map-making?
# The file name will be the same as model components, except with the
# suffix "_cln". Even if doclean=0, the data will be exported immediately
# before map-making.

#exportclean = 1

# --- Mean subtraction is fairly useful ---

# subtract a baseline polynomial of this order
order = 0

# Use default apodisation based on filter frequency. This over-rides
# the default of zero in smurf_sc2clean.def. Keep the <undef> default
# for PAD which is set up in smurf_makemap.def.
apod = <undef>

# If zeropad is set, the padded regions are set to 0, and apodization
# is used to slowly roll-off the ends of the time series to 0. If zeropad
# is not set, a cubic is used to smoothly interpolate the end of the time
# series with the beginning (ensuring continuity in both the value and
# first derivative). In both cases, the purpose is to remove sharp edges
# that may cause ringing in the later FFT filtering steps. There are
# similar flags for DKS cleaning, and the FLT model.
#zeropad = 1

# --- badfrac ensures that bad data from DA system are ignored ---

# fraction of samples to be bad to flag entire bolo as dead
badfrac = 0.05


# --- flag data when we're moving either too slow or too fast ---

# Flag data taken while telescope was moving to slow such that sources
# are buried in 1/f noise, or too fast such that sources are smeared
# (value is a threshold slew velocity (arcsec/sec) measured in
# tracking coordinates). Assuming we would like to be able to sample
# scales of at least 30 arcsec (at least two 15 arcsec beams at
# 850), and assuming a typical 1/f knee of 1 Hz, the telescope needs
# to slew at least 30 arcsec/sec to place sources in the signal band
# above the knee. Also, assuming a sample rate of 200 Hz, we want to
# be able to fully-sample the 450 and 850 beams, leading to rough upper
# limits of 300 and 600 arcsec/sec in each band respectively.

flagslow = 30
450.flagfast = 600
850.flagfast = 980

# --- Many of the following may not be useful ---

# If this flag is set, the common-mode calculation will be performed
# additionally as a pre-processing step. All parameters com.* and gai.*
# below are parsed and used (e.g., to also flag bad data and optionally
# flatfield off the relative response to the common-mode signal). If this
# pre-processing step is chosen, it is still possible to specify COM/GAI
# as model components in the iterative solution

#compreprocess=1

# An alternative to removing the simple common-mode is cleaning by way
# of principal component analysis (PCA). In this case, a new set of
# basis vectors (components) are calculated from the bolometer time-series
# such that they have 0 covariances. The amplitudes of these new correlated
# signals are then calculated, and the largest amplitude components can
# be removed. In this simplest case of white detectors noise + a common
# atmospheric signal, this operation would be similar to using compreprocess.
# However, PCA is capable of detecting multiple signals with different
# correlation patterns across the array.
#
# It is *ESSENTIAL* that the bolometer data first have their mean values
# removed (i.e., order=0), as this assumption is used to speed up the
# calculation.
#
# The single parameter to the PCA cleaning is the threshold above
# which components will be removed from the bolometer time-series. For
# each component, the RMS amplitude across all bolometers is
# calculated -- a single positive number related to the average
# strength of the component. An iterative sigma clipper is then used
# to flag components that are more than thresh*RMS away from the mean value.
# This approach is quite arbitrary, but a value of about 4 seems reasonable
# for some test data. Be warned that this statistical black box will remove
# real correlated astronomical signals as well! As with common-mode removal,
# the actual impact on science will need to be calibrated with simulations.

pcathresh = 0

# S/N threshold to detect DC steps. Note, this refers to the noise level
# in the bolometer data after it has been smoothed with a median filter of
# width given by DCSMOOTH. In order to find the equivalent threshold in
# the unsmoothed data, multiply the DCTHRESH value by # 1.25/sqrt(DCSMOOTH).
# For instance, the default values for DCSMOOTH (50) and DCTHRESH (25)
# correspond to a threshold of 25*1.25/sqrt(50) = 4.4 sigma in the
# unsmoothed data.
dcthresh = 25.0

# box size over which to fit data with a straight line on either side of
# a potential DC jump.
dcfitbox = 30

# The maximum number of steps that can be corrected in each minute of
# good data (i.e. per 12000 samples) from a bolometer before the entire
# bolometer is flagged as bad. A value of zero will cause a bolometer to
# be rejected if any steps are found in the bolometer data stream.
dcmaxsteps = 10

#  If more than DCLIMCORR bolometer have a step at a given time, then all
#  bolometers are corrected for a step at that time, using lower thresholds.
#  Setting it to zero here switches off the correction of correlated
#  steps. Removing this line causes the default value of 10 to be used.
dclimcorr = 0

# The width of the median filter used to smooth a bolometer data stream
# prior to finding DC jumps
dcsmooth = 50

# S/N ratio to flag spikes with sigma-clipper
# spikethresh = 5

# Size of filter box for sigma-clipper
# spikebox = 50

# Fill vicinity of spikes / DC steps with constrained realization of
# noise
fillgaps = 1

# The following filters are applied *before* the iterative loop. It is
# probably a better idea in general to do filtering with the 'flt'
# model component as described in the next section.

# Hard-edge high- and low-pass frequency-domain filter
#   e.g. keep only frequencies >= 0.1 Hz, and <= 90Hz

# filt_edgehigh = 0.1
# filt_edgelow = 90

# Alternatively, determine filter edges based on a range of requested
# spatial scales (arcsec), and using internal measurements of the
# average slew speed. These will override filt_edgehigh/filt_edgelow.
# For example, suppose the slew speed is 100 arcsec/sec. We want to
# ensure that the beam is fully sampled, say 2 arcsec at 450um. That
# scale is crossed in 2/100 = 0.02 s, so we don't need frequencies in
# the data above 1/0.02 = 50 Hz in this case (i.e. internally it will
# set filt_edgelow to 50Hz if filt_edge_smallscale is set to 2
# arcsec). Similarly, if we would like to attempt to preserve scales
# of 10 arcmin = 600 arcsec, we would want to keep frequencies that
# are greater than 1/(600/100.) = 0.17 Hz (i.e. setting
# filt_edge_largescale=600 would translate into filt_edgehigh = 0.17
# Hz).

# filt_edge_largescale = 600.
# 450.filt_edge_smallscale = 2.
# 850.filt_edge_smallscale = 4.

# Hard-edge band-cut frequency-domain notch filters.
# filt_notchlow gives lower edges of frequencies to cut in Hz
# filt_notchhigh gives upper edges of frequencies to cut in Hz
#   e.g. remove 25--35 Hz  and 55--65 Hz
#filt_notchlow  = (25,55)
#filt_notchhigh = (35,65)

# Should a whitening filter be applied to compensate for 1/f noise?
# whiten = 1

# Clip bolometers based on their noise. This parameter will remove
# any bolometers noisier than noiseclip standard deviations above
# the mean.
noiseclip = 4.0

# ----------------------------------------------------------------------------
# A number of analagous parameters to clean dark squid signals before fitting
# them to the data (only relevant if DKS is specified as a model component).
# Note that if padding has been added to the bolometer data, it is
# automatically added to the dark squids as well (i.e. there is no
# cleandk.padstart/padend).
# ----------------------------------------------------------------------------

cleandk.apod=<undef>
cleandk.badfrac = 0.05
cleandk.dcfitbox = 30
cleandk.dcmaxsteps = 10
cleandk.dcthresh = 25.0
cleandk.dcsmooth = 50
cleandk.fillgaps = 1
#cleandk.filt_edgelow = 0
#cleandk.filt_edgehigh = 0
#cleandk.filt_notchlow = <undef>
#cleandk.filt_notchhigh = <undef>
#cleandk.whiten = 0
cleandk.order = 0
#cleandk.spikethresh = 0
#cleandk.spikebox = 50
#cleandk.zeropad = 1

# ----------------------------------------------------------------------------
# These parameters control the iterative model components
# ----------------------------------------------------------------------------

# delay calculation of COM until after the first iteration? (good if
# the astronomical signal is expected to dominate the sky signal)

#com.notfirst = 1

# If this flag is set, the common-mode will be estimated while
# iteratively flagging and removing outlier detectors as
# usual. However, once the flagging is completed, the common-mode will
# not actually be removed from the time-series (and if the model is
# exported, it will be set to 0).

#com.noremove=1

# low-pass boxcar filter on COM (samples) to assist with convergence
# if boxfact set reduce width of boxcar by this factor each iteration
# boxmin specifies a minimum width below which it can't be reduced

com.boxcar = 10
#com.boxcar  = 400
#com.boxfact = 0.5
#com.boxmin  = 10

# the following COM parameters control the rejection of bad detectors
# based on the gain and correlation coefficients for the fit of the
# common-mode signal to each detector (good at identifying bolo signals
# with bizarre gains, or shapes if they have for example steps in them). These
# are basically sigma-clippers; outliers are removed at the given threshold
# and then new means and sample standard deviations are measured until
# convergence. The time axis is divided up into one or more equal sized boxes,
# and a separate fit is performed for each box.
#
# com.gain_box: the number of time slices in a box
# com.corr_tol: n-sigma away from mean correlation coefficient tolerance
# com.corr_abstol: the absolute lower limit of acceptable correlation
# com.gain_tol: n-sigma away from mean gain coefficient tolerance
# com.gain_abstol: absolute factor away from mean gain coefficient tolerance
# com.gain_fgood: minimum fraction of good boxes for a usable bolometer
# com.gain_rat: ratio of largest usable gain to mean gain for a bolometer

com.corr_tol = 5
com.gain_tol = 5
com.gain_abstol = 3

# by default negative gains are used to flag bad bolometer data. However, if
# this parameter is set to 0 negative values will be allowed
#com.gain_positive = 0

# Do not set com.gain_box lower than about 6000 which corresponds to
# 30s, or roughly the fridge oscillation period.
com.gain_box = 6000
#com.corr_abstol = 0.2
#com.gain_fgood = 0.25
#com.gain_rat = 4.0

# low-pass filter dark squid signals using boxcar of this width (if dks
# model is specified)
dks.boxcar = 100

# if set, replace dead dark squids with average of working dark squids
dks.replacebad = 0

# do we want to calculate noise weights immediately after pre-conditioning,
# or wait until we have the first iteration of the residual? The former can
# reduce execution time if noiseclip is also set since both operations
# share a single FFT.
#noi.calcfirst = 1

# additional despiking / DC step finding after each iteration within noi
# calculation. Setting noi.spikebox to 50 will check for excursions
# from a rolling median filter in a box of length 50 samples.
#noi.spikethresh = 10
#noi.spikebox = 50
noi.fillgaps = 1

# explicitly turn off iterative DC step finding for now
noi.dcfitbox = 0

#  Use default apodisation based on filter frequency
flt.apod = <undef>

# iterative filter.
#450.flt.filt_edgehigh = 0.1
#850.flt.filt_edgehigh = 0.3
#flt.filt_edgelow = 90
#flt.filt_notchlow  = (25,55)
#flt.filt_notchhigh = (35,65)
#flt.zeropad = 1

450.flt.filt_edge_largescale=600
850.flt.filt_edge_largescale=300

# delay calculation of FLT until after the first iteration? May help
# with negative structure around bright sources

#flt.notfirst = 1

# extinction correction (see EXTINCTION task for further information)
# Best is to use WVM, uses continuously varying measurements as a
# function of time stored with each observation. This is the default if
# nothing is specified.
#
# tausrc   : auto, wvmraw, csotau, filtertau
# taumethod: adaptive, full, quick

# filtertau "tausrc" requires a filtertau entry
# csotau is optional for "auto" and "csotau" tausrc. If not provided
# the value will be calculated from the header.

# csotau   : use value only if tausrc=csotau
# filtertau: use only if tausrc=filtertau

ext.tausrc    =auto
ext.taumethod =adaptive
#ext.csotau    = 0.2
#ext.filtertau = 0.2

# Use the GAIn/COMmon mode to re-calculate the flatfield? Probably a
# good idea in most cases, but dangerous for short scans of very bright
# sources because the astronomical signal may completely dominate
# sky signal.

#gai.flatfield = 1

# Constrain regions of the map to 0.
#
# Using ast.zero_lowhits will set a threshold region where
# the hits are this fraction lower than the mean.
#
# Using ast.zero_circle defines a circle on the map outside of which
# the map will be constrained to zero. The 3 parameters are:
# Longitude, Latitude, Radius of the circle, in decimal degrees, in
# the coordinate system of the map (e.g., RA and Dec.). Alternatively
# a single parameter may be given (the radius), and then the centre
# of the circle will default to the reference coordinates for the
# centre of the map (e.g. the tangent point).
#
# The ast.zero_snr parameter will create a mask based on map SNR. For
# example, if it is set to 5, after each iteration all pixels with a
# SNR below this threshold will be set to 0.
#
# If ast.zero_notlast is set, on the final iteration this boundary
# condition will not be applied. This feature will probably be useful
# for deep point-source observations for which the large-scale noise
# is not as important, but keeping as much data around the edges of
# the map is.

#ast.zero_circle = (70.72333,36.115,0.0083333)
#ast.zero_lowhits = 0.1
#ast.zero_notlast = 1
#ast.zero_snr = 5

# The AST model can also perform map-based de-spiking after the first
# iteration provided that there is also a NOI model present. The value
# of ast.mapspike indicates a SNR threshold sigma-clip based on the
# scatter of the samples that contribute to a given pixel value about
# the map value.
ast.mapspike = 10

# Smooth the time series

# don't smooth on the first iteration
smo.notfirst = 1

# Type of filter: mean or median
smo.type = median

# width of smoothing box (roughly equivalent to FLT with a high-pass
# filter at cutoff frequencies 0.1 and 0.3 Hz for 450 and 850
# respectively)
450.smo.boxcar = 2000
850.smo.boxcar = 600

# The TMP model fits an externally defined template to each bolometer
# time-series. The only parameter defines what that template
# is. Presently the only two valid options are "state_az" and
# "state_el" to use the telescope azimuth and elevation
# respectively. The former seems to be a good way for removing
# magnetic field pickup.
# tmp.source = state_az
