#!/bin/tcsh

#  Check a list of observations has been supplied on the command line.
if( $# < 1 ) then
   echo
   echo "Produces a 2D polynomial describing the SCUBA-2 focal plane distortion"
   echo
   echo "Usage: distortion <inlist> [-t|-extra] [-p]"
   echo
   echo "   <inlist> is a text file in which each line contains the path"
   echo "   to a directory holding the raw time series cubes for a single"
   echo "   planet observation."
   echo
   echo "If the -t option is supplied, the distortion is calculated on the"
   echo "basis of individual slices in the time series data. Otherwise it is"
   echo "calculated on the basis of maps made from individual bolometers."
   echo
   echo "If the -extra option is supplied (and the "-t" option is *not*"
   echo "supplied), a pair of images is created for each observation, one"
   echo "(with prefix '_amp') contains the peak amplitude of the fitted"
   echo "source in each bolometer map, and the other (with prefix '_sum')"
   echo "the total data sum in the source in each bolometer map. By default,"
   echo "this total data sum is the sum of the pixel values in a 60 arc-sec"
   echo "circular aperture (bad pixels are replaced using KAPPA:FILLBAD prior"
   echo "to finding the sum), but if the -p option is supplied it will be the"
   echo "integral of the model star profile found by the KAPPA:PSF command."
   echo
   exit
endif

#  Ensure SMURF tasks assume there is no focal plane distortion.
setenv SMURF_DISTORTION NONE

#  Ensure ADAM tasks fail rather than prompt for parameter values
setenv ADAM_NOPROMPT 1

#  Expand the supplied list of directories into absolute paths and check
#  they exist.
set dir_list = " "
foreach dir (`cat $1`)
   set indir = `readlink -f $dir`
   if( ! -d "$indir" ) then
      echo " "
      echo ">>>>  Cannot find directory $indir \!\!\!\!\!"
      echo " "
      exit
   endif
   set dir_list = "$dir_list $indir"
end

#  See if we are using the timeslices or bolomaps algorithm. Also see
#  if we are to create images of the peak value and total sum of the
#  fitted sources for each bolometer (can only be done when using the
#  bolomaps algorithm).
set method = BOLOMAPS
set make_extra = 0
if( $# > 1 ) then
   if( "$2" == "-t" ) then
      set method = TIMESLICES
   else if( "$2" == "-extra" ) then
      set make_extra = 1
   else
      echo "Unknown second command line argument - $2"
      exit
   endif
endif

#  If we are creating images of peak value and total sum, see if the total
#  sum should be the sum of the values in a 60 arc-sec aperture, or the
#  integral of the model psf.
set sum_method = APERADD
if( $make_extra ) then
   if( $# > 2 ) then
      if( "$3" == "-p" ) then
         set sum_method = PSF
      else
         echo "Unknown third command line argument - $3"
         exit
      endif
   endif
endif

#  Create a temporary directory to hold all the intermediate files, and
#  move into it.
rm -rf distortion-tmp >& /dev/null
mkdir distortion-tmp
cd distortion-tmp

#  Create a temporary ADAM directory within the above directory.
mkdir adam
setenv ADAM_USER $PWD/adam

#  Create some empty files so that we can append to them later.
touch outdx.lis outdy.lis outdx_A.lis outdy_A.lis

#  Loop round each observation.
set idir = 0
foreach indir ($dir_list)

#  Create a new directory in which to process this observation, and move
#  into it.
   @ idir = $idir + 1
   set pdir = "obs$idir"
   mkdir $pdir
   cd $pdir

#  Save the name of the output catalogue for this observation.
   set cat = "$PWD/total.txt"

#  Ensure NDG does not try to fork processes to expand shell meta-characters
#  for output NDFs ("fork" can fail when creating the bolomaps due to lack
#  of memory on big data sets).
   setenv NDG_NOSHELL 1

#  Tell the user what's happening
   echo "-----------------------------------------------"
   echo "Processing directory $indir using the $method method ....."
   echo " "









#  First handle the time slices method.
#  ===================================
   if( $method == TIMESLICES ) then

#  Need to identify usable scans. Loop round all scans in the current directory.
#  Store the names of the unusable scans in a text file in the temp directory.
#  Store the names of the usable scans in a variable.
      touch unusable.lis
      set usable = ""
      foreach n ($indir/s*_*_*.sdf)

#  If the file has SEQ_TYPE and OBS_TYPE headers, the scan is usable if
#  the values of these headers are equal
         set there = `$KAPPA_DIR/fitsmod $n edit=exist keyword=SEQ_TYPE`
         if( "$there" == "TRUE" ) then
            set there = `$KAPPA_DIR/fitsmod $n edit=exist keyword=OBS_TYPE`
            if( "$there" == "TRUE" ) then
               set seq_type = `$KAPPA_DIR/fitsmod $n edit=print keyword=SEQ_TYPE`
               set obs_type = `$KAPPA_DIR/fitsmod $n edit=print keyword=OBS_TYPE`
               if( "$seq_type" != "$obs_type" ) then
                  echo $n >> unusable.lis
               else
                  set usable = "$usable $n"
               endif
            endif
         endif

#  If either the SEQ_TYPE or OBS_TYPE header was not found, check the file has
#  a SHUTTER keyword in its FITS extension
         if( "$there" != "TRUE" ) then
            set there = `$KAPPA_DIR/fitsmod $n edit=exist keyword=SHUTTER`
            if( "$there" == "TRUE" ) then

#  If the value of SHUTTER is zero, the scan is a dark (unusable).
               set val = `$KAPPA_DIR/fitsmod $n edit=print keyword=SHUTTER`
               if( "$val" == "0" ) then
                  echo $n >> unusable.lis
               else
                  set usable = "$usable $n"
               endif
            endif
         endif
      end

#  We process each usable scan separately. Loop round them all.
      set cats = " "
      set iscan = 0
      foreach n ($usable)
         @ iscan = $iscan + 1
         set scandir = `basename $n .sdf`
         mkdir $scandir
         cd $scandir

#  Tell the user what's happening
         echo "=========================="
         echo "Processing scan $n ....."
         echo " "

#  Use the iterative mapmaker to extract the astronomical and residual signals
#  from a single subscan (with flat).
         echo "$n" > in.lis
         echo "^../unusable.lis" >> in.lis
         rm -f junk.log
         $SMURF_DIR/makemap ^in.lis method=iter out=junk \
              config="'^$SMURF_DIR/../../share/smurf/dimmconfig_distortionmap.lis,exportndf=(ast,res,qua),bolomap=0'" >& junk.log
         cat junk.log

#  Check makemap ran succesfully
         grep \!\! junk.log >& /dev/null
         if( $status == 1 ) then

#  Add the signals together, remove NaNs, and set the bad-bits mask.
            $KAPPA_DIR/native "*_res"
            $KAPPA_DIR/setbb "*_res" 255
            $KAPPA_DIR/add "*_res" "*_ast" test-new
            rm -f *_res.sdf *_ast.sdf

#  Get the subarray name, and its corresponding integer index.
            if( $iscan == 1 ) then
               set subarray = `$KAPPA_DIR/fitsmod junk edit=print keyword=SUBARRAY`
               if( $subarray == "s8a" ) then
                  set array = 0
               else if( $subarray == "s8b" ) then
                  set array = 1
               else if( $subarray == "s8c" ) then
                  set array = 2
               else if( $subarray == "s8d" ) then
                  set array = 3
               else if( $subarray == "s4a" ) then
                  set array = 4
               else if( $subarray == "s4b" ) then
                  set array = 5
               else if( $subarray == "s4c" ) then
                  set array = 6
               else if( $subarray == "s4d" ) then
                  set array = 7
               else
                  echo "Unknown subarray - $subarray"
                  exit
               endif

#  Get the observation and subscan numbers
               set obsnum = `$KAPPA_DIR/fitsmod $n edit=print keyword=OBSNUM`
            endif
            set subscan = `$KAPPA_DIR/fitsmod $n edit=print keyword=NSUBSCAN`

#  The name of the output catalogue for this scan.
            set scat = "$PWD/scan-$iscan.txt"

#  Keep a list of all the output catalogues
            set cats = "$cats $scat"

#  Looking at individual bolometer time series, the noise values put into
#  the _res model by the iterative mapmaker seem way too high. So find the
#  noise in each bolometer by smoothing the time series for each bolometer,
#  then substracting the smoothed from the original, and collapsing to get
#  sigma-clipped std. dev for each bolometer.
            $KAPPA_DIR/block in=test-new box=\[1,1,10\] out=test-smooth
            $KAPPA_DIR/sub test-new test-smooth noise
            $KAPPA_DIR/collapse noise axis=mjd bolo-noise estimator=csigma

#  Square the bolometer noise values, expand out to a full 3D array and set
#  as the variance component in test-new.
            $KAPPA_DIR/mult bolo-noise bolo-noise bolo-var
            $KAPPA_DIR/wcsalign method=near in=bolo-var ref=test-new out=bvar-cube accept
            $KAPPA_DIR/setvar test-new from=bvar-cube comp=data

#  Findback assumes the noise is the same through-out the data file. So convert
#  the signal into an SNR cube, so that we can use an RMS of 1.0 for all
#  pixels.
            $KAPPA_DIR/maths exp="ia/sqrt(va)" ia=test-new out=snr

#  We want findback to process time series independently, so we need to
#  re-order the axes to put the time axis first.
            $KAPPA_DIR/permaxes in=snr perm=\[3,1,2\] out=snr-perm

#  Now find the background in each time series.
            $CUPID_DIR/findback in=snr-perm out=snr-back-perm box=\[200,1,1\] \
                                rms=1.0 msg_filter=norm

#  Permute the axes in the background cube back to the original order.
            $KAPPA_DIR/permaxes in=snr-back-perm perm=\[2,3,1\] out=snr-back

#  Convert the background from SNR to data, and then subtract from the
#  original data.
            $KAPPA_DIR/maths exp="ia-ib*sqrt(va)" ia=test-new ib=snr-back \
                             out=backoff2

#  Get a list of the time slice indices with data sum more than 0.5 of the
#  maximum data sum in any slice.
            $SMURF_DIR/dsutils in=backoff2 border=4 outcat=out.txt \
                               lowfactor=0.5

#  Smooth the data, setting a low wlim in order to remove small groups of bad
#  pixels. Also remove the quality array otherwise the bad pixels come back again.
            $KAPPA_DIR/gausmooth in=backoff2 out=backoff wlim=1E-5 fwhm=1
            $KAPPA_DIR/erase backoff.quality ok

#  Strip the header from the out.txt file and create lists holding the
#  column values.
            grep -v \# out.txt > out2.txt
            set izs = `cat out2.txt | awk '{print $1}'`
            set sums = `cat out2.txt | awk '{print $2}'`
            set bc1s = `cat out2.txt | awk '{print $3}'`
            set bc2s = `cat out2.txt | awk '{print $4}'`
            set peak1s = `cat out2.txt | awk '{print $5}'`
            set peak2s = `cat out2.txt | awk '{print $6}'`
            rm -f out2.txt

#  Use pixel coords from here on, increasing the format precision from the
#  one decimal place provided by the NDF library.
            $KAPPA_DIR/wcsadd backoff frame=pixel domain=newpix maptype=unit accept
            $KAPPA_DIR/wcsattrib backoff set 'format(1)' "%5.3f"
            $KAPPA_DIR/wcsattrib backoff set 'format(2)' "%5.3f"
            $KAPPA_DIR/wcsattrib backoff set 'format(3)' "%5.3f"

#  Write out the header for the extended catalogue
            echo "# SCUBA-2 focal plane distortion data" > $scat
            echo "#" >> $scat
            echo "# IZ Sum BC1 BC2 PEAK1 PEAK2 BF1 BF2 DBF1 DBF2 Amp DAmp RMS obs subscan" >> $scat

#  Loop round the selected slice indices.
            set nslice = $#izs
            set islice = 0
            while( $islice < $nslice )
               @ islice = $islice + 1

#  Get the slice index.
               set iz = $izs[$islice]

#  Get the source peak position (pixel indicies) for this time slice
               set px = $peak1s[$islice]
               set py = $peak2s[$islice]

#  Find the centroid at the peak position, and its error. Use a smallish
#  search box to exclude the effect of pixels that remain lit up for some
#  time after the source has passed over them.
               rm -f junk.log
               $KAPPA_DIR/centroid backoff\(,,$iz\) mode=inter init="'$px $py'" \
                           maxshift=5 search=5 cerror=yes >& junk.log

#  Check the centroid was found succesfully.
               grep \!\! junk.log >& /dev/null
               if( $status == 1 ) then

#  Copy the centroid parameters into the output text file.
                  set posxy = `$KAPPA_DIR/parget centre centroid`
                  set errxy = `$KAPPA_DIR/parget error centroid`

#  Check there are no <bad> values.
                  echo "$posxy $errxy" | grep bad >& /dev/null
                  if( $status == 1 ) then

                     echo "$iz $sums[$islice] $bc1s[$islice] $bc2s[$islice] $peak1s[$islice] $peak2s[$islice] $posxy $errxy 1 0 0 $obsnum $subscan" >> $scat
                     echo "Slice $iz ($islice of $nslice) "

                  else
                     echo "Slice $iz ($islice of $nslice) - centroid failure"
                  endif

               else
                  echo "Slice $iz ($islice of $nslice) - centroid failure"
               endif

            end
         endif

#  Clean up some files to reduce the disk space usage of this script, but
#  retain some in order to allow debugging.
         rm -f snr*.sdf test-smooth.sdf noise.sdf bvar-cube.sdf

#  Move back to the observation directory.
         cd ..
      end

#  Now concatenate all the individual catalogues into one. Initialise it by
#  copying the first catalogue. Strip the header out of subsequent catalogues.
      set first = 1
      foreach n ($cats)
         if( $first == 1 ) then
            cp $n $cat
            set first = 0
         else
            grep -v \# $n >> $cat
         endif
      end

#  Set up a smoothing over 11 time slices
      set zbox = 6

#  Now handle the bolomaps method.
#  ===============================
   else

#  Use the iterative mapmaker to create map for each individual bolometers.
      $SMURF_DIR/makemap "$indir/*" method=iter out=junk system=AZEL \
                alignsys=t config="'^$SMURF_DIR/../../share/smurf/dimmconfig_distortionmap.lis,bolomap=1'" | tee makemap.log

#  See if the data has been flat-fielded (as implied by the map units being "pW"). If not,
#  the source features will be negative in the bolomaps.
      $KAPPA_DIR/ndftrace junk quiet
      set units = `$KAPPA_DIR/parget UNITS ndftrace`
      if( "$units" == "pW" ) then
         set negative = 0;
      else
         set negative = 1;
      endif

#  Get the subarray name, and its corresponding integer index.
      set subarray = `$KAPPA_DIR/fitsmod junk edit=print keyword=SUBARRAY`
      if( $subarray == "s8a" ) then
         set array = 0
      else if( $subarray == "s8b" ) then
         set array = 1
      else if( $subarray == "s8c" ) then
         set array = 2
      else if( $subarray == "s8d" ) then
         set array = 3
      else if( $subarray == "s4a" ) then
         set array = 4
      else if( $subarray == "s4b" ) then
         set array = 5
      else if( $subarray == "s4c" ) then
         set array = 6
      else if( $subarray == "s4d" ) then
         set array = 7
      else
         echo "Unknown subarray - $subarray"
         exit
      endif

#  See if the bolomaps have a chunk number in the NDF name or not. If so, get
#  the highest chunk number (only check up to 5 chunks).
      grep "Writing single bolo map" makemap.log | grep CH05 > /dev/null
      if( $status == 0 ) then
         set top_chunk = 5
      else
         grep "Writing single bolo map" makemap.log | grep CH04 > /dev/null
         if( $status == 0 ) then
            set top_chunk = 4
         else
            grep "Writing single bolo map" makemap.log | grep CH03 > /dev/null
            if( $status == 0 ) then
               set top_chunk = 3
            else
               grep "Writing single bolo map" makemap.log | grep CH02 > /dev/null
               if( $status == 0 ) then
                  set top_chunk = 2
               else
                  grep "Writing single bolo map" makemap.log | grep CH01 > /dev/null
                  if( $status == 0 ) then
                     set top_chunk = 1
                  else
                     set top_chunk = 0
                  endif
               endif
            endif
         endif
      endif

#  Get the date.
      set date = `$KAPPA_DIR/fitsmod junk edit=print keyword=UTDATE`

#  Get the middle elevation
      set el0 = `$KAPPA_DIR/fitsmod junk edit=print keyword=ELSTART`
      set el1 = `$KAPPA_DIR/fitsmod junk edit=print keyword=ELEND`
      set elev = `$KAPPA_DIR/calc exp="0.5*(pa+pb)" pa=$el0 pb=$el1`

#  Get the observation number.
      set obsnum = `$KAPPA_DIR/fitsmod junk edit=print keyword=OBSNUM`

#  Need to identify a usable subscan. Loop round all subscans in the
#  current directory.
      set usable = " "
      foreach n ($indir/s*_*_*.sdf)

#  If the file has SEQ_TYPE and OBS_TYPE headers, the scan is usable if
#  the values of these headers are equal
         set there = `$KAPPA_DIR/fitsmod $n edit=exist keyword=SEQ_TYPE`
         if( "$there" == "TRUE" ) then
            set there = `$KAPPA_DIR/fitsmod $n edit=exist keyword=OBS_TYPE`
            if( "$there" == "TRUE" ) then
               set seq_type = `$KAPPA_DIR/fitsmod $n edit=print keyword=SEQ_TYPE`
               set obs_type = `$KAPPA_DIR/fitsmod $n edit=print keyword=OBS_TYPE`
               if( "$seq_type" == "$obs_type" ) then
                  set usable = "$n"
               endif
            endif
         endif

#  If either the SEQ_TYPE or OBS_TYPE header was not found, check the file has
#  a SHUTTER keyword in its FITS extension
         if( "$there" != "TRUE" ) then
            set there = `$KAPPA_DIR/fitsmod $n edit=exist keyword=SHUTTER`
            if( "$there" == "TRUE" ) then

#  If the value of SHUTTER is zero, the scan is a dark (unusable).
               set val = `$KAPPA_DIR/fitsmod $n edit=print keyword=SHUTTER`
               if( "$val" != "0" ) then
                  set usable = "$n"
               endif
            endif
         endif
      end

      if( "$usable" == " " ) then
         echo "No usable scans found"
         exit
      endif

#  Get a Mapping from bolometer array pixel offsets from the reference point,
#  to (Az,El) offsets from the reference point, for a typical time slice,
#  in the usable scan found above, and invert it so it goes the other way.
#  Using this bolomaps approach, we need to assume that all the time slices
#  are rotated in the same way on the sky. The timeslices approach does not
#  suffer from this assumption.
      $SMURF_DIR/dsutils in=$usable bmap=bmap.ast
      $ATOOLS_DIR/astinvert bmap.ast bmap.ast

#  Write the header for the output catalogue.
      echo "# SCUBA-2 focal plane distortion data" > $cat
      echo "#" >> $cat
      echo "# ICH - zero-based makemap chunk index" >> $cat
      echo "# BC1 - array pixel X coord at centre of source " >> $cat
      echo "# BC2 - array pixel Y coord at centre of source " >> $cat
      echo "# BF1 - array pixel X coord at bolometer centre" >> $cat
      echo "# BF2 - - array pixel Y coord at bolometer centre" >> $cat
      echo "# DBC1 - error in BC1" >> $cat
      echo "# DBC2 - error in BC2" >> $cat
      echo "# AMP - source amplitude " >> $cat
      echo "# DAMP - error in AMP" >> $cat
      echo "# FSUM - total data value in fitted source " >> $cat
      echo "# RMS - RMS error of fit" >> $cat
      echo "# OBS - observation number" >> $cat
      echo "# DATE - observation date" >> $cat
      echo "# ARRAY - array index (s8a=0, s8b=1, s8c=2, s8d=3, s4a=4, s4b=5, s4c=6, s4d=7)" >> $cat
      echo "# ELEV - telescope elevation (degrees)" >> $cat
      echo "#" >> $cat
      echo "# ICH BC1 BC2 BF1 BF2 DBC1 DBC2 AMP DAMP FSUM RMS OBS DATE ARRAY ELEV" >> $cat

#  Loop round all GRID X columns (1 to 32)
      set ix = 0
      while( $ix < 32 )
         @ ix = $ix + 1

#  In the catalogue, the "true" source position (columns BF1 and BF2) is
#  given by the pixel coords of the centre of the bolometer used to make
#  the bolomap. Store the X pixel coord for the centre of bolometers in the
#  current column. This assumes the lower pixel index bound is zero on the
#  first axis.
         set bf1 = `$KAPPA_DIR/calc exp="pa-1.5" pa=$ix`

#  Loop round all GRID Y rows (1 to 40).
         set iy = 0
         while( $iy < 40 )
            @ iy = $iy + 1

#  In the catalogue, the "true" source position (columns BF1 and BF2) is
#  given by the pixel coords of the centre of the bolometer used to make
#  the bolomap. Store the Y pixel coord for the centre of bolometers in the
#  current row. This assumes the lower pixel index bound is zero on the second
#  axis.
            set bf2 = `$KAPPA_DIR/calc exp="pa-1.5" pa=$iy`

#  Loop round all chunks (if any)
            set ich = 0
            while( $ich <= $top_chunk )

#  Construct the name of the bolometer map.
               if( $top_chunk > 0 ) then
                  set bolo_name = "CH0${ich}"
               else
                  set bolo_name = ""
               endif

               if( $ix < 10 ) then
                  set bolo_name = "${bolo_name}C0${ix}"
               else
                  set bolo_name = "${bolo_name}C${ix}"
               endif

               if( $iy < 10 ) then
                  set bolo_name = "${bolo_name}R0${iy}"
               else
                  set bolo_name = "${bolo_name}R${iy}"
               endif

#  Skip if the bolomap was not created by makemap.
               grep -i $bolo_name makemap.log > /dev/null
               if( $status == 1 ) then
                  echo "Skipping bolomap $bolo_name"
               else
                  echo "Doing bolomap $bolo_name"

#  Get the full path to the bolomap NDF.
                  set ndf = "junk.more.smurf.bolomaps.$bolo_name"

#  From here on, use pixel coords to refer to positions within the bolomap,
#  increasing the format precision from the one decimal place provided by
#  the NDF library. NDF does not allow us to change the Format attributes for
#  the PIXEL Frame directly, so take a copy of the PIXEL Frame first, and set
#  the Format attributes of the copy.
                  $KAPPA_DIR/wcsadd $ndf frame=pixel domain=newpix maptype=unit accept
                  $KAPPA_DIR/wcsattrib $ndf set 'format(1)' "%5.3f"
                  $KAPPA_DIR/wcsattrib $ndf set 'format(2)' "%5.3f"

#  If source features are negative in the bolomap, negate the bolomap so that they become positive.
                  if( $negative == 1 ) then
                     $KAPPA_DIR/cmult $ndf -1 pos
                     set ndf = "pos"
                  endif

#  Find the pixel coords at the centre of the feature. The feature is
#  nominally at the reference point and so should, in the absence of errors
#  and incorrect polymaps, have pixel coords (0.5,0.5). PSF fails unless a good
#  central position is supplied, so first find the peak value in a box centred
#  on (0,0)
                  $KAPPA_DIR/stats $ndf'(0~20,0~20)' quiet
                  set maxco = `$KAPPA_DIR/parget maxcoord stats`
                  rm -f coin > /dev/null
                  echo $maxco > coin
                  $KAPPA_DIR/psf $ndf incat=! cofile=coin isize=31 norm=f device=! | grep \!\! >& /dev/null

#  Check a psf was found succesfully.
                  if( $status == 1 ) then

#  Get the parameters of the psf.
                     set amp = `$KAPPA_DIR/parget amp1 psf`
                     set posxy = `$KAPPA_DIR/parget centre psf`

#  Get the total data sum. Two methods - 1) aperture photometry...
                     if( $sum_method == APERADD ) then

#  Choose the aperture size in pixels (60 arc-secs assuming default makemap pixel sizes of 2
#  and 4 arc-seconds)..
                        if( $array > 3 ) then
                           set diam = 30
                        else
                           set diam = 15
                        endif

#  Replace any bad pixels within a box centred on the max pixel with sides twice
#  the above diameter.
                        @ size = $diam + $diam
                        $KAPPA_DIR/fillbad in=$ndf\($maxco[1]~$size,$maxco[2]~$size\) size=2 out=filled | grep \!\! >& /dev/null

#  Do the aperture photometry within the filled image. Check some bad pixels
#  were filled. If not, use $ndf instead of "filled".
                        if( $status == 1 ) then
                           $KAPPA_DIR/aperadd filled centre="'$posxy'" diam=$diam
                        else
                           $KAPPA_DIR/aperadd $ndf centre="'$posxy'" diam=$diam
                        endif
                        set fsum = `$KAPPA_DIR/parget total aperadd`

#  Alternatively - 2) use the integral of the model PSF as the souce total data sum.
                     else
                        set fsum = `$KAPPA_DIR/parget total psf`
                     endif

#  Get the Mapping from bolomap pixel coords to sky offsets from the
#  reference point, and combine with the mapping from sky offsets to focal
#  plane pixel coordinate offsets.
                     $ATOOLS_DIR/astgetmapping $ndf PIXEL SKY smap.ast
                     $ATOOLS_DIR/astcmpmap smap.ast bmap.ast yes \! sbmap.ast

#  Use this CmpMap to transform the psf centre from bolomap pixel coords
#  to offsets from the nominal reference point in pixel coords within the
#  bolometer array.
                     set dfp = `$ATOOLS_DIR/asttran2 sbmap.ast $posxy[1] $posxy[2] y`

#  Check for AST__BAD values from the above astTran2 call.
                     echo $dfp | grep -i "e+308" > /dev/null
                     if( $status == 0 ) then
                        echo "  astTran failure"

#  In the catalogue, the "base" source position (columns BC1 and BC2)
#  corresponds to the bolometer array pixel coords of the source after
#  distortion (columns BF1 and BF2 give the bolometer array pixel coords
#  of the source before distortion). In the absence of any distortion, the
#  psf centre found above would be at bolometer array pixel offsets (0,0).
#  Any discrepancy is caused by distortion (and noise). So modify the known
#  bolometer position ($bf1,$bf2) by subtracting off the discrepancies in
#  the psf position to get the distorted source position.
                     else
                        set bc1 = `$KAPPA_DIR/calc exp="pa-pb" pa=$bf1 pb=$dfp[1]`
                        set bc2 = `$KAPPA_DIR/calc exp="pa-pb" pa=$bf2 pb=$dfp[2]`

#  Copy the parameters of the fit into the output text file.
                        echo "$ich $bc1 $bc2 $bf1 $bf2 0 0 $amp 0 $fsum 0 $obsnum $date $array $elev " >> $cat
                     endif
                  else
                     echo "  psf failure"
                  endif
               endif

#  Increment the chunk index
               @ ich = $ich + 1
            end
         end
      end

#  If required, create an image containing the peak source values for every
#  bolometer in the current observation, and another containing the fitted
#  total data sum.
      if( $make_extra ) then
         $SMURF_DIR/dsutils infitx=\! incat=$cat subarray=$subarray \
                            outdx=! outdy=! outcat=\! \
                            colname=AMP colndf=../../$subarray$date-$obsnum-amp
         $SMURF_DIR/dsutils infitx=\! incat=$cat subarray=$subarray \
                            outdx=! outdy=! outcat=\! \
                            colname=FSUM colndf=../../$subarray$date-$obsnum-sum
      endif

      set zbox = !

   endif


#  From here on is common to both bolomaps and timeslices methods
#  ==============================================================

#  Bin the offsets in the "total.txt" catalogue to create two images, one
#  containing FplaneX offsets and the other containing FplaneY offsets,
#  both in units of mm. The current WCS Frame in these images is FPLANE
#  (also in units of mm). The GRID->FPLANE mapping includes no polynomial
#  distortion.
   $SMURF_DIR/dsutils infitx=\! incat=$cat subarray=$subarray \
                  outdx=outdx outdy=outdy outcat=\! zbox=$zbox

#  Move back to the "distortion-tmp" directory.
   cd ..

#  Construct a list of all the outdx.sdf files, and another of all the
#  outdy.sdf files.
   echo "$PWD/$pdir/outdx" >> outdx.lis
   echo "$PWD/$pdir/outdy" >> outdy.lis

#  Construct a list of all the aligned outdx.sdf files, and another of all the
#  aligned outdy.sdf files.
   echo "$PWD/$pdir/outdx_A" >> outdx_A.lis
   echo "$PWD/$pdir/outdy_A" >> outdy_A.lis

#  Choose a reference observation for later on. Prefer 450 um if both 450 and 850 are
#  present since the axes are the usual way round (unlike 850 which has swapped axes).
   if( $array > 3 ) then
      set refdx = "$PWD/$pdir/outdx"
      set refdy = "$PWD/$pdir/outdy"

   else if( $idir == 1 ) then
      set refdx = "$PWD/$pdir/outdx"
      set refdy = "$PWD/$pdir/outdy"
   endif

end

#  If we have more than one observation, we need to combine them.
if( $idir > 1 ) then

#  Align all the outdx and outdy files. Alignment occurs in focal plane
#  X and Y coords.
   $KAPPA_DIR/wcsalign in=^outdx.lis out=^outdx_A.lis method=sincsinc wlim=0.4 \
                       rebin=no ref=$refdx lbnd=!
   $KAPPA_DIR/wcsalign in=^outdy.lis out=^outdy_A.lis method=sincsinc wlim=0.4 \
                       rebin=no ref=$refdy lbnd=!

#  Mosaic them into a single image, adjusting the zero points to make
#  them agree as far as possible. Use the largest possible number of overlaps.
   @ nov = $idir - 1
   $CCDPACK_DIR/makemos in=^outdx_A.lis out=outdx-total zero scale \
                        logto=term skysup=0 method=median optov=$nov
   $CCDPACK_DIR/makemos in=^outdy_A.lis out=outdy-total zero scale \
                        logto=term skysup=0 method=median optov=$nov

#  If we only have one observation, just copy it to the right place.
else
   $KAPPA_DIR/ndfcopy in=^outdx.lis out=^outdx_A.lis
   $KAPPA_DIR/ndfcopy in=^outdy.lis out=^outdy_A.lis
   $KAPPA_DIR/ndfcopy in=^outdx_A.lis out=outdx-total
   $KAPPA_DIR/ndfcopy in=^outdy_A.lis out=outdy-total
endif

#  Ensure that the mean residual (after sigma clipping) is zero.
$KAPPA_DIR/stats outdx-total quiet clip=\[3,3,3\]
set mean = `$KAPPA_DIR/parget mean stats`
$KAPPA_DIR/csub outdx-total $mean a.sdf
mv -f a.sdf outdx-total.sdf

$KAPPA_DIR/stats outdy-total quiet clip=\[3,3,3\]
set mean = `$KAPPA_DIR/parget mean stats`
$KAPPA_DIR/csub outdy-total $mean a.sdf
mv -f a.sdf outdy-total.sdf

#  Save the names of the total focal plane offset images
set outdx = outdx-total
set outdy = outdy-total

#  Ensure focal plane Y is upwards so that we can use setaxis to transfer WCS
#  FPLANE coords into the NDF AXIS structures (as required by FITSURFACE)
$KAPPA_DIR/rotate $outdx out=outdxr angle=!

#  Set up AXIS structures holding the FPLANE X and Y positions in mm, and
#  make it the current Frame
$KAPPA_DIR/setaxis outdxr 1 wcs
$KAPPA_DIR/setaxis outdxr 2 wcs
$KAPPA_DIR/wcsframe outdxr axis

#  Fit a cubic surface to the values in the X error image, doing
#  sigma-clipping to get rid of aberrant points.
$KAPPA_DIR/surfit outdxr out=surfitx fittype=poly order=3 bindim=4 \
               estimator=mode fitclip=\[3,3\] evaluate=a

#  Surfit does not report the coefficients of the polynomial fit, so we now
#  use fitsurface to fit a surface to the cubic surface created by surfit.
#  Hopefully this fit will be exact since the surface is accurately cubic
#  by definition. The resulting polynomial coefficients are put into a
#  SURFACEFIT extension in the NDF. Select "cosys=data" so that the
#  polynomial transforms (Fx,Fy) in mm, into delta_Fx, also in mm.
$KAPPA_DIR/fitsurface surfitx variance=no fittype=poly nxpar=4 \
               nypar=4 overwrite cosys=data

#  Now do exactly the same with the Y correction image...
$KAPPA_DIR/rotate $outdy out=outdyr angle=!
$KAPPA_DIR/setaxis outdyr 1 wcs
$KAPPA_DIR/setaxis outdyr 2 wcs
$KAPPA_DIR/wcsframe outdyr axis
$KAPPA_DIR/surfit outdyr out=surfity fittype=poly order=3 bindim=4 \
               estimator=mode fitclip=\[3,3\] evaluate=a
$KAPPA_DIR/fitsurface surfity variance=no fittype=poly nxpar=4 \
               nypar=4 overwrite cosys=data


#  Produce the description of the forward transformation. C source code
#  defining the coefficients of the forward transformation of the PolyMap
#  are put in fwd.c
$SMURF_DIR/dsutils subarray=s8d infitx=surfitx infity=surfity outcode=fwd.c \
                            outdx=invdx outdy=invdy forward=yes


#  Now generate the inverse transformation. Allow the inverse polynomial to
#  be one degree higher than the forward polynomial, in order to achieve an
#  accurate inverse.
$KAPPA_DIR/rotate invdx out=invdxr angle=!
$KAPPA_DIR/setaxis invdxr 1 wcs
$KAPPA_DIR/setaxis invdxr 2 wcs
$KAPPA_DIR/wcsframe invdxr axis
$KAPPA_DIR/fitsurface invdxr variance=no fittype=poly nxpar=6 \
               nypar=6 overwrite cosys=data

$KAPPA_DIR/rotate invdy out=invdyr angle=!
$KAPPA_DIR/setaxis invdyr 1 wcs
$KAPPA_DIR/setaxis invdyr 2 wcs
$KAPPA_DIR/wcsframe invdyr axis
$KAPPA_DIR/fitsurface invdyr variance=no fittype=poly nxpar=6 \
               nypar=6 overwrite cosys=data

$SMURF_DIR/dsutils subarray=s8d infitx=invdxr infity=invdyr outcode=inv.c \
                            outdx=! outdy=! forward=no

#  Conbine both transformations into one file
rm -f code.c >& /dev/null
cat fwd.c inv.c > code.c

#  Now find the systematic offset unique to each individual directory.
foreach n (`cat outdx_A.lis`)

#  Find the mean residual between the X corrections for the current directory
#  and the overall X corrections.
   $KAPPA_DIR/sub $n outdx-total diff
   if( $idir > 1 ) then
      $KAPPA_DIR/stats diff quiet clip=\[3,3,3\]
   else
      $KAPPA_DIR/stats diff quiet
   endif
   set mean = `$KAPPA_DIR/parget mean stats`

#  Get the subarray name, and store the result in a file for the subarray
   set words = `$KAPPA_DIR/setext $n DSUTILS get SUBARRAY loop=no`
   set subarray = $words[3]
   if( -e $subarray.fpcx ) then
      echo $mean >> $subarray.fpcx
   else
      echo $mean > $subarray.fpcx
   endif
end

#  Do the same for the Y offsets.
foreach n (`cat outdy_A.lis`)
   $KAPPA_DIR/sub $n outdy-total diff
   if( $idir > 1 ) then
      $KAPPA_DIR/stats diff quiet clip=\[3,3,3\]
   else
      $KAPPA_DIR/stats diff quiet
   endif
   set mean = `$KAPPA_DIR/parget mean stats`
   set words = `$KAPPA_DIR/setext $n DSUTILS get SUBARRAY loop=no`
   set subarray = $words[3]
   if( -e $subarray.fpcy ) then
      echo $mean >> $subarray.fpcy
   else
      echo $mean > $subarray.fpcy
   endif
end

echo "" >> code.c

#  Find the median (or mean if less than 4 values are available) X offset for each subarray,
#  converting from mm to pixels.
foreach n (s*.fpcx)
   set w = `wc $n`
   $KAPPA_DIR/trandat freename=$n auto shape=$w[1] ndf=tmp

   if( $w[1] > 3 ) then
      $KAPPA_DIR/stats tmp order quiet
      set typical = `$KAPPA_DIR/parget median stats`
   else
      $KAPPA_DIR/stats tmp quiet
      set typical = `$KAPPA_DIR/parget mean stats`
   endif

   set typical = `$KAPPA_DIR/calc exp='pa/1.135' pa=$typical`
   set subarray = `basename $n .fpcx`
   echo "Add $typical pixels to the focal plane X centre of subarray $subarray" | tee -a code.c
end

#  Find the median (or mean if less than 4 values are available) Y offset for each subarray,
#  converting from mm to pixels.
foreach n (s*.fpcy)
   set w = `wc $n`
   $KAPPA_DIR/trandat freename=$n auto shape=$w[1] ndf=tmp

   if( $w[1] > 3 ) then
      $KAPPA_DIR/stats tmp order quiet
      set typical = `$KAPPA_DIR/parget median stats`
   else
      $KAPPA_DIR/stats tmp quiet
      set typical = `$KAPPA_DIR/parget mean stats`
   endif

   set typical = `$KAPPA_DIR/calc exp='pa/1.135' pa=$typical`
   set subarray = `basename $n .fpcy`
   echo "Add $typical pixels to the focal plane Y centre of subarray $subarray" | tee -a code.c
end

#  Move the final result ("code.c") into the parent directory

echo
if( -e code.c ) then
   mv -f code.c ..
   echo "Finished - results are in file code.c"
else
   echo "Finished - something went wrong so there are no results :-("
endif
echo




