#!/usr/bin/env python

'''
*+
*  Name:
*     POL2IMAP

*  Purpose:
*     Create an I map from a set of POL-2 "spin&scan" data files.

*  Description:
*     This script creates a total intensity map from a set of POL-2
*     observation. New observations can be added into the map without the
*     need to re-process previously processed observations.
*
*     It also determines the FCF degradation factor by comparing the
*     resulting total intensity map with the supplied reference map
*     (which should be derived from non-POL2 SCUBA-2 observations). The
*     corresponding FCF is stored in the FITS header of the output total
*     intensity map. This comparison also determines how to filter the
*     reference map so that it looks as similar as possible to the POL2
*     total intensity map (see parameter REFOUT).
*
*     Note, with the default configuration this script can take up to
*     an hour to run for each observation.

*  Usage:
*     pol2imap in out [pixsize] [qudir] [mapdir] [retain] [msg_filter]
*              [ilevel] [glevel] [logfile]

*  ADAM Parameters:
*     CONFIG = LITERAL (Read)
*        Extra parameter values to include in the MAKEMAP configuration.
*        The supplied configuration is applied on top of the following
*        set of parameters:
*
*        ^$STARLINK_DIR/share/smurf/.dimmconfig_pol2.lis
*        numiter = -100
*        maptol = 0.05
*        maptol_mask = <undef>
*        maptol_mean = 0
*        maptol_box = 60
*        maptol_hits = 1
*
*        ast.zero_snr = 3
*        ast.zero_freeze = 0.1
*        ast.skip = 10
*        ast.mapspike_freeze = 5
*
*        pca.pcathresh = -100
*        pca.zero_snr = 5
*        pca.zero_snrlo = 3
*        pca.zero_freeze = -1
*        pca.zero_niter = 0.2
*
*        If a configuration is supplied, values supplied for any of th
*        above parameters will over-write the values specified above.
*        In addition, the following mandatory values are always appended to
*        the end of the used configuration:
*
*        flagslow = 0.01
*        downsampscale = 0
*        noi.usevar=1
*
*        If null (!) or "def" is supplied, the above initial set of
*        configuration parameters are used withotu change. ["def"]
*     GLEVEL = LITERAL (Read)
*        Controls the level of information to write to a text log file.
*        Allowed values are as for "ILEVEL". The log file to create is
*        specified via parameter "LOGFILE. In adition, the glevel value
*        can be changed by assigning a new integer value (one of
*        starutil.NONE, starutil.CRITICAL, starutil.PROGRESS,
*        starutil.ATASK or starutil.DEBUG) to the module variable
*        starutil.glevel. ["ATASK"]
*     ILEVEL = LITERAL (Read)
*        Controls the level of information displayed on the screen by the
*        script. It can take any of the following values (note, these values
*        are purposefully different to the SUN/104 values to avoid confusion
*        in their effects):
*
*        - "NONE": No screen output is created
*
*        - "CRITICAL": Only critical messages are displayed such as warnings.
*
*        - "PROGRESS": Extra messages indicating script progress are also
*        displayed.
*
*        - "ATASK": Extra messages are also displayed describing each atask
*        invocation. Lines starting with ">>>" indicate the command name
*        and parameter values, and subsequent lines hold the screen output
*        generated by the command.
*
*        - "DEBUG": Extra messages are also displayed containing unspecified
*        debugging information.
*
*        In adition, the glevel value can be changed by assigning a new
*        integer value (one of starutil.NONE, starutil.CRITICAL,
*        starutil.PROGRESS, starutil.ATASK or starutil.DEBUG) to the module
*        variable starutil.glevel. ["PROGRESS"]
*     IN = NDF (Read)
*        A group of input files. Each specified file must be one of the
*        following types:
*        - a raw POL-2 data file
*        - a time-series file holding Stokes Q, U or I values (any Q or
*        U values are ignored)
*        - a two-dimensional map holding Stokes Q, U or I values (any Q or
*        U maps are ignored). Any I maps must be in units of pW.
*        Any combination of the above types can be supplied.
*     JY = _LOGICAL (Read)
*        If TRUE, the main output map specified by parameter "OUT" will be
*        in units of Jy/beam. Otherwise they will be in units of pW. Note,
*        the I maps made from individual observations (see parameter MAPDIR)
*        are always in units of pW. [True]
*     LOGFILE = LITERAL (Read)
*        The name of the log file to create if GLEVEL is not NONE. The
*        default is "<command>.log", where <command> is the name of the
*        executing script (minus any trailing ".py" suffix), and will be
*        created in the current directory. Any file with the same name is
*        over-written. The script can change the logfile if necessary by
*        assign the new log file path to the module variable
*        "starutil.logfile". Any old log file will be closed befopre the
*        new one is opened. []
*     MAPDIR = LITTERAL (Read)
*        The name of a directory in which to put the I maps made from
*        each individual observation supplied via "IN", before coadding
*        them (the OUT parameter specify the final coadded I map). If
*        null is supplied, the new maps are placed in the same temporary
*        directory as all the other intermediate files and so will be
*        deleted when the script exists (unless parameter RETAIN is set
*        TRUE). Note, these maps are always in units of pW. Each one will
*        contain FITS headers specifying the pointing corrections needed
*        to align the map with the reference map. [!]
*     MSG_FILTER = LITERAL (Read)
*        Controls the default level of information reported by Starlink
*        atasks invoked within the executing script. This default can be
*        over-ridden by including a value for the msg_filter parameter
*        within the command string passed to the "invoke" function. The
*        accepted values are the list defined in SUN/104 ("None", "Quiet",
*        "Normal", "Verbose", etc). ["Normal"]
*     NORTH = LITERAL (Read)
*        Specifies the celestial coordinate system to use as the reference
*        direction in any newly created Q and U time series files. For
*        instance if NORTH="AZEL", then they use the elevation axis as the
*        reference direction, and if "ICRS" is supplied, they use the ICRS
*        Declination axis. If "TRACKING" is supplied, they use north in the
*        tracking system - what ever that may be. ["TRACKING"]
*     OUT = NDF (Write)
*        The output NDF in which to return the total intensity (I) map
*        including all supplied observations.
*     PIXSIZE = _REAL (Read)
*        Pixel dimensions in the output I maps, in arcsec. The default
*        is 4 arc-sec for 850 um data and 2 arc-sec for 450 um data. []
*     QUDIR = LITTERAL (Read)
*        The name of a directory in which to put the Q, U and I time series
*        generated by SMURF:CALCQU, prior to generating maps from them. If
*        null (!) is supplied, they are placed in the same temporary directory
*        as all the other intermediate files and so will be deleted when the
*        script exists (unless parameter RETAIN is set TRUE). [!]
*     REF = NDF (Read)
*        An optional map defining the pixel grid for the output maps. See
*        also parameter REFOUT. [!]
*     REFOUT = NDF (Write)
*        An optional output map in which is stored a version of the
*        supplied REF map that is as similar as possible to the output
*        total intensity map. Low frequencies not present in the
*        output total intensity map are removed from the supplied REF map,
*        and the pixel values are adjusted to take account of the FCF
*        degradation measured in the total intensity map. This parameter is
*        only used if a non-null value is supplied for parameter REF. [!]
*     RETAIN = _LOGICAL (Read)
*        Should the temporary directory containing the intermediate files
*        created by this script be retained? If not, it will be deleted
*        before the script exits. If retained, a message will be
*        displayed at the end specifying the path to the directory. [FALSE]

*  Copyright:
*     Copyright (C) 2016 East Asian Observatory.
*     All Rights Reserved.

*  Licence:
*     This program is free software; you can redistribute it and/or
*     modify it under the terms of the GNU General Public License as
*     published by the Free Software Foundation; either Version 2 of
*     the License, or (at your option) any later version.
*
*     This program is distributed in the hope that it will be
*     useful, but WITHOUT ANY WARRANTY; without even the implied
*     warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
*     PURPOSE. See the GNU General Public License for more details.
*
*     You should have received a copy of the GNU General Public License
*     along with this program; if not, write to the Free Software
*     Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
*     02110-1301, USA.

*  Authors:
*     DSB: David S. Berry (EAO)
*     {enter_new_authors_here}

*  History:
*     13-DEC-2016 (DSB):
*        Original version
'''

import os
import math
import shutil
import starutil
import numpy as np
from starutil import invoke
from starutil import NDG
from starutil import Parameter
from starutil import ParSys
from starutil import msg_out
from starutil import AtaskError
from starutil import get_fits_header
from starutil import get_task_par

#  Assume for the moment that we will not be retaining temporary files.
retain = 0

#  A function to clean up before exiting. Delete all temporary NDFs etc,
#  unless the script's RETAIN parameter indicates that they are to be
#  retained. Also delete the script's temporary ADAM directory.
def cleanup():
   global retain
   ParSys.cleanup()
   if retain:
      msg_out( "Retaining temporary files in {0}".format(NDG.tempdir))
   else:
      NDG.cleanup()




#  Find the Gaussian filtering FWHM (in pixels) and FCF degradation factor
#  that produces the best match between the supplied reference map and the
#  supplied POL2 I map. The FCF degradation factor is defined by
#  "imap = degFac * ref".
def match( ref, imasked, fwhm1=4, fwhm2=100 ):

#  To avoid creating hundreds of temp NDFs, re-use the same ones for each
#  FWHM.
   lof = NDG(1)
   hif = NDG(1)
   iscaled = NDG(1)
   residuals = NDG(1)

#  Create a logarithmically spaced list of 5 FWHM values, in pixels,
#  between the supplied upper and lower FWHM limits. Try each smoothing FWHM
#  in turn, finding the one that gives the best match (i.e. lowest RMS
#  residuals) between high-pass filtered ref image and new I map. On each pass,
#  low frequencies are removed from the ref image using the current FWHM,
#  and the filtered ref image is compared to the new I map (allowing for
#  a degradation in FCF).
   minrms = 1.0E30
   result = (0.0,0.0)
   previous_fwhm = -1
   fwhm1_next = -1
   fwhm2_next = 0
   for fwhm in np.logspace( math.log10(fwhm1), math.log10(fwhm2), 5 ):

#  If required, record the current FWHM value as the upper limit for this
#  function on the next level of recursion.
      if fwhm2_next == -1:
         fwhm2_next = fwhm

#  If an error occurs estimating the RMS for a specific FWHM, ignore the
#  FWHM and pass on to the next.
      try:

#  High-pass filter the ref image by smoothing it with a Gaussian of the
#  current FWHM and then subtracting off the smoothed version.
         invoke("$KAPPA_DIR/gausmooth in={0} out={1} fwhm={2}".
                format( ref, lof, fwhm ))
         invoke("$KAPPA_DIR/sub in1={0} in2={1} out={2}".
                format( ref, lof, hif ))

#  We will now use kappa:normalize to do a least squares fit between the
#  pixel values in the filtered ref image and the corresponding pixel values
#  in the new I map. This gives us the FCF degradation factor for the I
#  map (the gradient of the fit), and scales the I map so that it has the same
#  normalisation as the ref map. The scaling information is in the high
#  data values (the source regions), and the fitting process will be
#  confused if we include lots of background noise regions, so we use the
#  masked I map instead of the full I map. We also tell kappa:normalise
#  to use inly pixels that have a ref value above 2 times the noise value
#  in ref map (to exclude any noise pixels that have been included in the
#  masked I map). So first find the maximum value in the filtered ref map
#  (the upper data limit for kappa:normalize).
         invoke( "$KAPPA_DIR/stats ndf={0}".format(hif) )
         highlimit = float( get_task_par( "MAXIMUM", "stats" ) )

#  Get the noise level in the filtered ref map. This gives us the lower
#  data limit for kappa:normalize. The filtered noise ref has no low
#  frequencies ad so will be basically flat. So we can just the standard
#  deviation of the pixel values as the noise. But we do 3 iterations of
#  sigma clipping to exclude the bright source regions.
         invoke( "$KAPPA_DIR/stats ndf={0} clip=\[3,3,3\]".format(hif) )
         noise = float( get_task_par( "SIGMA", "stats" ) )

#  Now use kappa:normalise to do the fit, using only ref values between
#  lowlimit and highlimit. The slope gives the FCF degradation factor,
#  and the offset indicates the difference in bowling between the filtered
#  ref map and the I map (we do not use the offset).
         invoke( "$KAPPA_DIR/normalize in1={0} in2={1} out={2} device=! "
                 "datarange=\[{3},{4}\]".format(imasked,hif,iscaled,2*noise,
                                                highlimit))
         degfac = float( get_task_par( "SLOPE", "normalize" ) )

#  Now we have a version of the I map that is scaled so that it looks
#  like the filtered ref map. Get the residuals between the filtered ref
#  map and the scaled I map. Turn these residuals into SNR values by dividing
#  them by the noise level in the filtered ref map, and then get the RMS
#  of the residuals. We convert the residuals to SNR values because, if the
#  ref map and I map were identical, heavier filtering would reduce the
#  noise, and thus the RMS of the residuals. We want to minimise the RMS
#  of the residuals, and so without conversion to SNR, the minimum would
#  always be found at the heaviest possible filtering.
         invoke( "$KAPPA_DIR/maths exp=\"'(ia-ib)/pa'\" ia={0} ib={1} pa={2} out={3}".
                 format(hif,iscaled,noise,residuals))

#  Get the RMS of the residuals.
         invoke( "$KAPPA_DIR/stats ndf={0}".format(residuals) )
         mean = float( get_task_par( "MEAN", "stats" ) )
         sigma = float( get_task_par( "SIGMA", "stats" ) )
         rms = math.sqrt( mean*mean + sigma*sigma )

#  If this is the lowest RMS found so far, remember it - together with
#  the FWHM and degradation factor.
         if rms < minrms:
            minrms = rms
            result = (degfac,fwhm)
            fwhm1_next = previous_fwhm
            fwhm2_next = -1

#  If an error occurs estimating the RMS for a specific FWHM, ignore the
#  FWHM and pass on to the next.
      except starutil.AtaskError as err:
         pass

#  Record the current FWHM value for use on the next pass.
      previous_fwhm = fwhm

#  Progress report....
      msg_out("   Smoothing with FWHM = {0} pixels gives RMS = {1}".format(fwhm,rms))

#  If the range of FWHM values used by this invocation is greater than 1,
#  invoke this function recursively to find the best FWHM within a smaller
#  range centred on the best FWHM.
   if minrms < 1.0E30 and (fwhm2 - fwhm1) > 1:
      if fwhm1_next <= 0:
         fwhm1_next = fwhm1
      if fwhm2_next <= 0:
         fwhm2_next = fwhm2
      result = match( ref, imasked, fwhm1_next, fwhm2_next )


   return result


#  Main entry...
#  Catch any exception so that we can always clean up, even if control-C
#  is pressed.
try:

#  Declare the script parameters. Their positions in this list define
#  their expected position on the script command line. They can also be
#  specified by keyword on the command line. No validation of default
#  values or values supplied on the command line is performed until the
#  parameter value is first accessed within the script, at which time the
#  user is prompted for a value if necessary. The parameters "MSG_FILTER",
#  "ILEVEL", "GLEVEL" and "LOGFILE" are added automatically by the ParSys
#  constructor.
   params = []

   params.append(starutil.ParNDG("IN", "The input POL2 data",
                                 get_task_par("DATA_ARRAY","GLOBAL",
                                              default=Parameter.UNSET)))

   params.append(starutil.ParNDG("OUT", "The output total intensity map",
                                 default=None, exists=False, minsize=1,
                                 maxsize=1 ))

   params.append(starutil.Par0S("CONFIG", "Map-maker tuning parameters",
                                "def", noprompt=True))

   params.append(starutil.Par0F("PIXSIZE", "Pixel size (arcsec)", None,
                                 maxval=1000, minval=0.01, noprompt=True))

   params.append(starutil.Par0S("QUDIR", "Directory in which to save new "
                                "Q, U and I time series", None, noprompt=True))

   params.append(starutil.Par0S("MAPDIR", "Directory in which to save new "
                                "I maps before they are co-added", None,
                                noprompt=True))

   params.append(starutil.Par0L("RETAIN", "Retain temporary files?", False,
                                 noprompt=True))

   params.append(starutil.ParNDG("REF", "Reference map defining the pixel grid", default=None,
                                 noprompt=True, minsize=0, maxsize=1 ))

   params.append(starutil.ParNDG("REFOUT", "The filtered and scaled reference map",
                                 default=None, exists=False, minsize=0,
                                 maxsize=1,noprompt=True))

   params.append(starutil.ParChoice( "NORTH", ("TRACKING","FK5","ICRS","AZEL",
                                     "GALACTIC","GAPPT","FK4","FK4-NO-E",
                                     "ECLIPTIC"), "Celestial system to "
                                     "use as reference direction", "TRACKING",
                                     noprompt=True ))

   params.append(starutil.Par0F("REFFCF", "FCF needed to convert REF map to pW"))

   params.append(starutil.Par0L("Jy", "Should output I map be converted from pW to Jy/beam?",
                 True, noprompt=True))


#  Initialise the parameters to hold any values supplied on the command
#  line.
   parsys = ParSys( params )

#  It's a good idea to get parameter values early if possible, in case
#  the user goes off for a coffee whilst the script is running and does not
#  see a later parameter propmpt or error...

#  Get the input POL-2 data files. They should be supplied as the first item on
#  the command line, in the form of a Starlink "group expression" (i.e.
#  the same way they are supplied to other SMURF commands such as makemap).
   indata = parsys["IN"].value

#  Now get the I output map.
   imap = parsys["OUT"].value

#  The user-supplied makemap config, and pixel size.
   config = parsys["CONFIG"].value
   pixsize = parsys["PIXSIZE"].value
   if pixsize:
      pixsize_par = "pixsize={0}".format(pixsize)
   else:
      pixsize_par = ""

#  See if temp files are to be retained.
   retain = parsys["RETAIN"].value

#  Get the reference map
   ref_fcf = None
   ref = parsys["REF"].value
   if not ref:
      ref = "!"
      refout = None
      ref_units = None
   else:

#  See if a filtered and scaled v ersion of the referenc emap is to be
#  created.
      refout = parsys["REFOUT"].value

#  If the REF map is in units of mJy/beam, convert it to pW using the FCF
#  in the "FCF" FITS header if available, or the standard FCF for the
#  wavelength otherwise.
      invoke("$KAPPA_DIR/ndftrace ndf={0} quiet".format(ref) )
      ref_units = get_task_par( "UNITS", "ndftrace" ).replace(" ", "")
      if ref_units != "pW":

         try:
            filter = int( float( get_fits_header( ref, "FILTER", True )))
         except starutil.NoValueError:
            filter = 850
            msg_out( "No value found for FITS header 'FILTER' in {0} - assuming 850".format(ref))

         if filter != 450 and filter != 850:
            raise starutil.InvalidParameterError("Invalid FILTER header value "
                   "'{0} found in {1}.".format( filter, ref ) )

         if ref_units == "mJy/beam":
            if filter == 450:
               fcf = 491000.0
            else:
               fcf = 537000.0

         elif ref_units == "Jy/beam":
            if filter == 450:
               fcf = 491.0
            else:
               fcf = 537.0

         elif ref_units == "mJy/arcsec**2" or ref_units == "mJy/arcsec^2" :
            if filter == 450:
               fcf = 4710
            else:
               fcf = 2340

         elif ref_units == "Jy/arcsec**2" or ref_units == "Jy/arcsec^2" :
            if filter == 450:
               fcf = 4.71
            else:
               fcf = 2.34

         else:
            raise starutil.InvalidParameterError("REF map {0} has unsupported units {1}".
                                                 format(ref, ref_units) )

         fcfhead = get_fits_header( ref, "FCF" )
         if fcfhead != None:
            fcfhead = float( fcfhead )
            ratio = fcfhead/fcf
            if ratio < 0.5 or ratio > 2.0:
               msg_out("WARNING: REF map {0} has units {1} but the FCF header is {2} "
                       "- which looks wrong (the expected FCF is {3}).".
                       format(ref, ref_units, fcfhead, fcf) )
            fcf = fcfhead

         parsys["REFFCF"].default = fcf
         ref_fcf = parsys["REFFCF"].value

         msg_out( "Converting REF map ({0}) from {1} to pW using FCF={2}...".
                  format(ref,ref_units,ref_fcf))
         refpw = NDG(1)
         invoke("$KAPPA_DIR/cdiv in={0} scalar={1} out={2}".format(ref,ref_fcf,refpw) )
         ref = refpw

#  See if we should convert the output I map from pW to Jy/beam.
   jy = parsys["JY"].value

#  See where to put new I maps for individual observations, and
#  ensure the directory exists.
   mapdir =  parsys["MAPDIR"].value
   if not mapdir:
      mapdir = NDG.tempdir
   elif not os.path.exists(mapdir):
      os.makedirs(mapdir)

#  See where to put new Q, U and I time series, and ensure the directory exists.
   qudir =  parsys["QUDIR"].value
   if not qudir:
      qudir = NDG.tempdir
   elif not os.path.exists(qudir):
      os.makedirs(qudir)

#  Get the reference direction.
   north = parsys["NORTH"].value






#  Classify each input data file as raw, QUI time-series or QUI map. Create
#  three separate text files containing all input NDFs of each type (plus
#  a fourth holing non-POL2 data). Also, create another text file
#  containing a list of ony missing raw sub-scan files.
   junks = NDG.tempfile()
   inraws = NDG.tempfile()
   inquis = NDG.tempfile()
   inmaps = NDG.tempfile()
   rawinfo = NDG.tempfile()
   missing = NDG.tempfile()
   invoke("$SMURF_DIR/pol2check in={0} quiet=yes junkfile={1} mapfile={2} "
          "rawfile={3} stokesfile={4} rawinfo={5} missing={6}".
          format(indata,junks,inmaps,inraws,inquis,rawinfo,missing))

#  Warn about any non-POL2 input data files that are being ignored.
   if get_task_par( "JUNKFOUND", "pol2check" ):
      msg_out( " ")
      msg_out( "WARNING: The following inappropriate input data files are "
               "being ignored: " )
      with open( junks ) as f:
         msg_out( f.read() )
      msg_out( " ")

#  Warn about any missing raw data scub-scans.
   if os.path.isfile( missing ):
      msg_out( " ")
      msg_out( "WARNING: The raw data files for the following sub-scans seem "
               "to be missing from the supplied list of input files: " )
      with open( missing ) as f:
         msg_out( f.read() )
      msg_out( " ")

#  Initialise the list of all Stokes time-series files to be processed by
#  makemap so that it holds any Stokes time-series files supplied by
#  parameter IN.
   allquis = NDG.tempfile()
   if get_task_par( "STOKESFOUND", "pol2check" ):
      shutil.copyfile( inquis, allquis )

#  Initialise the list of all Stokes maps to be included in the final I
#  map so that it holds any maps supplied by parameter IN. Check that any
#  supplied maps are in units of pW.
   allmaps = NDG.tempfile()
   if get_task_par( "MAPFOUND", "pol2check" ):
      shutil.copyfile( inmaps, allmaps )

      with open(allmaps) as infile:
         lines = infile.readlines()
      paths = [line.strip() for line in lines]
      for path in paths:
         invoke("$KAPPA_DIR/ndftrace ndf={0} quiet".format(path) )
         units = get_task_par( "UNITS", "ndftrace" ).replace(" ", "")
         if units != "pW":
            raise starutil.InvalidParameterError("All supplied "
                 "maps must be in units of 'pW', but '{0}' has units '{1}'.".
                 format(path,units))
   else:
      open( allmaps, 'a').close()



#  If any raw analysed intensity files were supplied, use smurf:calcqu to
#  convert them into Stokes paramater time-series files.
   if get_task_par( "RAWFOUND", "pol2check" ):
      msg_out( "Calculating Q, U and I time streams from raw analysed intensity data...")

#  Get a dict in which each key is an observation identifier of the form
#  <UT>_<OBS>, and each value is a list of raw data files for the observation.
      with open(inraws) as infile:
         lines = infile.readlines()
      paths = [line.strip() for line in lines]

      with open(rawinfo) as infile:
         lines = infile.readlines()
      infos = [line.strip() for line in lines]

      rawlist = {}
      for (path,id) in zip( paths, infos ):
         if id in rawlist:
            if path not in rawlist[id]:
               rawlist[id].append( path )
         else:
            rawlist[id] = [ path ]

#  Run calcqu separately on each observation.
      nobs = len(rawlist)
      iobs = 0
      for id in rawlist:
         iobs += 1
         msg_out("   {0}/{1}: Processing {2} raw data files from observation {3} ... ".
                 format(iobs,nobs,len(rawlist[ id ]), id ) )

#  Create an NDG object holding the raw POL2 files for the current
#  observation.
         rawdata = NDG( rawlist[ id ] )

#  Use CALCQU to create the new Q, U and I time streams from the supplied
#  analysed intensity time streams. Put them in the QUDIR directory.
         new_q = NDG.tempfile()
         new_u = NDG.tempfile()
         new_i = NDG.tempfile()
         try:
            invoke("$SMURF_DIR/calcqu in={0} lsqfit=yes config=def outq={1}/\*_QT "
                   "outu={1}/\*_UT outi={1}/\*_IT fix=yes north={2} outfilesi={3} "
                   "outfilesq={4} outfilesu={5}".
                   format( rawdata, qudir, north, new_i, new_q, new_u ) )

#  Append the new Stokes parameter time series files created above to the
#  list of all Stokes parameter time series files.
            with open(allquis, 'a') as outfile:
               for fname in ( new_q, new_u, new_i ):
                   if os.path.isfile( fname ):
                       with open(fname) as infile:
                          outfile.write(infile.read())

         except starutil.AtaskError as err:
            msg_out( err )
            msg_out( "\nAn error occurred within CALCQU. The above observation will be ignored.\nContinuing to process any remaining observations...\n" )

#  If we have some  time-series files to process...
   if os.path.isfile(allquis):

#  Create a text file holding information about all the Stokes time-series
#  files to be processed. For each one, get the Stokes parameter (Q, U or I)
#  and a key that is unique for the chunk of data, of the form
#  "<UT>_<OBS>_<SUBSCAN>".
      stokesinfo = NDG.tempfile()
      quindg = NDG("^{0}".format(allquis) )
      invoke("$SMURF_DIR/pol2check in={0} quiet=yes stokesinfo={1}".
             format(quindg,stokesinfo))

#  Set up three dicts - one each for Q, U and I. Each key is as described
#  above. Each value is a list of paths for NDFs holding data with the same
#  key and the same Stokes parameter (Q, U or I).
      with open(allquis) as infile:
         lines = infile.readlines()
      paths = [line.strip() for line in lines]

      with open(stokesinfo) as infile:
         lines = infile.readlines()
      infos = [line.strip() for line in lines]

      ilist = {}
      qlist = {}
      ulist = {}
      for (path,info) in zip( paths, infos ):
         (stokes,id) = info.split()
         if stokes == "Q":
            if id in qlist:
               if path not in qlist[id]:
                  qlist[id].append( path )
            else:
               qlist[id] = [ path ]

         elif stokes == "U":
            if id in ulist:
               if path not in ulist[id]:
                  ulist[id].append( path )
            else:
               ulist[id] = [ path ]

         else:
            if id in ilist:
               if path not in ilist[id]:
                  ilist[id].append( path )
            else:
               ilist[id] = [ path ]

#  Create a config file to use with makemap.
      conf = NDG.tempfile()
      fd = open(conf,"w")

#  Store the default set of config parameters in the config file.
      fd.write("^$STARLINK_DIR/share/smurf/.dimmconfig_pol2.lis\n")
      fd.write("numiter = -100\n")
      fd.write("maptol = 0.05\n")
      fd.write("maptol_mask = pca\n")
      fd.write("maptol_mask = <undef>\n")
      fd.write("maptol_mean = 0\n")
      fd.write("maptol_box = 60\n")
      fd.write("maptol_hits = 1\n")

      fd.write("ast.zero_freeze = 0.1\n")
      fd.write("ast.zero_snr = 3\n")
      fd.write("ast.skip = 10\n")
      fd.write("ast.mapspike_freeze = 5\n")

      fd.write("pca.pcathresh = -100\n")
      fd.write("pca.zero_snr = 5\n")
      fd.write("pca.zero_snrlo = 3\n")
      fd.write("pca.zero_freeze = -1\n")
      fd.write("pca.zero_niter = 0.2\n")

#  If the user supplied extra config parameters, append them to the
#  config file.
      if config and config != "def":
         fd.write("{0}\n".format(config))

#  Now put in values that are absolutely required by this script. These
#  over-write any values in the user-supplied config.
      fd.write("noi.usevar=1\n")
      fd.write("flagslow=0.01\n")
      fd.write("downsampscale=0\n")
      fd.close()

      if len(ilist) == 1:
         msg_out( "Only one observation supplied" )

#  Dictionaries holding the I map for each observation chunk.
      imaps = {}

#  Loop over all I time series files. Each separate observation will
#  usually have one I time series file (although there may be more if the
#  observation was split into two or more discontiguous chunks). We form
#  an I map for each observation chunk present in the supplied list of
#  input raw data.
      for key in ilist:

#  Get the I time stream files for the current observation chunk.
         isdf = NDG( ilist[ key ] )
         msg_out("\n>>>>   Making an I map from {0}...\n".format(key) )

#  AZ/EL pointing correction, for data between 20150606 and 20150930.
         ut = int(get_fits_header( isdf[0], "UTDATE", True ))
         if ut >= 20150606 and ut <= 20150929:
            pntfile = NDG.tempfile()
            fd = open(pntfile,"w")
            fd.write("# system=azel\n")
            fd.write("# tai dlon dlat\n")
            fd.write("54000 32.1 27.4\n")
            fd.write("56000 32.1 27.4\n")
            fd.close()
         else:
            pntfile = "!"

#  Make a map from the I time series. Ensure we continue to process any remaining
#  observation chunks if the current chunk fails.
         imaps[key] = NDG("{0}/{1}_imap".format(mapdir,key), False)
         try:
            invoke("$SMURF_DIR/makemap in={0} config=^{1} out={2} ref={3} pointing={4} "
                   "{5}".format(isdf,conf,imaps[key],ref,pntfile,pixsize_par))

#  If no ref map was supplied, use the I map for the first observatuon as
#  the ref map so that all I maps are aligned.
            if ref == "!":
               ref = imaps[key]

#  Append this I map to the text file listing all maps to be included in the final
#  I map coadd.
            with open(allmaps, 'a') as infile:
               infile.write( "{0}\n".format( imaps[key] ) )

#  See what translations (in pixels) are needed to align the imap with
#  the reference map. The determination of the shift is more accurate if
#  we first mask out background areas. Use the AST mask to define source
#  pixels, but only if the mask contains a reasonable number of pixels
#  (very faint sources will have very small or non-existant AST masks).
            invoke("$KAPPA_DIR/showqual ndf={0}".format(imaps[key]))
            if get_task_par( "QNAMES(1)", "showqual" ) == "AST":
               bb = 1
            elif get_task_par( "QNAMES(2)", "showqual" ) == "AST":
               bb = 2
            elif get_task_par( "QNAMES(3)", "showqual" ) == "AST":
               bb = 4
            else:
               bb = 0

            if bb > 0:
               invoke("$KAPPA_DIR/setbb ndf={0} bb={1}".format(imaps[key],bb))

#  Clear badbits to use the whole map if the above masking results in too
#  few pixels.
            invoke("$KAPPA_DIR/stats ndf={0}".format(imaps[key]))
            nused = float( get_task_par( "numgood", "stats" ) )
            if nused < 400:
               invoke("$KAPPA_DIR/setbb ndf={0} bb=0".format(imaps[key]))

#  Find the pixel shift that aligns features in this masked, trimmed I map with
#  corresponding features in the reference map.
            try:
               invoke("$KAPPA_DIR/align2d ref={0} out=! in={1} form=3 "
                      "corlimit=0.7 rebin=no method=sincsinc params=\[0,2\]".
                      format(ref,imaps[key]))
               dx = float( get_task_par( "TR(1)", "align2d" ) )
               dy = float( get_task_par( "TR(4)", "align2d" ) )

#  If align2d failed, use silly dx,dy values to ensure it is flagged by
#  the following code.
            except starutil.AtaskError:
               dx = 1E6
               dy = 1E6

#  Reset the bad-bits mask.
            if bb > 0:
               invoke("$KAPPA_DIR/setbb ndf={0} bb=0".format(imaps[key]))

#  If the shifts are suspiciously high, we do not believe them. In which
#  case we cannot do pointing ocorrection when creating the Q and U maps.
            if abs(dx) > 5 or abs(dy) > 5:
               pointing_dx = "null"
               pointing_dy = "null"
               msg_out( "\nWARNING: The I map created from the POL2 data cannot be aligned "
                        "with the supplied IP reference map.\n" )

#  Otherwise, convert the offset in pixels to (longitude,latitude) offsets
#  in the sky system of the reference map, in arc-seconds....
            else:

#  Strip the wavelength axis off the total intensity map created above.
               imap2d = NDG( 1 )
               invoke("$KAPPA_DIR/ndfcopy in={0} out={1} trim=yes".format(imaps[key],imap2d))

#  Get the pixel coords at the centre of the total intensity map.
               invoke("$KAPPA_DIR/ndftrace ndf={0}".format(imap2d))
               lbndx = float( get_task_par( "LBOUND(1)", "ndftrace" ) )
               lbndy = float( get_task_par( "LBOUND(2)", "ndftrace" ) )
               ubndx = float( get_task_par( "UBOUND(1)", "ndftrace" ) )
               ubndy = float( get_task_par( "UBOUND(2)", "ndftrace" ) )
               cenx = 0.5*( lbndx + ubndx )
               ceny = 0.5*( lbndy + ubndy )

#  Convert to SKY coords, in radians. Use ATOOLS rather than pyast in
#  order to avoid the need for people to install pyast. Also, ATOOLS
#  integrates with NDFs more easily than pyast.
               (cena,cenb) = invoke("$ATOOLS_DIR/asttran2 this={0} forward=yes "
                                    "xin={1} yin={2}".format( imap2d,cenx,ceny)).split()
               cena = float( cena )
               cenb = float( cenb )

#  Add on the pixel offsets, and convert to SKY coords, in radians.
               offx = cenx + dx
               offy = ceny + dy
               (offa,offb) = invoke("$ATOOLS_DIR/asttran2 this={0} forward=yes "
                                    "xin={1} yin={2}".format( imap2d,offx,offy)).split()
               offa = float( offa )
               offb = float( offb )

#   Now find the arc-distance parallel to the longitude axis, between the central
#   and offset positions, and convert from radians to arc-seconds.
               dx = invoke("$ATOOLS_DIR/astdistance this={0}, point1=\[{1},{2}\] "
                           "point2=\[{3},{4}\]".format(imap2d,cena,cenb,offa,cenb))
               dx = 3600.0*math.degrees( float( dx ) )

#  The value returned by astDistance is always positive. Adjust the sign
#  of dx so that it goes the right way.
               da = offa - cena
               while da > math.pi:
                  da -= math.pi
               while da < -math.pi:
                  da += math.pi
               if da < 0.0:
                  dx = -dx

#  Now find the arc-distance parallel to the latitude axis, between the central
#  and offset positions, and convert from radians to arc-seconds.
               dy = invoke("$ATOOLS_DIR/astdistance this={0}, point1=\[{1},{2}\] "
                           "point2=\[{3},{4}\]".format(imap2d,cena,cenb,cena,offb))
               dy = 3600.0*math.degrees( float( dy ) )

#  The value returned by astDistance is always positive. Adjust the sign
#  of dx so that it goes the right way.
               db = offb - cenb
               if db < 0.0:
                  dy = -dy

#  Create the pointing correction file to use with subsequent makemap
#  calls. If a file is already in use (because of the data being old)
#  append the new pointing correction to the end of the file, preceeded
#  by an "end-of-table" Marker (two minus signs). Makemap will then apply
#  both correction.
               msg_out( "Using pointing corrections of ({0},{1}) arc-seconds".format(dx,dy) )

#  Store the pointing corrections as FITS headers within the map.
               sym = invoke("$KAPPA_DIR/wcsattrib ndf={0} mode=get name='Symbol(1)'".
                                  format(imaps[key]))
               invoke("$KAPPA_DIR/fitsmod ndf={0} keyword=POINT_DX "
                      "edit=w value={1} comment=\"'{2} pointing correction [arcsec]'\""
                      " position=! mode=interface".format(imaps[key],dx,sym))

               sym = invoke("$KAPPA_DIR/wcsattrib ndf={0} mode=get name='Symbol(2)'".
                            format(imaps[key]))
               invoke("$KAPPA_DIR/fitsmod ndf={0} keyword=POINT_DY "
                      "edit=w value={1} comment=\"'{2} pointing correction [arcsec]'\""
                      " position=! mode=interface".format(imaps[key],dy,sym))

         except starutil.AtaskError:
            msg_out("WARNING: makemap failed - could not produce an I map "
                    "for observation chunk {0}".format(key) )
            if ref == imaps[key]:
               ref = "!"
            del imaps[key]

#  Create a text file holding information about all the Stokes maps. For each one,
#  get the Stokes parameter (Q, U or I) and a key that is unique for the chunk of
#  data, of the form "<UT>_<OBS>_<SUBSCAN>".
   mapinfo = NDG.tempfile()
   mapndg = NDG("^{0}".format(allmaps) )
   invoke("$SMURF_DIR/pol2check in={0} quiet=yes mapinfo={1}".
          format(mapndg,mapinfo))

   if not get_task_par( "MAPFOUND", "pol2check" ):
      raise starutil.InvalidParameterError("No usable maps remains to be processed.")

#  Set up a dict. Each key is as described above. Each value is path to an
#  NDF holding a map with the same key and I Stokes parameter.
   with open(allmaps) as infile:
      lines = infile.readlines()
   paths = [line.strip() for line in lines]

   with open(mapinfo) as infile:
      lines = infile.readlines()
   infos = [line.strip() for line in lines]

   imaps = {}
   for (path,info) in zip( paths, infos ):
      (stokes,id) = info.split()
      if stokes == "I":
         imaps[id] = path

#  Check some good maps remain to be processed.
   if len(imaps) == 0:
      raise starutil.InvalidParameterError("No usable maps remains to be processed.")

#  If we have only one observation just copy it to the output maps. If we will be
#  converting to Jy/beam, we need to use intermediate NDFs for the mosaics.
#  Otherwise, we can put the mosaics into their final destinations.
   if jy:
      imos = NDG(1)
   else:
      imos = imap

   if len(imaps) == 1:
      key = list(imaps)[0]
      invoke("$KAPPA_DIR/ndfcopy in={0} out={1}".format(imaps[key],imos))

#  If we have more than one observation, coadd them. Also coadd the
#  extension NDFs (EXP_TIMES and WEIGHTS), but without normalisation so
#  that the coadd is the sum rather than the mean of the inputs.
   elif len(imaps) > 1:

      msg_out("Coadding I maps from all observations")
      allmaps = NDG( list( imaps.values() ) )
      invoke("$CCDPACK_DIR/makemos in={0} out={1} method=mean".format(allmaps,imos))

      invoke("$KAPPA_DIR/erase object={0}.more.smurf.exp_time ok=yes".format(imos))
      invoke("$KAPPA_DIR/wcsmosaic in={{{0}}}.more.smurf.exp_time lbnd=! ref=! "
             "out={1}.more.smurf.exp_time conserve=no method=bilin norm=no "
             "variance=no".format(allmaps,imos))

      invoke("$KAPPA_DIR/erase object={0}.more.smurf.weights ok=yes".format(imos))
      invoke("$KAPPA_DIR/wcsmosaic in={{{0}}}.more.smurf.weights lbnd=! ref=! "
             "out={1}.more.smurf.weights conserve=no method=bilin norm=no "
             "variance=no".format(allmaps,imos))

#  Produce a copy of the new I map in which background regions are set
#  bad, for use when finding the FCF degradation factor. Two masks are
#  used: the first sets bad all pixels that have lass than half of the
#  mean exposure time (i.e. edge pixels), the second sets bad all pixels
#  with SNR less than 3. The mask is then smoothed.
   invoke("$KAPPA_DIR/stats ndf={0}.more.smurf.exp_time".format(imos))
   mean = float(get_task_par( "MEAN", "stats" ))
   mask1 = NDG(1)
   invoke("$KAPPA_DIR/thresh in={0}.more.smurf.exp_time out={1} thrlo={2} "
          "newlo=bad thrhi=1E20 newhi=bad".format(imos,mask1,0.5*mean))

   imasked = NDG( 1 )
   invoke( "$KAPPA_DIR/maths exp=\"'qif(((ia/sqrt(va))<3),<bad>,ia)+0*ib'\" "
           "ia={0} ib={1} out={2}".format(imos,mask1,imasked))

#  Find the FCF degradation factor. This is done by comparing the new I
#  map (in pW) with the supplied REF map (which has been converted to pW).
#  The degradation factor is defined by:
#
#     POL2_pW = degFac * SC2_pW
#
#  or equivalently
#
#     SC2_FCF = degfac * POL2_FCF

   if ref_units:
      msg_out("Finding FCF degradation factor")
      (degfac,fwhm) = match( ref, imasked )

      msg_out("\nFCF degradation factor: {0}".format(degfac))
      msg_out("\nGaussian filtering size: {0} pixels".format(fwhm))

#  If required create a filtered and scaled version of the reference map.
      if refout:
         lof = NDG(1)
         invoke("$KAPPA_DIR/gausmooth in={0} out={1} fwhm={2}".
                format( ref, lof, fwhm ))
         hif = NDG(1)
         invoke("$KAPPA_DIR/sub in1={0} in2={1} out={2}".
                format( ref, lof, hif ))
         invoke("$KAPPA_DIR/cmult in={0} scalar={1} out={2}".
                format( hif, degfac, refout ))

   else:
      degfac = 1.0;
      fwhm = 0

#  Choose the units for the FCF value to store in the imap, and calculate
#  the FCF value. These are only used if the "HY" parameter indicates
#  that the output map is to be in Jy.
   if ref_fcf:
      imap_fcf = ref_fcf/degfac
      imap_units = ref_units
   else:
      try:
         filter = int( float( get_fits_header( imos, "FILTER", True )))
      except starutil.NoValueError:
         filter = 850
         msg_out( "No value found for FITS header 'FILTER' in output I "
                  "map - assuming 850".format(ref))

      if filter != 450 and filter != 850:
         raise starutil.InvalidParameterError("Invalid FILTER header value "
                "'{0} found in output I map.".format( filter, ref ) )

      imap_units == "Jy/beam"
      if filter == 450:
         imap_fcf = 491.0/degfac
      else:
         imap_fcf = 537.0/degfac

#  Store the FCF in the FITS header.
      invoke("$KAPPA_DIR/fitsmod ndf={0} keyword=FCF edit=w value={1} "
             "comment=\"'FCF [{2}/pw]'\" position=! mode=interface".
             format(imos,imap_fcf,imap_units))

#  If output I values are to be in Jy, convert I map to Jy and store in its
#  final destination.
   if jy:
      invoke( "$KAPPA_DIR/cmult in={0} scalar={1} out={2}".format(imos,imap_fcf,imap))
      invoke( "$KAPPA_DIR/setunits ndf={0} units={1}".format(imap,imap_units))




#  Remove temporary files.
   cleanup()

#  If an StarUtilError of any kind occurred, display the message but hide the
#  python traceback. To see the trace back, uncomment "raise" instead.
except starutil.StarUtilError as err:
#  raise
   print( err )
   print( "See the end of the log file ({0}) for further details.".format(starutil.logfile) )
   cleanup()

# This is to trap control-C etc, so that we can clean up temp files.
except:
   cleanup()
   raise





