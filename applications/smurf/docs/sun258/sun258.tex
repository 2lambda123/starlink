\documentclass[twoside,11pt]{article}

% ? Specify used packages
\usepackage{graphicx}        %  Use this one for final production.
% \usepackage[draft]{graphicx} %  Use this one for drafting.
% ? End of specify used packages

\pagestyle{myheadings}

% -----------------------------------------------------------------------------
% ? Document identification
% Fixed part
\newcommand{\stardoccategory}  {Starlink User Note}
\newcommand{\stardocinitials}  {SUN}
\newcommand{\stardocsource}    {sun\stardocnumber}
\newcommand{\stardoccopyright} 
{Copyright \copyright\ 2009 University of British Columbia, Science \& Technology Facilities Council}

% Variable part - replace [xxx] as appropriate.
\newcommand{\stardocnumber}    {258.1}
\newcommand{\stardocauthors}   {Edward Chapin, Andrew G. Gibb, Tim Jenness \& David S. Berry}
\newcommand{\stardocdate}      {20 July 2009}
\newcommand{\stardoctitle}     {SMURF}
\newcommand{\stardocversion}   {0.5}
\newcommand{\stardocmanual}    {User's Guide}
\newcommand{\stardocabstract}  {

  The Sub-Millimetre User Reduction Facility (SMURF) is a software
  package for reducing data produced by the ACSIS correlater and
  SCUBA-2 bolometer array on the James Clerk Maxwell Telescope
  (JCMT). This document describes how to use SMURF to process raw
  ACSIS data into data cubes, and raw SCUBA-2 data into images.

}
% ? End of document identification
% -----------------------------------------------------------------------------

% +
%  Name:
%     sun258.tex
%
%  Purpose:
%     Documentation for ACSIS and SCUBA-2 data reduction
%
%  Authors:
%     EC: Edward Chapin (UBC)
%     AGG: Andy Gibb (UBC)
%
%  History:
%     2008-11-14 (EC):
%        Initial version -- based on sun.tex
%     2009-04-15 (AGG):
%        Convert Maria's document to LaTeX
%     2009-07-20 (AGG):
%        Significant updates in time for Nanahope Starlink release
%     {Add further history here}
%
% -

\newcommand{\stardocname}{\stardocinitials /\stardocnumber}
\markboth{\stardocname}{\stardocname}
\setlength{\textwidth}{160mm}
\setlength{\textheight}{230mm}
\setlength{\topmargin}{-2mm}
\setlength{\oddsidemargin}{0mm}
\setlength{\evensidemargin}{0mm}
\setlength{\parindent}{0mm}
\setlength{\parskip}{\medskipamount}
\setlength{\unitlength}{1mm}

% -----------------------------------------------------------------------------
%  Hypertext definitions.
%  ======================
%  These are used by the LaTeX2HTML translator in conjunction with star2html.

%  Comment.sty: version 2.0, 19 June 1992
%  Selectively in/exclude pieces of text.
%
%  Author
%    Victor Eijkhout                                      <eijkhout@cs.utk.edu>
%    Department of Computer Science
%    University Tennessee at Knoxville
%    104 Ayres Hall
%    Knoxville, TN 37996
%    USA

%  Do not remove the %begin{latexonly} and %end{latexonly} lines (used by 
%  LaTeX2HTML to signify text it shouldn't process).
%begin{latexonly}
\makeatletter
\def\makeinnocent#1{\catcode`#1=12 }
\def\csarg#1#2{\expandafter#1\csname#2\endcsname}

\def\ThrowAwayComment#1{\begingroup
    \def\CurrentComment{#1}%
    \let\do\makeinnocent \dospecials
    \makeinnocent\^^L% and whatever other special cases
    \endlinechar`\^^M \catcode`\^^M=12 \xComment}
{\catcode`\^^M=12 \endlinechar=-1 %
 \gdef\xComment#1^^M{\def\test{#1}
      \csarg\ifx{PlainEnd\CurrentComment Test}\test
          \let\html@next\endgroup
      \else \csarg\ifx{LaLaEnd\CurrentComment Test}\test
            \edef\html@next{\endgroup\noexpand\end{\CurrentComment}}
      \else \let\html@next\xComment
      \fi \fi \html@next}
}
\makeatother

\def\includecomment
 #1{\expandafter\def\csname#1\endcsname{}%
    \expandafter\def\csname end#1\endcsname{}}
\def\excludecomment
 #1{\expandafter\def\csname#1\endcsname{\ThrowAwayComment{#1}}%
    {\escapechar=-1\relax
     \csarg\xdef{PlainEnd#1Test}{\string\\end#1}%
     \csarg\xdef{LaLaEnd#1Test}{\string\\end\string\{#1\string\}}%
    }}

%  Define environments that ignore their contents.
\excludecomment{comment}
\excludecomment{rawhtml}
\excludecomment{htmlonly}

%  Hypertext commands etc. This is a condensed version of the html.sty
%  file supplied with LaTeX2HTML by: Nikos Drakos <nikos@cbl.leeds.ac.uk> &
%  Jelle van Zeijl <jvzeijl@isou17.estec.esa.nl>. The LaTeX2HTML documentation
%  should be consulted about all commands (and the environments defined above)
%  except \xref and \xlabel which are Starlink specific.

\newcommand{\htmladdnormallinkfoot}[2]{#1\footnote{#2}}
\newcommand{\htmladdnormallink}[2]{#1}
\newcommand{\htmladdimg}[1]{}
\newcommand{\hyperref}[4]{#2\ref{#4}#3}
\newcommand{\htmlref}[2]{#1}
\newcommand{\htmlimage}[1]{}
\newcommand{\htmladdtonavigation}[1]{}

\newenvironment{latexonly}{}{}
\newcommand{\latex}[1]{#1}
\newcommand{\html}[1]{}
\newcommand{\latexhtml}[2]{#1}
\newcommand{\HTMLcode}[2][]{}

%  Starlink cross-references and labels.
\newcommand{\xref}[3]{#1}
\newcommand{\xlabel}[1]{}

%  LaTeX2HTML symbol.
\newcommand{\latextohtml}{\LaTeX2\texttt{HTML}}

%  Define command to re-centre underscore for Latex and leave as normal
%  for HTML (severe problems with \_ in tabbing environments and \_\_
%  generally otherwise).
\renewcommand{\_}{\texttt{\symbol{95}}}

% -----------------------------------------------------------------------------
%  Debugging.
%  =========
%  Remove % on the following to debug links in the HTML version using Latex.

% \newcommand{\hotlink}[2]{\fbox{\begin{tabular}[t]{@{}c@{}}#1\\\hline{\footnotesize #2}\end{tabular}}}
% \renewcommand{\htmladdnormallinkfoot}[2]{\hotlink{#1}{#2}}
% \renewcommand{\htmladdnormallink}[2]{\hotlink{#1}{#2}}
% \renewcommand{\hyperref}[4]{\hotlink{#1}{\S\ref{#4}}}
% \renewcommand{\htmlref}[2]{\hotlink{#1}{\S\ref{#2}}}
% \renewcommand{\xref}[3]{\hotlink{#1}{#2 -- #3}}
%end{latexonly}
% -----------------------------------------------------------------------------
% ? Document specific \newcommand or \newenvironment commands.

% Shorthand and HTML references for other Starlink tasks
\newcommand{\CCDPACK}{\textsc{ccdpack}}
\newcommand{\CCDPACKref}{\xref{\CCDPACK}{sun139}{}}
\newcommand{\GAIA}{\textsc{gaia}}
\newcommand{\GAIAref}{\xref{\GAIA}{sun214}{}}
\newcommand{\HDSTRACE}{\textsc{hdstrace}}
\newcommand{\HDSTRACEref}{\xref{\HDSTRACE}{sun102}{}}
\newcommand{\KAPPA}{\textsc{kappa}}
\newcommand{\KAPPAref}{\xref{\KAPPA}{sun95}{}}
\newcommand{\SMURF}{\textsc{smurf}}
\newcommand{\SMURFcook}{\xref{\SMURF\ SCUBA-2 Cookbook}{sc19}{}}
\newcommand{\ADAM}{\xref{ADAM}{sg4}}
\newcommand{\AST}{\xref{AST}{sun210}}
\newcommand{\ndf}{\xref{NDF}{sun33}{}}

% Application tasks
\newcommand{\task}[1]{\textsf{#1}}
 
% ADAM parameters
\newcommand{\param}[1]{\texttt{#1}}
 
% SMURF tasks
\newcommand{\badbolos}{\xref{\task{badbolos}}{sun258}{BADBOLOS}}
\newcommand{\calcdark}{\xref{\task{calcdark}}{sun258}{CALCDARK}}
\newcommand{\calcflat}{\xref{\task{calcflat}}{sun258}{CALCFLAT}}
\newcommand{\calcresp}{\xref{\task{calcresp}}{sun258}{CALCRESP}}
\newcommand{\dreamsolve}{\xref{\task{dreamsolve}}{sun258}{DREAMSOLVE}}
\newcommand{\dreamweights}{\xref{\task{dreamweights}}{sun258}{DREAMWEIGHTS}}
\newcommand{\gsdtoacsis}{\xref{\task{gsd2acsis}}{sun258}{GSD2ACSIS}}
\newcommand{\gsdshow}{\xref{\task{gsdshow}}{sun258}{GSDSHOW}}
\newcommand{\smurfhelp}{\xref{\task{smurfhelp}}{sun258}{SMURFHELP}}
\newcommand{\impaztec}{\xref{\task{impaztec}}{sun258}{IMPAZTEC}}
\newcommand{\makecube}{\xref{\task{makecube}}{sun258}{MAKECUBE}}
\newcommand{\qlmakemap}{\xref{\task{qlmakemap}}{sun258}{QLMAKEMAP}}
\newcommand{\rawunpress}{\xref{\task{rawunpress}}{sun258}{RAWUNPRESS}}
\newcommand{\rawfixmeta}{\xref{\task{rawfixmeta}}{sun258}{RAWFIXMETA}}
\newcommand{\sctwosim}{\xref{\task{sc2sim}}{sun258}{SC2SIM}}
\newcommand{\sctwothreadtest}{\xref{\task{sc2threadtest}}{sun258}{SC2THREADTEST}}
\newcommand{\scanfit}{\xref{\task{scanfit}}{sun258}{SCANFIT}}
\newcommand{\skynoise}{\xref{\task{skynoise}}{sun258}{SKYNOISE}}
\newcommand{\smurfcopy}{\xref{\task{smurfcopy}}{sun258}{SMURFCOPY}}
\newcommand{\starecalc}{\xref{\task{starecalc}}{sun258}{STARECALC}}
\newcommand{\timesort}{\xref{\task{timesort}}{sun258}{TIMESORT}}
\newcommand{\unmakecube}{\xref{\task{unmakecube}}{sun258}{UNMAKECUBE}}    

\newcommand{\extinction}{\xref{\task{extinction}}{sun258}{EXTINCTION}}
\newcommand{\flatfield}{\xref{\task{flatfield}}{sun258}{FLATFIELD}}
\newcommand{\jcmtstate}{\xref{\task{jcmtstate2cat}}{sun258}{JCMTSTATE2CAT}}
\newcommand{\makemap}{\xref{\task{makemap}}{sun258}{MAKEMAP}}

\newcommand{\remsky}{\xref{\task{remsky}}{sun258}{REMSKY}}
\newcommand{\clean}{\xref{\task{sc2clean}}{sun258}{SC2CLEAN}}
\newcommand{\concat}{\xref{\task{sc2concat}}{sun258}{SC2CONCAT}}
\newcommand{\fft}{\xref{\task{sc2fft}}{sun258}{SC2FFT}}
\newcommand{\fts}{\xref{\task{sc2fts}}{sun258}{SC2FTS}}

\newcommand{\rebin}{\texttt{rebin}}
\newcommand{\iterate}{\texttt{iterate}}

% Other tasks
\newcommand{\makemos}{\xref{\task{makemos}}{sun139}{MAKEMOS}}

\newcommand{\fitsedit}{\xref{\task{fitsedit}}{sun95}{FITSEDIT}}
\newcommand{\kapdiv}{\xref{\task{div}}{sun95}{DIV}}
\newcommand{\ndfcopy}{\xref{\task{ndfcopy}}{sun95}{NDFCOPY}}
\newcommand{\thresh}{\xref{\task{thresh}}{sun95}{THRESH}}
\newcommand{\wcsmosaic}{\xref{\task{wcsmosaic}}{sun95}{WCSMOSAIC}}
\newcommand{\wcsalign}{\xref{\task{wcsalign}}{sun95}{WCSALIGN}}


%% Definitions imported from SUN/95

% A kind of list item, like description, but with an easily adjustable
% item separation.  Note that the paragraph and fount-size change are
% needed to make the revised \baselinestretch work.
\newlength{\menuwidth}
\newlength{\menuindent}
\newcommand{\menuitem}[2]
  {{\bf #1} \settowidth{\menuwidth}{{\bf #1} }
  \setlength{\menuindent}{-0.5em}
  \addtolength{\menuwidth}{-2\menuwidth}
  \addtolength{\menuwidth}{\textwidth}
  \addtolength{\menuwidth}{\menuindent}
  \hspace{\menuindent}\parbox[t]{\menuwidth}{
  \renewcommand{\baselinestretch}{0.75}\small
  #2 \par \vspace{1.0ex}
  \renewcommand{\baselinestretch}{1.0}\normalsize} \\ }
\begin{htmlonly}
\newcommand{\menuitem}[2]
  {\item [\htmlref{#1}{#1}] #2}
\end{htmlonly}

\newcommand{\classitem}[1]{\item [\htmlref{#1}{#1}]}

% an environment for references (for the SST sstdiytopic command).
\newenvironment{refs}{\vspace{-4ex} % normally 3ex
                      \begin{list}{}{\setlength{\topsep}{0mm}
                                     \setlength{\partopsep}{0mm}
                                     \setlength{\itemsep}{0mm}
                                     \setlength{\parsep}{0mm}
                                     \setlength{\leftmargin}{1.5em}
                                     \setlength{\itemindent}{-\leftmargin}
                                     \setlength{\labelsep}{0mm}
                                     \setlength{\labelwidth}{0mm}}
                    }{\end{list}}

%+
%  Name:
%     SST.TEX

%  Purpose:
%     Define LaTeX commands for laying out Starlink routine descriptions.

%  Language:
%     LaTeX

%  Type of Module:
%     LaTeX data file.

%  Description:
%     This file defines LaTeX commands which allow routine documentation
%     produced by the SST application PROLAT to be processed by LaTeX and
%     by LaTeX2html. The contents of this file should be included in the
%     source prior to any statements that make of the sst commnds.

%  Notes:
%     The style file html.sty provided with LaTeX2html needs to be used.
%     This must be before this file.

%  Authors:
%     RFWS: R.F. Warren-Smith (STARLINK)
%     PDRAPER: P.W. Draper (Starlink - Durham University)

%  History:
%     10-SEP-1990 (RFWS):
%        Original version.
%     10-SEP-1990 (RFWS):
%        Added the implementation status section.
%     12-SEP-1990 (RFWS):
%        Added support for the usage section and adjusted various spacings.
%     8-DEC-1994 (PDRAPER):
%        Added support for simplified formatting using LaTeX2html.
%     21-JUL-2009 (TIMJ):
%        Added \sstdiylist{}{} as used when a Parameters section is located that
%        is not "ADAM Parameters".
%     {enter_further_changes_here}

%  Bugs:
%     {note_any_bugs_here}

%-

%  Define length variables.
\newlength{\sstbannerlength}
\newlength{\sstcaptionlength}
\newlength{\sstexampleslength}
\newlength{\sstexampleswidth}

%  Define a \tt font of the required size.
\latex{\newfont{\ssttt}{cmtt10 scaled 1095}}
\html{\newcommand{\ssttt}{\tt}}

%  Define a command to produce a routine header, including its name,
%  a purpose description and the rest of the routine's documentation.
\newcommand{\sstroutine}[3]{
   \goodbreak
   \rule{\textwidth}{0.5mm}
   \vspace{-7ex}
   \newline
   \settowidth{\sstbannerlength}{{\Large {\bf #1}}}
   \setlength{\sstcaptionlength}{\textwidth}
   \setlength{\sstexampleslength}{\textwidth}
   \addtolength{\sstbannerlength}{0.5em}
   \addtolength{\sstcaptionlength}{-2.0\sstbannerlength}
   \addtolength{\sstcaptionlength}{-5.0pt}
   \settowidth{\sstexampleswidth}{{\bf Examples:}}
   \addtolength{\sstexampleslength}{-\sstexampleswidth}
   \parbox[t]{\sstbannerlength}{\flushleft{\Large {\bf #1}}}
   \parbox[t]{\sstcaptionlength}{\center{\Large #2}}
   \parbox[t]{\sstbannerlength}{\flushright{\Large {\bf #1}}}
   \begin{description}
      #3
   \end{description}
}

%  Format the description section.
\newcommand{\sstdescription}[1]{\item[Description:] #1}

%  Format the usage section.
\newcommand{\sstusage}[1]{\item[Usage:] \mbox{}
\\[1.3ex]{\raggedright \ssttt #1}}

%  Format the invocation section.
\newcommand{\sstinvocation}[1]{\item[Invocation:]\hspace{0.4em}{\tt #1}}

%  Format the arguments section.
\newcommand{\sstarguments}[1]{
   \item[Arguments:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Format the returned value section (for a function).
\newcommand{\sstreturnedvalue}[1]{
   \item[Returned Value:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Format the parameters section (for an application).
\newcommand{\sstparameters}[1]{
   \item[Parameters:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Format the examples section.
\newcommand{\sstexamples}[1]{
   \item[Examples:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Define the format of a subsection in a normal section.
\newcommand{\sstsubsection}[1]{ \item[{#1}] \mbox{} \\}

%  Define the format of a subsection in the examples section.
\newcommand{\sstexamplesubsection}[2]{\sloppy
\item[\parbox{\sstexampleslength}{\ssttt #1}] \mbox{} \vspace{1.0ex}
\\ #2 }

%  Format the notes section.
\newcommand{\sstnotes}[1]{\item[Notes:] \mbox{} \\[1.3ex] #1}

%  Provide a general-purpose format for additional (DIY) sections.
\newcommand{\sstdiytopic}[2]{\item[{\hspace{-0.35em}#1\hspace{-0.35em}:}]
\mbox{} \\[1.3ex] #2}

%  Format the a generic section as a list
\newcommand{\sstdiylist}[2]{
   \item[#1:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #2
   \end{description}
}

%  Format the implementation status section.
\newcommand{\sstimplementationstatus}[1]{
   \item[{Implementation Status:}] \mbox{} \\[1.3ex] #1}

%  Format the bugs section.
\newcommand{\sstbugs}[1]{\item[Bugs:] #1}

%  Format a list of items while in paragraph mode.
\newcommand{\sstitemlist}[1]{
  \mbox{} \\
  \vspace{-3.5ex}
  \begin{itemize}
     #1
  \end{itemize}
}

%  Define the format of an item.
\newcommand{\sstitem}{\item}

%% Now define html equivalents of those already set. These are used by
%  latex2html and are defined in the html.sty files.
\begin{htmlonly}

%  sstroutine.
   \newcommand{\sstroutine}[3]{
      \subsection{#1\xlabel{#1}-\label{#1}#2}
      \begin{description}
         #3
      \end{description}
   }

%  sstdescription
   \newcommand{\sstdescription}[1]{\item[Description:]
      \begin{description}
         #1
      \end{description}
      \\
   }

%  sstusage
   \newcommand{\sstusage}[1]{\item[Usage:]
      \begin{description}
         {\ssttt #1}
      \end{description}
      \\
   }

%  sstinvocation
   \newcommand{\sstinvocation}[1]{\item[Invocation:]
      \begin{description}
         {\ssttt #1}
      \end{description}
      \\
   }

%  sstarguments
   \newcommand{\sstarguments}[1]{
      \item[Arguments:] \\
      \begin{description}
         #1
      \end{description}
      \\
   }

%  sstreturnedvalue
   \newcommand{\sstreturnedvalue}[1]{
      \item[Returned Value:] \\
      \begin{description}
         #1
      \end{description}
      \\
   }

%  sstparameters
   \newcommand{\sstparameters}[1]{
      \item[Parameters:] \\
      \begin{description}
         #1
      \end{description}
      \\
   }

%  sstexamples
   \newcommand{\sstexamples}[1]{
      \item[Examples:] \\
      \begin{description}
         #1
      \end{description}
      \\
   }

%  sstsubsection
   \newcommand{\sstsubsection}[1]{\item[{#1}]}

%  sstexamplesubsection
   \newcommand{\sstexamplesubsection}[2]{\item[{\ssttt #1}] #2}

%  sstnotes
   \newcommand{\sstnotes}[1]{\item[Notes:] #1 }

%  sstdiytopic
   \newcommand{\sstdiytopic}[2]{\item[{#1}] #2 }

%  sstimplementationstatus
   \newcommand{\sstimplementationstatus}[1]{
      \item[Implementation Status:] #1
   }

%  sstitemlist
   \newcommand{\sstitemlist}[1]{
      \begin{itemize}
         #1
      \end{itemize}
      \\
   }
%  sstitem
   \newcommand{\sstitem}{\item}

\end{htmlonly}

%  End of "sst.tex" layout definitions.
%.



% ? End of document specific commands
% -----------------------------------------------------------------------------
%  Title Page.
%  ===========
\renewcommand{\thepage}{\roman{page}}
\begin{document}
\thispagestyle{empty}

%  Latex document header.
%  ======================
\begin{latexonly}
   \textsc{University of British Columbia} / \textsc{Joint Astronomy Centre} \hfill \textbf{\stardocname}\\
   {\large Science \& Technology Facilities Council}\\
   {\large Starlink Software Collection\\}
   {\large \stardoccategory\ \stardocnumber}
   \begin{flushright}
   \stardocauthors\\
   \stardocdate
   \end{flushright}
   \vspace{-4mm}
   \rule{\textwidth}{0.5mm}
   \vspace{5mm}
   \begin{center}
   {\Huge\textbf{\stardoctitle \\ [2.5ex]}}
   {\LARGE\textbf{\stardocversion \\ [4ex]}}
   {\Huge\textbf{\stardocmanual}}
   \end{center}
   \vspace{5mm}

% ? Add picture here if required for the LaTeX version.
%   e.g. \includegraphics[scale=0.3]{filename.ps}
\begin{center}
\includegraphics[scale=0.3]{sun258_logo.eps}
\end{center}
% ? End of picture

% ? Heading for abstract if used.
   \vspace{10mm}
   \begin{center}
      {\Large\textbf{Abstract}}
   \end{center}
% ? End of heading for abstract.
\end{latexonly}

%  HTML documentation header.
%  ==========================
\begin{htmlonly}
   \xlabel{}
   \begin{rawhtml} <H1> \end{rawhtml}
      \stardoctitle\\
      \stardocversion\\
      \stardocmanual
   \begin{rawhtml} </H1> <HR> \end{rawhtml}

% ? Add picture here if required for the hypertext version.
%   e.g. \includegraphics[scale=0.7]{filename.ps}
\includegraphics[scale=0.7]{sun258_logo.eps}
% ? End of picture

   \begin{rawhtml} <P> <I> \end{rawhtml}
   \stardoccategory\ \stardocnumber \\
   \stardocauthors \\
   \stardocdate
   \begin{rawhtml} </I> </P> <H3> \end{rawhtml}
      \htmladdnormallink{University of British Columbia}
                        {http://www.ubc.ca} \\
      \htmladdnormallink{Joint Astronomy Centre}
                        {http://www.jach.hawaii.edu}\\
      \htmladdnormallink{Science \& Technology Facilities Council}
                        {http://www.pparc.ac.uk} \\
   \begin{rawhtml} </H3> <H2> \end{rawhtml}
      \htmladdnormallink{Starlink Software Collection}{http://starlink.jach.hawaii.edu/}
   \begin{rawhtml} </H2> \end{rawhtml}
   \htmladdnormallink{\htmladdimg{source.gif} Retrieve hardcopy}
      {http://starlink.jach.hawaii.edu/cgi-bin/hcserver?\stardocsource}\\

%  HTML document table of contents. 
%  ================================
%  Add table of contents header and a navigation button to return to this 
%  point in the document (this should always go before the abstract \section). 
  \label{stardoccontents}
  \begin{rawhtml} 
    <HR>
    <H2>Contents</H2>
  \end{rawhtml}
  \htmladdtonavigation{\htmlref{\htmladdimg{contents_motif.gif}}
        {stardoccontents}}

% ? New section for abstract if used.
  \section{\xlabel{abstract}Abstract}
% ? End of new section for abstract
\end{htmlonly}

% -----------------------------------------------------------------------------
% ? Document Abstract. (if used)
%  ==================
\stardocabstract
% ? End of document abstract

% -----------------------------------------------------------------------------
% ? Latex Copyright Statement
%  =========================
\begin{latexonly}
\newpage
\vspace*{\fill}
\stardoccopyright
\end{latexonly}
% ? End of Latex copyright statement

% -----------------------------------------------------------------------------
% ? Latex document Table of Contents (if used).
%  ===========================================
  \newpage
  \begin{latexonly}
    \setlength{\parskip}{0mm}
    \tableofcontents
    \setlength{\parskip}{\medskipamount}
    \markboth{\stardocname}{\stardocname}
  \end{latexonly}
% ? End of Latex document table of contents
% -----------------------------------------------------------------------------

\cleardoublepage
\renewcommand{\thepage}{\arabic{page}}
\setcounter{page}{1}

% ? Main text

\section{\xlabel{introduction}Introduction\label{se:smurfintro}}

This guide is divided into two main parts, one dedicated to processing
ACSIS data and the other for processing SCUBA-2 data. This first
section will introduce \SMURF\ and the basics of operation. Subsequent
sections will deal with ACSIS- and SCUBA-2-specific processing. A
cookbook is available for SUCBA-2 data processing.

\SMURF\ is a suite of Starlink \ADAM\ tasks and therefore
requires the Starlink environment to be defined.

\subsection{Using SMURF}

\subsubsection{Starting SMURF}

Enable the \SMURF\ environment by typing \verb+smurf+ at the shell
prompt. The welcome message will appear as shown below:
\begin{verbatim}

        SMURF commands are now available -- (Version 0.5.2)

        Type smurfhelp for help on SMURF commands.
        Type 'showme sun258' to browse the hypertext documentation.

        NOTE, several applications have had major changes made to their
        parameter lists. See the 'Release Notes' section of SUN/258 for
        details.


\end{verbatim}
This defines aliases for each \SMURF\ command, shows the help command
and version number. You can now use \SMURF\ routines or ask for help.

\subsubsection{Getting Help}

Access the \SMURF\ online help system as follows:
\begin{enumerate}
\item At the prompt, type \verb+smurfhelp+. The welcome message is
  displayed along with a list of available topics.
\item To get information, type the name of an available topic at the
  help prompt.  The next level of help lists information and further
  subtopics.
\item To go to the next level, type the name of a subtopic.
\item Type a question mark, \verb+?+, to re-display the available
  topics at the current level.
\item To go back one level, press \verb+<Enter>+.
\item To exit the help system, press \verb+<Enter>+ until you return
  to the shell prompt.
\end{enumerate}
Further help on the help system maybe obtained by accessing the topic
\verb+smurfhelp+ from within \verb+smurfhelp+.

\subsubsection{SMURF parameters}

\SMURF\ uses named parameters to specify input and output files and
other variables necessary for data processing. \KAPPAref\ has a
convenient overview of the parameter system used by \SMURF.

\subsubsection{Message filter}

All \SMURF\ commands support the ``message filter'' parameter
(\verb+msg_filter+), which controls the number of messages \SMURF\
writes to the screen during routines. The default setting for the
message filter is \verb+normal+. Table \ref{tab:msgfilter}  lists the available
values for \verb+msg_filter+. Be aware that specifying \verb+verbose+
or \verb+debug+ will slow down execution due to the (potentially vast)
number of messages written to the terminal.

\begin{table}
\centering
\begin{tabular}{|c|l|}
\hline
Option  & Description \\
\hline
none   & No messages \\
quiet   & Limited messages \\
normal  & Very few messages \\
verbose & Full messages \\
debug   & Some debugging messages (useful for programmers) \\
all & All messages regardless of debug level \\
\hline
\end{tabular}
\label{tab:msgfilter}
\end{table}

\subsubsection{Working with Data Files}

\SMURF\ does not itself enforce a naming scheme on files. However, raw
data from ACSIS and SCUBA-2 obey a well-defined naming scheme. The
convention is as follows: the name is composed of an instrument
prefix, the UT date in the form YYYYMMDD, a zero-padded five-digit
observation number, followed by a two-digit subsystem number (ACSIS
only) and a zero-padded four-digit subscan number, all separated by
underscore characters. The file has an extension of \verb+.sdf+. The
instrument prefix for ACSIS is simply \verb+a+. For SCUBA-2 it is a
three-character string dependent on the particular subarray from which
the data were recorded. The SCUBA-2 subarrays are labelled a--d at
each wavelength, which are coded by a single digit (either 4 or 8);
thus the SCUBA-2 prefix is \verb+s[4|8][a-d]+.

Example ACSIS filename: a20090620\_00023\_01\_0002.sdf\\
Example SCUBA-2 filename: s8a20090620\_00075\_0001.sdf

You can process files either singly or in batches. It is more
efficient to process multiple files at a time. To work with multiple
files:
\begin{enumerate}
\item Create an input file listing the filename of each subscan you
  wish to process.
\item Create an output file listing corresponding output filenames for
  each input subscan, if appropriate.
\item When specifying an input (or output list file for a routine,
  type \verb+in=^infiles.lis+ or \verb+out=^outfiles.lis+. The caret
  (\verb+^+) indicates that the input file is a list file.
\end{enumerate}
Note that the output filenames should be listed in the same order as
the input filenames otherwise the processed data will be written under
the wrong filenames. Take care to supply a different output file name
from the input as the contents are overwritten!

\subsection{Document conventions}

Observing modes are denoted by all upper case body text (e.g.\
FLATFIELD).

Starlink package names are shown in small caps (e.g.\ \textsc{smurf});
individual task names are shown in sans-serif (e.g.\ \textsf{makemap}).

NDF extensions and components are shown in upper case fixed-width type
(e.g.\ \texttt{HISTORY}). Content listings are shown in fixed-width type.

Text relating to filenames, key presses or entries typed at the
command line are denoted by fixed-width type (e.g.\ \texttt{\%
  smurf}), as are parameters for tasks (e.g.\ \texttt{METHOD}).

%\section{ACSIS and SCUBA-2 Data}

\subsection{Data File Structure}

Data files for both ACSIS and SCUBA-2 use the Starlink N-Dimensional
data format (\ndf), a hierarchical format which allows
additional data and metadata to be stored within a single file. Raw
files contain a number of NDF components which store
observation-specific data necessary for subsequent processing. The
contents of these (and other NDF) files may be listed with
\HDSTRACEref. Each file on disk is also known as a subscan.

The main (top-level) components are:
\begin{itemize}
\item Raw data (a 3-dimensional array);
\item World Coordinate System information;
\item History;
\item Raw data units (K for ACSIS).
\end{itemize}
For ACSIS, the raw data are stored as $N_{\rm chan} \times N_{\rm
  receptors} \times N_{\rm samp}$, while SCUBA-2 data are stored as
$N_{\rm rows} \times N_{\rm columns} \times N_{\rm samp}$, where
$N_{\rm samp}$ is the number of samples in a file.

The files also contain additional NDF components common to both
instruments are stored:
\begin{itemize}
\item JCMT State structure (the telescope pointing record);
\item JCMT Observatory Control System (OCS) information, with the
  contents of the XML file used to set up the observation;
\item Flexible Image Transport System (FITS) header containing
  information that does not change during a subscan.
\end{itemize}
The FITS header is used to store information that either does not
change or changes by a small amount during the course of an
observation. The FITS header may be viewed with the \KAPPA\ fitslist
command.

Each instrument has further specific components. SCUBA-2 files contain
dark squid data, the current flatfield solution and a polynomial fit
to detector signal versus raw data (a correction for linear drift).
ACSIS files contain information about the receptors used.

Output files created by \SMURF\ may contain some or all of these plus
new components with information about the output data. These are noted
in the description of specific applications. All output files contain
contain a \texttt{PROVENANCE} extension which contains a detailed
record of the data processing history. Use the \KAPPA\ command
provshow to list the contents.

\subsection{Supported coordinate systems}

\SMURF\ uses \AST\ for its astrometry and thus any coordinate system
supported by \AST\ may be used when creating images/cubes. The default
behaviour is to use the same system in which the observations were
made (known as \texttt{TRACKING}).

\subsubsection{Moving sources}

WCS attributes to set...

The mapping tasks \qlmakemap, \makemap\ and \makecube\ automatically
deal with moving sources.

\subsection{File sizes and disk space}

Be aware that the raw data files from both instruments may be large
(tens to hundreds of megabytes). Subsequent processing of raw SCUBA-2
time-series data produces output files which are larger
due to the conversion from integer\footnote{Data can be written in either \texttt{\_WORD} or \texttt{\_INTEGER} format so the uncompression factor can vary from 2 to 4. The \rawunpress\ command can be used to uncompress the \texttt{\_WORD} data to \texttt{\_INTEGER} format prior to running \flatfield.}
to \verb+_DOUBLE+. \SMURF\
mapping tasks have the ability to restrict the size of output data
files for manipulation on 32-bit operating systems. See the sections
on \qlmakemap, \makemap\ and \makecube\ for further
details. Processing SCUBA-2 data is faster on 64-bit systems due to
its use of double precision for all calculations.

\section{\xlabel{acsis}ACSIS Data Reduction\label{se:acsisdr}}

To be written. In the meantime, see the ACSIS-DR web page at the JCMT:\\
\htmladdnormallink{\texttt{http://www.jach.hawaii.edu/JCMT/spectral\_line/data\_reduction/acsisdr/}}
{http://www.jach.hawaii.edu/JCMT/spectral_line/data_reduction/acsisdr/}

\section{\xlabel{scuba2}SCUBA-2 Data Reduction\label{se:sc2dr}}

SCUBA-2 has two primary observing modes where the telescope is either
stationary relative to the source (DREAM, STARE and when the FTS or
polarimeter are in use), or moving (SCAN). The data processing differs
in detail for each observing mode, though the general procedure is the
same.

In addition to data files, each observation is bracketed by dark
frames. In some cases dark frames may also be recorded part-way
through an observation. These dark frames are necessary for correcting
for the drift in the bolometer zero-point and should be provided in
the list of input files for all tasks that read raw data. Maps made
without correcting for this drift will be sub-optimal (or even
unuseable in the worst cases). Dark frames can be identified by
searching for the FITS keyword \texttt{SHUTTER}, which is 0 for dark
frames.

\subsection{\xlabel{scuba2}SCUBA-2 description\label{se:scuba2}}

Reminder overview of SCUBA-2 - 4 subarrays times 2 wavelengths. Basic
info (FoV etc). Location, footprint on sky, field rotation. Figure
would be useful. Observing modes.

\subsection{\xlabel{arraycal}Array Calibration and Characterization Data\label{se:arraycal}}

Data from array calibration observations (such as FLATFIELD and NOISE)
are processed with \SMURF. NOISE observations are used to identify
bolometers which are not in spec, from which a bad-bolometer mask can
be created. There is usually no need to re-process these data, but
they are included here for completeness. Note that for both
observation types the data are all ``dark'', i.e.\ the value of
\texttt{SHUTTER} is 0.

\subsubsection{\xlabel{flatcal}FLATFIELD\label{se:flatcal}}

FLATFIELD observations are processed with the \calcflat\ command. The
input data must be from the same observation and the same
subarray. The data are a series of dark frames in which the current
supplied to the internal pixel heaters is varied about a nominal value
(see the FITS keyword \texttt{PIXHEAT}). \calcflat\ solves for the
optimum heater setting given a list of resistances for each bolometer
and a reference resistor value. The list of resistances is mandatory
and requires knowledge of the subarray performance. However, a file
with suitable default values is included with the installation of
\SMURF: \texttt{\$STARLINK\_DIR/share/smurf/resist.cfg}.

The output from processing a FLATFIELD observation is a data file
(which may be named automatically if not supplied) which contains the
flatfield solution in the NDF extension \texttt{.MORE.SCUBA2.FLATCAL},
the same location as for the raw data. The main data array for this
output file is a three-dimensional array containing the
dark-subtracted measurements for each heater setting ($N_{\rm
  row}\times N_{\rm column} \times N_{\rm heat}$).

In addition to generating the flatfield solution, \calcflat\ can also
create a responsivity image for the current subarray. The
\texttt{RESP} parameter may be specified to store the
responsivity. The responsivity has units of A\,W$^{-1}$. [WHAT ELSE
CAN WE SAY ABOUT THE RESPONSIVITY?]

\subsubsection{NOISE}

NOISE observations are designed to check that the bolometers are
operating within spec. This is achieved by calculating the power
spectrum and comparing the relative noise power at two frequencies.
Excessively noisy bolometers are noted and a bad bolometer mask
generated. There is no single \SMURF\ command that processes NOISE
observations in this way but the procedure for creating a bad
bolometer mask is as follows:
\begin{itemize}
\item Calculate the power spectrum with \SMURF\ \fft;
\item Select data at the two chosen frequencies with \KAPPA\ \ndfcopy\
  (collapsing if necessary);
\item Form the ratio of those two files with \KAPPA\ \kapdiv;
\item Use \KAPPA\ \thresh\ (multiple times if necessary) to define a
  bad-bolometer mask.
\end{itemize}

\subsection{\xlabel{dsworkflow}DREAM/STARE Data Reduction Workflow\label{se:dsworkflow}}

The DREAM/STARE observing modes are designed for mapping compact
sources, i.e.\ those which are smaller than the field of view of
SCUBA-2 (approximately 8 arcmin).

The workflow for processing DREAM and STARE data may proceed in one of
two ways: a simplified workflow using images calculated by the data
acquisition (DA) at the time of the observation, or the full workflow
starting from the raw data. The full procedure is described below, and
steps which are unnecessary in the simplified workflow are noted.

The workflow proceeds as follows:
\begin{enumerate}
\item Apply flatfield solution (full only);
\item Remove atmospheric emission;
\item Correct for atmospheric extinction;
\item Calculate images from time-series (full only);
\item Combine images to create output mosaic.
\end{enumerate}

\subsubsection{DA images}

The images calculated by the DA are stored as NDF extensions in the
raw data files under \texttt{.MORE.SCU2RED.In} where \texttt{n} is an
integer (non-zero-padded). Each image is an average of the data in
typically 1 second. Note the final image is created from the whatever
samples remain if the duration of the file is not an integer number of
seconds. Each image has its own FITS header associated with it which
contains values which vary between images.

\subsubsection{\xlabel{flatfield}Applying the Flatfield Correction\label{se:flatfield}}

This section describes how to apply the flatfield solution to raw
data. This step is not necessary for the simplified workflow.

A FLATFIELD observation records variation in the sensitivity of each
bolometer. Ideally, every bolometer gives the same reading when
exposed to a calibrated radiation source. In practice, each one
responds in a slightly different way.

The flatfield response for each subarray is derived at the telescope
from a dedicated FLATFIELD observation. This solution is written to
all subsequent data files until a new solution is derived (see Section
\ref{se:flatcal} above).

Bolometer output is modified by the gain of the individual bolometer
and its offset from a one-to-one relationship with the input
radiation. Thus the output power from bolometer $i$ is related to the
input (optical) power by:
\begin{equation}
P_{{\rm out},i} = G_i P_{{\rm in},i} + O_i.
\end{equation}
where $G$ is the gain and $O$ is the offset.

The \SMURF\ routine that applies the flatfield correction is called
\flatfield. Since the flatfield information is already included in
each subscan, multiple files can be flatfielded with a single call to
the \flatfield\ routine; there is no need to process files from
different subarrays separately. Dark frames should be included in the
list of input files in order to correct for bolometer zero-point
drifts. Note that only flatfielded data (non-dark) files are written
out, and that the naming scheme will change. The list of output files
given is truncated at the appropriate number. The list of files
actually written to disk is obtained via the \texttt{OUTFILES}
parameter.

\subsubsection{\xlabel{skysub}Removing the atmosphere\label{se:skysub}}

This section describes how to subtract the signal from the atmosphere
(or sky) from your observations. This step is required for both the
full and simplified workflows.

The sky is highly emissive (bright) at submillimetre wavelengths, and
the radiation received from an astronomical source is only a very
small fraction of the radiation received from the
atmosphere. Typically the atmospheric signal is a factor of $10^5$
times greater than that from the source (see in Figure
\ref{fig:signal} for a pictorial representation). In addition, the
atmospheric emission varies significantly over the timescales of a
typical observation, further swamping any contribution from the
source. Fortunately, the emission from the sky is correlated over the
SCUBA-2 field of view which enables simple sky removal techniques to
be used effectively.

\begin{latexonly}
   \begin{figure}[hbt]
   \begin{center}
     \includegraphics[width=150mm]{sun258_submmsignal.eps}
     \caption{Illustration of the relative magnitudes of atmospheric
       and source signals at submillimetre wavelengths. Data from 850
       $\mu$m observations of Jupiter with SCUBA-2. The sharp features
       occur when Jupiter is seen by the bolometer. The increase in
       optical power from Jupiter is $\sim$0.5\%. Most sources will be
       many thousands of times fainter.}
     \label{fig:signal}
   \end{center}
   \end{figure}
\end{latexonly}
\begin{htmlonly}
   \label{fig:signal}
   \htmladdimg{sun258_submmsignal.gif}

   Figure ??: Illustration of the relative magnitudes of atmospheric
   and source signals at submillimetre wavelengths. Data from 850
   $\mu$m observations of Jupiter with SCUBA-2. The sharp features
   occur when Jupiter is seen by the bolometer. The increase in
   optical power from Jupiter is $\sim$0.5\%. Most sources will be
   many thousands of times fainter.

\end{htmlonly}

In a single sample the signal collected from an astronomical source is
negligible in comparison with the contribution from the
atmosphere. Many samples are required to collect a statistically
significant signal from the source. 

The \SMURF\ routine that removes the sky is called \remsky\ and has
several options for fitting and removing the atmospheric contribution
to the signal. All take advantage of the fact that the sky signal is
correlated between adjacent bolometers.

You can fit the atmospheric signal in the following ways:
\begin{itemize}
\item Calculate the mean value of the signal;
\item Fit a gradient in elevation only;
\item Fit a plane of arbitrary orientation.
\end{itemize}
Furthermore, \remsky\ can make use of the data from all available
subarrays to make a better estimate of the atmospheric emission (see
the \texttt{GROUP} parameter).

For simple cases, subtracting a mean value may be sufficient, though
it is not recommended for bright sources as the mean will be biassed
high by the presence of the source. A more sophisticated solution may
be obtained by fitting a plane to the data. The plane may have
arbitrary orientation (in azimuth and elevation) or may be fixed so
that the slope is in elevation only.

\subsubsection{\xlabel{extinction}Correcting for atmospheric extinction\label{se:extinction}}

This section describes how to correct your data for atmospheric
extinction, the loss of radiation from the source as it travels
through the atmosphere. This step is required for both the full and
simplified workflows.

The observed signal from an astronomical source decreases as the
atmosphere along the line of sight increases. At lower elevations,
there is more atmosphere along the line of sight between the source
and the telescope.

The radiation received by SCUBA-2 is the sum of the radiation from the
astronomical source (represented by $I_{\rm src}$ in Equation
\ref{eq:iobs} below) and the radiation from the atmosphere ($I_{\rm
  atm}$). However, $I_{\rm src}$ is diminished by the optical depth
of the atmosphere ($\tau$) as follows:
\begin{equation}
I_{\rm obs} = I_{\rm atm} + I_{\rm src} \exp(-\tau)
\label{eq:iobs}
\end{equation}
The optical depth is usually quoted as the value at the zenith
($\tau_{\rm zenith}$), but you need the value of tau at the same
elevation as your observations ($\tau_{\rm obs}$). For a
plane-parallel atmosphere, $\tau_{\rm obs} = A \times \tau_{\rm
  zenith}$, where airmass ($A$) is a measure of the total atmosphere
along the line of sight.

Airmass is defined as $1 / \cos \theta$, where $\theta$ is the zenith
angle. The zenith angle is the vertical angle measured from the zenith
($\theta = 0^\circ$) towards the horizon ($\theta = 90^\circ$) and is
thus equal to $90-\phi$, where $\phi$ is the elevation. You can now
calculate $\tau_{\rm obs}$ from $\tau_{\rm zenith}$ and $\phi$ as
follows:
\begin{equation}
\tau_{\rm obs} = \tau_{\rm zenith} / \cos(90 - \phi )
\label{eq:tau}
\end{equation}

\begin{figure}
%\includegraphics{extinction.eps}
\caption{Atmospheric extinction as a function of airmass.}
\end{figure}

Using Equation \ref{eq:tau}, rewrite Equation \ref{eq:iobs} as:
\begin{equation}
I_{\rm obs} = I_{\rm atm} + I_{\rm src} \exp \left( 
\frac{-\tau_{\rm zenith}}{\cos(90-\phi)}\right)
\end{equation}
The top graph in Figure 6 shows how the observed signal varies with elevation
and airmass.

The elevation angle of each bolometer can be calculated and given
$\tau_{\rm zenith}$ \remsky\ calculates the $\tau_{\rm obs}$ at the
elevation angle of each bolometer. 

The zenith optical depth can be obtained via three methods:
\begin{enumerate}
\item Skydips: The zenith optical depth is derived from a SKYDIP
  observation, in which the signal at each wavelength is recorded over
  a range of airmasses. \SMURF\ does not yet have the capability to
  process SCUBA-2 skydips.

\item CSO tipping radiometer: The Caltech Submillimeter Observatory
  (CSO) radiometer measures $\tau_{\rm zenith}$ from skydip
  observations at 225 GHz. The CSO radiometer records a new $\tau_{\rm
    zenith}$ every 10 minutes and values are stored in the FITS
  headers corresponding to the start and end timestamps of the file
  (\texttt{TAU225ST} and \texttt{TAU225EN}). \SMURF\ converts CSO
  $\tau_{\rm zenith}$ to $\tau_{\rm zenith}$ at 450, or 850 $\mu$m,
  relying on an empirical relationship between $\tau_{\rm zenith}$ at
  225 GHz and $\tau_{\rm zenith}$ at 450, or 850 $\mu$m.

\item JCMT Water Vapour Monitor: The JCMT Water Vapour Monitor (WVM)
  provides measurements of $\tau_{\rm zenith}$ every 1.2 seconds. It
  measures $\tau_{\rm zenith}$ at 183 GHz which is converted to
  $\tau_{\rm zenith}$ at 225 GHz. The raw WVM data are stored in the
  JCMT state structure, though the values at times corresponding to
  the start and end of the file are stored in the FITS headers
  (\texttt{WVMTAUST} and \texttt{WVMTAUEN}).
\end{enumerate}
Optical depth measurements derived from the WVM are most useful in
variable atmospheric conditions where the CSO radiometer may not be
giving sufficiently-frequent readings.

The \SMURF\ routine that corrects for atmospheric extinction is called
\extinction. The \extinction\ routine can use $\tau_{\rm zenith}$
determined by all of the above methods, and obtains values
automatically from the FITS headers for the WVM and CSO cases.

\subsubsection{\xlabel{dsimages}Calculating images from time-series data\label{se:dsimages}}

This step is not required for the simplified workflow.

\SMURF\ provides separate routines for calculating images from STARE
and DREAM data. STARE images are calculated with \starecalc; DREAM
images are calculated with \dreamsolve. 

In \starecalc\ the user may specify how many samples to average to
create images (the default is to calculate averages once a second).

\dreamsolve\ requires the the DREAM weights file specified in the FITS
header keyword \texttt{DRMWGHTS} to reside in the current
directory. Data from each subarray require a corresponding weights
file. See section \ref{se:dream} below for details on calculating
alternative weights files.

\subsubsection{\xlabel{mosaic}Combining the images\label{se:mosaic}}

\SMURF\ does not have any image mosaicking tasks itself. This step is
handled by routines in \KAPPA\ and \CCDPACK. Suitable tasks are
\wcsmosaic\ in \KAPPA\ and a combination of \KAPPA\ \wcsalign\ (to
align all the images to a common coordinate frame) followed by
\CCDPACK\ \makemos.

See the \SMURFcook\ (SC/19) for more detailed information about
mosaicking SCUBA-2 images.

\subsubsection{\xlabel{dream}Using alternative DREAM solutions\label{se:dream}}

This step is not usually necessary for either workflow but is included
for completeness.

The DREAM observing mode moves the secondary mirror in a pattern which
causes adjacent bolometers to observe the same region of the sky
multiple times. The data is then described by a series of simultaneous
equations which are solved via a matrix inversion (using singular
value decomposition). Since the pattern traced out by the secondary
mirror is known, the inverse of the matrix can be pre-calculated (a
time-consuming task) for a given output grid and applied to data at
the time of observation (quick).

It is {\em strongly} recommended that users become familiar with the
details of DREAM (references) before using weights other than the
default for science data processing.

The user may wish to experiment with different regridding schemes or
they may be other reasons, not known at the time of observation, which
require the inverse matrix to be re-calculated. The task for doing
this is called \dreamweights\ which allows the user to specify
different output grid parameters. The calculation of the inverse is
moderately time-consuming (compared with calculating the images) and
takes of order 5-10 minutes on current hardware. The output file from
\dreamweights\ is the weights file required by \dreamsolve. \KAPPA\
\fitsedit\ may be used to specify weights files which differ in name
from the default. Note that this process must be repeated for each
subarray for which data exists and that data will are to be combined
should all use the same grid.

\subsection{\xlabel{scanworkflow}SCAN Data Reduction Workflow\label{se:scanworkflow}}

When observing with SCAN mode, there are two DR workflows available:
\rebin and \iterate. In practice, the \iterate\ workflow will always
yield the best results. However, there are cases, such as for bright
compact sources (bright enough to be detected in one sample and
smaller than the field of view of the array), when the \rebin\ method
may allow for adequate processing. The \rebin\ method is also suitable
for obtaining a ``quick-look'' image.

\SMURF\ provides two map-making routines: \qlmakemap\ and \makemap,
both of which can make maps via the \rebin method.

\subsubsection{\xlabel{rebin}Rebinning map-maker\label{se:rebin}}

See Figure \ref{flow} for a flowchart showing the SCAN DR workflow.

\begin{figure}
%\includegraphics....
\caption{Flowchart\label{flow}}
\end{figure}

For bright compact sources, or sources with structure on scales
smaller than eight arcmin:
\begin{enumerate}
\item Apply the flatfield correction (see Section \ref{se:flatfield}).
\item Remove the contribution of atmosphere to the signal (see Section \ref{se:skysub}).
\item Correct for atmospheric extinction (See Section \ref{se:extinction}).
\item Make a map using the Rebin method (see Section \ref{se:rebin}).
\end{enumerate}

\subsubsection{\xlabel{iterate}Iterative map-maker\label{se:iterate}}

The iterative map-maker (DIMM) takes raw data as input (which may or
may not be flatfielded beforehand) and solves for the best
astronomical image. Control of the DIMM is through a series of
parameters specified in a configuration file. A default configuration
file is provided with the installation of SMURF:
\texttt{\$STARLINK\_DIR/share/smurf/dimmconfig.lis}.

See the following section \ref{se:imaging} for more detail.

\subsection{\xlabel{imaging}Making an image\label{se:imaging}}

This section describes how to create a map of your source from raw
time-series data. The challenge is to make an image when the data
taken at each bolometer position does not line up exactly with the
output map pixels.

\subsubsection{Introduction}

For SCUBA-2, the distance between bolometers, as projected on the sky,
is 5.8 arcsec. For mapping, the output pixel size is usually set at 1
arcsec for observations at 450 $\mu$m and 3 arcsec at 850 $\mu$m.

Data from the SCAN observing mode can be converted into a
two-dimensional (2-D) map using a routine called \makemap. This
routine accepts multiple files as input and produces a single map file
as output. There are two mapmaking methods available:
\begin{itemize}
\item Rebin method
\item Iterate method
\end{itemize}

The \rebin\ method is the final step in the workflow for bright point
sources, or sources with structure on scales less than eight arcmin
(see Section 1.2 and Figure 2). This method applies a one-pass
rebinning algorithm to the data, which regrids the signal from each
bolometer onto a map in the desired co-ordinate system.

The \iterate\ method is the workflow for faint point sources, or
sources with structure on a scale larger than eight arcmin (see
Section 1.2 and Figure 2). This method applies an iterative algorithm
to the raw data, assuming that the observed signal is composed of:
\begin{itemize}
\item Radiation from the atmosphere
\item Radiation from the astronomical source
\item Variations in bolometer response (detector drift)
\item Cosmic ray spikes
\item Systematic noise from the bolometers and the atmosphere
\item White noise from the instrument and the atmosphere
\end{itemize}
The theory behind the iterative map-maker is described in more detail
in the following section \ref{se:dimm}.

The top panel of Figure 7 shows the observed signal from a single
bolometer during one subscan. The lower three panels shows how the
signal is composed of signal from the atmosphere, the source and white
noise. The iterate algorithm estimates the contribution of all those
factors and compares the model with the original raw data. The
algorithm refines the estimates in an iterative loop until it meets
certain convergence criteria.

The \rebin\ method is a good option if you want to produce an image
quickly, but it does not fully correct for systematic noise. The
\iterate\ method produces more accurate maps, with better sky
subtraction.

\begin{figure}
%\includegraphics{signal-components.eps}
\caption{The top panel shows the observed signal, with subsequent
  panels showing the relative contributions from the atmosphere, the
  astronomical source and white noise.}
\end{figure}

\subsubsection{\xlabel{rebinmap}Rebin method\label{se:rebinmap}}

The rebinning algorithm shares the observed signal from a single
bolometer between neighbouring output map pixels, as determined by the
pixel-spreading function. The value of each pixel in the map is the
sum of the signal from every bolometer that observed at that position.

There are many options for the pixel spreading scheme (see Table A-1
for a summary). The fastest option is to use the nearest-neighbour
pixel spreading scheme (Nearest), which assigns the whole signal from
one bolometer to the nearest map pixel. This option does not always
produce smooth maps, but it produces a robust estimate of the noise.

For smoother maps, use the Linear scheme to share the input signal
equally among the four nearest map pixels. There are more complicated
options available, e.g., Sinc-type functions, or Gaussian
distributions. These methods produce aesthetically pleasing maps, at
the risk of introducing correlations into the noise.

Figure 8 shows an example map created from simulated observations of
an extended source with bright features. It was created using the
Rebin method and the nearest-neighbour pixel spreading scheme.

Note the dark regions around the bright sources. They are negative
bowls introduced by the sky subtraction method (Section 3.2). The
random dots are cosmic ray spikes which are not removed by this
workflow.

\begin{figure}
%\includegraphics...
\caption{Example map}
\end{figure}



\subsection{\xlabel{dimm}Dynamic Iterative Map-Maker\label{se:dimm}}

The Dynamic Iterative Map-Maker (DIMM) is the preferred tool for
producing maps of SCUBA-2 total-power data. Rather than executing each
of the steps described in the previous section seperately, the DIMM is
capable of performing all of the data pre-processing steps, as well as
iteratively solving for multiple signal components (including the
image of the astronomical sky) using a single call to the \makemap\
task. 

\subsubsection{Signal model}

We first develop the model used by the DIMM for time-varying bolometer
signals as a linear combination of several components:
%
\begin{equation}
I^i_{\mathrm{obs}}(t) = [G_C^i COM(t) + O_C^i] + [G_D^i DKS^j(t) + O_D^i] +
                      EXT^i(t) AST^i(t) + N^i(t).
\end{equation}
%
Here $I^i_{\mathrm{obs}}(t)$ is the total power delivered to the $i$th
detector in pW as a function of time. The actual data written to disk
has some arbitrary digital units that are proportional to pW. The
conversion to pW is accomplished by flatfield measurements described
in ... .

There is a dominant signal seen almost equally by all of the
detectors. This ``common-mode'' component, $COM$, is a mixture of
emission from atmospheric water vapour and the ambient thermal load
from the telescope itself. Each detector has two free parameters
associated with this signal component: a gain, $G_C^i$, and offset,
$O_C^i$. This enables the map-maker to handle cases where the
flatfield has a small residual error, and/or small residual baseline
offsets are present.

The first successful observations with SCUBA-2 used test arrays that
exhibited strong signals correlated along columns which were believed
to be caused by magnetic field pickup. Dark squids, $DKS$, (readouts
with no thermal absorbers) at the ends of the $j$th column seem to
provide a good measurement of this signal. Similar to $COM$, the DIMM
can fit a gain and offset, $G_D^i$ and $O_D^i$, to each detector for
the appropriate dark squid signal in a given column.

The actual astronomical signal from which we wish to make a map,
$AST$, is attenuated by an extinction factor, $EXT$, resulting from
absorption by atmospheric water vapour. The calculation of $EXT$ is
described in detail in ... . The ultimate goal of the DIMM is to
isolate the component of the bolometer signals produce by $AST$ and to
re-grid it into a map.

Finally, there is a residual noise term for each detector, $N^i(t)$,
which accounts for all of the remaining signal not accounted for by
the other model components. Ideally the dominant component of this
signal would be the white noise resulting from the thermal background,
the noise component responsable for the noise equivalent power (NEP)
and corresponding noise equivalent flux density (NEFD) used to plan
observations. In practice, the detectors also have other
slowly-varying baselines that are independent of the correlated $COM$
and $DKS$ signals described above. Therefore we express the residual
noise as
%
\begin{equation}
N^i(t) = N^i_w(t) + N^i_{lf}(t),
\label{eq:dimm_noise}
\end{equation}
%
where $N^i_w(t)$ and $N^i_{lf}(t)$ are the white and independent
low-frequency noise components respectively. The DIMM can attempt to
fit $N^i_{lf}(t)$ such that the residual signal is given only by
$N^i_w(t)$.

The strategy used by the DIMM is to estimate each of the signal
components sequentially, roughly in order of decreasing amplitude. At
the end of this procedure a numerical value proportional to $\chi^2$
quantifying the mismatch between the model and the data is calculated
from the r.m.s. in the residual noise $N^i_w(t)$. Provided that the
model components are in some sense ``orthogonal'', multiple iterations
of this procedure produces improved estimates of each component with
stable convergence properties. This can be checked by monitoring the
value of $\chi^2$: if the change between subsequent iterations is
small enough the DIMM can stop automatically. Alternatively, a set
number of iterations may be requested. In the future, separate
convergence tests for each model component may be added.

The iterative algorithm solves for different model components,
creating a better model of the raw data in successive iterations. The
algorithm runs until it reaches a pre-set number of iterations or
until the difference between the model and the real data ($\chi^2$) is
no longer changing significantly.

\subsubsection{Detailed Operation}

\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{sun258_dimm_flow.eps}
\caption{Flow chart depicting operation of the dynamic iterative
  map-maker (DIMM).}
\label{fig:dimm_flow}
\end{center}
\end{figure}

Most of the processing steps followed by the DIMM are controlled by a
configuration file (... reference ...). An overview of the DIMM
operation is shown in Figure~\ref{fig:dimm_flow}, and the numbered
boxes are described below:

\begin{description}

\item[1. Concatenate:] The \makemap\ task typically takes raw SCUBA-2
  data as its input. The best maps are produced by first concatenating
  as much data from a given observation as possible into single
  continuous data streams in memory. This step is optional, and is
  controlled by the MEMITER and MAXLEN configuration file parameters,
  as well as the \makemap\ parameter MAXMEM. When the files are
  concatenated, it is also possible add extra zero-padding at the
  beginning and end of the data streams to facilitate filtering (see
  the PADSTART and PADEND configuration file parameters). This
  operation is equivalent to using the \concat\ task.

  Whether concatenation is requested or not, it is also worth noting
  that \makemap\ automatically applies the internally stored flatfield
  as data files are loaded, so that they have units of pW before
  estimating the map.

\item[2. Pre-process:] Before the iterative process begins, several
  pre-processing (data cleaning) steps may be applied. See the
  configuration file parameters APOD, ORDER, BADFRAC, FLAGSTAT,
  DCTHRESH, DCBOX, SPIKETHRESH, SPIKEITER, FILT\_EDGEHIGH,
  FILT\_EDGELOW, FILT\_NOTCHHIGH and FILT\_NOTCHLOW. These options
  provide the same functionality as the \clean\ task.

\item[3. Fit pre-map estimate models:] Once the iterative process has
  begun, models are fit to the data in the order described by the
  MODELORDER configuration file parameter (see
  Table~\ref{tab:dimm_components}). The default order is $COM, GAI,
  EXT, AST, FLT, RES, NOI, QUA$. Components specified before $AST$ are
  signals that are generally brighter than the astronomical
  signal. $COM$ and $GAI$ are both used to estimate and remove the
  bright common-mode signal. $EXT$ is a special model that applied the
  extinction correction determined from external sensors (see ... ).

\item[4. Estimate map:] The location of the $AST$ component in
  MODELORDER indicates when the astronomical image should be
  estimated. For example, with the default settings $COM$ is fit and
  removed from the data first, and the extinction correction
  applied. Then, once $AST$ is encountered, the signals are re-gridded
  using nearest-neighbour sampling to produce an estimate of the
  map. Since many samples typically contribute to the estimate of the
  signal in a given pixel, the noise is greatly reduced compared to
  the time-series data. Using the pointing solution, the map is then
  projected back into the time-domain (the result of ``scanning'' each
  detector across the map), storing it as the $AST$ signal component,
  and then removing it from the detector time streams. This model
  component is special since both the map and $AST$ are estimated by
  this step.

\item[5. Fit post-map estimate models:] Once the map has been
  estimated and the astronomical signal removed from the data, the
  residual should contain only noise. However, this signal often
  contains a weak drift ($N_{lf}$ in Eq.~\ref{eq:dimm_noise}) that is
  independent from one detector to the next. By specifying the $FLT$
  model component after $AST$, it is possible to remove this component
  using a low-pass filter. It is advisable to apply this filter after
  estimating the map to avoid causing ringing around bright
  astronomical sources. However, in this case at least two iterations
  are required for this component to have any effect on the estimated
  map. It is also advisable to specify $NOI$ as the final model
  component. This model calculates the r.m.s. noise in each detector,
  and is required if a $\chi^2$ stopping criterion has been
  requested. Furthermore, the measured r.m.s. are used to weight each
  detector in the map estimate. If $NOI$ has not been specified each
  detector is given the same weight, which can be highly non-optimal
  if the detectors exhibit a wide range of sensitivities.

\item[6. Check for convergence:] Finally, the solution is checked for
  convergence -- either by reaching the number of pre-defined
  iterations requested, or $\chi^2$ has changed by less than the
  CHITOL value specified in the configuration file. In the latter
  case, $\chi^2$ is calculated in the following way. In the first
  iteration, $NOI$ estimates the white-noise contribution to the
  r.m.s., $\sigma_w$ in each detector directly from the flat part of
  their power spectra (presently defined over the frequency range 2 to
  10 Hz). If any astronomical signal, or low-frequency signal
  components are present in the data, the r.m.s. of the data stream
  will be much larger than this (the integral over the entire power
  spectrum). However, as the solution converges, the residual signal
  should slowly approach a white noise distribution once the other
  signal components are estimated and removed. $\chi^2$ is therefore
  calculated as $(1/N) \sum_i[ r_i^2/\sigma^2_w]$, where $r_i$ is the
  $i$th residual sample for a given detector, and $N$ is the total
  number of samples for that detector. This number, averaged over all
  samples and detectors, should tend to 1 as the solution converges,
  although in practice it is off by some factor related to the
  bandwidth used to calculate $\sigma_w$.

  The final map estimate, model signal components, and residual signal
  may then all be exported to files for examination (see EXPORTNDF
  configuration file parameter).

\end{description}

\paragraph{Model components}

See Table 2 for a list of model components and their definitions. It
may be necessary to add more model components during the commissioning
of SCUBA-2.
\begin{table}
\begin{tabular}{cl}
 Model Component & Definition \\
\hline
$COM$ & Removes common-mode signal, i.e., the signal seen by all \\
      & bolometers. This is the removal of the atmosphere. In addition \\
      & bad detectors are also flagged if there signal does not resemble \\
      & the common mode measured by the other detectors. \\
$GAI$ & If $COM$ specified, a gain and offset is used to fit $COM$ to each \\
      & detector before removal. \\
$DKS$ & Fits gain and offset to remove signal recorded by dark squids. \\  
$EXT$ & Applies the extinction correction. \\
$AST$ & Triggers map estimation, and removal of astronomical signal from \\
      & time-series. \\
$FLT$ & Applied frequency domain filter. \\
$NOI$ & Estimates the time-domain variance to establish relative detector \\ 
      & weights for map estimated, and for chi-squared ($\chi^2$) tolerance. \\
\end{tabular}
\caption{Model Components for Iterative Mapmaking}
\label{tab:dimm_components}
\end{table}

\paragraph{Processing time}

The memiter parameter (Table 3) influences the time it takes the iterative
algorithm to generate a solution. It determines whether:
\begin{enumerate}
\item Iterations are performed in memory (memiter=1)
\item Component values are written to a file after each iteration
  (memiter=0)
\end{enumerate}

For the first option, the algorithm loads as many data files as
possible into memory and processes the data in a single, continuous
chunk. Once the algorithm has estimated a map, it saves the map and
loads the next continuous chunk of data. When all the data is
processed, the routine combines the maps from each continuous chunk
into one image.

For the second option the algorithm loads one data file (or file
chunk) into memory, processes the file, saves the map, and moves onto
the next file. This method uses less memory, but it takes much longer
because of the extra time spent writing files to disk.

If your computer has enough random access memory (RAM), it is
recommended that you set the memiter=1 and allow the iterative
algorithm to process as much data as possible. However, you can still
limit the size of the continuous chunk using the parameter maxmem.

\paragraph{Convergence criteria}

The iterative algorithm calculates the chi-squared ($\chi^2$)
tolerance after each iteration, and then, calculates the difference
between $\chi^2$ from current iteration and the previous iteration. If
the difference is less than $10^{-6}$, then the iterative routine
stops.

\paragraph{Example image}

\begin{figure}
%\includegraphics...
\caption{Example figure processed with the iterative mapmaker}
\end{figure}

Figure 9 shows an example of a map created from simulated observations
of an extended source using the Iterate method. Compare this image
with the map created from the same observations using the Rebin method
(see Figure 8).The dark regions around the bright sources have
disappeared and the cosmic ray spikes have been removed.


\paragraph{Using the iterate method}
When using the Makemap routine with the iterate option, you need to apply
the following parameters and options:

\begin{itemize}
\item Create a configuration file, e.g. config.lis, containing all the
  required parameters listed in the form keyword=value. The
  configuration parameters are summarized in Table 3 and the default
  values are shown in the third column.
\item Set the method parameter to iterate.
\item Set the correct pixel size for your observed wavelength using
  the pixsize parameter.
\item If necessary, set the co-ordinate system using the system
  parameter.
\end{itemize}

To make the map:
\begin{verbatim}
makemap in=^input.lis out=mapname method=iterate config=^config.lis \
        pixsize=value
\end{verbatim}


\subsubsection{Quick reference}

This table summarizes options available for each of the parameters
passed to the Makemap routine.

\begin{table}
\begin{tabular}{lccccccc}
\hline
        & \multicolumn{4}{c}{Required Parameters}           & \multicolumn{3}{c}{Optional Parameter} \\
Method & method    &  config   &    pixsize   &   system         &  spread    & params(1) & params(2) \\
       &           &           &   (arcsec)   &  (co-ordinates)  &            &           & \\
\hline
Rebin  & rebin     &  --       &              &                  &  Linear,   &   --      & -- \\
       &           &           &              &                  &  Nearest   &     --       & \\
       &           &           &              &                  &  Sinc,     &              &   -- \\
       &           &           &              &                  &  Somb      &              & \\
       &           &           &              &   ICRS, GAPPT,   &            &              & \\
       &           &           &              &   FK5, FK4,      &  SincSinc, &  Usually 2   &  Default: 2\\
       &           &           &              &                  &  SincCos,  &  Minimum:1   &  Minimum: 1\\
       &           &           &      3 or 1  &   FK4-NO-E,      &  SombCos   & Auto $\leq$0 & \\
       &           &           &              &   AZEL,          &            &              & \\
       &           &           &              &   GALACTIC,      &  Gauss,    &              &   Default: 1\\
       &           &           &              &   ECLIPTIC       &  SincGauss &              &   Minimum:\\
       &           &           &              &                  &            &              &           0.1\\
\hline
Iterate& iterate   &    See    &              &                  &  Nearest   &     --       &   -- \\
       &           &    Section&              &                  &            &              & \\
       &           &    5.4.1  &              &                  &            &              & \\
\hline
\end{tabular}
\caption{For further information about spread, params(1) and params(2), see Table A-1.}
\end{table}

\paragraph{Configuration parameters}

Table 3 summarizes the configuration parameters available for the
model components in the Iterate method. The default values are shown
in the third column.


\begin{table}
\begin{tabular}{llc}
\hline
Parameter        &       Definition                                                         &  Default Value \\
(keyword)        &                                                                          & \\
\hline
numiter          &      Either give a positive number that equals the number of             & 10\\
                 &      iterations, or give a negative number that equals the maximum       & \\
                 &      number of iterations using chi squared ($\chi^2$) stopping criteria.& \\
exportndf        &      An option to export iterative mapmaker files as NDF files. It       & 0 (do not\\
                 &      exports one file per model component, per subarray. Use this        & export as NDF\\
                 &      option if you want to view the values in these files.               & files)\\
\hline
\multicolumn{3}{l}{If applying a filter to remove artifacts} \\
\hline
filt\_edgehigh,      &   Enter low and high frequencies in hertz (Hz).                     & -- \\
filt\_edgelow        & & \\
filt\_notchhigh,     &   Enter a range of high frequencies for filt\_notchhigh and a range & -- \\
filt\_notchlow       &   of low frequencies for filt\_notchlow. & \\
\hline
\multicolumn{3}{l}{If removing common mode signal (atmosphere)} \\
\hline
com\_boxcar          &    A low-pass boxcar filter that assists with convergence. Specify  & 400 \\
                     &   size, i.e., the number of samples to use.                         & \\
com\_boxfact         &    Reduce the width of the boxcar by this box factor in each        &   0.5 \\
                     &   iteration.                                                        & \\
com\_boxmin          &   The minimum width below which the boxcar can't be reduced.        & 100 \\
\hline
\multicolumn{3}{l}{If estimating the time-domain variance for chi-squared ($\chi^2$) tolerance (if numiter is negative)} \\
\hline
chitol            &   $\chi^2$ tolerance, requires noi model component. If the $\chi^2$ difference & $10^{-6}$\\
                  &   $<1\times10^{-6}$, then make the current iteration the last iteration.       & \\
noispikethresh    &   Additional despiking after each iteration, within the noi                    & 10 \\
                  &   calculation.                                                                 & \\
noispikeiter      &   Additional despiking after each iteration, within the noi                    & 0 \\
                  &   calculation.                                                                 & \\
varmapmethod      &   Method of estimating variance map. If equal to zero, then use the            & 0 \\
                  &   spread of values from the time-series (i.e. the raw data). If equal          & \\
                  &   to 1, then it samples the variance of data that land in each output          & \\
                  &   map pixel.                                                                   & \\
\hline
\multicolumn{3}{l}{Whether to write the history of the modal components to file} \\
\hline
memiter           &   Either perform the iterations in memory (=1) or write the       &    1 \\
                  &   component values to a file (=0).                                & \\
maxlen            &   If performing the iterations in memory, this is the maximum     &    0 \\
                  &   length (seconds) for concatenated data. If equal to zero, then  & \\
                  &   attempt to concatenate entire continuous chunks.                & \\
\hline
\end{tabular}
\caption{Stuff...}
\end{table}

\section{\xlabel{simulator}SCUBA-2 simulator\label{se:sc2sim}}

\SMURF\ has the capability to produce simulated data from SCUBA-2 with
the \sctwosim\ task. The simulator requires an input astronomical sky
image and a model of the atmosphere. Suitable model atmospheres may be
generated with \skynoise. Output files are written in the same format
as real data from SCUBA-2 with complete flatfield and state structure
information and can be processed with other \SMURF\ tasks.

The simulator supports the primary observing modes: DREAM, STARE, SCAN
along with FLATFIELD, POINTING and FOCUS observations. Rudimentary
support exists for the SCUBA-2 polarimeter though this is
untested. Instrument apertures may be set (offsets which adjust the
tracking position to a specific subarray) and microsteps (small
offsets from the tracking position) are fully supported. Simulating
the motion of the major Solar System bodies (Venus, the Moon, Mars,
Jupiter, Saturn, Uranus and Neptune) is supported.

For SCAN observations, the simulator has two modes controlled by the
\texttt{SIMTYPE} parameter. A \texttt{FULL} simulation generates
simulated complete astronomical data including the effect of the
atmosphere. A \texttt{WEIGHTS} simulation generates data which may be
used to assess areal coverage and ``hit'' density (i.e.\ the number of
times a point on the sky is observed) for different mapping strategies
or the impact of non-working bolometers.

\subsection{\xlabel{simuse}Simulator workflow\label{se:simuse}}

The simulator requires some preparatory work before data can be
simulated. The basic procedure is outlined below:
\begin{itemize}
\item Obtain an astronomical sky image;
\item Calculate a model atmosphere;
\item Calculate a flatfield solution;
\item Decide on simulation parameters;
\item Run simulation.
\end{itemize}
It is not necessary to recalculate a model atmosphere or flatfield
solution for every simulation, even for different input sky images. 

Example files are installed as part of \SMURF\ and may be found in the
\texttt{\$STARLINK\_DIR/share/smurf} directory. An explanation may be
found in the \texttt{README} file in that directory.

\subsubsection{Astronomical image}

The astronomical image may be any suitable image, provided it has WCS
information. The WCS is used unless the source is a moving object
(listed above). The image must be an NDF. It is recommended that the
image pixel scale be set to be much less than the likely output map
pixel spacing (typically 3 arcsec at 850\,$\mu$m, 1 arcsec at
450\,$\mu$m) to avoid imaging and sampling artefacts.

\subsubsection{Model atmosphere}

The model atmosphere is calculated with the \skynoise\ task. The
atmosphere is modelled as a Kolmogorov turbulent thin-screen (refs)
with a characteristic turnover frequency and scaling law. Different
models may be generated for the same parameters using a random number
seed (specified or calculated internally using the system clock). The
parameters may be modified though the user should be familiar with the
details of this model of the atmosphere before exploring the parameter
space too widely.

The model atmosphere calculated is generic and may be used for
simulations at both 850\,$\mu$m and 450\,$\mu$m. The model is scaled
at the time of simulation according to the particular wavelength.

\subsubsection{Flatfield simulation}

Before a data simulation can take place, the flatfield solution for
each subarray must be calculated. This is achieved by specifying a
special observing mode called \texttt{heatrun} and running a
simulation. The flatfield solution is written to a file using a naming
scheme which follows that for raw data. The convention is
\verb+s[4|8][a-d]heatYYYYMMDD_NNNNN.sdf+ where \verb+s[4|8][a-d]+ is
the subarray name (e.g.\ \verb+s8a+), \verb+heat+ indicates a
flatfield observation, \verb+YYYYMMDD+ is the date of observation and
\verb+NNNNN+ is a zero-padded, 5-digit observation number.

The simulator relies on this naming scheme for reading the flatfield
information, and the files must be present in the current directory.

\subsubsection{Running the simulator}

The simulator has a large number of parameters which may be freely
adjusted. The list of parameters is divided between two groups:
simulation parameters (usually telescope- and instrument-specific) and
observation parameters (properties of the observation in
question). These are specified using the \texttt{SIMPAR} and
\texttt{OBSPAR} ADAM parameters to \sctwosim. For convenience, the
parameters are stored in plain text files and are passed in using the
\verb+^+ scheme mentioned above (ref...).

Since the data output from the simulator mimics the real instrument,
it is possible to generate many GB of data which may take many minutes
to hours of CPU time. The \sctwosim\ parameter \texttt{SIMSTATS}
provides an estimate of the simulation properties including the
quantity of data, memory requirements and CPU time.

\section{Acknowledgments}

The SCUBA-2 simulator code was originally written as a standalone
application by Dennis Kelly at the UK Astronomy Technology Centre and
re-written as a \SMURF\ task by Jen Balfour. The authors are grateful
for the documentation written by Maria Kelly on which this SUN is
based, and Christa van Laerhoven for an earlier version.

% End of main text

\section{Release Notes---V0.1}

\subsection{Global changes}
\begin{itemize}
  \item Improve description of SCUBA-2 processing routines for Nanahope Starlink release
\end{itemize}

\subsection{New applications}
\begin{itemize}
  \item calcresp...
\end{itemize}

\subsection{Modified applications}
\begin{itemize}
  \item makemap
\end{itemize}

\newpage
\appendix
\begin{small}
\section{\xlabel{ap_summary}An Alphabetical Summary of SMURF Commands
\label{ap:summary}}
\begin{htmlonly}
\begin{description}
\end{htmlonly}

\menuitem{BADBOLOS}{
  Generate a map of random dead bolometers and add it as an NDF extension to the input file.}
\menuitem{CALCDARK}{
 Calculate the 2d dark frame from a dark observation.}
\menuitem{CALCFLAT}{
 Calculate a flatfield solution}
\menuitem{CALCRESP}{
 Calculate bolometer responsivity from stored flatfield solution.}
\menuitem{DREAMSOLVE}{
 DREAM solver.}
\menuitem{DREAMWEIGHTS}{
 DREAM weight matrix generation.}
\menuitem{dumpocscfg}{
Retrieve OCS XML configuration used to generate the raw data.}
\menuitem{EXTINCTION}{
 Extinction correct SCUBA-2 data.}
\menuitem{FLATFIELD}{
 Flatfield SCUBA-2 data.}
\menuitem{GSD2ACSIS}{
 Convert a GSD format DAS data file to an ACSIS format NDF. (beta test)}
\menuitem{GSDSHOW}{
 Display the contens of a GSD file's headers and arrays.}
\menuitem{IMPAZTEC}{
  Import AzTEC NETCDF files and produce SCUBA-2 format data files. (untested)}
\menuitem{jcmtstate2cat}{
Dump JCMTSTATE information to ASCII table.}
\menuitem{MAKECUBE}{
 Regrid ACSIS spectra into a data cube.}
\menuitem{MAKEMAP}{
 Regrid SCUBA-2 data into a map.}
\menuitem{QLMAKEMAP}{
  Quick-Look SCUBA-2 map maker.}
\menuitem{RAWUNPRESS}{
  Uncompress raw SCUBA-2 data.}
\menuitem{RAWFIXMETA}{
 Report metadata issues with ACSIS data files.}
\menuitem{REMSKY}{
  Remove Sky signal from SCUBA-2 observations.}
\menuitem{SC2CLEAN}{
 Clean-up SCUBA-2 time series.}
\menuitem{SC2CONCAT}{
 Concatenate files from a single observation into a single file.}
\menuitem{SC2FFT}{
 Perform an forward or inverse FFT on SCUBA-2 data.}
\menuitem{SC2FTS}{
 FTS-2 data processing (disabled).}
\menuitem{SC2SIM}{
SCUBA-2 simulator.}
\menuitem{SCANFIT}{
  Fit a sky signal to each SCUBA-2 scan.}
\menuitem{SKYNOISE}{
 Generate a simulated sky background.}
\menuitem{SMURFCOPY}{
Copy a 2d image out of a time series file.}
\menuitem{SMURFHELP}{
Gives help about SMURF.}
\menuitem{STARECALC}{
 Calculate a map from a Stare-mode observation.}
\menuitem{TIMESORT}{
 Re-order time slices in a raw data cube into increasing time.}
\menuitem{UNMAKECUBE}{
 Produce simulated time series data from a regridded ACSIS data cube.}
\begin{htmlonly}
\end{description}
\end{htmlonly}

\newpage
\section{\xlabel{ap_classified}Classified SMURF commands
\label{ap:classified}}

\SMURF\ applications may be classified in terms of their
functions as follows.

{\large
\begin{center}
{\bf General Purpose}
\end{center}
}

\begin{description}
\classitem{dumpocscfg}
Retrieve OCS XML configuration used to generate the raw data.
\classitem{jcmtstate2cat}
Dump JCMTSTATE information to ASCII table.
\classitem{SMURFHELP}
Gives help about SMURF.
\end{description}

{\large
\begin{center}
{\bf SCUBA-2 Data Processing}
\end{center}
}

\begin{description}
\classitem{CALCDARK}
 Calculate the 2d dark frame from a dark observation.
\classitem{CALCFLAT}
 Calculate a flatfield solution
\classitem{CALCRESP}
 Calculate bolometer responsivity from stored flatfield solution.
\classitem{DREAMSOLVE}
 DREAM solver.
\classitem{DREAMWEIGHTS}
 DREAM weight matrix generation.
\classitem{EXTINCTION}
 Extinction correct SCUBA-2 data.
\classitem{FLATFIELD}
 Flatfield SCUBA-2 data.
\classitem{MAKEMAP}
 Regrid SCUBA-2 data into a map.
\classitem{QLMAKEMAP}
  Quick-Look SCUBA-2 map maker.
\classitem{RAWUNPRESS}
  Uncompress raw SCUBA-2 data.
\classitem{REMSKY}
  Remove Sky signal from SCUBA-2 observations.
\classitem{SC2CLEAN}
 Clean-up SCUBA-2 time series.
\classitem{SC2CONCAT}
 Concatenate files from a single observation into a single file.
\classitem{SC2FFT}
 Perform an forward or inverse FFT on SCUBA-2 data.
\classitem{SC2FTS}
 FTS-2 data processing (disabled).
\classitem{SCANFIT}
  Fit a sky signal to each SCUBA-2 scan.
\classitem{SMURFCOPY}
Copy a 2d image out of a time series file.
\classitem{STARECALC}
 Calculate a map from a Stare-mode observation.
\end{description}

{\large
\begin{center}
{\bf ACSIS Data Processing}
\end{center}
}

\begin{description}
\classitem{MAKECUBE}
 Regrid ACSIS spectra into a data cube.
\classitem{RAWFIXMETA}
 Report metadata issues with ACSIS data files.
\classitem{TIMESORT}
 Re-order time slices in a raw data cube into increasing time.
\classitem{UNMAKECUBE}
 Produce simulated time series data from a regridded ACSIS data cube.
\end{description}

{\large
\begin{center}
{\bf Data Import}
\end{center}
}

\begin{description}
\classitem{GSD2ACSIS}
 Convert a GSD format DAS data file to an ACSIS format NDF. (beta test)
\classitem{GSDSHOW}
 Display the contens of a GSD file's headers and arrays.
\classitem{IMPAZTEC}
  Import AzTEC NETCDF files and produce SCUBA-2 format data files. (untested)
\end{description}

{\large
\begin{center}
{\bf SCUBA-2 Simulations}
\end{center}
}

\begin{description}
\classitem{BADBOLOS}
 Generate a map of random dead bolometers and add it as an NDF extension to the input file.
\classitem{SC2SIM}
SCUBA-2 simulator.
\classitem{SKYNOISE}
 Generate a simulated sky background.
\end{description}

\end{small}

\section{\xlabel{ap_full}Specifications of SMURF applications\label{ap:full}}

The following pages describe all the SMURF commands in detail.

\input{../../libsmurf/smurfmon}

\end{document}

\paragraph{}
