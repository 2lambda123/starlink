0 SURF

This is the interactive help system for the SURF (SCUBA User 
Reduction Facility) package.


1 Classified_commands

2 Alphabetic_list

ADD_DBM         - Generate simulated chopped images
BOLREBIN        - Generate a separate regridded image from each bolometer
CALCSKY         - Calculate sky variation independent of source structure
CHANGE_DATA     - Change data (or variance) values in the data 
CHANGE_FLAT     - Change the stored flatfield information
CHANGE_NACENTRE - Shift Nasmyth centre of array
CHANGE_POINTING - Change Az and El pointing offsets for map data
CHANGE_QUALITY  - Change pixel quality
DESPIKE         - Despike JIGGLE/MAP data
DESPIKE2        - Despike SCAN/MAP data
DSPBOL          - Interactive despiking and data inspection (requires Kappa)
EXTINCTION      - Correct the data for atmospheric extinction
EXTRACT_DATA    - Write bolometer positions and data to text file
EXTRACT_FLAT    - Write flatfield information to a text file
FLATFIELD       - Multiply the data array by the flatfield volumes
INTREBIN        - Generate a separate regridded image for each integration
MAPSUM          - Generate a summary of all map observations
OBSSUM          - Generate a one-line summary of all observations
PHOTSUM         - Generate a summary of all photometry observations
PLTBOL          - Interactive data inspection (requires Kappa)
POINTSUM        - Generate a summary of all pointing observations
QDRAW           - Plot photometry data (requires Kappa)
REBIN           - Regrid all data onto a rectangular grid.
REDUCE_NOISE    - Process demodulated noise data.
REDUCE_SWITCH   - Convert raw demodulated data to standard format and
                  process individual switches.
REMDBM          - Remove dual beam response from SCAN/MAP images (needs Kappa)
REMIP           - Remove instrumental polarisation from polarimetry data
REMSKY          - Remove sky contribution from each jiggle
RESTORE         - Remove dual-beam response from SCAN/MAP data
RLINPLOT        - Interactive data inspection via MLINPLOT (requires Kappa)
SCAN_RLB        - Remove linear baselines from SCAN/MAP data
SCUBA2MEM       - Calculate bolometer positions including chops
SCUCAT          - Concatenate photometry results into a single file
SCUCLIP         - Perform sigma clipping of each bolometer
SCUCLKERR       - Determine potential error in the SCUBA time headers
SCUHELP         - This help system
SCULOG          - Provide detailed descriptions of all observation data
SCUMAKEWT       - Generate fourier weights of chop function
SCUNOISE        - Display SCUBA noise data
SCUOVER         - Overlay bolometer array on image
SCUPA           - Show position angle of array (requires Kappa)
SCUPHOT         - Process extinction corrected photometry data
SCUPLOT         - Interactive despiking and data inspection (requires Kappa)
SCUQUICK        - Script to automate SURF data reduction
SCUSETENV       - Set SCUBA environment variables (JAC only)
SCUSHIFT        - Correct for 'data-shift' problem.
SDIP            - Script to reduce and display skydip data (requires Kappa)
SETBOLWT        - Calculate and set bolometer weights (requires Kappa)
SIGCLIP         - Remove spikes from photometry data (requires Kappa)
SKYDIP          - Process SKYDIP data in order to determine atmospheric
                  extinction
SKYSUM          - Generate a summary of skydip observations


2 Observation_summaries

SCULOG          - Generate log of all observations in a directory
MAPSUM          - Generate a summary of all map observations
OBSSUM          - Generate a one-line summary of all observations
PHOTSUM         - Generate a summary of all photometry observations
POINTSUM        - Generate a summary of all pointing observations
SKYSUM          - Generate a summary of skydip observations

2 General_Tasks

EXTRACT_FLAT    - Write the flatfield information to a text file
REDUCE_NOISE    - Process demodulated noise data.
SCUBA2MEM       - Calculate bolometer positions
SCUCLKERR       - Determine potential error in SCUBA time headers
SCUHELP         - This help system
SCUPA           - Show position angle of array (requires Kappa)
SCUQUICK        - Script to automate SURF data reduction
SCUSETENV       - Set SCUBA environment variables (JAC only)
SCUSHIFT        - Correct for `data shift' problem
SDIP            - Script to reduce and display skydip data (requires Kappa)
SKYDIP          - Process SKYDIP data in order to determine atmospheric
                  extinction

2 Initial_processing

REDUCE_SWITCH - Convert raw demodulated data to standard format and
                process individual switches.
FLATFIELD     - Multiply the data array by the flatfield volumes.
EXTINCTION    - Correct the data for atmospheric extinction
CALCSKY       - Calculate sky signal

2 JIGGLE_data_processing

DESPIKE         - Despike JIGGLE data
REMSKY          - Remove sky contribution from each jiggle
SCUCLIP         - Sigma clip photometry data and maps of weak sources

2 SCAN/MAP_data_processing

ADD_DBM         - Add dual-beam to single-beam data
DESPIKE2        - Despike SCAN/MAP data
REMDBM          - Remove dual-beam response from SCAN/MAP images (needs Kappa)
RESTORE         - Remove dual-beam response from SCAN/MAP data (EKH)
SCAN_RLB        - Remove linear baselines from scans
SCUMAKEWT       - Generate fourier weights (used by REMDBM)

2 Polarimetry

REMIP           - Remove instrumental polarisation from polarimetry data

2 Inspection

PLTBOL          - Interactive bolometer display (requires Kappa)
RLINPLOT        - Interactive display via MLINPLOT (requires Kappa)
SCUPLOT         - Interactive display and despiking (requires Kappa)
SCUNOISE        - Plot SCUBA noise data

2 Modification

CHANGE_DATA     - Change data (or variance) values in the data 
CHANGE_FLAT     - Change the stored flatfield information
CHANGE_NACENTRE - Change Nasmyth coordinates of array centre
CHANGE_POINTING - Change Az and El pointing offsets for map data
CHANGE_QUALITY  - Change pixel quality
DSPBOL          - Interactive despiking (requires Kappa)

2 Mapping

REBIN         - Regrid all data onto a rectangular grid.
BOLREBIN      - Generate a map from each bolometer separately
INTREBIN      - Generate a map of each integration separately
EXTRACT_DATA  - Write bolometer positions and data to text file
SCUOVER       - Overlay bolometer array on image
SETBOLWT      - Calculate and set bolometer weights (requires Kappa)

2 Photometry

SCUPHOT       - Process extinction corrected photometry data
SCUCAT        - Concatenate photometry results into a single file
QDRAW         - Kappa script to aid in the plotting of photometry data
SIGCLIP       - Kappa script to mark spikes in photometry data.



1 SCUBA_sections

None of the SURF tasks can accept NDF sections (SUN/33). This is
because all the tasks rely on information in the NDF extensions that
must correspond to data in the main DATA_ARRAY.  Since on many
occasions it is desirable to work on a subset of the observation
(e.g. data from a specific exposure, integration or measurement) the
SURF package has a concept of a 'SCUBA section.'

A SCUBA section is indicated by using curly brackets after the file
name (c.f. round brackets for NDF sections). The brackets then contain
a specification that selects a certain part of the input data
using the following format:

   Specifier  Definition
   ---------  ----------
       {      Begins a SCUBA section
       }      Ends a SCUBA section  
       b      indicates that the following numbers 
              describe bolometer numbers (ie X axis)
       p      indicates data position (ie Y axis)
       s      switches 
       e      exposures 
       i      integrations
       m      measurements
       ;      Separates components
       ,      Separates numbers
       :      indicates a range of values
       -      Negates a section if placed after the last curly bracket

2 Examples

  Here are some example SCUBA sections:

      test{i3}  
          means select all bolometers in integration 3 for all
          measurements

      test{b3:5}
          select bolometers 3 to 5 for all points
 
      test{}     
          select all points (good for resetting CHANGE_QUALITY
          mask)
 
      test{e3}
          select the 3rd exposure in each integration
 
      test{e3;i4}  
          select the third exposure in integration 4
 
      test{b5;p500:600} 
          select points 500 to 600 for bolometer 5
 
      test{b5:7,19}   
          select bolometers 5 through 7 and bolometer 19
 
      test{i2}-
          select everything except integration 2.

      test{i1:4,7}{b3}-
          select everything except integrations 1,2,3,4 and 7 and the 
          data for bolometer 3.

      test{b2}{i3}
          select bolometer 2 and integration 3. Note that this
          is different to {b2;i3} which would only select the second
          bolometer from integration 3.

1 Release_notes

2 New_in_version_1_6_10

Two minor bug fixes:

  - Fix problem in BOLREBIN on linux (unintialized pointer)

  - Fix REMIP problem with aborted polarimeter observations

2 New_in_version_1_6_9

This is a bug fix release. Main changes are:

  - Fix problems with SCUBA2MEM when using SC (EKH) scanning

  - Correctly rebin photometry observations taken with AZ jiggling.
    [previously AZ offsets were simply ignored unless pointing
     corrections were being applied]

2 New_in_version_1_6_8

This is a bug fix release. Main changes are:

  - Add support for Raster skydips

  - New version of the mapping cookbook (SC/11) to include scan map

  - Update of REMDBM to support KAPPA 0.18

  - Minor fixes to SCUBA2MEM with EKH scanning

  - Dont calculate clock correction when using AZ

2 New_in_version_1_6

Important changes to SKYDIP and a fix for the clock error problem.

3 New_Tasks

  - SCUCLKERR can be used to determine possible clock errors
    in the acquisition system.

3 Changes_to_existing_tasks

  - Add correction for the SCUVAX clock error problem

  - Skydips now 'know' the correct value for ETA_TEL, T_COLD and T_HOT

  - In REMSKY the outer ring of bolometers can be specified using R-1
    (ie it counts from the outside in if you use a negative ring number)

  - SCUOVER is now a little cleverer (and the text can be a different
    color to the circles)

  - SCUNOISE works on Windows NT.

  - If the second LST provided to REMSKY is less than the first
    LST it is now assumed that the time refers to the following day.

3 Bug_Fixes

  - Fixed error when SCUPHOT runs in the pipeline where occasionally the
    parabola fit of the complete coadd could give incorrect answers.

  - Can now combine data taken at almost the same wavelengths (a 20 micron
    difference is allowed) when using REBIN.

  - Output file from REMDBM now no longer contains CHOP_* keywords

2 New_in_version_1_5

Minor update.

3 New_Tasks

  - SCUBA2MEM officially released (previously it was available
    but undocumented.

  - The SURF Programming Guide (SSN/72) now available

3 Changes_to_existing_tasks

  - SCULOG and related tools rewritten to handle data from
    multiple UT dates in a single directory. Extended support for
    POLMAP and POLPHOT observing modes.

  - Improve support of external data model in CALCSKY. Can now
    import image of arbritrary coordinates and automatically add 
    chop functions.

  - ADD_DBM can now be used to addd a triple beam

  - Scripts now compatible with KAPPA version 0.14

3 Bug_fixes

  - Fix bug in REMDBM when using filtering when data have a pixel
    origin that is not in the middle of the array.

2 New_in_version_1_4

  SURF can now process polarimetry data.

3 New_Tasks

  - REMIP for removal of instrumental polarisation

  - ADD_DBM can be used to generate simulated dual beam images

  - SCUSETENV for setting environment variables at the JAC

3 Changes_to_existing_tasks

  - Units should now be propagated correctly through all tasks
    (ie calibration units are not lost after REBIN or SCUPHOT)
 
  - SURF version number is now written to history information

  - SCAN_RLB: Area to use for baseline removal can now be specified
    as a SCUBA section.

  - REMDBM: The -filter option will filter out high frequencies
           before inverting the Fourier transform.

  - REBIN: Add TRIM parameter to trim edge regions from rebinned
           images (useful when trying to mosaic)

  - REBIN: Astrometry information is now entirely contained in 
           the AST/WCS component. No longer written to FITS or
           IRAS90 extensions. Also, the pixel origin is now centred
           on the specified RA/Dec centre of the image and not
           the bottom left hand corner.

  - REBIN: REFPIX parameter has been added to make it easier to specify
           the reference pixel location when changing the map size
           (in the past the reference pixel was always the middle of the
           map when specifying the map size)

  - REBIN: The output file is now propagated from the input when
           processing a single file (keeps history intact)

  - INTREBIN: Waveplate position and sky rotation angle are now
        written to the fits headers for polarimetry observations.

  - EXTINCTION: Can process FAST_AXIS polarimetry information correctly

  - SKYDIP: Add preliminary support for RASTER mode (not yet stable)
  
  - OBSSUM/SCULOG: POLMAP and POLPHOT are now supported modes.

  - SCUPHOT now recognizes measurements as well as integrations
      (required for polarimetry observing)

  - SCUOVER: Now reads astrometry from WCS/AST component.

  - SCUMAKEWT: Now can make a weights image like a reference image
     (ie same size, chop throw and position angle). See the LIKE parameter.

2 New_in_version_1_3

This is a minor upgrade.

3 New_Tasks

  - REDUCE_NOISE has been added

3 Changes_to_existing_tasks

  - REBIN now uses the AST library for world coordinate specification.

  - SCUNOISE can process text files generated by REDUCE_NOISE.

  - REBIN can now combine 256 input files.

  - The guard ring has been turned on for LINEAR and GAUSSIAN regridding.
    (It had been turned off in v1.2). A new parameter (GUARD) can be used
    to turn the bolometer guard ring on or off.

  - The output image from REMDBM now contains axis information.

3 Minor_fixes

  - The RA field in SCULOG is now processed correctly.

2 New_in_version_1_2

  The changes can be grouped into three categories:

3 New_Tasks

  - Sky removal for SCAN map is now available using the CALCSKY task.
 
  - Dual beam images taken using the new SCAN map observing mode can now be
    reduced using the REMDBM task (also uses SCUMAKEWT).

  - The offset between the arrays can be compensated for by using
    CHANGE_NACENTRE.

  - Noise data can now be displayed with SCUNOISE.

  - Bolometer weights can be set with SETBOLWT.

3 Changes_to_existing_tasks

  - SCUCAT can now accept a comma separated list of input files
    or a text file containing a list of files rather than having to
    supply one at a time. Also, there is now a METHOD option in
    SCUCAT to control whether bolometers are treated independently or
    combined regardless of bolometer name.

  - SCUPHOT can now propagate all samples to the output file. This is
    necessary for observations where the number of integrations is
    small and the variance can not be calculated reliably.

  - SCAN_RLB now has two extra modes for baseline removal (MEAN and
    MEDIAN). 

  - A Gaussian regridding option has been added to REBIN (BOLREBIN,
    INTREBIN). Also, the radius and footprint size of the convolution
    functions can now be configured.

  - A median regridding option is available. This option simply
    calculates the median value of all points in an output cell.

  - A histogram of the distribution of data samples on the output
    image can be obtained with the TIMES parameter in REBIN

  - Bolometer weighting has been added to REBIN. This is still in
    alpha test since it has been shown not to conserve flux for small
    data sets (for larger datasets -- hours -- there is a
    signal-to-noise gain without turning off bad pixels).

  - SKYDIP now provides an estimate of the errors.

3 Bug_fixes

  - DESPIKE can now be told to write output files automatically via
    the DEFOUT parameter.

  - SCUCLIP now performs an iterative clip by default.

  - Units are propagated through SCUPHOT.

  - SDIP now resets the LINPLOT colour settings to their original values
  after use.

  - The size of the 'IN' parameter has been increased in
    CHANGE_QUALITY and CHANGE_DATA.

  - A memory leak has been fixed in DESPIKE.

2 New_in_version_1_1

  The changes can be grouped into three categories:

3 General Changes

  - Output files are now as small as possible. In version 1.0-0 output
    files were the same size as the input file.

  - Observation numbers, rather than the full filename, can now be
    given to tasks that process the raw demodulated data (REDUCE_SWITCH,
    SKYDIP, SDIP, SCUQUICK)
    This feature requires the SCUBA_PREFIX environment variable.
 
  - All tasks now supply a default output filename. The form of this
    filename is governed by the SCUBA_SUFFIX environment variable.

  - The MAP_X, MAP_Y and LOCAL_COORDS observing parameters are now
    supported.

3 New_Tasks

  - A despiking task has been added for JIGGLE/MAP data (DESPIKE).

  - An experimental despiking task is available for SCAN/MAP data (DESPIKE2).

  - The data clipping functionality has been moved from REMSKY to a
    stand-alone task (SCUCLIP).

  - There is now a task for extracting flatfield information from data
    files (EXTRACT_FLAT).

  - Data suffering from the `data shift' problem (mainly Semester 97a)
    can be fixed with the SCUSHIFT task.

  - The experimental task, SCAN_RLB, can be used to remove linear baselines
    from SCAN/MAP data.

  - The addition of some interactive despiking and data inspection tools
    (DSPBOL, PLTBOL, RLINPLOT and SCUPLOT).

3 Changes_to_Existing_Tasks

  - SKYSUM is now officially released with documentation.
  
  - SKYDIP data can now be processed with REDUCE_SWITCH and CHANGE_QUALITY.
    This allows bad skydip points to be removed prior to fitting with SKYDIP.
    This required changes to REDUCE_SWITCH (cold load temperatures are 
    requested) and SKYDIP

  - REDUCE_SWITCH now creates axis information (instead of EXTINCTION).

  - For SCAN/MAP data SCUOVER now displays the position of the array at the
    start of a scan.

  - SKYDIP now reads default values for ETA_TEL from the observation 
    header and allows the T_HOT value to be modified. Additionally,
    the fit results are stored in parameters.

  - EXTINCTION now reads default values for FIRST_TAU from the
    observation header and supplies a default for SECOND_TAU (the value
    accepted for FIRST_TAU.)

  - REMSKY now adds the mean sky level back onto the data in order to
    minimise the removal of flux from the image.

  - REMSKY no longer despikes the data. This facility is now provided by
    the  SCUCLIP/DESPIKE tasks.

  - Bolometer groups (e.g. ring 1, ring 2, all) can now be used to specify
    bolometer lists for REMSKY.

  - The size of the output map can now be specified in REBIN

  - The filenaming system used by SCUQUICK  has been modified slightly so
    that it conforms with the SCUBA_SUFFIX=long mode. SCUQUICK now also
    recognizes SKYDIP data.


1 ADD_DBM
Generate a dual beam map from a single beam map

Usage:

   add_dbm in chop pa out

Description:

     Create a chopped image from a single beam input map.
     Can be used to create a dual-beam (e.g.\ a simlated
     scan map image) or a triple-beam map (e.g.\ a simulated
     jiggle map image).

     For dual-beam it simply finds the signal detected at each pixel
     by looking at the difference between the pixels nearest to each
     chop beam. This calculates a middle beam response. (ie the response
     at each pixel is the difference between the L and the R
     beams).

     For the triple-beam response the signal is the difference
     between the middle pixel and half the values measured
     in the negative beams. Set NBEAMS to 3 to use triple-beam
     response.

     This task can be used to generate test data for REMDBM.

2 Parameters
For information on individual parameters, select from the list below:
3 CHOP
CHOP = REAL (Read)
   Chop throw in pixels of the input image. There is no default.
   The range of this parameter should lie between 1 and the
   size of the input image.
3 IN
IN = NDF (Read)
   Input single beam image
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Options are QUIET, NORMAL and
   VERBOSE. Default is NORM.
3 NBEAMS = INTEGER (Read)
   When NBEAMS=2 a dual-beam response is calculated. When
   NBEAMS=3 a triple-beam response is calculated.
3 OUT
OUT = NDF (Write)
   Output Dual beam image. Default output name is input name
   + _dbm_int(pa)_int(chop).
3 PA
PA = REAL (Read)
   Position angle of chop throw. Positive is anti-clockwise starting
   from North. The angle should be specified in degrees.
3 PIXSIZE
PIXSIZE = REAL (Read)
   Pixel size in arcseconds. This is required for compatibility
   with REMDBM (since the CHOP_THR FITS keyword has to be in
   arcseconds rather than pixels and REMDBM requires SCUPIXSZ
   FITS keyword). A null value will be treated as 1 arcsec.
   Default is to use the value of SCUPIXSZ from the FITS header
   (if present).
2 Examples
add_dbm gaussian 0 30 dbm_out
   Generate a dual beam image from the single beam 'gaussian'
   input NDF using a 30 pixel chop at 0 degrees. Write the
   resulting image to dbm_out.sdf.

add_dbm image 90 45 3bm_out nbeams=3
   Generate a triple-beam image with throw 45 and position angle
   90 degrees.
2 Notes
- The output images are compatible with REMDBM.

- All extensions and AST/WCS information are propogated to the
  output image.

- A variance array is created if present in the input image.

- If a quality array is present in the input image it is used
  to generate a bad pixel mask in the output image and is removed.

- Bad pixels in the input image are treated as zeroes for the
  dual beam calculation.

2 Related_Applications
   SURF: REMDBM
2 Authors
Tim Jenness (t.jenness@jach.hawaii.edu)

1 BOLREBIN
Generate a separate regridded image for each bolometer.

Usage:

   bolrebin ref

Description:

   This routine rebins the demodulated data from SCUBA MAP observations
   onto a rectangular mesh by a variety of methods.
   Currently convolution by weighting functions,  spline interpolation 
   and median are supported.

   - Weighting functions:
     Currently linear, Bessel and Gaussian weighting functions are supported.
     The width of the Bessel function is such that it should preserve all
     spatial information obtained by the telescope at the wavelength of
     observation, but suppress higher spatial frequencies. To minimise edge
     effects the Bessel function is truncated at a radius of 10 half-widths
     from the centre, and apodized over its outer third by a cosine
     function. Viewed in frequency space the method consists of Fourier
     transforming the input dataset(s), multiplying the transform by a
     cylindrical top-hat (the F.T. of the Bessel function),
     then transforming back into image space.
     A linear weighting function is also available which works out
     to one half-width - this has the advantage that it is much faster to
     process and is much less susceptible to edge effects.

     The Gaussian weighting function is probably the best compromise
     between the Bessel (slow and prone to edge effects) and Linear (fast
     but the point spread function is non-trivial for modeling).

     The radius and size of `footprint' for the weighting functions
     are configurable using the WTFNRAD and SCALE parameters.

   - Splines:
     Additionally, spline interpolation and smoothing routines are also
     available. Note that the spline routines work on each integration
     in turn, whereas the weighting function routines work on all the input
     data in one go. At present the spline routines are experimental and
     comments are welcomed.

    - Median:

      A regridding option derived from DESPIKE is available. This
      method simply puts all data points in an output grid and calculates
      the median of each output cell. Small pixel scales require large
      datasets (since not all cells in a 1 arcsecond grid will contain
      data points) although the Kappa commands FILLBAD and GLITCH
      can be used to smooth over bad pixels.

  A separate map will be made of each bolometer. The output file will
   contain an NDF for each bolometer.

2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = CHAR (Read)
   The name of the input file to be rebinned. This parameter is requested
   repeatedly until a NULL value (!) is supplied. LOOP must be TRUE.
   IN can include a SCUBA section.
   Like the REF parameter this parameter accepts a text file.
3 LAT_OUT
LAT_OUT = CHAR (Read)
   The latitude of the output map centre. The supplied default value
   is that of the map centre of the first map.
3 LONG_OUT
LONG_OUT = CHAR (Read)
   The longitude of the output map centre. The supplied default value
   is that of the map centre of the first map.
3 LOOP
LOOP = LOGICAL (Read)
   Task will ask for multiple input files if true. Only REF is read
   if noloop.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Options are QUIET, NORMAL and VERBOSE.
   Default is NORM.
3 OUT
OUT = NDF (Write)
   This is the name of the HDS container file that will contain the
   rebinned images. The map for each bolometer is stored in an NDF
   inside this NDF container. The maps can be accessed as 
   `out.name' where `name' is the bolometer name (e.g. H7 or G1 etc.).
3 OUT_COORDS
OUT_COORDS = CHAR (Read)
   The coordinate system of the output map. Available coordinate
   systems are:

   - AZ:  Azimuth/elevation offsets

   - NA:  Nasmyth offsets

   - PL:  RA/Dec Offsets from moving centre (e.g. Planets)

   - RB:  RA/Dec (B1950)

   - RJ:  RA/Dec (J2000)

   - RD:  RA/Dec (epoch of observation)

   - GA:  Galactic coordinates (J2000)

   For RD current epoch is taken from the first input file.
3 OUT_OBJECT
OUT_OBJECT = CHAR (Read)
   The name of the object (ie the NDF title).
3 PIXSIZE_OUT
PIXSIZE_OUT = REAL (Read)
   Size of pixels in the output map. Units are arcsec.
3 REBIN_METHOD
REBIN_METHOD = CHAR (Read)
   The rebin method to be used. A number of regridding methods are
   available:

   - LINEAR:  Linear weighting function

   - GAUSSIAN: Gaussian weighting function

   - BESSEL:  Bessel weighting function

   - SPLINE1: Interpolating spline (PDA_IDBVIP)

   - SPLINE2: Smoothing spline (PDA_SURFIT)

   - SPLINE3: Interpolating spline (PDA_IDSFFT)

   - MEDIAN:  Median regridding

   Please refer to the PDA documentation (SUN/194) for more information
   on the spline fitting algorithms.
3 REF
REF = CHAR (Read)
   The name of the first NDF to be rebinned. The name may also be the
   name of an ASCII text file containing NDF and parameter values.
   See the notes. REF can include a SCUBA section.
3 REFPIX
REFPIX ( 2 ) = INTEGER (Read)
   The coordinate of the reference pixel in the output data
   array. This corresponds to the pixel associated with the
   specified RA/Dec centre. Default is to use the middle pixel
   if a size is specified or the optimal pixel if the default
   size is used (see the SIZE parameter).
3 SCALE
SCALE = REAL (Read)
  Radius of one scale size in arcsec. This effectively governs the
  size of the weighting function. For LINEAR one scale size corresponds
  to the zero of the cone, for BESSEL it is the first zero of the
  Bessel function (PI) and for Gaussian it is the half-width
  half maximum (HWHM).
3 SFACTOR
SFACTOR = REAL (Read)
  This is the smoothing factor to use for a SPLINE2 regrid.
  See the PDA_SURFIT documentation for more information.
3 SIZE
SIZE ( 2 ) = INTEGER (Read)
   This array parameter sets the size of the output grid (nx, ny).
   The default values are the minimum dimensions required to display
   the entirety of the mapped area.
3 SHIFT_DX
SHIFT_DX = REAL (Read)
   The pointing shift (in X) to be applied that would bring the
   maps in line. This is a shift in the output coordinate frame.
3 SHIFT_DY
SHIFT_DY = REAL (Read)
   The pointing shift (in Y) to be applied that would bring the
   maps in line. This is a shift in the output coordinate frame.
3 TIMES
TIMES = LOGICAL (Read)
   Store an extra NDF in the output map containing the 2-D histogram
   of the data. This can be used to make an estimate of the actual
   number of samples responsible for each point in the output grid.
   Note that, in general, the number of pixels in the output grid
   exceeds the number of independent beams in the image.
   The data can be accessed as OUT.more.reds.times. Default is FALSE.
3 TRIM
TRIM = INTEGER (Read)
   This parameter determines the amount of good data that should
   be trimmed from the final image to correct for edge effects.
   The supplied value should be in arcseconds. All pixels closer
   to a bad pixel than this distance will be set to bad in the
   output image. Default is 0.0.
3 GUARD
GUARD = LOGICAL (Read)
   Controls whether the bolometer guard ring should be used during
   the regridding process. The guard ring enforces zero flux at the
   edge of the regridded image. Should be turned off if flux is present
   at the edge. Default is to use the guard ring for LINEAR, BESSEL
   and GAUSSIAN rebin modes.
3 WEIGHT
WEIGHT = REAL (Read)
   The relative weight that should be assigned to each dataset.
3 WEIGHTS
WEIGHTS = LOGICAL (Read)
   This parameter governs whether the convolution weights array will be
   stored in the output NDF. The default is FALSE. (ie do not store the
   weights array).
3 WTFNRAD = INTEGER (Read)
   Size of the weighting function in scale sizes. This parameter
   is irrelevant for LINEAR regridding. For Gaussian the default
   is 3 (i.e. a diameter of 3 FWHM for the footprint), and for
   Bessel it is 10. The smaller the weighting function is (a
   combination of WTFNRAD and SCALE) the faster the regridding goes.
2 Examples
bolrebin rebin_method=LINEAR out_coords=RJ
   Rebin the maps with LINEAR weighting function in J2000 RA/Dec
   coordinates. You will be asked for input datasets until a null
   value is given.

bolrebin rebin_method=BESSEL out=map
   Rebin the maps with Bessel weighting function. Each bolometer is
   rebinned separately and placed in an NDF in the output container file
   map.sdf. Bolometer H7 can be accessed by displaying map.h7.

bolrebin noloop REF=test.bat
   Rebin each bolometer using the data specified in the file test.bat.
2 Notes
For each file name that is entered, values for the parameters
WEIGHT, SHIFT_DX and SHIFT_DY are requested.

- The application can read in up to 256 separate input datasets.

- The output map will be large enough to include all data points.

- Spline regridding may have problems with SCAN/MAP (since integrations
contain lots of overlapping data points).

- SCUBA sections can be given along with any input NDF

- The relative weights associated with each point in the output map
are stored in a WEIGHTS NDF in the REDS extension of the output
data. For spline rebinning each point is equivalent to the number
of integrations added into the final data point. For weight function
regridding the situation is more complicated.

- Bolometer weights will be used if a BOLWT extension is found
         in the input data file (usually set with SETBOLWT).

- Astrometry information is stored in the WCS component and not 
  the FITS extension.


2 ASCII_input_files
   The REF and IN parameters accept ASCII text files as input. These
   text files may contain comments (signified by a #), NDF names,
   values for the parameters WEIGHT, SHIFT_DX and SHIFT_DY,
   and names of other ASCII files. There is one data file per line.
   An example file is:

       file1{b5}   1.0   0.5   0.0  # Read bolometer 5 from file1.sdf
       file2                        # Read file 2 but you will still be
                                    # prompted fro WEIGHT, and shifts.
       file3{i3}-  1.0   0.0   0.0  # Use everything except int 3
       test.bat                     # Read in another text file

   Note that the parameters are position dependent and are not necessary.
   Missing parameters are requested. This means it is not possible to
   specify SHIFT_DX (position 3) without specifying the WEIGHT.
   If the file has the .txt extension the NDF system will attempt to
   convert it to NDF format before processing -- this is probably not
   what you want.
2 Related_Applications
   SURF: REBIN, INTREBIN, EXTRACT_DATA

2 Authors
JFL: John Lightfoot (jfl@roe.ac.uk)

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)


1 CALCSKY
Calculate sky contribution from median image

Usage:

   calcsky ref

Description:

   This routine calculates the sky contribution by attempting
   to remove the source from the input data stream. The source
   signal can either be calculated by this routine or by reading
   in a model of the source from a file.

   When calculating the source structure internally a similar
   method to that used by DESPIKE is employed. The input data
   are placed into bins of size one quarter beam-width. The median
   of each bin is calculated and this is treated as the source
   model (cf. REBIN_METHOD=MEDIAN in REBIN).

   Once the source model is available, it is removed from
   all of the input data. The source-removed data are then analysed
   with the sky emission derived from the mean of the signal across
   the array for all the sample times.

   Since the sky signal is expected to vary on time-scales of the
   order of one second, an option is included for smoothing the
   sky signal. This is especially useful for scan map data where
   samples are taken at 7.8~Hz.
2 Parameters
For information on individual parameters, select from the list below:
3 BOXSZ
BOXSZ = INTEGER (Given)
   Size of smoothing box in seconds. This is used to smooth
   the time series. Default is 2.0 seconds.
3 IN
IN = CHAR (Read)
   The name of the input file to be processed. This parameter is
   requested repeatedly until a NULL value (!) is supplied.
   LOOP must be TRUE. IN can include a SCUBA section.
   Like the REF parameter this parameter accepts a text file.
3 LOOP
LOOP = LOGICAL (Read)
   Task will ask for multiple input files if true. Only REF is read
   if noloop.
3 MODEL
MODEL = NDF (Read)
   NDF containing the model of the source. The astrometry
   is read from this file. The model must have been generated
   by SURF since it relies on the presence of certain FITS keywords.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Allowed values are QUIET, NORM and
   VERBOSE. Default is NORM.
3 NOSRC
NOSRC = NDF (Write)
   File to store source removed data. This can be used to
   check the source removal. Note that this output file can
   not be used directly by SURF for further processing since
   the header is incomplete. No file is written by default.
3 OUT_COORDS
OUT_COORDS = CHAR (Read)
   The coordinate system to be used for the model determination.
   Available coordinate systems are:

   - AZ:  Azimuth/elevation offsets

   - NA:  Nasmyth offsets

   - PL:  RA/Dec Offsets from moving centre (e.g. Planets)

   - RB:  RA/Dec (B1950)

   - RJ:  RA/Dec (J2000)

   - RD:  RA/Dec (epoch of observation)

   - GA:  Galactic coordinates (J2000)

   For RD current epoch is taken from the first input file.
3 REF
REF = CHAR (Given)
   The name of the first NDF to be processed. The name may also be the
   name of an ASCII text file containing NDF and parameter values.
   REF can include a SCUBA section. See REBIN for more information
   on the format of the ASCII input file.
3 SHIFT_DX
SHIFT_DX = REAL (Read)
   The pointing shift (in X) to be applied that would bring the
   maps in line. This is a shift in the output coordinate frame.
3 SHIFT_DY
SHIFT_DY = REAL (Read)
   The pointing shift (in Y) to be applied that would bring the
   maps in line. This is a shift in the output coordinate frame.
3 WEIGHT
WEIGHT = REAL (Read)
   This parameter does nothing in CALCSKY. It must be present
   when using text file input. Any value is allowed.
2 Examples
calcsky test_rlb model=! \\
   Calculate sky for test_rlb.sdf. Only read in one file and
   don't use an external source model.

calcsky list.inp model=m82 noloop\\
   Read in the files specified in list.inp and use m82.sdf
   as a model of the source.

calcsky file nosrc=nosrc boxsz=10.0 \\
   Calculate sky for file.sdf. Store the source subtracted image
   in nosrc.sdf. Use a smoothing size of 10 seconds.
2 Notes
- The model itself is only an approximation
  to the data (since the data points can fall anywhere within
  a given cell) so some source signal will remain after source
  subtraction.

- If a model is supplied externally (via MODEL parameter) the
  cell size of the model is used for the source subtraction.

- The sky signal is stored in an NDF extension (.MORE.REDS.SKY).
  The file must be processed by REMSKY to actually remove the
  sky contribution.
2 Related_Applications
   SURF: REMSKY

2 Authors

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)


1 CHANGE_DATA
Set SCUBA data to any value.

Usage:

   change_data ndf{spec1}{spec2}{specn} value=??

Description:

   This application is used to set SCUBA data to any value by using
   SCUBA sections to specify a subset of the full data. Data, Variance
   and Quality arrays can be modified.

     Once the data specification has been decoded the application will
   read from parameter VALUE the value of the data that should be used.
   All data specified by the section (or by the inverse of this section
   if specified) will be set to this value.
2 Parameters
For information on individual parameters, select from the list below:
3 COMP
COMP = LITERAL (Read)
   The name of the NDF array component which should be changed:
   "Data","Error", "Quality" or "Variance" (where "Error" is the
   alternative to "Variance" and causes the square root of the
   variance values to be taken). The default component is always DATA.
   If "Quality" is specified, then the quality values are treated
   as numerical values (in the range 0 to 255).
3 IN
IN = CHAR (Read)
   Name of data set and the specification of the data to be changed.
   Usually of the form `ndf{spec1}{spec2}' where ndf is the filename
   and spec1...n are the section specifications.
   The section can be read from the SECTION parameter if the
   SCUBA section is omitted.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 OUT
OUT = NDF (Write)
   Name of the NDF that stores the modified data.
3 SECTION
SECTION() = CHAR (Read)
   This parameter can be used to specify SCUBA sections.
   Curly brackets must still be given. Since this is an array
   parameter square brackets must be used to specify more than
   one component:

         SECTION > [ {b3} , {i2} ]

   would supply two SECTIONS of {b3} and {i2}. Only {b3} will
   be used if the square brackets are not used. Care must also
   be taken when using commas in SCUBA sections - the parameter
   system will split multiple entries on commas unless the entire
   section is quoted:

         SECTION > [ "{b3,5}" , {i2} ]

   If necessary the negation character should come after a
   section (ie after the closing curly bracket) and that
   negation applies to the combined section and not just the string
   containing the negation character:

       SECTION > [ {b3}-, {i2} ]

   implies that the section consists of everything except bolometer 3
   and integration 2.

   This parameter is only used when no SCUBA section was specified
   via the IN parameter.
3 VALUE
VALUE = LITERAL (Read)
   Value to which all selected data points should be set. A value
   of `bad' will set the data point to VAL__BAD (Starlink bad data
   value). For COMP=Quality only numbers 0 to 255 are allowed -
   numbers outside this range are assumed to be bad values.
2 Examples
change_data 'ndf{b2}' value=bad out=changed
   Copy all data in ndf.sdf to changed.sdf and change all data
   in bolometer 2 to bad.

change_data 'ndf{}' comp=variance value=0.0001
   Copy ndf.sdf to the output file (asked for explicitly) and
   set all variance values to 0.0001.

change_data test  section='[{b47},{i3}]' value=1.02
   Select data from bolometer 47 and integration 3 in test.sdf and set
   this to a value of 1.02. This method of selecting a section is not
   recommended given the complication using commas and square
   brackets.

change_data test2 section='["{b2,5}", {i2}-]' value=0.2 comp=err
   Select everything except integration 2 and bolometers 2 and 5.
   Set the error for this section to 0.2

change_data 'phot{i2:6}{b3}' comp=quality value=8
   Explicitly set the quality array to 8 for integrations 2 through
   6 and bolometer 3. The task CHANGE_QUALITY is recommended in this
   case since then only bit 3 is affected.

change_data 'map{i2,5}-' value=0.0
   Set everything except integrations 2 and 5 to zero.
2 Notes
- This software sets the actual value in the specified component
  and so, unlike CHANGE_QUALITY, is not reversible. For this reason
  a new output file is created.

- This task does not attempt to create a component if the specified
  component is missing. A Variance array can be created using the
  KAPPA task SETVAR if necessary.

- The SECTION parameter is not used if a SCUBA section was given
  via the IN parameter.
2 Related_Application
   SURF: CHANGE_QUALITY, REBIN, SCUPHOT
2 Authors
JFL:  J.Lightfoot (jfl@roe.ac.uk)

TIMJ: T.Jenness   (t.jenness@jach.hawaii.edu)

1 CHANGE_FLAT
Change the flatfield in a SCUBA datafile

Usage:

   change_flat in new_flat

Description:

   The flatfield information is stored inside each demodulated
   data file and this task can be used to change the flatfield that is
   stored internally. The new flatfield is read from a text file.
2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = NDF (Read)
   Name of NDF to change.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level (Default is NORM).
3 NEW_FLAT
NEW_FLAT = CHAR (Read)
   Name of the new flatfield file.
2 Examples
change_flat test newflat.dat
   This will change the flatfield stored in test.sdf to that stored
   in newflat.dat.
2 Related_Application
   SURF: FLATFIELD, SCUQUICK

2 Authors
JFL: John Lightfoot (jfl@roe.ac.uk)

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)


1 CHANGE_NACENTRE
Shift the Nasmyth centre of the array

Usage:

   change_nacentre [-h | -v ] infile dx dy

Description:

   This routine shifts the position of the Nasmyth centre of a
   SCUBA array. It can be used to take out the small difference
   between the centres of the LONG and SHORT wave arrays.
   Should be run after EXTINCTION.
2 Parameters
For information on individual parameters, select from the list below:
3 -h
-h
   Return a help message only.
3 -v
-v
   Return the version number of scunoise
3 infile
infile
   Input file name. The file is modified in place.
3 dx
dx
   Shift in Nasmyth X (du3) direction
3 dy
dy
   Shift in Nasmyth Y (du4) direction
2 Examples
change_nacentre
   Will prompt for input file name and shift

change_nacentre file 5 -3
   Will move the array centre of file.sdf by (5,-3) arcsec.
2 Notes
This command can only be reversed by running change_nacentre
with minus the previous X,Y shift.
EXTINCTION must have been run on the input file (otherwise the
file will contain more than 1 array) -- this is not checked
for explicitly.
2 Related_Applications
   SURF: REBIN

2 Authors

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)


1 CHANGE_POINTING
Change the pointing corrections to map data.

Usage:

   change_pointing in change_point

Description:

   This application is used to change the pointing corrections to map
   data.

      If the observing mode of the input datafile is `MAP' the
   application will search for pointing corrections in the file and, if it
   finds any, report them. You will be asked if you wish to change the
   pointing correction data in the file. `No' will result in the data
   remaining unaltered, `yes' will then ask you for the time of the
   pointing offset (LST in hh mm ss.ss format) and the azimuth and
   elevation correction (in arcseconds) that would have to be added to
   the observation position to correct the pointing at that time. If
   you supply no data the existing pointing corrections will be removed.
   Corrections will be requested until a negative number is given
   for the local sidereal time.
2 Parameters
For information on individual parameters, select from the list below:
3 CHANGE_POINT
CHANGE_POINT = CHAR (Read)
   If true you will be prompted for pointing corrections otherwise
   the program will exit after listing the current pointing
   corrections.
3 IN
IN = NDF (Read)
   Name of NDF to change.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. (Default is NORM)
3 POINT_DAZ
POINT_DAZ = REAL (Read)
   The Azimuth pointing correction (arcsec).
3 POINT_DEL
POINT_DEL = REAL (Read)
   The elevation pointing correction (arcsec).
3 POINT_LST
POINT_LST = CHAR (Read)
   The sidereal time of the pointing correction. Pointing corrections
   are asked for repeatedly until a NULL (!) or negative value are
   given for POINT_LST.
2 Notes
- Pointing corrections are erased when new items are written.

- Pointing corrections can be removed completely by issuing
  null (!) in response to POINT_LST when first prompted.
  (ie pointing corrections are removed if no corrections are given)

- Use ABORT (!!) if you don't want to change the pointing corrections
  once you have started entering values.

- Pointing corrections must be given in LST order.
2 Related_Application
   SURF: REBIN
2 Authors
JFL:  J.Lightfoot (jfl@roe.ac.uk)

TIMJ: T.Jenness   (t.jenness@jach.hawaii.edu)

1 CHANGE_QUALITY
Set SCUBA data quality bad or good.

Usage:

   change_quality ndf{spec1}{specn} bad_quality

Description:

   This application is used to set SCUBA data quality bad or good by
   using SCUBA sections to specify a subset of the full data.

     Once the data specification has been decoded the application will
   read from parameter BAD_QUALITY whether quality should be set good
   or bad. A `yes' answer will mark the area bad, a `no' answer will
   mark the area good (an area will only be good if no other QUALITY
   bits are set - CHANGE_QUALITY only uses QUALITY bit 3). The section
   can be inverted by using the negation character at the end of the
   section.
2 Parameters
For information on individual parameters, select from the list below:
3 BAD_QUALITY
BAD_QUALITY = LOGICAL (Read)
   Set quality to BAD. Answering this question with a `yes' will
   mean that the selected data will be set to BAD. `no'
   will set them to good.
3 IN
IN = CHAR (Read)
   Name of data set and the specification of the data to be changed.
   Usually of the form `ndf{spec1}{spec2}' where ndf is the filename
   and spec1...n are the section specifications.
   The section can be read from the SECTION parameter if the
   SCUBA section is omitted.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 SECTION
SECTION() = CHAR (Read)
   This array parameter can be used to specify SCUBA sections.
   Curly brackets must still be given. Since this is an array
   parameter square brackets must be used to specify more than
   one component:

       SECTION > [ {b3} , {i2} ]

   would supply two SECTIONS of {b3} and {i2}. Only {b3} will
   be used if the square brackets are not used. Care must also
   be taken when using commas in SCUBA sections - the parameter
   system will split multiple entries on commas unless the entire
   section is quoted:

       SECTION > [ "{b3,5}" , {i2} ]

   If necessary the negation character should come after a
   section (ie after the closing curly bracket) and that
   negation applies to the combined section and not just the string
   containing the negation character:

       SECTION > [ {b3}-, {i2} ]

   implies that the section consists of everything except bolometer 3
   and integration 2.

   This parameter is only used when no SCUBA section was specified
   via the IN parameter.
2 Examples
change_quality 'ndf{}' BAD_QUALITY=false
   Select the entire array and unset bit 3.

change_quality 'ndf{b2}' BAD_QUALITY
   Select the second bolometer and mark it bad.

change_quality 'ndf{b2;i3}-' BAD_QUALITY
   Select the third integration of bolometer two but set all
   other data points bad by inverting the section.

change_quality 'ndf{b16}{i2}' BAD_QUALITY
   Select all of bolometer 16 and the whole of integration 2.

change_quality 'ndf{e5,16:18}' MSG_FILTER=quiet
   Select exposure 5 and 16 through 18. Messaging is turned off.

change_quality ndf
   Since no section has been specified, the user will be prompted
   for a section later.

change_quality test SECTION='["{b41,52}",{i3}]' BAD_QUALITY
   Set bolometers 41 and 52 as well as integration 3 to bad quality.
   Use of SECTION here is not recommended given the complication
   when using commas and square brackets.

change_quality test SECTION='[{b2;i2}-]' BAD_QUALITY
   Set everything bad except bolometer 2 and integration 2.
2 Notes
Samples are marked bad by setting bit 3 of the quality array.
The effects of CHANGE_QUALITY  can be removed by changing the
value of the bad bit mask (with the KAPPA task SETBB or by running
CHANGE_QUALITY on the entire array [section is {} for entire array]
but with BAD_QUALITY=false) so that bit 3 (decimal value of 8) is
no longer used as a masking bit.
2 Related_Application
   SURF: CHANGE_DATA, REBIN, SCUPHOT;
   KAPPA: SETBB
2 Authors
JFL:  J.Lightfoot (jfl@roe.ac.uk)

TIMJ: T.Jenness   (t.jenness@jach.hawaii.edu)

1 DESPIKE
Despike data by position

Description:
      This routine despikes demodulated data by comparing points
      that lie in the same region of sky. Each point is placed in the
      output grid (similar to REBIN but without the smoothing) depending
      on its position. The points in each cell are then compared with each
      other and spikes are detected if any points lie more than NSIGMA
      from the mean.

      Optionally, a plot is provided showing the points in each bin
      along with the clipping level to
      be used for despiking. In order to provide a 2-dimensional plot
      of 3-dimensional data the grid is unwrapped such that all the cells
      are plotted in one axis. The unwrapping order is governed by the
      DMODE parameter.

2 Parameters
For information on individual parameters, select from the list below:
3 DEFOUT
DEFOUT = LOGICAL (Read)
   Determines whether output files should be written automatically
   (using the default output names) or whether the user should
   be prompted. Default is FALSE.
3 DEVICE
DEVICE = DEVICE (Read)
   The device on which to display the binned data. Can be null (!)
3 DMODE
DMODE = CHAR (Given)
   For display purposes the points in each cell are plotted
   sequentially on a 1-dimensional plot. This parameter governs
   the way in which the cells are extracted from the grid.
   Allowed values are:

     o SPIRAL: A Spiral outwards from the reference pixel

     o XLINEAR: unfold each X strip in turn for each Y    

     o YLINEAR:  unfold each Y strip in turn for each X    

     o DIAG1:    diagonal strips starting at position (1,1)
 
     o DIAG2:   diagonal strips starting at positions (nx,1)

   This parameter is also required if SMODE is not equal to
   'NONE' since the smoothing depends on the order that the points
   are extracted from the grid.
3 IN
IN = CHAR (Read)
   The name of the input file to be rebinned. This parameter is requested
   repeatedly until a NULL value (!) is supplied. LOOP must be TRUE.
   IN can include a SCUBA section.
   Like the REF parameter this parameter accepts a text file.
3 LOOP
LOOP = LOGICAL (Read)
   Task will ask for multiple input files if true. Only REF is read
   if noloop.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM. In verbose mode the positions of
   detected spikes are reported.
3 NSIGMA = REAL (Read)
   The sigma clipping level used for despiking each cell.
3 SMODE = CHAR (Given)
   This parameter controls the mode used for smoothing of the clipping
   envelope. If smoothing is selected, the extraction mode (DMODE) is used
   to determine the pixels that are adjacent to each other.

   Allowed modes are:

       o NONE: No smoothing

       o HANN: Hanning smoothing 

3 OUT
OUT = NDF (Write)
   This is the name of the NDF that will contain the despiked data. There
   will be one prompt per input filename (assuming spikes were detected).
3 OUT_COORDS
OUT_COORDS = CHAR (Read)
   The coordinate system of the output map. Available coordinate
   systems are:

   - AZ:  Azimuth/elevation offsets

   - NA:  Nasmyth offsets

   - PL:  RA/Dec Offsets from moving centre (e.g. Planets)

   - RB:  RA/Dec (B1950)

   - RJ:  RA/Dec (J2000)

   - RD:  RA/Dec (epoch of observation)

   - GA:  Galactic coordinates (J2000)
3 REF
REF = CHAR (Read)
   The name of the first NDF to be rebinned. The name may also be the
   name of an ASCII text file containing NDF and parameter values.
   See the notes. REF can include a SCUBA section.
3 SHIFT_DX
SHIFT_DX = REAL (Read)
   The pointing shift (in X) to be applied that would bring the
   maps in line. This is a shift in the output coordinate frame.
3 SHIFT_DY
SHIFT_DY = REAL (Read)
   The pointing shift (in Y) to be applied that would bring the
   maps in line. This is a shift in the output coordinate frame.
3 WEIGHT
WEIGHT = REAL (Read)
   The relative weight that should be assigned to each dataset.
3 XRANGE
XRANGE = INTEGER (Read)
   The X-range of the plot. This parameter loops indefinitely until a
   null response is provided (!)
2 Examples

despike out_coords=RJ smode=none device=!
   Despike the maps by placing points onto an RJ grid.
   Do not plot the data points before despiking and do not smooth
   the clipping envelope.
   You will be asked for input datasets until a null
   value is given.

despike device=! out_coords=RB smode=hann dmode=sp nsigma=4.0
   Despike on a RB grid with Hanning smoothing. Use a 4.0 sigma clip 
   and do not display. Note that the smoothing uses the spiral mode
   for grid unwinding.

despike device=xwindows dmode=x nsigma=3.0
   Unwind with XLINEAR mode and display the data before despiking.

despike noloop accept ref=test.bat
   Despike the files specified in test.bat using an RJ grid.

2 Notes
For each file name that is entered, values for the parameters
SELECT_INTS, WEIGHT, SHIFT_DX and SHIFT_DY are requested.

- The application can read in up to 256 separate input datasets.

- No data is returned if the DATA or positions are bad.
  Data is still returned if Variance is bad.

2 ASCII_input_files
   The REF and IN parameters accept ASCII text files as input. These
   text files may contain comments (signified by a #), NDF names,
   values for the parameters WEIGHT, SHIFT_DX and SHIFT_DY,
   and names of other ASCII files. There is one data file per line.
   An example file is:

       file1{b5}   1.0   0.5   0.0  # Read bolometer 5 from file1.sdf
       file2                        # Read file 2 but you will still be
                                    # prompted for WEIGHT, and shifts.
       file3{i3}-  1.0   0.0   0.0  # Use everything except int 3
       test.bat                     # Read in another text file

   Note that the parameters are position dependent and are not necessary.
   Missing parameters are requested. This means it is not possible to
   specify SHIFT_DX (position 3) without specifying the WEIGHT.
   Also note that SCUBA sections can be specified with any input NDF.
2 Related_Applications
   SURF: DESPIKE2, SCUCLIP, SIGCLIP, CHANGE_QUALITY, DSPBOL
2 Authors
TIMJ: Tim Jenness (JACH)


1 DESPIKE2
Remove spikes from SCAN/MAP observations

Usage:

   restore in out nsigma

Description:

   This routine removes spikes from SCAN/MAP observations.
   The scan map differential despiking algorithm uses 2 criteria
   to decide which points are spikes.

   First, for each bolometer used a pass is made through each
   scan calculating for each point:-

     diff(i) = point(i) - (point(i-1) + point(i+1))

                          -------------------------
                                     2.0

   Values of 'diff' for the first and last points in the scan are
   calculated in a similar way but subtracting the mean of points
   2 and 3 and points n-1 and n-2 respectively.

   The mean and standard deviation of 'diff' are calculated by
   co-adding the 10 points at each end of the scan where,
   hopefully, there is no source emission. Spikes in these
   regions are handled by removing points from the co-add that lie
   further than 3 sigma from the mean, then redoing the
   calculation recursively until no further points need be
   removed.

   The first criterion for a spike is that it's 'diff' value
   should be further from the mean of 'diff' by NSIGMA times the
   sigma derived from the endpoints.

   The problem with this simple approach is that bright sources
   in the scan themselves lead to excursions in 'diff' that can
   be wrongly identified as spikes. To prevent this happening a
   second criterion is used. In this the scan values are
   convolved with a 3 sample wide box so that each 'box' point is
   the average of the point itself and the points on either side of
   it. 'Box' is expected to increase faster for real sources than
   for spikes because in them the increase will be spread over
   all 3 averaged points rather than just 1.

   The second criterion for a spike is met, therefore, if a
   point's 'diff' is further from the 'diff' mean than the value
   of 'box' at that point.

   Fixed-up values for points that have identified as spikes are
   calculated by interpolating between the closest healthy points
   on either side.

   The second spike criterion also means unfortunately that the
   technique is less sensitive to spikes on bright sources than
   elsewhere. In addition, it is still possible to clip bright
   sources if too low a value for NSIGMA is used. It is
   recommended to run despike several times with different values
   of NSIGMA. Begin with NSIGMA=5, look at the result to see how
   effective despiking has been, then repeat the process with
   NSIGMA=4.5, 4.0 etc. until you start to clip source
   information.
2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = NDF (Read)
   The name of the input file containing demodulated SCUBA data.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM. No verbose messages are used.
3 NSIGMA
NSIGMA = REAL (Read)
   Nsigma from mean at which 'spikes' begin.
3 OUT
OUT = NDF (Write)
   The name of the output file to contain the processed data.
   A default output name is suggested that is derived from the
   input.
2 Examples
restore o37 o37_des 5.0
   Despike o37.sdf at 5.0 sigma.

restore o37 \
   Despike using the default sigma level and writing to the
   default output file.
2 Notes
Care must be taken when despiking bright sources.
2 Related_Applications
   SURF: DESPIKE, SCUCLIP, SIGCLIP, RESTORE
2 Authors
JFL: John Lightfoot (jfl@roe.ac.uk)

1 DSPBOL

Interactive despiking and data inspection (requires Kappa)

See SCUPLOT for more information.

1 EXTINCTION
Remove the effect of atmospheric extinction from a SCUBA observation

Usage:

   extinction in sub_instrument first_tau first_lst
              second_tau second_lst out

Description:

   This application extracts from a demodulated-data file data for a
   specified SCUBA sub-instrument and corrects it for the effect of
   atmospheric extinction. The airmass at which each bolometer measurement
   was made is calculated, then multiplied by the zenith sky extinction at
   the time of the measurement to give the extinction optical depth along
   the line of sight. The data point in question is then multiplied by the
   exponential of the optical depth to give the value that would have been
   measured in the absence of the atmosphere.

     The zenith optical depth is assumed to vary linearly with time between
   the values input in parameters FIRST_TAU and LAST_TAU. If the measurement
   was taken at a time outside the range covered by FIRST_TAU and LAST_TAU
   then the value closest in time will be used.
2 Parameters
For information on individual parameters, select from the list below:
3 FIRST_LST
FIRST_LST = CHAR (Read)
   The local sidereal time at which FIRST_TAU was
   the zenith sky opacity, in hh mm ss.ss format.
3 FIRST_TAU
FIRST_TAU = REAL (Read)
   The zenith sky opacity before the observation. The default value is the
   zenith tau value accepted by the on-line system before the observation.
3 IN
IN = NDF (Read)
   The name of the input file containing demodulated SCUBA data.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 OUT
OUT = NDF (Write)
   The name of the output file to contain the
   extinction corrected data for the specified
   sub-instrument.
3 SECOND_LST
SECOND_LST = CHAR (Read)
   The local sidereal time at which SECOND_TAU was
   the zenith sky opacity, in hh mm ss.ss format. The default value is
   that of FIRST_LST. If this value is less than FIRST_LST it is assumed you
   are referring to the following day.
3 SECOND_TAU
SECOND_TAU = REAL (Read)
   The zenith sky opacity after the observation. The default value is that
   of FIRST_TAU.
3 SUB_INSTRUMENT
SUB_INSTRUMENT = CHAR (Read)
   The name of the sub-instrument whose data are to
   be selected from the input file and extinction
   corrected. Permitted values are SHORT, LONG,
   P1100, P1350 and P2000. This parameter is only used if
   more than one sub-instrument is present in the file.
2 Examples
extinction flat long 0.24 '01 00 00' 0.3 '02 00 00' corr
   Process the LONG sub-instrument from flat.sdf using the
   knowledge that the 850 tau (assuming LONG refers to the 850
   micron filter) was 0.24 at 1h LST and 0.3 at 2h LST. The
   output is written to corr.sdf

extinction test short 0.6 0 0.6 0 test2
   Process the SHORT sub-instrument from test.sdf assuming
   a constant tau of 0.6 (since FIRST_LST = SECOND_LST) and write
   the result to test2.sdf
2 Related_Applications
   SURF: SCUQUICK, REBIN, SCUPHOT
2 Authors
JFL: John Lightfoot (jfl@roe.ac.uk)

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)


1 EXTRACT_DATA
Write bolometer positions and values to text file

Description:

   This routine writes the value, variance and position of each
   data point to a ASCII file.
   The interface is the same as that used in the REBIN task.
   The data and variance are in volts. The positions are in radians.
   The data are written out as columns: RA DEC DATA VAR
2 Parameters
For information on individual parameters, select from the list below:
3 FILE
FILE = FILENAME (Write)
   The name of the ASCII file used for storing the data.
3 IN
IN = CHAR (Read)
   The name of the input file to be rebinned. This parameter is requested
   repeatedly until a NULL value (!) is supplied. LOOP must be TRUE.
   IN can include a SCUBA section.
   Like the REF parameter this parameter accepts a text file.
3 LAT_OUT
LAT_OUT = CHAR (Read)
   The latitude of the output map centre. The supplied default value
   is that of the map centre of the first map.
3 LONG_OUT
LONG_OUT = CHAR (Read)
   The longitude of the output map centre. The supplied default value
   is that of the map centre of the first map.
3 LOOP
LOOP = LOGICAL (Read)
   Task will ask for multiple input files if true. Only REF is read
   if noloop.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 OUT_COORDS
OUT_COORDS = CHAR (Read)
   The coordinate system of the output map. Available coordinate
   systems are:

   - AZ:  Azimuth/elevation offsets

   - NA:  Nasmyth offsets

   - PL:  RA/Dec Offsets from moving centre (e.g. Planets)

   - RB:  RA/Dec (B1950)

   - RJ:  RA/Dec (J2000)

   - RD:  RA/Dec (epoch of observation)

   - GA:  Galactic coordinates (J2000)
3 REF
REF = CHAR (Read)
   The name of the first NDF to be rebinned. The name may also be the
   name of an ASCII text file containing NDF and parameter values.
   See the notes. REF can include a SCUBA section.
3 SHIFT_DX
SHIFT_DX = REAL (Read)
   The pointing shift (in X) to be applied that would bring the
   maps in line. This is a shift in the output coordinate frame.
3 SHIFT_DY
SHIFT_DY = REAL (Read)
   The pointing shift (in Y) to be applied that would bring the
   maps in line. This is a shift in the output coordinate frame.
3 WEIGHT
WEIGHT = REAL (Read)
   The relative weight that should be assigned to each dataset.
2 Notes
For each file name that is entered, values for the parameters
SELECT_INTS, WEIGHT, SHIFT_DX and SHIFT_DY are requested.

- The application can read in up to 256 separate input datasets.

- No data is returned if the DATA or positions are bad.
  Data is still returned if Variance is bad.

2 ASCII_input_files
   The REF and IN parameters accept ASCII text files as input. These
   text files may contain comments (signified by a #), NDF names,
   values for the parameters WEIGHT, SHIFT_DX and SHIFT_DY,
   and names of other ASCII files. There is one data file per line.
   An example file is:

       file1{b5}   1.0   0.5   0.0  # Read bolometer 5 from file1.sdf
       file2                        # Read file 2 but you will still be
                                    # prompted for WEIGHT, and shifts.
       file3{i3}-  1.0   0.0   0.0  # Use everything except int 3
       test.bat                     # Read in another text file

   Note that the parameters are position dependent and are not necessary.
   Missing parameters are requested. This means it is not possible to
   specify SHIFT_DX (position 3) without specifying the WEIGHT.
   Also note that SCUBA sections can be specified with any input NDF.
2 Related_Applications
   SURF: REBIN, BOLREBIN, INTREBIN, CHANGE_QUALITY
2 Authors
TIMJ: Tim Jenness (JACH)

1 EXTRACT_FLAT
Extract a flatfield from a SCUBA demodulated data file

Usage:

   extract_flat in file

Description:

   This routine extracts the flatfield information from a SCUBA
   demodulated data file and writes it out in a format suitable for
   use by CHANGE_FLAT.
   The full flatfield is extracted: Bolometer positions and relative
   responsivities.
2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = NDF (Read)
   The name of the NDF containing the demodulated data with the
   required flatfield.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM. There are no verbose messages.
3 FILE
FILE = FILE (Write)
   The name of the ascii file to which the flatfield information
   will be written
2 Examples
extract_flat 19971017_dem_0002 oldflat.dat
   This will read the flatfield from 19971017_dem_0002.sdf and
   write it to a text file
2 Related_Applications
   SURF: CHANGE_FLAT, FLATFIELD
2 Authors

TIMJ: T. Jenness (JACH)

1 FLATFIELD
Flatfield demodulated SCUBA data

Usage:

   flatfield in out

Description:

   This routine flatfields SCUBA demodulated data. The data must previously
   have been processed by REDUCE_SWITCH.
2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = NDF (Read)
   The name of the NDF containing the demodulated data to be
   flatfielded. This file should already have been run through the
   REDUCE_SWITCH application.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 OUT
OUT = NDF (Write)
   The name of the NDF to which the flatfielded data are to be written.
2 Examples
flatfield redsw flat
   This will flatfield the data from redsw.sdf and write it to flat.sdf
2 Related_Applications
   SURF: CHANGE_FLAT, SCUQUICK, EXTRACT_FLAT
2 Authors
JFL: J.Lightfoot (ROE)

TIMJ: T. Jenness (JACH)

1 INTREBIN
Generate a separate regridded image for each integration

Usage:

   intrebin ref

Description:

   This routine rebins the demodulated data from SCUBA MAP observations
   onto a rectangular mesh by a variety of methods.
   Currently convolution by weighting functions,  spline interpolation 
   and median are supported.

   - Weighting functions:
     Currently linear, Gaussian and Bessel weighting functions are supported.
     The width of the Bessel function is such that it should preserve all
     spatial information obtained by the telescope at the wavelength of
     observation, but suppress higher spatial frequencies. To minimise edge
     effects the Bessel function is truncated at a radius of 10 half-widths
     from the centre, and apodized over its outer third by a cosine
     function. Viewed in frequency space the method consists of Fourier
     transforming the input dataset(s), multiplying the transform by a
     cylindrical top-hat (the F.T. of the Bessel function),
     then transforming back into image space.
     A linear weighting function is also available which works out
     to one half-width - this has the advantage that it is much faster to
     process and is much less susceptible to edge effects.

     The Gaussian weighting function is probably the best compromise
     between the Bessel (slow and prone to edge effects) and Linear (fast
     but the point spread function is non-trivial for modeling).

     The radius and size of `footprint' for the weighting functions
     are configurable using the WTFNRAD and SCALE parameters.

   - Splines:
     Additionally, spline interpolation and smoothing routines are also
     available. Note that the spline routines work on each integration
     in turn, whereas the weighting function routines work on all the input
     data in one go. At present the spline routines are experimental and
     comments are welcomed.

   - Median:

      A regridding option derived from DESPIKE is available. This
      method simply puts all data points in an output grid and calculates
      the median of each output cell. Small pixel scales require large
      datasets (since not all cells in a 1 arcsecond grid will contain
      data points) although the Kappa commands FILLBAD and GLITCH
      can be used to smooth over bad pixels.

   A separate map will be made of each integration. The output file
   will contain an NDF for each integration.

2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = CHAR (Read)
   The name of the input file to be rebinned. This parameter is requested
   repeatedly until a NULL value (!) is supplied. LOOP must be TRUE.
   IN can include a SCUBA section.
   Like the REF parameter this parameter accepts a text file.
3 LAT_OUT
LAT_OUT = CHAR (Read)
   The latitude of the output map centre. The supplied default value
   is that of the map centre of the first map.
3 LONG_OUT
LONG_OUT = CHAR (Read)
   The longitude of the output map centre. The supplied default value
   is that of the map centre of the first map.
3 LOOP
LOOP = LOGICAL (Read)
   Task will ask for multiple input files if true. Only REF is read
   if noloop.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Options are QUIET, NORMAL and VERBOSE.
   Default is NORM.
3 OUT
OUT = NDF (Write)
   This is the name of the HDS container file that will contain the
   rebinned images. The map for each integration is stored in an NDF
   inside this NDF container. The maps can be accessed as 
   `out.name' where `name' is the integration name (i.e. i1, i2, i3, etc.).
3 OUT_COORDS
OUT_COORDS = CHAR (Read)
   The coordinate system of the output map. Available coordinate
   systems are:

   - AZ:  Azimuth/elevation offsets

   - NA:  Nasmyth offsets

   - PL:  RA/Dec Offsets from moving centre (e.g. Planets)

   - RB:  RA/Dec (B1950)

   - RJ:  RA/Dec (J2000)

   - RD:  RA/Dec (epoch of observation)

   - GA:  Galactic coordinates (J2000)

   For RD current epoch is taken from the first input file.
3 OUT_OBJECT
OUT_OBJECT = CHAR (Read)
   The name of the object (ie the NDF title).
3 PIXSIZE_OUT
PIXSIZE_OUT = REAL (Read)
   Size of pixels in the output map. Units are arcsec.
3 REBIN_METHOD
REBIN_METHOD = CHAR (Read)
   The rebin method to be used. A number of regridding methods are
   available:

   - LINEAR:  Linear weighting function

   - GAUSSIAN: Gaussian weighting function

   - BESSEL:  Bessel weighting function

   - SPLINE1: Interpolating spline (PDA_IDBVIP)

   - SPLINE2: Smoothing spline (PDA_SURFIT)

   - SPLINE3: Interpolating spline (PDA_IDSFFT)

   - MEDIAN:  Median regridding

   Please refer to the PDA documentation (SUN/194) for more information
   on the spline fitting algorithms.
3 REF
REF = CHAR (Read)
   The name of the first NDF to be rebinned. The name may also be the
   name of an ASCII text file containing NDF and parameter values.
   See the notes. REF can include a SCUBA section.
3 REFPIX
REFPIX ( 2 ) = INTEGER (Read)
   The coordinate of the reference pixel in the output data
   array. This corresponds to the pixel associated with the
   specified RA/Dec centre. Default is to use the middle pixel
   if a size is specified or the optimal pixel if the default
   size is used (see the SIZE parameter).
3 SCALE
SCALE = REAL (Read)
  Radius of one scale size in arcsec. This effectively governs the
  size of the weighting function. For LINEAR one scale size corresponds
  to the zero of the cone, for BESSEL it is the first zero of the
  Bessel function (PI) and for Gaussian it is the half-width
  half maximum (HWHM).
3 SFACTOR
SFACTOR = REAL (Read)
  This is the smoothing factor to use for a SPLINE2 regrid.
  See the PDA_SURFIT documentation for more information.
3 SIZE
SIZE ( 2 ) = INTEGER (Read)
   This array parameter sets the size of the output grid (nx, ny).
   The default values are the minimum dimensions required to display
   the entirety of the mapped area.
3 SHIFT_DX
SHIFT_DX = REAL (Read)
   The pointing shift (in X) to be applied that would bring the
   maps in line. This is a shift in the output coordinate frame.
3 SHIFT_DY
SHIFT_DY = REAL (Read)
   The pointing shift (in Y) to be applied that would bring the
   maps in line. This is a shift in the output coordinate frame.
3 TIMES
TIMES = LOGICAL (Read)
   Store an extra NDF in the output map containing the 2-D histogram
   of the data. This can be used to make an estimate of the actual
   number of samples responsible for each point in the output grid.
   Note that, in general, the number of pixels in the output grid
   exceeds the number of independent beams in the image.
   The data can be accessed as OUT.more.reds.times. Default is FALSE.
3 TRIM
TRIM = INTEGER (Read)
   This parameter determines the amount of good data that should
   be trimmed from the final image to correct for edge effects.
   The supplied value should be in arcseconds. All pixels closer
   to a bad pixel than this distance will be set to bad in the
   output image. Default is 0.0.
3 GUARD
GUARD = LOGICAL (Read)
   Controls whether the bolometer guard ring should be used during
   the regridding process. The guard ring enforces zero flux at the
   edge of the regridded image. Should be turned off if flux is present
   at the edge. Default is to use the guard ring for LINEAR, BESSEL
   and GAUSSIAN rebin modes.
3 WEIGHT
WEIGHT = REAL (Read)
   The relative weight that should be assigned to each dataset.
3 WEIGHTS
WEIGHTS = LOGICAL (Read)
   This parameter governs whether the convolution weights array will be
   stored in the output NDF. The default is FALSE. (ie do not store the
   weights array).
3 WTFNRAD = INTEGER (Read)
   Size of the weighting function in scale sizes. This parameter
   is irrelevant for LINEAR regridding. For Gaussian the default
   is 3 (i.e. a diameter of 3 FWHM for the footprint), and for
   Bessel it is 10. The smaller the weighting function is (a
   combination of WTFNRAD and SCALE) the faster the regridding goes.
2 Examples
intrebin rebin_method=LINEAR out_coords=RJ
   Rebin the maps with LINEAR weighting function in J2000 RA/Dec
   coordinates. You will be asked for input datasets until a null
   value is given.

intrebin rebin_method=BESSEL out=map
   Rebin the maps with Bessel weighting function. Each integration is
   rebinned separately and placed in an NDF in the output container file
   map.sdf. Integration can be accessed by displaying map.i2

intrebin noloop ref=test.bat
   Rebin each integration using the data specified in the file test.bat.
2 Notes
For each file name that is entered, values for the parameters
WEIGHT, SHIFT_DX and SHIFT_DY are requested.

- The application can read in up to 256 separate input datasets.

- The output map will be large enough to include all data points.

- Spline regridding may have problems with SCAN/MAP (since integrations
contain lots of overlapping data points).

- SCUBA sections can be given along with any input NDF

- The relative weights associated with each point in the output map
are stored in a WEIGHTS NDF in the REDS extension of the output
data. For spline rebinning each point is equivalent to the number
of integrations added into the final data point. For weight function
regridding the situation is more complicated.

- Bolometer weights will be used if a BOLWT extension is found
         in the input data file (usually set with SETBOLWT).

- Astrometry information is stored in the WCS component and not 
  the FITS extension.


2 ASCII_input_files
   The REF and IN parameters accept ASCII text files as input. These
   text files may contain comments (signified by a #), NDF names,
   values for the parameters WEIGHT, SHIFT_DX and SHIFT_DY,
   and names of other ASCII files. There is one data file per line.
   An example file is:

       file1{b5}   1.0   0.5   0.0  # Read bolometer 5 from file1.sdf
       file2                        # Read file 2 but you will still be
                                    # prompted fro WEIGHT, and shifts.
       file3{i3}-  1.0   0.0   0.0  # Use everything except int 3
       test.bat                     # Read in another text file

   Note that the parameters are position dependent and are not necessary.
   Missing parameters are requested. This means it is not possible to
   specify SHIFT_DX (position 3) without specifying the WEIGHT.
   If the file has the .txt extension the NDF system will attempt to
   convert it to NDF format before processing -- this is probably not
   what you want.
2 Related_Applications
   SURF: REBIN, BOLREBIN, EXTRACT_DATA
2 Authors
JFL: J.Lightfoot (ROE)

TIMJ: T. Jenness (t.jenness@jach.hawaii.edu)


1 MAPSUM
Produce a one-line summary of SCUBA map observations

Usage:

   mapsum [-h] [-demod] [-reduced] [-all|[-begin nn -end nn]]

Description:

   Mapsum goes through all the sdf files in the current  directory
   and, optionally, DATADIR (defined in an environment  variable)
   and summarizes files containing map observations.

   In the absence of the -all flag, a  numeric range is
   requested. This range only has an effect on raw data or reduced
   files which have the run number embedded into the file
   name. Filenames with no numbers are treated as scan 0.
2 Parameters
For information on individual parameters, select from the list below:
3 -h[elp]
-h[elp]
   Return a help message only. More help can be obtained by using
   `showme sun216' or `scuhelp mapsum'.
3 -all
-all
   List map files in the current directory and $DATADIR
3 -demod
-demod
   Only list demodulated data files (signified by _dem_ file name)
3 -reduced
-reduced
   Only list reduced data files (signified by _red_ file name)
3 -begin_nn
-begin nn
   First scan number to be considered (same as --begin==nn)
3 -end_nn
-end nn
   Final scan number to be considered (same as --end=nn)

2 Examples
mapsum
   Ask for a range of scan numbers and then give a full listing
   of every map file matching this criterion in DATADIR and the
   current directory.

mapsum -all
   Generate a summary of all map files in the current and
   DATADIR directory.

mapsum --begin=5 -end 100
   Generate a detailed log of all map data from scans 5 to 100 inclusive.

mapsum -all -reduced
   Produce a one line summary of all reduced (_red_) map files.

mapsum -all -reduced > log.txt
   Produce a one line summary of all the reduced map files and store
   the output in the text file log.txt (note this example is
   shell specific).

mapsum -all -reduced -demod
   Produce a summary of all reduced (_red_) and demodulated (_dem_)
   map data files (ie not files produced during off-line data reduction).


2 Notes

- Files are drawn from the current working directory and the directory
  indicated by the $DATADIR environment variable.

- Data reduced by the off-line system will all be treated as
  run 0 for the purposes of listing unless numbers are present
  in the filename.

- The output can be stored in a file by using unix redirection as
  long as the search range is fully specified (either as `-all' or
  with `-begin' and `-end').

- Command line options can be abbreviated.

- Options that take values can be used either as `-flag option' or
  as `--flag=option'

2 Authors

T. Jenness (JACH)

1 OBSSUM
Produce a one-line summary of SCUBA observations

Usage:

   sculog [-h] [-demod] [-reduced] [-mode ??]
          [-all|[-begin nn -end nn]]

Description:

   Obssum goes through all the sdf files in the current  directory
   and, optionally, DATADIR (defined in an environment  variable)
   and extracts information from any FITS entries that may  be
   present. 

   In the absence of the -all flag, a  numeric range is
   requested. This range only has an effect on raw data or reduced
   files which have the run number embedded into the file
   name. Filenames with no numbers are treated as scan 0.
2 Parameters
For information on individual parameters, select from the list below:
3 -h[elp]
-h[elp]
   Return a help message only. More help can be obtained by using
   `showme sun216' or `scuhelp obssum'.
3 -all
-all
   List all files in the current directory and $DATADIR
3 -demod
-demod
   Only list demodulated data files (signified by _dem_ file name)
3 -reduced
-reduced
   Only list reduced data files (signified by _red_ file name)
3 -begin_nn
-begin nn
   First scan number to be considered (same as --begin==nn)
3 -end_nn
-end nn
   Final scan number to be considered (same as --end=nn)
3 -mode_obs
-mode obs
   Select only specified observation modes for listing.
   The list should be comma separated. (same as --mode=obs)
2 Examples
obssum
   Ask for a range of scan numbers and then give a full listing
   of every sdf file matching this criterion in DATADIR and the
   current directory.

obssum -all
   Generate a summary of all sdf files in the current and
   DATADIR directory.

obssum --begin=5 -end 100
   Generate a detailed log of all data from scans 5 to 100 inclusive.

obssum -all -reduced
   Produce a one line summary of all reduced (_red_) files.

obssum -all -reduced > log.txt
   Produce a one line summary of all the reduced files and store
   the output in the text file log.txt (note this example is
   shell specific).

obssum -all -reduced -demod
   Produce a summary of all reduced (_red_) and demodulated (_dem_)
   data files (ie not files produced during off-line data reduction).

obssum -all -mode pointing
   Produce a one line summary of all pointing observations

obssum -reduced --begin=100 --end=200 --mode=photom,skydip
   Produce a one line summary of the photom and skydip observations
   of reduced files with scan numbers 100 to 200. This is similar to
   photsum except that the signal and signal-to-noise will not be
   displayed even if reduced files are being listed.
2 Notes
- obssum only uses information stored in the FITS header of
  reduced and raw data files and does not  provide summaries
  of reduced (RO) data such as photometry results (essentially for
  reasons of clarity). `photsum' must
  be used to generate a summary of photometry observations that
  includes reduced data.

- Files are drawn from the current working directory and the directory
  indicated by the $DATADIR environment variable.

- Data reduced by the off-line system will all be treated as
  run 0 for the purposes of listing unless numbers are present
  in the filename.

- The output can be stored in a file by using unix redirection as
  long as the search range is fully specified (either as `-all' or
  with `-begin' and `-end').

- Command line options can be abbreviated.

- Options that take values can be used either as `-flag option' or
  as `--flag=option'

2 Authors

T. Jenness (JACH)



1 PHOTSUM
Produce a one-line summary of SCUBA pointing observations

Usage:

   photsum [-h] [-demod] [-reduced] [-all|[-begin nn -end nn]]

Description:

   Photsum goes through all the sdf files in the current  directory
   and, optionally, DATADIR (defined in an environment  variable)
   and summarizes files containing photometry observations.

   In the absence of the -all flag, a  numeric range is
   requested. This range only has an effect on raw data or reduced
   files which have the run number embedded into the file
   name. Filenames with no numbers are treated as scan 0.
2 Parameters
For information on individual parameters, select from the list below:
3 -h[elp]
-h[elp]
   Return a help message only. More help can be obtained by using
   `showme sun216' or `scuhelp pointsum'.
3 -all
-all
   List all photometry files in the current directory and $DATADIR
3 -demod
-demod
   Only list demodulated data files (signified by _dem_ file name)
3 -reduced
-reduced
   Only list reduced data files (signified by _red_ file name)
3 -begin_nn
-begin nn
   First scan number to be considered (same as --begin==nn)
3 -end_nn
-end nn
   Final scan number to be considered (same as --end=nn)

2 Examples
photsum
   Ask for a range of scan numbers and then give a full listing
   of every photometry file matching this criterion in DATADIR and the
   current directory.

photsum -all
   Generate a summary of all photometry files in the current and
   DATADIR directory.

photsum --begin=5 -end 100
   Generate a detailed log of all photometry data from scans 5 to 100 
   inclusive.

photsum -all -reduced
   Produce a one line summary of all reduced (_red_) photometry files.
   This will include the photometry results calculated by the on-line
   system.

photsum -all -reduced > log.txt
   Produce a one line summary of all the reduced photometry files and store
   the output in the text file log.txt (note this example is
   shell specific).

photsum -all -reduced -demod
   Produce a summary of all reduced (_red_) and demodulated (_dem_)
   photometry  data files (ie not files produced during off-line data 
   reduction).


2 Notes

- If the task is run on reduced data (`_red_' files) then the photometry 
  results will be listed.

- Skydip data is printed for convenience.

- Files are drawn from the current working directory and the directory
  indicated by the $DATADIR environment variable.

- Data reduced by the off-line system will all be treated as
  run 0 for the purposes of listing unless numbers are present
  in the filename.

- The output can be stored in a file by using unix redirection as
  long as the search range is fully specified (either as `-all' or
  with `-begin' and `-end').

- Command line options can be abbreviated.

- Options that take values can be used either as `-flag option' or
  as `--flag=option'

- It may be necessary to set the HDS_SCRATCH environment variable if 
  files are being logged from directories for which write access is
  denied (e.g. setenv HDS_SCRATCH /tmp)

2 Authors

T. Jenness (JACH)

1 PLTBOL

Interactive data inspection (requires Kappa)

See SCUPLOT for more information.


1 POINTSUM
Produce a one-line summary of SCUBA pointing observations

Usage:

   pointsum [-h] [-demod] [-reduced] [-all|[-begin nn -end nn]]

Description:

   Pointsum goes through all the sdf files in the current  directory
   and, optionally, DATADIR (defined in an environment  variable)
   and summarizes files containing pointing observations.

   In the absence of the -all flag, a  numeric range is
   requested. This range only has an effect on raw data or reduced
   files which have the run number embedded into the file
   name. Filenames with no numbers are treated as scan 0.
2 Parameters
For information on individual parameters, select from the list below:
3 -h[elp]
-h[elp]
   Return a help message only. More help can be obtained by using
   `showme sun216' or `scuhelp pointsum'.
3 -all
-all
   List all pointing files in the current directory and $DATADIR
3 -demod
-demod
   Only list demodulated data files (signified by _dem_ file name)
3 -reduced
-reduced
   Only list reduced data files (signified by _red_ file name)
3 -begin_nn
-begin nn
   First scan number to be considered (same as --begin==nn)
3 -end_nn
-end nn
   Final scan number to be considered (same as --end=nn)

2 Examples
pointsum
   Ask for a range of scan numbers and then give a full listing
   of every pointing file matching this criterion in DATADIR and the
   current directory.

pointsum -all
   Generate a summary of all pointing files in the current and
   DATADIR directory.

pointsum --begin=5 -end 100
   Generate a detailed log of all pointing data from scans 5 to 100 inclusive.

pointsum -all -reduced
   Produce a one line summary of all reduced (_red_) pointing files.

pointsum -all -reduced > log.txt
   Produce a one line summary of all the reduced pointing files and store
   the output in the text file log.txt (note this example is
   shell specific).

pointsum -all -reduced -demod
   Produce a summary of all reduced (_red_) and demodulated (_dem_)
   pointing data files (ie not files produced during off-line data reduction).


2 Notes

- Files are drawn from the current working directory and the directory
  indicated by the $DATADIR environment variable.

- Data reduced by the off-line system will all be treated as
  run 0 for the purposes of listing unless numbers are present
  in the filename.

- The output can be stored in a file by using unix redirection as
  long as the search range is fully specified (either as `-all' or
  with `-begin' and `-end').

- Command line options can be abbreviated.

- Options that take values can be used either as `-flag option' or
  as `--flag=option'

2 Authors

T. Jenness (JACH)


1 QDRAW
Draw a data set with plus or minus 5 sigma range

Usage:

   qdraw [-noline] NDF [Linplot/Stats/Drawsig parameters]

Description:

   This program uses kappa routines to calculate mean and standard
   deviation of an NDF. It then uses linplot to display the data with
   a range of plus or minus 5 sigma. Optionally, DRAWSIG can be used
   to overlay 3 sigma lines.
2 Parameters
For information on individual parameters, select from the list below:
3 -noline
-noline
   A Unix-type switch which controls whether the 3 sigma lines are
   displayed or not.
3 NDF
NDF (Given)
   The required dataset
3 ADAM_parameters
ADAM parameters = Any
   Any parameters accepted by the individual routines as long as they
   use PARAM=VALUE format.
2 Examples
qdraw test
   Draws test.sdf  with a scale of +/- 5 sigma and draws lines at +/- 3
   sigma.

qdraw -noline test
   Same as above but without the 3 sigma lines

qdraw mode=2 test
   Plot the data using `+' symbols (LINPLOT mode 2)

qdraw mode=2 sigcol=red test
   Plot with `+' symbols and use red lines to show the +/- 3 sigma lines.
2 Notes
The $KAPPA_DIR environment variable must point to the location
of the KAPPA binaries (this is usually done during a Starlink login).
2 Related_Applications
   SURF: SCUCAT, SCUPHOT;
   KAPPA: STATS, LINPLOT, DRAWSIG

2 Authors

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)


1 REBIN
Rebin demodulated SCUBA data onto output map

Usage:

   rebin ref

Description:

   This routine rebins the demodulated data from SCUBA MAP observations
   onto a rectangular mesh by a variety of methods.
   Currently convolution by weighting functions,  spline interpolation 
   and median are supported.

   - Weighting functions:
     Currently linear, Gaussian and Bessel weighting functions are supported.
     The width of the Bessel function is such that it should preserve all
     spatial information obtained by the telescope at the wavelength of
     observation, but suppress higher spatial frequencies. To minimise edge
     effects the Bessel function is truncated at a radius of 10 half-widths
     from the centre, and apodized over its outer third by a cosine
     function. Viewed in frequency space the method consists of Fourier
     transforming the input dataset(s), multiplying the transform by a
     cylindrical top-hat (the F.T. of the Bessel function),
     then transforming back into image space.
     A linear weighting function is also available which works out
     to one half-width - this has the advantage that it is much faster to
     process and is much less susceptible to edge effects.
     
     The Gaussian weighting function is probably the best compromise
     between the Bessel (slow and prone to edge effects) and Linear (fast
     but the point spread function is non-trivial for modeling).

     The radius and size of `footprint' for the weighting functions
     are configurable using the WTFNRAD and SCALE parameters.

   - Splines:
     Additionally, spline interpolation and smoothing routines are also
     available. Note that the spline routines work on each integration
     in turn, whereas the weighting function routines work on all the input
     data in one go. At present the spline routines are experimental and
     comments are welcomed.

   - Median:

      A regridding option derived from DESPIKE is available. This
      method simply puts all data points in an output grid and calculates
      the median of each output cell. Small pixel scales require large
      datasets (since not all cells in a 1 arcsecond grid will contain
      data points) although the Kappa commands FILLBAD and GLITCH
      can be used to smooth over bad pixels.


2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = CHAR (Read)
   The name of the input file to be rebinned. This parameter is requested
   repeatedly until a NULL value (!) is supplied. LOOP must be TRUE.
   IN can include a SCUBA section.
   Like the REF parameter this parameter accepts a text file.
3 LAT_OUT
LAT_OUT = CHAR (Read)
   The latitude of the output map centre. The supplied default value
   is that of the map centre of the first map.
3 LONG_OUT
LONG_OUT = CHAR (Read)
   The longitude of the output map centre. The supplied default value
   is that of the map centre of the first map.
3 LOOP
LOOP = LOGICAL (Read)
   Task will ask for multiple input files if true. Only REF is read
   if noloop.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Options are QUIET, NORMAL and VERBOSE.
   Default is NORM.
3 OUT
OUT = NDF (Write)
   This is the name of the NDF that will contain the rebinned map. 
   A null value can be supplied to shut down rebin without error.
   This can be used to determine the size of the output map
   without creating it.
3 OUT_COORDS
OUT_COORDS = CHAR (Read)
   The coordinate system of the output map. Available coordinate
   systems are:

   - AZ:  Azimuth/elevation offsets

   - NA:  Nasmyth offsets

   - PL:  RA/Dec Offsets from moving centre (e.g. Planets)

   - RB:  RA/Dec (B1950)

   - RJ:  RA/Dec (J2000)

   - RD:  RA/Dec (epoch of observation)

   - GA:  Galactic coordinates (J2000)

   For RD current epoch is taken from the first input file.
3 OUT_OBJECT
OUT_OBJECT = CHAR (Read)
   The name of the object (ie the NDF title).
3 PIXSIZE_OUT
PIXSIZE_OUT = REAL (Read)
   Size of pixels in the output map. Units are arcsec.
3 REBIN_METHOD
REBIN_METHOD = CHAR (Read)
   The rebin method to be used. A number of regridding methods are
   available:

   - LINEAR:  Linear weighting function

   - GAUSSIAN: Gaussian weighting function

   - BESSEL:  Bessel weighting function

   - SPLINE1: Interpolating spline (PDA_IDBVIP)

   - SPLINE2: Smoothing spline (PDA_SURFIT)

   - SPLINE3: Interpolating spline (PDA_IDSFFT)

   - MEDIAN:  Median regridding

   Please refer to the PDA documentation (SUN/194) for more information
   on the spline fitting algorithms.
3 REF
REF = CHAR (Read)
   The name of the first NDF to be rebinned. The name may also be the
   name of an ASCII text file containing NDF and parameter values.
   See the notes. REF can include a SCUBA section.
3 REFPIX
REFPIX ( 2 ) = INTEGER (Read)
   The coordinate of the reference pixel in the output data
   array. This corresponds to the pixel associated with the
   specified RA/Dec centre. Default is to use the middle pixel
   if a size is specified or the optimal pixel if the default
   size is used (see the SIZE parameter).
3 SCALE
SCALE = REAL (Read)
  Radius of one scale size in arcsec. This effectively governs the
  size of the weighting function. For LINEAR one scale size corresponds
  to the zero of the cone, for BESSEL it is the first zero of the
  Bessel function (PI) and for Gaussian it is the half-width
  half maximum (HWHM).
3 SFACTOR
SFACTOR = REAL (Read)
  This is the smoothing factor to use for a SPLINE2 regrid.
  See the PDA_SURFIT documentation for more information.
3 SIZE
SIZE ( 2 ) = INTEGER (Read)
   This array parameter sets the size of the output grid (nx, ny).
   The default values are the minimum dimensions required to display
   the entirety of the mapped area.
3 SHIFT_DX
SHIFT_DX = REAL (Read)
   The pointing shift (in X) to be applied that would bring the
   maps in line. This is a shift in the output coordinate frame.
3 SHIFT_DY
SHIFT_DY = REAL (Read)
   The pointing shift (in Y) to be applied that would bring the
   maps in line. This is a shift in the output coordinate frame.
3 TIMES
TIMES = LOGICAL (Read)
   Store an extra NDF in the output map containing the 2-D histogram
   of the data. This can be used to make an estimate of the actual
   number of samples responsible for each point in the output grid.
   Note that, in general, the number of pixels in the output grid
   exceeds the number of independent beams in the image.
   The data can be accessed as OUT.more.reds.times. Default is FALSE.
3 TRIM
TRIM = INTEGER (Read)
   This parameter determines the amount of good data that should
   be trimmed from the final image to correct for edge effects.
   The supplied value should be in arcseconds. All pixels closer
   to a bad pixel than this distance will be set to bad in the
   output image (by setting bit 1 in the quality array). 
   Default is 0.0.
3 GUARD
GUARD = LOGICAL (Read)
   Controls whether the bolometer guard ring should be used during
   the regridding process. The guard ring enforces zero flux at the
   edge of the regridded image. Should be turned off if flux is present
   at the edge. Default is to use the guard ring for LINEAR, BESSEL
   and GAUSSIAN rebin modes.
3 WEIGHT
WEIGHT = REAL (Read)
   The relative weight that should be assigned to each dataset.
3 WEIGHTS
WEIGHTS = LOGICAL (Read)
   This parameter governs whether the convolution weights array will be
   stored in the output NDF. The default is FALSE. (ie do not store the
   weights array).
3 WTFNRAD = INTEGER (Read)
   Size of the weighting function in scale sizes. This parameter
   is irrelevant for LINEAR regridding. For Gaussian the default
   is 3 (i.e. a diameter of 3 FWHM for the footprint), and for
   Bessel it is 10. The smaller the weighting function is (a
   combination of WTFNRAD and SCALE) the faster the regridding goes.

2 Examples
rebin rebin_method=LINEAR out_coords=RJ
   Rebin the maps with LINEAR weighting function in J2000 RA/Dec
   coordinates. You will be asked for input datasets until a null
   value is given.

rebin rebin_method=BESSEL out=map out_coords=NA
   Rebin the maps with Bessel weighting function in Nasmyth coordinates.

rebin noloop accept ref=test.bat out=rebin
   Rebin the files specified in test.bat onto a rectangular
   grid using linear interpolation, 3 arcsecond pixels and RJ
   coordinates.
2 Notes
For each file name that is entered, values for the parameters
WEIGHT, SHIFT_DX and SHIFT_DY are requested.

- The application can read in up to 100 separate input datasets.

- The output map will be large enough to include all data points.

- Spline regridding may have problems with SCAN/MAP (since integrations
contain lots of overlapping data points).

- SCUBA sections can be given along with any input NDF

- The relative weights associated with each point in the output map
are stored in a WEIGHTS NDF in the REDS extension of the output
data. For spline rebinning each point is equivalent to the number
of integrations added into the final data point. For weight function
regridding the situation is more complicated.

- Bolometer weights will be used if a BOLWT extension is found
         in the input data file (usually set with SETBOLWT).

- Astrometry information is stored in the WCS component and not 
  the FITS extension.

2 ASCII_input_files
   The REF and IN parameters accept ASCII text files as input. These
   text files may contain comments (signified by a #), NDF names,
   values for the parameters WEIGHT, SHIFT_DX and SHIFT_DY,
   and names of other ASCII files. There is one data file per line.
   An example file is:

       file1{b5}   1.0   0.5   0.0  # Read bolometer 5 from file1.sdf
       file2                        # Read file 2 but you will still be
                                    # prompted fro WEIGHT, and shifts.
       file3{i3}-  1.0   0.0   0.0  # Use everything except int 3
       test.bat                     # Read in another text file

   Note that the parameters are position dependent and are not necessary.
   Missing parameters are requested. This means it is not possible to
   specify SHIFT_DX (position 3) without specifying the WEIGHT.
   If the file has the .txt extension the NDF system will attempt to
   convert it to NDF format before processing -- this is probably not
   what you want.
2 Related_Applications
   SURF: BOLREBIN, INTREBIN, SCUQUICK, EXTRACT_DATA
2 Authors
JFL: J.Lightfoot (ROE)

TIMJ: T. Jenness (t.jenness@jach.hawaii.edu)

1 REDUCE_NOISE
Process demodulated noise data

Description:

   This routine takes raw demodulated noise data and processes it.
   NDF and ASCII results files are generated.

   The output NDF file is a 2-D dataset with a chop signal and
   calibrator signal per bolometer. The text file is similar
   to the file generated by the real-time system.
2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = NDF (Read)
   The name of the raw noise data file. A single number can be
   supplied if SCUBA_PREFIX is set. DATADIR is recognised.
3 OUT
OUT = NDF (Write)
   Output NDF. This file is 2-dimensional. The first
   dimension is bolometer number. The second dimension is
   chop signal and calibrator signal (along with variances
   and quality). If no output NDF is required a null value
   can be given.
3 FILE
FILE = FILENAME (Write)
   Output text file. Format is almost identical to that
   generated by the real-time system. A null value can be
   supplied to prevent a text file from being written. The
   default output name is the same name as generated by the
   on-line system (noise_YYMMDD_nr.dat)
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message output level. Default is NORM. Allowed values are
   QUIET, NORMAL and VERBOSE.
2 Examples
reduce_noise 19981113_dem_0001 out_noise !
   Read in observation 1 and write the output to an NDF
   names out_noise.sdf. Do not write a text file.

reduce_noise '3' ! accept
   Process observation 3 but do not write an NDF output file.
   Use the default file name for the text file.
2 Notes
Noise observations containing multiple measurements are condensed
into a single measurement.
2 Authors
JFL: John Lightfoot (ROE)

TIMJ: Tim Jenness (JACH)


1 REDUCE_SWITCH
reduce the switch sequence for a SCUBA observation

Usage:

   reduce_switch in out

Description:

   This application takes a SCUBA demodulated data file and splits the
   data array up into its various `planes'; data, variance and quality.
   In addition, the application reduces the component switches of an
   exposure to give the exposure result. Optionally, the routine will
   divide the internal calibrator signal into the data before doing either
   of these things. It is also possible to select a single switch
   from the input data.

   For skydip data this routine calculates the sky temperature for each 
   integration and sub-instrument.
2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = NDF (Read)
   The name of the demodulated data file. If $SCUBA_PREFIX is set this can
   be the number of the observation rather than the full filename.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 OUT
OUT = NDF (Read)
   The name of the file to contain the output data.
3 SPIKE_LEVEL
SPIKE_LEVEL = INTEGER (Read)
   Number of spikes tolerated before marking data point bad.
   The default is that the sample should be marked bad if the
   transputers detected more than 5 spikes during a 1 second
   sample.
3 SWITCH
SWITCH = INTEGER (Read)
   Parameter to indicate which switch to extract. A value of 0 means
   that all switches should be reduced. Default is 0.
3 TARRAY = LOGICAL (Read)
   Controls whether the T_COLD parameters are read as an array
   of values (true) or read as a sequence of scalars (false) . 
   This parameter is useful if the command is to be run in batch mode.
   Default is false.
3 T_COLD
T_COLD = REAL (Read)
   Temperature of the cold load when processing skydip data. The default 
   value is taken from the input file.
3 T_HOT
T_HOT = REAL (Read)
   Temperature of the hot load when processing skydip data. The default 
   value is taken from the input file.
3 USE_CALIBRATOR
USE_CALIBRATOR = LOGICAL (Read)
   Yes, if you want the data for each bolometer measurement
   divided by the corresponding internal calibrator signal.
   The default is not to use the calibrator.
2 Examples
reduce_switch
   All parameters will be requested.

reduce_switch test nosw
   This will reduce the switch from input file test.sdf without dividing
   by the calibrator signal and tolerating up to 5 spikes in a 1 second
   sample. The output data will be written to nosw.sdf.

reduce_switch test nosw SWITCH=2
   This will select switch 2 from test.sdf and write it to nosw.sdf
2 Notes
If the input file is not found in the current directory, the directory
specified by the DATADIR environment variable is searched. This means
that the raw data does not have to be in the working directory.
2 Authors
JFL: J.Lightfoot (jfl@roe.ac.uk)

TIMJ: T. Jenness (t.jenness@jach.hawaii.edu)

1 REMDBM
Remove dual beam signature from scan maps

Usage:

   remdbm [-h] [-v] [-out=] [-noams] [-filter] files

Description:

   This program should be used to reduce SCAN-MAP data taken
   using the technique described by Emerson (1995, ASP Conf Ser 75, 309).
   The deconvolution is performed using Fast Fourier techniques.
2 Parameters
For information on individual parameters, select from the list below:
3 -h
-h
   Help message
3 -v
-v
   Version number. Also indicates whether ADAM communication is
   enabled.
3 -out
-out=file
   Filename of output image. Default is 'final.sdf'
3 -noams
-noams
   Turns off ADAM messaging. Default is false (if ADAM messaging
   is available.)
3 -filter
-filter
   Turns on high frequency filtering. When used, data at frequencies
   greater than that to which the telescope is sensitive are set to zero.
3 files
files
   List of input files to be processed. Shell wildcards are allowed.
   See notes for restrictions.
2 Examples
remdbm *_reb.sdf
   Process all files matching the pattern.

remdbm -out=m82 o66_lon_reb o67_lon_reb o68_lon_reb o69_lon_reb
   Process the four input images. The output filename is set to
   m82.sdf.
remdbm -filter -noams *_reb.sdf
   Process the supplied files with high frequency filtering. Do not
   use the messaging system.
2 Notes
The following restrictions apply:

- Each image should contain a single chop configuration.

- Each image must have identical dimensions and pixel size
  (they do not need to be square)

- The images must be rebinned in the same coordinate system
  as the chop throw.
2 Related_Applications
   SURF: SCUMAKEWT, ADD_DBM
   KAPPA: FOURIER

2 Authors
JFL: John Lightfoot (jfl@roe.ac.uk)

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)

1 REMIP
Remove instrumental polarisation from SCUBA pol data

Usage:

   remip in ipfile out

Description:

   This task calculates and removes the instrumental polarisation
   signal from SCUBA polarimeter data.

     Actual flux = measured flux / ( 1 + %age IP)

   where IP = P * cos (4 WP - 2 THETA )
   and P is the (elevation dependent) instrumental percentage
   polarisation, WP is the position angle of the wave plate and
   THETA is the (elevation dependant) position angle of the IP.

   This is an approximation of

     Actual flux = measured flux - mean flux * %age IP

   where IP = P * (1 + cos (4 WP - 2 THETA ) )
   because the mean flux can not be calculated trivially since
   the bolometers are jiggling on and off the source
2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = NDF (Read)
   Input data file.
3 IPFILE
IPFILE = FILE (Read)
   File containing the IP `flatfield'
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Options are QUIET, NORMAL and
   VERBOSE. Default is NORM.
3 OUT
OUT = NDF (Write)
   Output file containing IP removed data. Default output
   filename is `_ip' (`i' for short form).
2 Examples
remip file1 ipfile.dat \\
   Correct file1.sdf using ipfile.dat and write IP corrected
   data to the default output file (eg file1_ip).
2 Notes
- Variance is propagated correctly.

- This task writes out the waveplate angles and rotation angles.
  The waveplate angle per integration is written to .MORE.REDS.WPLATE.
  The rotation angle (waveplate 0 to X pixel axis) is written
  to .MORE.REDS.ANGROT (angle per integration). The angle
  between nasmyth and the ra/dec frame (ie ANGROT - 90 degrees)
  is stored in .MORE.REDS.NASMYTH_ANG (angle per sample).
  These are written as NDFs and so can be displayed in the normal way.
  The angles are in degrees.

- An array containing the fast axis angle is also written
  to the REDS extension (FAST_AXIS). The size of this array
  matches the number of sub-instruments in the file.
2 Authors
Tim Jenness (t.jenness@jach.hawaii.edu)

1 REMSKY
Remove sky noise and constant offsets from SCUBA jiggle data

Usage:

   remsky in out

Description:

   This task removes sky noise and constant offsets from SCUBA jiggle
   data. It does this by requesting `sky' bolometers, calculating some
   average value for each jiggle and then subtracts this off the
   jiggle. Each jiggle is analysed in turn. The average value can be
   calculated in two ways: either MEDIAN or MEAN.

   After the calculation, the mean value removed from each jiggle can be 
   added back on to the data - this should protect against removing 
   flux from MAP data.   

   If a SKY NDF is found in the REDS extension, it is assumed that
   the sky variation has already been determined (eg by CALCSKY) and
   this sky signature is removed. The 'ADD' parameter is ignored in
   this case.



2 Parameters
For information on individual parameters, select from the list below:
3 ADD
ADD = LOGICAL (Read)
   This parameter governs whether the average value removed from the 
   data should be added back after sky removal. The default is for ADD
   to be true for MAPs and false for other modes (the assumption being
   that sky bolometers in PHOTOM observations are guaranteed to be
   on sky).
3 BOLOMETERS
BOLOMETERS = CHAR (Read)
   List of sky bolometers. The following options are now recognised for 
   the BOLOMETERS parameter: 

       Code       Description     Example
       ----       -----------     -------
        nn         A number       5 or 19
        id         Bolometer id   H7 or C14
        rn         Ring number    r1 (for the inner ring) and
                                  r5 (for the outer ring of the SHORT array)
                                  r-1 (for the outer ring)
                                  r-2 (one ring in from outer ring)
        all        All bolometers all (select the entire array)

    Each value must be comma separated but can be preceded by a minus
    sign to remove the bolometer(s) from the list. The definitions of
    ring number and `all' are dependent on the selected
    sub-instrument.

    Here are some examples values for BOLOMETERS:

     [17,18,19,20]                    Bolometers 17, 18, 19 and 20
     [h6,h7,h8,h9]                    Bolometers H6, H7, H8, H9 
     [all]                            Whole array 
     [r0]                             Ring zero (central pixel)
     [r0,-19]                         No bolometers (bol 19 of LONG is R0/H7)
     [h7,r1]                          inner ring and H7
     [r1,-h8]                         inner ring without H8
     [r1,-18]                         inner ring without bolometer 18
     [all,-r1,-h7]                    all pixels except the inner ring/H7
     [all,-r3,g1]                     all pixels except ring 3 but with
                                      G1 (which happens to be in r3)
     [all,-r1,-r2,-r3,-r4,-r5]        Selects the central pixel          
     [all,-r-1]                       Selects all except the outer ring

   Note that the bolometer sum is calculated sequentially so that
   [all,-all,h7] would leave you with bolometer H7.
3 IN
IN = NDF (Read)
   This is the name of the input demodulated data file
3 ITER_SIGMA
ITER_SIGMA = REAL (Read)
   When using MEAN to calculate the average, this is the sigma clipping
   level used. This is an iterative value - points will be removed
   from the mean until the spread of data points is smaller than
   this value. Supplying a negative value  will turn off clipping.
3 MODE
MODE = CHAR (Read)
   Method to be used for calculating the average sky. There are
   two methods available:

   - Median - the median value for all the sky bolometers is taken
              from each bolometer signal.

   - Mean   - the mean of the sky bolometers is used as the average.
              This mean value is iterative - ie The mean and standard
              deviation are calculated, any points greater than the
              given distance from the mean are removed and the mean
              and standard deviation are calculated.  This process
              is repeated until no bolometers are dropped from the
              mean.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message output level. Default is NORM. In VERBOSE mode a list of 
   selected bolometers is returned along with the value of the sky offset
   removed from each jiggle.
3 OUT
OUT = NDF (Write)
   Output data file
2 Examples
remsky ndf sky_removed bolometers='[g1,g2,g3,g4,g5]' mode=median \
   Use the median of bolometers g1,g2,g3,g4,g5 (not necessarily
   the best choice) to calculate the sky signal and write the
   output to sky_removed.sdf. No despiking is to be used.
remsky o25_sho_ext bolometers=[r5] mode=mean iter_sigma=4 \
  Use the outer ring of the short-wave array as the sky bolometers.
  Calculate the sky contribution by using a clipped mean of each
  jiggle and remove any points from the
  calculation of the mean that are more than 4 sigma from the mean.
  Write the output to the default output file.

2 Notes
- Source rotation is not accounted for so use only those bolometers
  that always observe sky. This can be checked by using
  SCUOVER to overlay the bolometer positions on a NAsmyth regridded
  image (since NA shows the signal measured by each bolometer
  throughout the observation without source rotation).

- For weak sources (i.e. sources that are not obvious in a single 
  integration) it is probably sufficient to choose BOLOMETERS=[all] and
  MODE=median.

2 Related_Applications
   SURF: SCUQUICK, REBIN, SCUPHOT, SCUOVER;
2 Authors
TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)

1 RESTORE
remove the chopped beam response from SCAN/MAP observations

Usage:

   restore in out chop

Description:

   This routine removes the chopped beam response from SCAN/MAP
   observations.
2 Parameters
For information on individual parameters, select from the list below:
3 CHOP
CHOP = INTEGER (Read)
   Chop throw in arcseconds. The default chop throw is read from
   the FITS header of the input file.
3 IN
IN = NDF (Read)
   The name of the input file containing demodulated SCUBA data.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 OUT
OUT = NDF (Write)
   The name of the output file to contain the processed data.
2 Examples
restore input output \
   Restore input.sdf to output.sdf using the default chop throw.

restore resw restore 40.2
   Restore resw.sdf to restore.sdf using a chop throw of 40.2
   arcseconds.
2 Notes
Uses the Emerson, Klein and Haslam algorithm (1979, A&A, 76, 92).

Currently this routine must be run on data before it has been extinction
corrected.

2 Related_applications

SURF: DESPIKE2, REBIN
JCMTDR: RESTORE

2 Authors
JFL: John Lightfoot (jfl@roe.ac.uk)

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)

1 RLINPLOT

Interactive data inspection via MLINPLOT (requires Kappa)

See SCUPLOT for more information.


1 SCAN_RLB
Remove the baselines from SCAN/MAP data

Usage:

   scan_rlb in out

Description:

   This routine removes a baseline from each scan.
   The baseline is determined in a number of ways. For removal of 
   a linear baseline, a fit is made to the scan ends before removing
   this from the entire scan.

2 Parameters
For information on individual parameters, select from the list below:
3 CHOP
CHOP = INTEGER (Read)
   The baseline fit is calculated over regions CHOP arcseconds from the
   scan ends. This region should be as large as possible but should
   only include baseline regions -- any scan that includes a source
   detection within CHOP arcseconds of the scan ends will be rendered
   useless.
   The default value is the chop throw.
3 IN
IN = NDF (Read)
   The name of the input file containing demodulated SCUBA data.
3 METHOD
METHOD = CHAR (Read)
   Governs the method to be used for calculating the baseline.
   Options are MEDIAN: Remove the median from each scan, 
   MEAN: remove the mean level from each scan, LINEAR: fit a linear
   baseline to the ends of the scan. SECTION: Use a SCUBA section to 
   specify regions of each integration that are thought to be flux free.
   Remove the median of the specified section from the associated 
   integration.
   Default is LINEAR.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   The messaging level. Default is NORM. There are no verbose messages.
3 OUT
OUT = NDF (Write)
   The name of the output file to contain the processed data.
3 RLB
RLB = INTEGER (Read)
   This parameter governs whether the baseline fit is removed from the
   input data or stored instead of the data. If RLB is .TRUE. the
   corrected data are returned. If RLB is .FALSE. the fit is returned.
3 SECTION
SECTION = CHAR (Read)
   This array parameter can be used to specify SCUBA sections
   to be used for baseline calculation. It is requested when 
   METHOD=SECTION. In general the SCUBA section should
   include scan (exposure) or position (p) specifiers which 
   will be applied to each bolometer and integration. It is
   possible to be more specific and to provide multiple sections
   singling out certain bolometers or integrations. If entire
   integrations are selected no baseline removal will occur
   on unselected integrations (this will be stated).
   The median of the section supplied for each integration
   is subtracted from every exposure in that integration (remember
   that if no integration is specified, all integrations are assumed).

   Curly brackets must still be given. Since this is an array
   parameter square brackets must be used to specify more than
   one component:

       SECTION > [ {e1} , {e4;b2} ]

   would select exposure one from each integration along with
   exposure 4 for bolometer 2.
   be used if the square brackets are not used. 

   Care must also be taken when using commas in SCUBA sections -
   the parameter system will split multiple entries on commas 
   unless the entire section is quoted:

       SECTION > "{e1,4}"

   If necessary the negation character should come after a
   section (ie after the closing curly bracket) and that 
   negation applies to the combined section and not just the string 
   containing the negation character:

       SECTION > {e3}-

   implies that the section consists of everything except exposure 3.

2 Examples
scan_rlb infile method=linear \
   Remove linear baselines from each scan using baseline regions the
   same size as the chop. Write the results to the default output file.

scan_rlb infile norlb method=median \
   Calculate the fit using the median of each scan but do not
   remove the baseline from the data. Store the baseline determination
   for later analysis.

scan_rlb method=section rlb section={e1,4}
   Calculate the baseline using the first and 4th exposures of
   each integration.

2 Notes
   The Kappa SUB command can be used to subtract the baseline from the
   input data at a later stage (if RLB is false).
2 Authors
JFL: John Lightfoot (jfl@roe.ac.uk)

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)

1 SCUBA2MEM
Calculate bolometer positions as tangent plane offsets

Usage:

   scuba2mem in out

Description:

   This routine reads in SCUBA demodulated data and writes it
   out along with the positions of the bolometers on the sky
   for each sample. The positions of the
   chop beams can be requested as well as the positions of the tracking
   centre. Returns tangent plane offsets from the map centre in arcseconds.
   Additionally, the LST of each sample is stored as axis information.
2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = CHAR (Read)
   The name ofthe input files to be processed. This is a demodulated
   data file. RESTORE should not have been run on it. Multiple
   file names can be specified (see the documentation on GRP).
   All the input files are referenced to the same output coordinate
   frame.
3 LAT
LAT = CHAR (Read)
   The latitude of the output map centre. The supplied default value
   is that of the map centre of the observation in the output
   coordinates.
3 LONG
LONG = CHAR (Read)
   The longitude of the output map centre. The supplied default value
   is that of the map centre of the observation in the output
   coordinates.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 NBEAMS
NBEAMS = INTEGER (Read)
   Number of output beams to be written to file. NBEAMS=1 just
   writes the Middle beam, NBEAMS=2 writes the Left (negative)
   and Right beams, NBEAMS=3 writes Middle, Left and Right beams.
3 OUT
OUT = NDF (Write)
   This parameter specifies the name of the output file to be used
   to store the positional information.
   The file format is described below.
3 OUT_COORDS
OUT_COORDS = CHAR (Read)
   The coordinate system of the output map. Available coordinate
   systems are:

   - AZ:  Azimuth/elevation offsets

   - NA:  Nasmyth offsets

   - PL:  RA/Dec Offsets from moving centre (eg Planets)

   - RB:  RA/Dec (B1950)

   - RJ:  RA/Dec (J2000)

   - RD:  RA/Dec (epoch of observation)

   - GA:  Galactic coordinates (J2000)
3 SHIFT
SHIFT = REAL( 2 ) (Read)
   The pointing shift [X,Y] to be applied that would bring the
   map into the correct position.
   This is a shift in the output coordinate frame. CHANGE_POINTING
   should be used to add Az/El pointing offsets.
2 Examples
scuba2mem out_coords=GA o34_lon_ext o34_mem nbeams=1 \\
   Calculate the coordinates of all bolometer positions
   in tangent plane offsets from the GA map centre.

scuba2mem o34_lon_ext nbeams=3 \\
   Calculate all chop positions for o34_lon_ext. Use RJ coordinates.
2 Notes
- Can be used on JIGGLE and SCAN data.

- The coordinates of the selected output frame are written
  to the output FITS extension in keywords OUT_CRDS, OUTLONG and
  OUTLAT. The full FITS header of the observation itself is still
  available.
2 Format_of_output_file
   SCUBA DBMEM requires the data, positions of every beam and the
   LST for every point. This information (along with a standard FITS
   header) is stored as a standard NDF. The data array is constructed
   as follows:
       3 dimensional: N_BOL * N_POS * ((N_BEAM * 2) + 1)
       where N_BOL is the number of bolometers
             N_POS is the number of samples for each bolometer (time axis)
             N_BEAM is the number of beams

       The 3rd dimension contains the actual data value plus positions
       of every beam associated with the data point. Each beam has two
       positions (X offset and Y offset)
       Axis components store bolometer number, LST and beam weight.
2 Related_Applications
   SURF: EXTRACT_DATA, REBIN
   DBMEM
2 Authors
TIMJ: T. Jenness (timj@jach.hawaii.edu)



1 SCUCAT
Concatenate photometry datasets for further processing

Usage:

   scucat out in

Description:

   This routine reads in a list of user specified files and
   concatenates their data, variance and quality arrays so that
   KAPPA routines like STATS and KSTEST can analyse a complete set
   of photometry observations. SCUCAT can be configured so that either
   all data are concatenated into one file regardless of bolometer
   (METHOD=catall) or data for each bolometer is kept separate
   (METHOD=separate). In the latter case, if a file contained data for
   H7 and H9 then two output files would be created (eg test_h7 and
   test_h9 - if the OUT parameter was set to `test') and for each new
   bolometer a new file is created (existing files are overwritten)
   and data is appended to these files when more data for these
   bolometers is supplied.

2 Parameters
For information on individual parameters, select from the list below:
3 BOL
BOL = CHAR (Read)
   If the input file is an NDF (and not an HDS container as
   expected) then this parameter should be given to tell the software
   the bolometer that should be associated with this data.
3 IN
IN = NDF (Read)
   The input dataset(s). This parameter is requested repeatedly
   until a NULL (!) value is given. The input dataset can either
   be output from SCUPHOT or an NDF file. A comma-separated list
   of files is allowed. A text file containing a list of files
   can be specified using the up-carat symbol (^) in 
   front of the text file name.

3 LOOP
LOOP = LOGICAL (Read)
   Turns the looping on (default is true) or off (false)
3 METHOD
METHOD = CHAR (Read)
   Governs whether data from different bolometers are combined
   regardless (CATALL) or written to separate files (SEPARATE).
   Default is `SEPARATE'. The choice of this parameter governs
   the behaviour of the OUT parameter.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 OUT
OUT = CHAR (Write)
   If METHOD=separate this parameter governs the  root name of 
   the output NDF (i.e. <OUT>_bol). If METHOD=catall this
   parameter can be used to specify the actual output file name.
2 Examples
scucat test phot
   This routine will copy the data from phot to test_<bol>,
   reducing multiple bolometers to individual files.
   If the input set contained data
   for bolometer H7 the output file will be test_h7.sdf.
   The program will then ask for another data set.

scucat test ext_long noloop
   This will copy all the data from ext_long.sdf to test_<bol>.sdf
   and will then exit without asking further questions.

scucat outfile 'file1,file2,file3' noloop method=separate
   Concatenate the data from file1, file2 and file3 into output
   files containing the rootname of `outfile'

scucat outfile in=^input.lis noloop method=catall
   This will copy all the data contained in the files listed in
   input.lis and write it to a file called outfile.sdf.

2 Notes
- SCUCAT can process output data from scuphot (eg file.sdf as an
  HDS container containing NDF files with the names <bol>_peak) or
  NDF files.

- If given an NDF the data array is vectorized so that the output
  is 1-dimensional regardless of the shape of the input file.

- This task can also be used to simplify further processing of the
  photometry data even if no data is to be concatenated (in this case
  the task would be identical to the Kappa task NDFCOPY).
2 Related_Applications
   SURF: SCUPHOT;
   KAPPA: NDFCOPY, KSTEST
2 Authors
TIMJ: Tim Jenness (JACH)

2 Implementation_Status
   - NDF sections can not be used

   - All input pixels are propagated to the output file

1 SCUCLIP
Simple sigma clipping for each bolometer

Usage:

   scuclip in out

Description:

   Each bolometer is analysed independently, the mean and standard
   deviation are calculated, any points greater than NSIGMA sigma
   from the mean are treated as spikes and removed. Note that for mapping
   this despiking algorithm is only useful for very weak
   sources; bright sources will be removed (since a bolometer
   jiggles on and off bright sources). Photometry observations
   do not suffer from this problem as the bolometers are always on
   source.
2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = NDF (Read)
   This is the name of the input demodulated data file
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message output level. Default is NORM. If MSG_FILTER is set
   to VERBOSE the number of spikes removed from each bolometer is
   reported.
3 NSIGMA
NSIGMA = DOUBLE (Read)
   Number of sigma beyond which data are thought to be spikes.
3 OUT
OUT = NDF (Write)
   Output data file.
2 Examples
scuclip infile outfile nsigma=5
   Clip any data points that are further than 5 sigma from the mean.
   The clipping is done on a per bolometer basis.
2 Notes
- The despiking routine is very primitive and should not be used
  with jiggle map data of bright sources. It can be used
  on PHOTOM data since the jiggle pattern never moves off source
  (although SIGCLIP can be used once the data has been processed
   by SCUPHOT).
2 Related_Applications
   SURF: SCUQUICK, REBIN, SCUPHOT, SCUOVER, SIGCLIP, DESPIKE;
   KAPPA: SETBB
2 Authors
TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)

2 Implementation_Status
   The despiking routine sets QUALITY bit 5 to bad. It does not affect
   the data. The effects of despiking can be removed by using the
   Kappa task SETBB to unset quality bit 5.


1 SCUCLKERR
Determine the possible error in the times stored in the data header

Usage:

   scuclkerr filename

Description:

   This routine calculates the error in the times stored in the
   data header. It performs a self-consistency check to determine
   the local sidereal time from the Azimuth and elevation information
   (that comes directly from the telescope) and compares this to
   the LST stored in the header.
2 Parameters
For information on individual parameters, select from the list below:
3 CLOCKERR
CLOCKERR = REAL (Write)
   On exit, the clock error, in seconds,  determined from the header.
3 DANG
DANG = REAL (Write)
   Error in the array rotation angle due to the clock error (degrees)
3 DR
DR = REAL (Write)
   Positional error at the edge of the array for this particular
   observation. In arcseconds.
   Edge is defined as a radius of 70 arcseconds.
3 IN
IN = NDF (Read)
   The name of the NDF containing to be tested.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 LAG
LAG = REAL (Write).
   The discrepancy between the LST stored in the FITS header
   and the LST when data acquisition begins. This provides
   a measure of the lag in starting up the observation (including
   slew times). The value is stored in seconds.
3 MJD
MJD = DOUBLE (Write)
   Modified Julian Date of start of observation corrected for the
   lag time and the clock error.
2 Notes
- The calculated clock error is only accurate to about 15 seconds.
2 Copyright
   Copyright (C) 2000 Particle Physics and Astronomy
   Research Council. All Rights Reserved.
2 References
   Jenness T., 2000, JCMT Technical Report TR/001/84
     <http://www.jach.hawaii.edu/JACdocs/JCMT/tr/001/84>
2 Authors
TIMJ: Tim Jenness (JAC)

1 SCULOG
Produce summary of SCUBA observations

Usage:

   sculog [-h] [-summary] [-demod] [-reduced] [-mode ??]
          [-all|[-begin nn -end nn]]

Description:

   Sculog goes through all the sdf files in the current  directory
   and, optionally, DATADIR (defined in an environment  variable)
   and extracts information from any FITS entries that may  be
   present. If a HISTORY record is present (i.e. the data have
   been partially reduced) the most recent application to
   manipulate  the data is reported.

   In the absence of the -all flag, a  numeric range is
   requested. This range only has an effect on raw data or reduced
   files which have the run number embedded into the file
   name. Filenames with no numbers are treated as scan 0.
2 Parameters
For information on individual parameters, select from the list below:
3 -h[elp]
-h[elp]
   Return a help message only. More help can be obtained by using
   `showme sun216' or `scuhelp sculog'.
3 -summary
-summary
   Return a one line summary of each observation file. No HISTORY
   information is reported.
3 -all
-all
   List all files in the current directory and $DATADIR
3 -demod
-demod
   Only list demodulated data files (signified by _dem_ file name)
3 -reduced
-reduced
   Only list reduced data files (signified by _red_ file name)
3 -begin_nn
-begin nn
   First scan number to be considered (same as --begin==nn)
3 -end_nn
-end nn
   Final scan number to be considered (same as --end=nn)
3 -mode_obs
-mode obs
   Select only specified observation modes for listing.
   The list should be comma separated. (same as --mode=obs)
2 Examples
sculog
   Ask for a range of scan numbers and then give a full listing
   of every sdf file matching this criterion in DATADIR and the
   current directory.

sculog -all
   Generate a full listing of all sdf files in the current and
   DATADIR directory.

sculog --begin=5 -end 100
   Generate a detailed log of all data from scans 5 to 100 inclusive.

sculog -summary -all
   Produce a one line summary of all files.

sculog -summary -all -reduced
   Produce a one line summary of all reduced (_red_) files.

sculog -summary -all -reduced > log.txt
   Produce a one line summary of all the reduced files and store
   the output in the text file log.txt (note this example is
   shell specific).

sculog -summary -all -reduced -demod
   Produce a summary of all reduced (_red_) and demodulated (_dem_)
   data files (ie not files produced during off-line data reduction).

sculog -summary -all -mode pointing
   Produce a one line summary of all pointing observations

sculog -summary -reduced --begin=100 --end=200 --mode=photom,skydip
   Produce a one line summary of the photom and skydip observations
   of reduced files with scan numbers 100 to 200. This is similar to
   photsum except that the signal and signal-to-noise will not be
   displayed even if reduced files are being listed.
2 Notes
- sculog only uses information stored in the FITS header of
  reduced and raw data files and does not  provide summaries
  of reduced (RO) data such as photometry results (essentially for
  reasons of clarity). `photsum' must
  be used to generate a summary of photometry observations that
  includes reduced data.

- Files are drawn from the current working directory and the directory
  indicated by the $DATADIR environment variable.

- Data reduced by the off-line system will all be treated as
  run 0 for the purposes of listing unless numbers are present
  in the filename.

- The output can be stored in a file by using unix redirection as
  long as the search range is fully specified (either as `-all' or
  with `-begin' and `-end').

- Command line options can be abbreviated.

- Options that take values can be used either as `-flag option' or
  as `--flag=option'

2 Authors

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)


1 SCUMAKEWT
Create weights array for dual beam deconvolution

Usage:

   scumakewt chop pa pixsize size ftchop wtchop

Description:

   Construct an NDF holding the weights array for a particular
   chop throw and the Fourier Transform (FT) of the chop function
   (a sine wave).
2 Parameters
For information on individual parameters, select from the list below:
3 CHOP
CHOP = REAL (Read)
   Chop throw in arcseconds. There is no default
3 FTCHOP
FTCHOP = NDF (Write)
   Output NDF containing fourier transform of the chop function.
   The size of the output array matches the dimensions supplied
   by parameter SIZE
3 LIKE
LIKE = NDF (Read)
   This parameter may be used to supply an NDF which is to be
   used as a template.  If such a template is supplied, then its
   origin (its lower pixel-index bounds) and extent will be read
   used for the output NDFs. By default no template will be used
   and the size information will be read from the SIZE parameter.
   Additionally, the PA, PIXSIZE and CHOP parameters are searched
   for in the FITS extension if one is present (using keywords
   of CHOP_PA, SCUPIXSZ and CHOP_THR respectively). These parameters
   values are requested if not found in the FITS extension.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 OUTCHOP
OUTCHOP = REAL (Write)
   Chop throw actually used (arcsec).
3 OUTPA
OUTPA = REAL (Write)
   Position angle actually used.
3 OUTPIXSZ
OUTPIXSZ = REAL (Write)
   Actual pixel size used (arcsec).
3 PA
PA = REAL (Read)
   Position angle of chop throw. Positive is anti-clockwise starting
   from North. The angle should be specified in degrees.
3 PIXSIZE
PIXSIZE = INTEGER (Read)
   Pixel size to be used for output images. Should be in arcseconds
   (ie same units as used for the CHOP parameter)
3 SIZE
SIZE( 2 ) = INTEGER (Read)
   Array parameter containing the number of pixels (X, Y)
   in the output images.
3 WTCHOP
WTCHOP = NDF (Write)
   Output NDF containing the weights contributed by this chop
   configuration. This is FTCHOP squared.
   The size of the output array matches the dimensions supplied
   by parameter SIZE
2 Examples
scumakewt 20 90 3 '[256,256]' ft wt
   Generate the FT and weight of a 20 arcsec RA chop using
   3 arcsec pixels and a 256 square output image. The weight
   is written to wt.sdf and the FT to ft.sdf.

scumakewt chop=20 size=[256,512] ftchop=fft wtchop=weights
   Generate the weight and ft of a chop of size 20 arcseconds
   on a 256 x 512 image. The pixel scale will be requested.

2 Authors
JFL: John Lightfoot (jfl@roe.ac.uk)

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)


1 SCUNOISE
Display SCUBA noise data

Usage:

   scunoise [-h | -v | -d] [obsdate] [runnr]

Description:

   Scunoise can read in a directory of noise summaries (the .dat
   files produced by the real-time system) and plot them. A date
   must be supplied so that SCUNOISE can pick up the correct file
   associated with a given run number.
   Once the noise data are displayed the pointer can be moved over
   a point to determine the associated bolometer name. Double
   on the window will bring up a diagram of the array with all
   bolometers above the specified noise level (specified by the position
   of the pointer for the double click) highlighted in a different
   colour.
2 Parameters
For information on individual parameters, select from the list below:
3 -h
-h
   Return a help message only.
3 -v
-v
   Return the version number of scunoise
3 -d
-d
   Switch on debug output
3 obsdate
obsdate
   Observation directory/date (eg. 19980210)
3 runnr
runnr
   SCUBA observation number of noise measurement.
2 Examples
scunoise
   Prompt for date and run number

scunoise 19980210 5
   Display the noise data for observation 5 on 19980210

scunoise 19980315
   Prompt user for observation number, using data from 19980315.
2 Notes
SCUNOISE has been developed for use at the JAC and therefore knows
where to find the archived data. The current directory and $DATADIR
are searched for files when the program is run outside of JAC.

2 Authors

RPT: Remo Tilanus (JACH)

1 SCUOVER
Routine to overlay the bolometer names onto a rebinned image

Usage:

   scuover

Description:

   This routine is used to overlay the array layout onto a rebinned
   SCUBA image. The displayed image is read from the graphics database
   unless a command line value is given. In order to calculate the bolometer
   positions it is also necessary to read in the extinction corrected
   data file that was used to regrid the data (in fact any extinction
   corrected file can be used, possible with strange results).
   By default the position of the bolometers at the start of
   the first integration and zero jiggle offset is plotted. Optionally,
   it is possible to plot the bolometer positions at any point during
   the observation (still with zero jiggle offset).
2 Parameters
For information on individual parameters, select from the list below:
3 COL
COL = LITERAL (Read)
   Colour of overlay (by name or number). The previous value is used
   by default.
3 DEVICE
DEVICE = DEVICE (Read)
   The graphics device on which the bolometers are to be drawn.
   The global default (set with Kappa GDSET) will be used unless
   specified otherwise.
3 EXPOSURE
EXPOSURE = INTEGER (Read)
   Use the bolometer positions at the specified exposure within the
   specified INTEGRATION and MEASUREMENT. For SCAN/MAP data the
   middle of an exposure (ie scan) is used. Default is exposure 1.
3 EXT
EXT = NDF (Read)
   The name of the extinction corrected data from which the bolometer
   positions should be taken.
3 INTEGRATION
INTEGRATION = INTEGER (Read)
   Use the bolometer positions at the specified integration. Default
   is measurement 1.
3 MEASUREMENT
MEASUREMENT = INTEGER (Read)
   Use the bolometer positions at the specified exposure. Default
   is measurement 1.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 NDF
NDF = NDF (Read)
   The name of the regridded data set (taken from the AGI graphics
   database).
3 NAME
NAME = LOGICAL (Read)
   Label with bolometer name if true, else bolometer number. The default
   is true.
2 Examples
scuover
   The bolometer names will be overlaid using the default colour.

scuover col=red noname
   This command will overlay bolometer numbers over the image in red.

scuover integration=2
   Overlay the bolometer positions at the start of the second
   integration.
2 Notes
- An image must have already been displayed before using SCUOVER.

- The array position is always shown with zero jiggle offset.

- This routine does not take into account the use of SHIFT_DX or
SHIFT_DY in REBIN. (the relevant information is not stored in the
rebinned image).

- Pointing shifts are taken into account.
2 Related_Applications
   SURF: REBIN, SCUPA
   KAPPA: DISPLAY, GDSET
   FIGARO: IMAGE
2 Authors
JFL: J.Lightfoot (ROE)

TIMJ: T. Jenness (t.jenness@jach.hawaii.edu)

1 SCUPHOT
Reduce SCUBA PHOTOM data

Usage:

   scuphot analysis in out file

Description:

      This routine reduces the data for a single sub-instrument from a
   PHOTOM observation. For each bolometer used to look at the source the
   data will be analysed as follows:-

    - An ndf called <bolname>_map (e.g. h7_map) will be created in the
      OUT file to hold the coadded data from all the integrations. If the
      jiggle pattern points fit a 2-d rectangular pattern then these data
      will be arranged as a 2-d map suitable for plotting as an image. A
      2-d parabola will be fitted to the coadded image and the results
      written in ASCII form to FILE. If an irregular jiggle pattern is
      used the map will take the form of a 1-D strip.

    - Second, an ndf called <bolname>_peak (e.g. h7_peak) will be created
      in the OUT file to hold the fit results to the data for each
      integration. The results stored are the fit peak, its variance and
      quality and they are held as a 1-d array suitable for plotting as
      a graph. The fit results are also written in ASCII form to FILE, as
      is the coadd of all the individual fits to the data.
2 Parameters
For information on individual parameters, select from the list below:
3 ALLBOLS
ALLBOLS = LOGICAL (Read)
   By default only the observed bolometers are processed (i.e. if you
   observed with H7 only H7 data will be stored). If ALLBOLS is set
   to true then all middle beam data is processed. This is useful
   for examining sky noise. Note that for 2 and 3 bolometer photometry
   ALLBOLS must be false to avoid weighting problems for the
   bolometers that were observed in the left or right beams.
3 ANALYSIS
ANALYSIS = CHAR (Read)
  The method used to determine the peak for each integration.  Either
  average or parabola.  Parabola is not recommended at this
  time. Alternatively, all the samples can be propagated without
  processing (`samples') -- this will give the same result for the
  signal as `average' (since `average' returns a smoothing of all 
  data) but for small datasets may give a more accurate measure of the
  error.  The discrepancy is especially noticeable for calibration
  measurements where N_INTEGRATIONS may only be 6 -- the noise
  statistics on 6 averaged numbers are less reliable than those of
  6 x 9 numbers (assuming 9 samples per integration).


3 FILE
FILE = FILENAME (Write)
   The name of the ASCII output file.
3 IN
IN = NDF (Read)
   The name of the input file containing demodulated (extinction
   corrected) SCUBA data.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message output level. Default is NORM.
3 OUT
OUT = CHAR (Write)
   The name of the HDS output file to contain the NDFs described above.
   This file will have the extension .sdf but this should not be
   specified in the name.
2 Notes
- ALLBOLS must be false for 2 and 3 bolometer photometry unless you
  know what you are doing.

- SCUPHOT can process JIGGLE/MAP data. The output is the signal
  for each integration for each bolometer. This is useful
  for checking sky removal and should not be used for performing
  on-source photometry on map data! This method can not be used
  for SCAN/MAP data.
2 Related_Applications
   SURF: SCUCAT
2 Authors
JFL: John Lightfoot (ROE)

TIMJ: Tim Jenness (JACH)

2 Implementation_Status
   Ideally SCUPHOT should process MAP data on a per exposure basis.
   Currently only per integration is supported.

1 SCUPLOT
Interactive display and despiking

Usage:

   scuplot [-m mode ] [-f sdf_file] [-d sdf_file2] [-s min max] [-l #]
             [bol [bol [bol] ... ]]

Description:

   Scuplot is a wrapper script around a number of kappa
   utilities. Since it understands the Scuba NDF file format, it
   hides most of the complicated syntax from the user.  Mode = `p'
   and `r' are wrappers around plotting utilities and facilitate the
   inspection of the data of each bolometer.  The utility allows
   change to the plot scales via the menu but will keep the scales
   the same for all bolometers which makes is easy to compare
   bolometers. Mode = `d' allows for interactive despiking. Please
   read the note below the description of the menu on the use of the
   mouse.

   Mode = `p' or pltbol (or any p* link to scuplot) is a wrapper
   around the Kappa utility linplot. It allows plots of a whole series
   of bolometers one by one, optionally overlaying them with the same
   bolometer from a second file. Obvious overlays are despiked on
   non-despiked data or data from different exposures to check the
   noise.

   Mode = `r' or rlinplot (or any r* link to scuplot) is a wrapper
   around the Kappa utility mlinplot. It provides plots of sets of
   bolometers in a single window with optionally data from a second
   file in a second window.  Obvious files are despiked and
   non-despiked data or data from different exposures to check the
   noise.

   Mode = `d' or dspbol (or any d* link to scuplot) can be used to
   interactively despike bolometers. While it is not as fast as a
   completely integrated routine would be, it makes interactive
   despiking much easier by hiding the cycle between linplot and
   change_quality for the user. The most common use is to zoom in on
   the region with the spike via the `X' menu option (either typing
   the input or using the cursor) and subsequently to flag the
   offending point (just type the coordinate of the point, a range, or
   use the cursor; IN GENERAL THE COORDINATE IS TO THE RIGHT OF THE
   PLOTTED POINT). The routine will overlay the despiked data, prompt
   the user to accept the new set and de-zoom to the original
   scale. To reset a previously flagged point, flag the point again
   but do NOT accept it: the point will be set to GOOD again.  Please
   read the note below the description of the menu on the use of the
   mouse.

   For each mode the menu items are a subset of:

     [M,H]                 Redisplay menu
     [Q]                   Quit
     [N]                   Next bolometer
     [B#]                  Switch to bol #
     [X min max], [X cen]  X-axis from min:max or cen+/-10
                           Just `x' activates the cursor.
     [R]                   Reset X-axis
     [Y min max], [Y lim]  Y-axis from min:max or -lim:+lim
     [U]                   Reset Y-axis
     [#], [#:#], [#-#]     Despike point or range of points;
                           Just `p' activates the cursor.

     Option >

   Note that a X center defined with the cursor or [X cen] defaults to
   a 20 points window around cen, the position of the spike. Using the
   CURSOR, the Left Mouse button always defines the point, the Right
   Mouse button exits the cursor task while accepting the last point
   clicked.
2 Parameters
For information on individual parameters, select from the list below:
3 -h[elp]
-h[elp]
   Print the help information.
3 -m_mode:
-m      mode:
   Select usage mode:
     p: plot bolometers one by one, optionally overlaid with
        data from the second input file (equivalent to PLTBOL)
     d: interactively despike the data for the bolometers in
        specified file (equivalent to DSPBOL).
     r: same as 'p' except that a whole set of bolometers is
        plotted in a window (equivalent to RLINPLOT).
3 -f_file
-f file
   name of SDF file (.sdf may be included in the name).
3 -d_file2
-d file2
   name of a second file: e.g. the despiked version of the SDF
   file. The same bolometers will be plotted in a second window or
   overlaid for comparison.
3 -s_min_max
-s min max
   Y-axis scales for plot (can be changed via menu).
3 -l_#
-l #
   number of bolometers per window
3 bol
bol
   list of bolometers to plot. Type 'all' for 1..37 and 'alls'
   for 1..91. Can be added via menu if mode = 'r'.
2 Examples
scuplot
   The user will be asked for a mode and input file before proceeding.

scuplot -m d -f o39_lon_ext
   Interactive despiking on o39_lon_ext.sdf (see also DSPBOL)

scuplot  -m p -f s14_lon_ext 12 13 18 20 25 26 19
   Enter p mode and use file s14_lon_ext.sdf. Plot bolometers 12,13,
   18, 20, 25, 26 and 19.
2 Notes
- Can not handle blanked bolometers.

- If the overlay comes up scrambled, delete the agi_xxx files
  in your home directory and if that does not work also files like
  linplot.sdf in the /home/you/adam subdirectory.
2 Related_Applications
   SURF: PLTBOL, DSPBOL, RLINPLOT, CHANGE_QUALITY
   KAPPA: LINPLOT, MLINPLOT, CURSOR
2 Authors
R.P.J. Tilanus (JACH)

2 Bugs
   Freezes when asked to plot a bad bolometer.

1 SCUQUICK
automate the basic SCUBA data reduction

Usage:

   scuquick [-quick] [-tau|notau] NDF [PARAM=value]

Description:

   This script attempts to automate the first 3 steps of scuba data
   reduction. This script runs REDUCE_SWITCH, CHANGE_FLAT (if
   requested), FLATFIELD on the data. Then for each sub-instrument
   EXTINCTION, SCUPHOT (if a photometry observation), REMSKY
   (if requested) and REBIN (if requested) are used.
   The output name for each task is related to the task and
   current sub-instrument (see Notes).
2 Parameters
For information on individual parameters, select from the list below:
3 -help
-help
   Print the help message.
3 -quick
-quick
   This flag makes all of the SURF tasks run with the `accept'
   flag (see SUN/95) so that default values are accepted for all
   parameters unless specified on the command line.
3 -quiet
-quiet
   Hide all messages generated by the script (note this is
   not the same as using MSG_FILTER=quiet which hides messages
   from the tasks)
3 -tau_value
-tau value
   Run extinction with a tau of `value'. (the LST range is set
   automatically since we are using a constant tau) Note that this
   is dangerous when processing multiple sub-instruments. (Same
   as --tau=value).
3 -notau
-notau
   Run extinction with a zero value of tau (the LST range is set
   for you). This is equivalent to using the --tau=0.0 option.
3 -sub_sub_instrument
-sub sub_instrument
   Only process the specified sub instrument. This is equivalent
   to setting the SUB_INSTRUMENT parameter explicitly. (same
   as --sub=sub_instrument)
3 -change_flat
-change_flat
   Invoke the CHANGE_FLATFIELD task after REDUCE_SWITCH
3 -remsky
-remsky
   Invoke the REMSKY task after EXTINCTION
3 -rebin
-rebin
   Invoke the REBIN package after EXTINCTION (or REMSKY)
3 NDF
NDF
   The required dataset. This parameter is optional - REDUCE_SWITCH
   will ask for an input file if no value is given.
3 ADAM_parameters
ADAM parameters = Any
   Any parameters accepted by the individual routines as long as they
   use PARAM=VALUE format.
2 Examples
scuquick
   When run this way, REDUCE_SWITCH will ask for the input file name
   and for the output root name. FLATFIELD will then run followed
   by EXTINCTION on each sub-instrument. Each task will ask questions
   as needed.

scuquick -quick
   Same as scuquick except that defaults will be assumed for all
   parameters that have defaults.

scuquick -rebin
   Process as for scuquick except that REBIN is run on each
   sub-instrument.

scuquick -quick jun02_dem_0002
   Process the input file jun02_dem_0002.sdf, accepting all defaults.

scuquick -quick jun02_dem_0003 MSG_FILTER=QUIET
   Process jun02_dem_0003.sdf, accepting all defaults and turning off
   all but the most important messages from the SURF tasks.

scuquick -quick -notau -rebin temp OUT=root
   Process temp.sdf with zero extinction correction, accept all
   defaults, use 'root' as the default filename and regrid.

scuquick -remsky -change_flat --sub=long
   Run the REMSKY and CHANGE_FLAT tasks in addition to the standard
   tasks but only process the LONG sub-instrument.

scuquick -rebin -quick MSG_FILTER=QUIET PIXSIZE_OUT=1 test OUT=temp
   Process test.sdf. Accept all defaults. Use `temp' as the filename
   root. Regrid all data onto a 1 arcsecond grid. Hide all messages
   from the SURF tasks.
2 Notes
Given a rootname (specified with OUT=root)
SCUQUICK produces the following files:

- root.sdf  from REDUCE_SWITCH

- root_flat.sdf from FLATFIELD

- root_<sub>_ext.sdf from EXTINCTION (one for each sub)
                
- root_<sub>_sky.sdf from REMSKY (with the -remsky switch)
                
- root_<sub>_reb.sdf from REBIN (with the -rebin switch)
                
- root_<sub>_pht.sdf from SCUPHOT (if processing a PHOTOM observation)
                
- root_<sub>_pht.dat from SCUPHOT (if processing a PHOTOM observation)

Where <sub> is the first three letters of the sub-instrument name.
Using the -tau switch is dangerous when processing multiple
sub-instruments since the extinction changes with wavelength.

- Command line options can be abbreviated.

- Options that take values can be used either as `-flag option' or
  as `--flag=option'

- Skydip data are recognized.

2 Prior_requirements
   - The NDF perl module must exist (this should be installed by
     your system administrator if it is missing).
2 Related_Applications
   SURF: REDUCE_SWITCH, CHANGE_FLAT, FLATFIELD, EXTINCTION, REBIN, REMSKY,
         SCUPHOT

2 Authors

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)


1 SCUSETENV
Set the startup environment variables for SURF

Usage:

   scusetenv [UTdate]

Description:

   This script sets the standard DATADIR and SCUBA_PREFIX
   environment variables given a UT date.
2 Examples
scusetenv
   Set DATADIR and SCUBA_PREFIX for the current UT date

scusetenv 19980201
   Set DATADIR and SCUBA_PREFIX for the data observed on date
   19980201
2 Notes
- Currently this routine only works for the JAC and JCMT systems.
  This is because the data are stored in standard
  directories and indexed by YYYYMMDD UT date.

- ORAC_DATA_IN environment variable is also set (only relevant
  for users of the ORAC-DR pipeline)

- If this routine is run from a non-JAC/JCMT site DATADIR
  will not be set but SCUBA_PREFIX will be set.
2 Parameters
   UTdate = YYYYMMDD format string (Optional)
     The UT date of the data to be processed (in YYYYMMDD format).
     The default value is to use the current UT date
2 Authors
Tim Jenness (JACH)

1 SCUSHIFT
Correct for data shift error in demodulated data files

Usage:

   scushift [-h] NDF card shift

Description:

   This script corrects for the DAQ communications error and shifts
   the data from ADC cards along by a specified amount.
   Since all channels are read from a particular ADC card but only some
   of them are actually stored in the demodulated data file, the shift
   may result in fewer bolometers being stored for a given sub-instrument.
2 Parameters
For information on individual parameters, select from the list below:
3 -h
-h
   Help information
3 NDF
NDF (Given)
   The input files to be modified.
3 card
card
   The letter identifying the A-to-D card (allowed values are A to I)
3 shift
shift
   The number of bolometers to shift by. A negative shift moves
   D1 to D16 (for example) and a positive shift D1 to D2. In most
   cases a negative shift is required (usually -1).
2 Examples
scushift test i -2
   Move the I card data of test.sdf by minus 2 bolometers

scushift test2 h 1
   Move the H-card data by plus 1 bolometer.
2 Notes
- EXTINCTION must not have been run on the input NDF.

- Arguments are requested if they are missing from the command line

- If the system stores channels 1,2,3,6,7,8,10 but we know that we
  have a shift of -1 in the system (ie an extra byte is present).
  This implies that we have actually stored channels 16,1,2,5,6,7,9
  and if  only bolometers 1,2,6,7 are from the required sub-instrument
  we have to throw away data from channels 15,5 and 9.

- The DAQ hardware fault always introduced extra bytes and therefore
  a negative shift should be used in scushift.

- Currently PHOTOMETRY data is not corrected properly (the PHOT_BB
  extension is not modified so the correct bolometer will not be
  extracted by SCUPHOT). This can be overcome by using the
  ALLBOLS parameter in SCUPHOT.
2 Author
   Tim Jenness (JACH)


1 SDIP
Reduces and displays skydip data

Usage:

   sdip [NDF]

Description:

   This script first runs the skydip task in order to fit the sky
   parameters to the data. The sky data and model are written to files
   and are then displayed using Kappa's linplot.
2 Parameters
For information on individual parameters, select from the list below:
3 NDF
NDF = NDF (Read)
   Name of raw data file, or if $SCUBA_PREFIX is set, the number of the
   observation (raw demodulated data only). Can be located in $DATADIR. 
   The filename will be requested if not specified on the command line.
2 Examples
sdip 19970623_dem_0008
   Reduce the skydip data in 19970623_dem_008.sdf and plots the result.
2 Related_Applications
   SURF: SKYDIP;
   KAPPA: LINPLOT
2 Authors
Tim Jenness (JACH)

2 Implementation_Status
   - Requires Kappa.

   - All files created by this task are removed.


1 SETBOLWT
Calculate or set bolometer weights

Usage:

   setbolwt [-h] [-wtfile=] [-filelist=] filenames...

Description:

   This routine sets the bolometer weights.
   It can do this in two ways:

    1. Calculate the statistics for each bolometer then generate the
       weights relative to the central pixel. Should not be used when
       a strong source is present. The weights are calculated by
       using Kappa STATS to calculate the standard deviation of
       each bolometer in turn. The weight is defined as the relative
       variance between this bolometer and the reference bolometer.

    2. Read the weights from a text file using the -wtfile option.

   Writes to the BOLWT extension. This extension is then read by REBIN.

   Multiple files can be referenced to the first file by specifying
   multiple files on the command line or by using a REBIN-style input
   file and the -filelist option. In conjunction with the -wtfile option
   all input files are given the same weights.
2 Parameters
For information on individual parameters, select from the list below:
3 -h
-h
   Return a usage message.
3 -wtfile
-wtfile=file
   An ASCII text file containing the weights, one weight per line
   corresponding to the order of bolometers stored in the file.
3 -filelist
-filelist=file
   An ASCII text file containing a list of files to be processed.
   There must be one file per line and it must be in a form
   acceptable to REBIN (ie comments can be included).
3 filenames
filenames
   List of filenames to be processed. Wild cards can be used.
   eg *_lon_ext.sdf.
2 Examples
setbolwt
   The user will be prompted for a list of input NDFs. The weights
   will be calculated by setbolwt.

setbolwt -wtfile=weights.dat file1
   Set the weights in file1.sdf from the list contained in
   weights.dat

setbolwt file1 file2 file3 file4
   Calculate the weights of each bolometer in all four files
   relative to the central pixel in file1.sdf.

setbolwt -wtfile=wt.dat -filelist=rebin.inp
   Set the weights of the files listed in rebin.inp to those
   stored in wt.dat (same weights for each file).
2 Notes
- Input files must have been extinction corrected so that only
  one sub-instrument is present per file.

- When multiple files are used bolometers are compared to the
  central bolometer of the first file.

- If source signal is present in any bolometer at a level
  significantly above the noise, the automatic weighting will
  be skewed (in fact the bolometer with the source signal will
  be down-weighted relative to all the others since the standard
  deviation on the bolometer will be much higher.). The weights
  must be set via an external file in this case.
2 Related_Applications
   SURF: REBIN
   KAPPA: STATS

2 Authors

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)


1 SIGCLIP
Clip a dataset at n-sigma

Usage:

   sigclip NDF SIGMA

Description:

   This program uses kappa STATS to calculate mean and standard
   deviation of an NDF. It then uses kappa THRESH to set the values at +/-
   n-sigma to BAD. The clipped data are written to NDF_clip.sdf.
2 Parameters
For information on individual parameters, select from the list below:
3 NDF
NDF (Given)
   The required dataset
3 SIGMA
SIGMA = REAL (Given)
   The clipping level
2 Examples
sigclip test 3.0
   Clips test.sdf at +/-3.0 sigma and writes the data to
   test_clip.sdf.
2 Notes
The $KAPPA_DIR environment variable must point to the location
of the KAPPA binaries (this is usually done during a Starlink login).
2 Related_Applications
   SURF: SCUCAT, SCUPHOT;
   KAPPA: STATS, THRESH
2 Implementation_Status
   - The program must have two arguments. Parameters are not requested
     if an argument is omitted from the command line.
2 Authors

TIMJ: Tim Jenness (t.jenness@jach.hawaii.edu)


1 SKYDIP
calculate sky properties from SCUBA skydip data

Usage:

   skydip in sub_instrument t_cold eta_tel b_fit out model_out

Description:

   This application takes raw SKYDIP data and calculates tau, eta_tel
   and B by fitting. Sky brightness temperatures are calculated for
   different airmasses and then fitted with a model of the sky.

2 Parameters
For information on individual parameters, select from the list below:
3 IN
IN = NDF (Read)
   The name of the raw skydip data file or, if $SCUBA_PREFIX is set,
   the number of the observation (raw demodulated data only). Can be located
   in $DATADIR.
3 B_ERR
B_ERR = REAL (Write)
   Error in the fitted value of B. Set to bad if the fit has failed.
3 B_FIT
B_FIT = REAL (Write)
   The fitted value of the B parameter (filter transmission). Set to bad if
   fit fails.
3 B_VAL
B_VAL = REAL (Read)
   The B parameter (filter transmission). This efficiency factor
   must be between 0 and 1. A negative value allows this parameter
   to be free.
3 CVAR
CVAR = LOGICAL (Read)
   This parameter governs whether the points are fitted with a constant
   variance for all points (true) or the variance derived from the 
   scatter in the individual integrations (false). The value used for
   the fixed variance is the mean of all the calculated variances.
3 ETA_TEL
ETA_TEL = REAL (Read)
   The telescope efficiency. If available the current telescope value 
   is used as the default.  Values must be between 0 and 1.0. 
   A negative value allows this parameter to be free.
   For data taken before 26 April 2000, the default values supplied
   for 850 and 450 are provided by the routine rather than being
   read from the FITS header.3 ETA_TEL_ERR
ETA_TEL_ERR = REAL (Write)
   Error in the fitted value of ETA_TEL. Set to bad if the fit has failed.
3 ETA_TEL_FIT
ETA_TEL_FIT = REAL (Write)
   The fitted value of ETA_TEL. Set to bad if the fit fails.
3 GOODFIT
GOODFIT = LOGICAL (Write)
   Flag to indicate whether the fit was good (TRUE) or bad (FALSE).
3 MODEL_OUT
MODEL_OUT = CHAR (Write)
   The name of the output file that contains the fitted sky
   temperatures.
3 MSG_FILTER
MSG_FILTER = CHAR (Read)
   Message filter level. Default is NORM.
3 OUT
OUT = CHAR (Write)
   The name of the output file that contains the measured
   sky temperatures.
3 RESIDUAL (Write)
   Absolute difference between the model and the data in Kelvin.
   i.e. Sum( Abs(Data - model) )
3 SIGMA
SIGMA = REAL (Write)
  Standard deviation of the residuals of the fit (Kelvin).
3 SUB_INSTRUMENT
SUB_INSTRUMENT = CHAR (Read)
   The name of the sub-instrument whose data are to be
   selected from the input file and fitted. Permitted
   values are SHORT, LONG, P1100, P1350 and P2000
3 TAUZ_ERR
TAUZ_ERR = REAL (Write)
   Error in the fitted value of TAUZ. Set to bad if the fit has failed.
3 TAUZ_FIT
TAUZ_FIT = REAL (Write)
   The fitted sky opacity for the selected sub instrument.
3 T_COLD
T_COLD = REAL (Read)
   Temperature of the cold load. The default value is
   taken from the input file.
3 T_HOT
T_HOT = REAL (Read)
   Temperature of the hot load. The default 
   value is taken from the input file.
3 WAVELENGTH
WAVELENGTH = REAL (Write)
   The wavelength of the sub instrument used.
3 XISQ
XISQ = REAL (Write)
  The reduced chi square of the fit. The nature of the error
  determination forces the reduced $\chi^2$ to be approximately 1. The
  SIGMA parameter provides a better guide to the goodness of fit.
2 Examples
skydip jun10_dem_0002 short \
   Process the short sub-instrument using the default value
   for T_COLD and allowing ETA_TEL and B to be free parameters.
   No output files are written.

skydip 19970610_dem_0003 long eta_tel=0.9 out=sky model_out=model \
   Process the long wave sub-instrument with ETA_TEL fixed at 0.9
   and B free. Write the sky temperature to sky.sdf and the fitted
   model to model.sdf.
2 Notes
If the input file is not found in the current directory, the directory
specified by the DATADIR environment variable is searched. This means
that the raw data does not have to be in the working directory.
In addition IN accepts a number. This number is converted to a
demodulated data filename by prepending it with information specified in
the SCUBA_PREFIX environment variable. This filename expansion only
works for demodulated data (ie data containing _dem\_). The
_dem_ is assumed and should not be present in SCUBA_PREFIX.

If the CVAR parameter is true the reduced chi^2 value can not
be used to compare the goodness of fit between datasets.

Both RASTER and DISCRETE skydips are supported.

2 Related_Applications
   SURF: EXTINCTION, SDIP, SKYSUM
2 Authors
TIMJ: T. Jenness (t.jenness@jach.hawaii.edu)

Nick Tothill (QMW)

1 SKYSUM
Produce a one-line summary of SCUBA skydip observations

Usage:

   skysum [-h] [-demod] [-reduced] [-all|[-begin nn -end nn]]

Description:

   Skysum goes through all the sdf files in the current  directory
   and, optionally, DATADIR (defined in an environment  variable)
   and summarizes files containing pointing observations.

   In the absence of the -all flag, a  numeric range is
   requested. This range only has an effect on raw data or reduced
   files which have the run number embedded into the file
   name. Filenames with no numbers are treated as scan 0.
2 Parameters
For information on individual parameters, select from the list below:
3 -h[elp]
-h[elp]
   Return a help message only. More help can be obtained by using
   `showme sun216' or `scuhelp skysum'.
3 -all
-all
   List all skydip files in the current directory and $DATADIR
3 -demod
-demod
   Only list demodulated data files (signified by _dem_ file name)
3 -reduced
-reduced
   Only list reduced data files (signified by _red_ file name)
3 -begin_nn
-begin nn
   First scan number to be considered (same as --begin==nn)
3 -end_nn
-end nn
   Final scan number to be considered (same as --end=nn)

2 Examples
skysum
   Ask for a range of scan numbers and then give a full listing
   of every skydip file matching this criterion in DATADIR and the
   current directory.

skysum -all
   Generate a summary of all skydip files in the current and
   DATADIR directory.

skysum --begin=5 -end 100
   Generate a detailed log of all skydip data from scans 5 to 100 inclusive.

skysum -all -reduced
   Produce a one line summary of all reduced (_red_) skydip files.

skysum -all -reduced > log.txt
   Produce a one line summary of all the reduced skydip files and store
   the output in the text file log.txt (note this example is
   shell specific).

skysum -all -reduced -demod
   Produce a summary of all reduced (_red_) and demodulated (_dem_)
   skydip data files (ie not files produced during off-line data reduction).


2 Notes

- Files are drawn from the current working directory and the directory
  indicated by the $DATADIR environment variable.

- Data reduced by the off-line system will all be treated as
  run 0 for the purposes of listing unless numbers are present
  in the filename.

- The output can be stored in a file by using unix redirection as
  long as the search range is fully specified (either as `-all' or
  with `-begin' and `-end').

- Command line options can be abbreviated.

- Options that take values can be used either as `-flag option' or
  as `--flag=option'

2 Authors

T. Jenness (JACH)
