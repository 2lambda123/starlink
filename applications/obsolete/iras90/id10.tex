\documentstyle{article}
\pagestyle{myheadings}

%------------------------------------------------------------------------------
\newcommand{\irasdoccategory}  {IRAS90 Document}
\newcommand{\irasdocinitials}  {ID}
\newcommand{\irasdocnumber}    {10.2}
\newcommand{\irasdocauthors}   {D.S. Berry}
\newcommand{\irasdocdate}      {11th February 1992}
\newcommand{\irasdoctitle}     {MAPCRDD -  Mapping algorithms}
%------------------------------------------------------------------------------

\newcommand{\irasdocname}{\irasdocinitials /\irasdocnumber}
\renewcommand{\_}{{\tt\char'137}}     % re-centres the underscore
\markright{\irasdocname}
\setlength{\textwidth}{160mm}
\setlength{\textheight}{240mm}
\setlength{\topmargin}{-5mm}
\setlength{\oddsidemargin}{0mm}
\setlength{\evensidemargin}{0mm}
\setlength{\parindent}{0mm}
\setlength{\parskip}{\medskipamount}
\setlength{\unitlength}{1mm}

%------------------------------------------------------------------------------
% Add any \newcommand or \newenvironment commands here
%------------------------------------------------------------------------------

\begin{document}
\thispagestyle{empty}
SCIENCE \& ENGINEERING RESEARCH COUNCIL \hfill \irasdocname\\
RUTHERFORD APPLETON LABORATORY\\
{\large\bf IRAS90\\}
{\large\bf \irasdoccategory\ \irasdocnumber}
\begin{flushright}
\irasdocauthors\\
\irasdocdate
\end{flushright}
\vspace{-4mm}
\rule{\textwidth}{0.5mm}
\vspace{5mm}
\begin{center}
{\Large\bf \irasdoctitle}
\end{center}
\vspace{5mm}
\setlength{\parskip}{0mm}
\tableofcontents
\setlength{\parskip}{\medskipamount}
\markright{\irasdocname}

\section{Producing a Surface Brightness Image}
MAPCRDD produces a surface brightness image of some part of the sky, divided
into a finite number of pixels. Let these pixel values be $f_{j}$ where $j$ goes
from 1 to $M$, the number of pixels in the image. Let the mean surface
brightness of the {\em sky} averaged over the area covered by pixel $j$ be
$g_{j}$. The finite resolution of the image will cause $f_{j}$ and $g_{j}$ to be
different.

If the image is made up from $N$ CRDD samples with values $D_{k}$ (where $k$ is
in the range 1 to $N$), then each sample value can be represented (ignoring
noise) by the equation:

\begin {equation}
D_{k}=\Omega_{k}.\sum_{j=1}^{M} P_{jk}.g_{j}
\end {equation}

where $\Omega_{k}$ is the effective solid angle of the detector in steradians,
and $P_{jk}$ is the response of sample $k$ to sky pixel $j$. The $P_{jk}$ values
are normalised so that

\begin {equation}
\sum_{j=1}^{M} P_{jk} = 1.0
\end {equation}

Each CRDD sample is a measure of flux (or flux density), but can be converted to
a measure of surface brightness by dividing the sample value by it's effective
solid angle. The resulting surface brightness value is a measure of the typical
sky brightness over the sky area to which the sample was sensitive (i.e the sky
pixels for which $P_{jk}$ is greater than zero).

If the detector centre position for each CRDD sample is mapped into the frame of
the output image from MAPCRDD, they will be unevenly distributed across the
image. To estimate the surface brightness of a single pixel in the map
($f_{j}$), one should look at the nearby CRDD samples. Each sample will give a
different estimate for the mean sky surface brightness in that area. Obviously,
greater importance should be put on the sample values which are closest to the
pixel, and possibly on sample values which are more accurate. MAPCRDD forms each
output pixel value as the weighted mean of all nearby input data samples.

\begin{equation}
f_{j}=\frac{\sum_{k=1}^{N}W_{kj}.(\frac{D_{k}}{\Omega_{k}})}
{\sum_{k=1}^{N}W_{kj}}
\label {EQ:FJ}
\end{equation}

where $f_{j}$ is the $j$th pixel value in units of $Jy/Sr$, $D_{k}$ is the value
of the $k$th input data sample in units of Janskys, $\Omega_{k}$ is the solid
angle of the $k$th input data sample in units of steradians, $W_{kj}$ is the
weight of the $k$th input data sample at the $j$th output pixel, $N$ is the
number of input data samples.

MAPCRDD provides two weighting schemes:
\begin{enumerate}
\item All image pixels which lie within the geometric area of the detector mask
corresponding to a particular CRDD sample are given an equal weight, and all
other pixels are given a weight of zero. In this case, a pixel is only affected
by those CRDD samples for which the corresponding mask area includes the pixel
in question. Pixels which lie {\em partially} inside the detector mask are given
a weight in proportion to the fraction of the pixel area which lies within the
detector mask.
\item A sample is given a weight which is a Gaussian function of the
displacement from the pixel to the detector centre. Thus samples which are
further away from the pixel get a lower weight than those closer to the pixel.
The displacement has an in-scan component and a cross-scan component, each
component having its own Gaussian with independent FWHM. The final weight is the
product of the in-scan and cross-scan Gaussian functions. This scheme is further
modified by clipping the Gaussian functions to zero at the edges of the
geometric mask of the detector. Again, the weight assigned to pixels which lie
{\em partially} inside the detector mask is reduced in proportion to the
fraction of the pixel area which lies outside the detector mask.

\end{enumerate}

In either case, the weights are initially normalize so that the total weight of
each sample is unity (but see section \ref {SEC:ACC}), that is:

\begin{equation}
\sum_{j=1}^{M}W_{kj}=1.0
\label {EQ:WS}
\end{equation}
for all $k$.

The ``ideal'' weighting scheme (in the least squares sense) is one in which the
weight of each sample value is equal to the response of the detector to a sky
pixel at the same position as the image pixel. This scheme is not supported by
MAPCRDD.

In practice, the first step to mapping a CRDD sample into an image is to find
the detector centre and orientation within the image frame. The geometric
boundary of the detector mask can then be ``traced'' over the pixel array, as
illustrated in the following diagram:

\setlength{\textwidth}{190mm}
\setlength{\unitlength}{0.5mm}
\begin{picture}(190,170)
\thinlines
\put(19,0){\line(0,1){152}}
\put(38,0){\line(0,1){152}}
\put(57,0){\line(0,1){152}}
\put(76,0){\line(0,1){152}}
\put(95,0){\line(0,1){152}}
\put(114,0){\line(0,1){152}}
\put(133,0){\line(0,1){152}}
\put(152,0){\line(0,1){152}}
\put(171,0){\line(0,1){152}}
\put(0,19){\line(1,0){190}}
\put(0,38){\line(1,0){190}}
\put(0,57){\line(1,0){190}}
\put(0,76){\line(1,0){190}}
\put(0,95){\line(1,0){190}}
\put(0,114){\line(1,0){190}}
\put(0,133){\line(1,0){190}}
\thicklines
\put(105,86){\makebox(0,0){x}}
\put(82.8,47.2){\line(3,2){66.6}}
\put(60.8,80.7){\line(3,2){66.6}}
\put(82.8,47.2){\line(-2,3){22.2}}
\put(149.8,91.2){\line(-2,3){22.2}}
\end{picture}
\setlength{\textwidth}{160mm}

The above diagram shows an array of image pixels with the outline of a detector
mask superimposed, centred on the symbol ``\verb+x+''.


Having positioned the sample within the image frame, the next task is to
evaluate the weights $W_{kj}$ to be assigned to each pixel. To do this
the mask area is divided up into rectangular ``sectors'' which ideally
are much smaller than a pixel. These sectors have edges which are parallel to
the mask edges, rather than the image edges, as shown in the diagram below.

\setlength{\textwidth}{190mm}
\setlength{\unitlength}{0.5mm}
\begin{picture}(190,170)
\thinlines
\put(19,0){\line(0,1){152}}
\put(38,0){\line(0,1){152}}
\put(57,0){\line(0,1){152}}
\put(76,0){\line(0,1){152}}
\put(95,0){\line(0,1){152}}
\put(114,0){\line(0,1){152}}
\put(133,0){\line(0,1){152}}
\put(152,0){\line(0,1){152}}
\put(171,0){\line(0,1){152}}
\put(0,19){\line(1,0){190}}
\put(0,38){\line(1,0){190}}
\put(0,57){\line(1,0){190}}
\put(0,76){\line(1,0){190}}
\put(0,95){\line(1,0){190}}
\put(0,114){\line(1,0){190}}
\put(0,133){\line(1,0){190}}
\thicklines
\put(105,86){\makebox(0,0){x}}
\put(82.8,47.2){\line(3,2){66.6}}
\put(78.4,53.9){\line(3,2){66.6}}
\put(74.0,60.6){\line(3,2){66.6}}
\put(69.6,67.3){\line(3,2){66.6}}
\put(65.2,74.0){\line(3,2){66.6}}
\put(60.8,80.7){\line(3,2){66.6}}

\put(82.8,47.2){\line(-2,3){22.2}}
\put(89.5,51.6){\line(-2,3){22.2}}
\put(96.2,56.0){\line(-2,3){22.2}}
\put(102.9,60.4){\line(-2,3){22.2}}
\put(109.6,64.8){\line(-2,3){22.2}}
\put(116.3,69.2){\line(-2,3){22.2}}
\put(123.0,73.6){\line(-2,3){22.2}}
\put(129.7,78.0){\line(-2,3){22.2}}
\put(136.4,82.4){\line(-2,3){22.2}}
\put(143.1,86.8){\line(-2,3){22.2}}
\put(149.8,91.2){\line(-2,3){22.2}}
\end{picture}
\setlength{\textwidth}{160mm}

Each sector has a corresponding weight value $s_{i}$ (where $i$ goes from $1$ to
the number of sectors) which is pre-computed before the mapping process starts.
These sector weight values are calculated using one of the two methods described
in the previous section (i.e. either all sector weights are equal or they vary
as a 2-dimensional Gaussian function), and are normalised so that they have a
sum of unity. A temporary pixel grid is created to hold the pixel weights, and
the pixel values are set to zero. The sector weights are then binned into the
pixel grid (i.e. each sector weight is summed into the total weight of the
closest pixel).

Ideally, a new set of pixel weights should be calculated for each sample,
because of the fact that the alignment of the sector and pixel grids will have
changed. In the previous diagram, the centre of the sector grid (marked by the
\verb+x+ symbol) was positioned at the centre of a pixel, in the following
diagram it is positioned towards a corner of a pixel, and the weights will be
different in each pixel as a result:

\setlength{\textwidth}{190mm}
\setlength{\unitlength}{0.5mm}
\begin{picture}(190,170)
\thinlines
\put(19,0){\line(0,1){152}}
\put(38,0){\line(0,1){152}}
\put(57,0){\line(0,1){152}}
\put(76,0){\line(0,1){152}}
\put(95,0){\line(0,1){152}}
\put(114,0){\line(0,1){152}}
\put(133,0){\line(0,1){152}}
\put(152,0){\line(0,1){152}}
\put(171,0){\line(0,1){152}}
\put(0,19){\line(1,0){190}}
\put(0,38){\line(1,0){190}}
\put(0,57){\line(1,0){190}}
\put(0,76){\line(1,0){190}}
\put(0,95){\line(1,0){190}}
\put(0,114){\line(1,0){190}}
\put(0,133){\line(1,0){190}}
\thicklines
\put(113,94){\makebox(0,0){x}}
\put(90.8,55.2){\line(3,2){66.6}}
\put(86.4,61.9){\line(3,2){66.6}}
\put(82.0,68.6){\line(3,2){66.6}}
\put(77.6,75.3){\line(3,2){66.6}}
\put(73.2,82.0){\line(3,2){66.6}}
\put(68.8,88.7){\line(3,2){66.6}}

\put(90.8,55.2){\line(-2,3){22.2}}
\put(97.5,59.6){\line(-2,3){22.2}}
\put(104.2,64.0){\line(-2,3){22.2}}
\put(110.9,68.4){\line(-2,3){22.2}}
\put(117.6,72.8){\line(-2,3){22.2}}
\put(124.3,77.2){\line(-2,3){22.2}}
\put(131.0,81.6){\line(-2,3){22.2}}
\put(137.7,86.0){\line(-2,3){22.2}}
\put(144.4,90.4){\line(-2,3){22.2}}
\put(151.1,94.8){\line(-2,3){22.2}}
\put(157.8,99.2){\line(-2,3){22.2}}
\end{picture}
\setlength{\textwidth}{160mm}

Calculating these weights for every sample is time consuming, and the need to do
this can be avoided by storing sets of pre-computed pixel weights for several
different offsets between pixel and sector grids. When mapping a sample value,
the set of pixel weights used is that for which the offset is closest to the
offset between the sample centre and the centre of the closest pixel.

These sets of pixel weights assume some particular orientation and image scale.
Both these values can change slightly over the course of a long scan (of
several degrees), thus invalidating the pixel weights. For this reason, a check
is made for each sample that the orientation and image scale have not changed
significantly since the last sets of pixel weights were calculated. If some
significant change {\em is} found, then new pixel weights are calculated.

Having found the sample weight $W_{kj}$ associated with each pixel, the weight
is multiplied by the sample's surface brightness value $(D_{k}/\Omega_{k})$ and
summed into a pixel grid holding the running sum of these values. The weight
itself is summed into another pixel grid holding the the running sum of the
weights. After all samples have been mapped, the first pixel grid is divided by
the second to get the properly normalised surface brightness image.

\subsection{Small Detectors}
If a small detector was given the same total weight as a full sized detector,
then the small detector's weight {\em per pixel} in the output image would be
greater than that of the full size detector (the small detectors weight is
divided between fewer pixels). Pixels which had contributions from both small
and full size detectors would thus be unduly influenced by the small detector
values. To get round this, the total weight assigned to a detector (i.e. the sum
of the pixel weights) is reduced in proportion to the detector size, thus giving
the same weight per pixel to both small and full size detectors.

\subsection{Weighing the more Accurate CRDD Samples}
\label {SEC:ACC}
CRDD files may contain variance values $V_{k}$ associated with each CRDD sample
$D_{k}$. In this case, the variance of the surface brightness estimate
$(D_{k}/\Omega_{k})$ is $V_{k}.\Omega_{k}^{-2}$. In order to give greater weight
to the more accurate samples, the weights $W_{kj}$ in equations \ref{EQ:FJ} and
\ref{EQ:WS} should be replaced by $W^{\prime}_{kj}$  where

\begin{equation}
W^{\prime}_{kj}=\frac{W_{kj}}{V_{k}.\Omega_{k}^{-2}}
\label {EQ:WKJ}
\end{equation}

\section{Estimating the Variance of each Output Pixel Value}
\label {SEC:VAR}
There are two ways of producing a variance estimate $\sigma^{2}_{j}$ for each
output pixel value $f_{j}$:

\begin{enumerate}

\item

Using the input variances $V_{k}$:

\begin{equation}
\sigma^{2}_{j}=\frac{\sum_{k=1}^{N} W^{\prime^{2}}_{kj}.(V_{k}.\Omega_{k}^{-2})}
{(\sum_{k=1}^{N}W^{\prime}_{kj})^{2}}
\label {EQ:SIGMAJ}
\end{equation}

Note, this method assumes that the only errors present in the input values are
the independent Gaussian errors described by the input variance values. This is
usually not the case. The error on adjacent CRDD samples is correlated to some
extent. Also, samples from different scans can have different zero levels (due
to changes in the detectors, electronics, etc, or to changes in zodiacal
background), which do not effect the stored variance values. Thus, this method
will usually underestimate the uncertainty in the output surface brightness
estimates.

\item

The second approach to estimating the uncertainty in each output pixel value
is to base it on the spread of the CRDD samples that contributed to the pixel.
This method can be used if there are no variance values available for the input
CRDD.
Using this method, each contributing CRDD sample is (after division by the
effective solid angle) considered to be an estimate of the surface brightness at
the required pixel, and variation in these CRDD samples is considered to be due
to noise. Of course, in practice such variation will also be partly due to
spatial structure in the surface brightness image.

The variance of the surface brightness at the pixel is then just the mean of
the squared residuals between the input CRDD sample values and the output pixel
surface brightness.

\begin{equation}
\sigma^{2}_{j}=\frac{\sum_{k=1}^{N}W\prime_{kj}.(\frac{D_{k}}{\Omega_{k}}-f_{j})^{2}}
{\sum_{k=1}^{N}W\prime_{kj}}
\end{equation}

or equivalently

\begin{equation}
\sigma^{2}_{j}=\frac{\sum_{k=1}^{N}W\prime_{kj}.(\frac{D_{k}}{\Omega_{k}})^{2}}
{\sum_{k=1}^{N}W\prime_{kj}} - f_{j}^2
\label {EQ:SIGMAJ2}
\end{equation}

This method of calculating output variances has the advantage that differences
in zero level between different data streams are reflected in higher output
variances. However, it also has the disadvantage that the resulting variances
will artificially increase in regions of high spatial structure.

\end{enumerate}

\section{Pseudo-code}
The following is high-level pseudo-code describing the algorithm used by MAPCRDD
if no output variances are required:

\begin{verbatim}
      Create a 2D array representing the array of sectors covering a
      full-size detector.

      Store the sector weights in the array just created.

      Normalise the sector weights to have a total sum of unity.

      Create two 2D grids the same size as the output map. Grid 1 will hold the
      sum of the weighted CRDD samples at each pixel, and grid 2 will hold the
      sum of the weights at each pixel.

      Store zeros in every element of the two pixel grids.

      For each CRDD file...

         For each detector...

            Find the linear transformation coefficients which transform sector
            indices to focal plane coordinate offsets from the detector centre.
            This transformation will effectively shrink the sector array to the
            size of the detector.

            Reduce each sector weight in proportion to the detector size.

            Set the "saved" scan angle, and X and Y image scales to bad values.

            For each sample...

               Find the linear transformation coefficients which transform
               focal plane coordinate offsets from the detector centre to
               pixel coordinates. This transformation locates the sample
               within the two pixel grids.

               Calculate the current scan angle, and the X and Y image scales.

               If any of these are significantly different to the "saved"
               values, then...

                  Calculate a new set of pixel weight grids.

                  "Save" the current scan angle, and X and Y image scale.

               End if

               Find the fractional pixel X and Y offset between the centre of
               the detector and the centre of the closest pixel.

               Find the pixel weight grid which corresponds to these offsets.

               For each pixel in the pixel weight grid...

                  Modify the pixel weight by dividing it by the variance of
                  the current CRDD sample (converted to a surface brightness).

                  Increment the corresponding pixel value in grid 1 by the
                  product of the modified pixel weight and the sample
                  value (converted to a surface brightness).

                  Increment the corresponding pixel value in grid 2 by the
                  modified pixel weight.

               Next pixel.

            Next sample.

         Next detector.

      Next CRDD file.

      Divide pixel grid 1 by pixel grid 2 to get the output surface brightness
      values.

\end{verbatim}

If not all input CRDD files have associated variance values, then the above
pseudo-code must be changed slightly by removing the line which modifies the
pixel weights, and then using the original (un-modified) pixel weights when
incrementing the two pixel grids.

If all input CRDD files have associated variance values, and these variance
values are to be used to generate output variances using the first method
described in section \ref {SEC:VAR}, then the following pseudo-code
is used:

\begin{verbatim}
      Create a 2D array representing the array of sectors covering a
      full-size detector.

      Store the sector weights in the array just created.

      Normalise the sector weights to have a total sum of unity.

      Create three 2D grids the same size as the output map. Grid 1 will hold
      the sum of the weighted CRDD samples at each pixel, grid 2 will hold
      the sum of the weights at each pixel, and grid 3 will hold the sum of the
      weighted input variances.

      Store zeros in every element of the three pixel grids.

      For each CRDD file...

         For each detector...

            Find the linear transformation coefficients which transform sector
            indices to focal plane coordinate offsets from the detector centre.
            This transformation will effectively shrink the sector array to the
            size of the detector.

            Reduce each sector weight in proportion to the detector size.

            Set the "saved" scan angle, and X and Y image scales to bad values.

            For each sample...

               Find the linear transformation coefficients which transform
               focal plane coordinate offsets from the detector centre to
               pixel coordinates. This transformation locates the sample
               within the two pixel grids.

               Calculate the current scan angle, and the X and Y image scales.

               If any of these are significantly different to the "saved"
               values, then...

                  Calculate a new set of pixel weight grids.

                  "Save" the current scan angle, and X and Y image scale.

               End if

               Find the fractional pixel X and Y offset between the centre of
               the detector and the centre of the closest pixel.

               Find the pixel weight grid which corresponds to these offsets.

               For each pixel in the pixel weight grid...

                  Modify the pixel weight by dividing it by the variance of
                  the current CRDD sample (converted to a surface brightness).

                  Increment the corresponding pixel value in grid 1 by the
                  product of the modified pixel weight and the sample
                  value (converted to a surface brightness).

                  Increment the corresponding pixel value in grid 2 by the
                  modified pixel weight.

                  Increment the corresponding pixel value in grid 3 by the
                  product of the square of the modified pixel weight and the
                  variance of the current CRDD sample (converted to a surface
                  brightness).

               Next pixel.

            Next sample.

         Next detector.

      Next CRDD file.

      Divide pixel grid 1 by pixel grid 2 to get the output surface brightness
      values.

      Divide pixel grid 3 by the square of pixel grid 2 to get the output
      variance values.

\end{verbatim}

If output variances are required but no input variances are available, then the
output variances must be based on the spread of input CRDD values as
described in the second method in section \ref {SEC:VAR}. In this case, the
following pseudo-code is used:

\begin{verbatim}

      Create a 2D array representing the array of sectors used to map a
      full-size detector.

      Store the sector weights in the array just created.

      Normalise the sector weights to have a total sum of unity.

      Create three 2D grids the same size as the output map. Grid 1 will hold
      the sum of the weighted CRDD samples at each pixel, grid 2 will hold
      the sum of the weights at each pixel, and grid 3 will hold the sum of the
      weighted squared CRDD samples at each pixel.

      Store zeros in every element of the three pixel grids.

      For each CRDD file...

         For each detector...

            Find the linear transformation coefficients which transform sector
            indices to focal plane coordinate offsets from the detector centre.
            This transformation will effectively shrink the sector array to the
            size of the detector.

            Reduce each sector weight in proportion to the detector size.

            Set the "saved" scan angle, and X and Y image scales to bad values.

            For each sample...

               Find the linear transformation coefficients which transform
               focal plane coordinate offsets from the detector centre to
               pixel coordinates. This transformation locates the sample
               within the two pixel grids.

               Calculate the current scan angle, and the X and Y image scales.

               If any of these are significantly different to the "saved"
               values, then...

                  Calculate a new set of pixel weight grids.

                  "Save" the current scan angle, and X and Y image scale.

               End if

               Find the fractional pixel X and Y offset between the centre of
               the detector and the centre of the closest pixel.

               Find the pixel weight grid which corresponds to these offsets.

               For each pixel in the pixel weight grid...

                  Modify the pixel weight by dividing it by the variance of
                  the current CRDD sample (converted to a surface brightness).

                  Increment the value of the corresponding pixel in grid 1 by
                  the product of the modified pixel weight and the current
                  CRDD sample value (converted to a surface brightness).

                  Increment the value of the corresponding pixel in grid 2 by
                  the modified pixel weight.

                  Increment the value of the corresponding pixel in grid 3 by
                  the product of the modified sector weight and the square of
                  the current CRDD sample (converted to a surface brightness).

               Next pixel.

            Next sample.

         Next detector.

      Next CRDD file.

      Divide pixel grid 1 by pixel grid 2 to get the output surface brightness
      values.

      Divide pixel grid 3 by pixel grid 2.

      Subtract the square of the normalised pixel grid 1 from the normalised
      pixel grid 3, and limit to be positive or zero, to get the output
      variances.

\end{verbatim}
\end{document}
