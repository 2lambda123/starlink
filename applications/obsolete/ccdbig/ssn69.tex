\documentstyle[11pt]{article}
\pagestyle{myheadings}

% -----------------------------------------------------------------------------
% ? Document identification
\newcommand{\stardoccategory}  {Starlink System Note}
\newcommand{\stardocinitials}  {SSN}
\newcommand{\stardocsource}    {ssn\stardocnumber}
\newcommand{\stardocnumber}    {[number].[version]}
\newcommand{\stardocauthors}   {Mark Taylor}
\newcommand{\stardocdate}      {27 May 1998}
\newcommand{\stardoctitle}     {
   CCDBIG: benchmarking CCDPACK for large data sets
}
\newcommand{\stardocabstract}  {
CCDBIG is a small set of scripts to investigate 
how CCDPACK behaves with large sets of data.
A typical data reduction sequence is performed for 
increasingly large frame sizes, and the resource 
(memory and time) usage is logged. 
This document describes their operation and interpretation
of the results.
}
% ? End of document identification
% -----------------------------------------------------------------------------

\newcommand{\stardocname}{\stardocinitials /\stardocnumber}
\markright{\stardocname}
\setlength{\textwidth}{160mm}
\setlength{\textheight}{230mm}
\setlength{\topmargin}{-2mm}
\setlength{\oddsidemargin}{0mm}
\setlength{\evensidemargin}{0mm}
\setlength{\parindent}{0mm}
\setlength{\parskip}{\medskipamount}
\setlength{\unitlength}{1mm}

% -----------------------------------------------------------------------------
%  Hypertext definitions.
%  ======================
%  These are used by the LaTeX2HTML translator in conjunction with star2html.

%  Comment.sty: version 2.0, 19 June 1992
%  Selectively in/exclude pieces of text.
%
%  Author
%    Victor Eijkhout                                      <eijkhout@cs.utk.edu>
%    Department of Computer Science
%    University Tennessee at Knoxville
%    104 Ayres Hall
%    Knoxville, TN 37996
%    USA

%  Do not remove the %\begin{rawtex} and %\end{rawtex} lines (used by 
%  star2html to signify raw TeX that latex2html cannot process).
%\begin{rawtex}
\makeatletter
\def\makeinnocent#1{\catcode`#1=12 }
\def\csarg#1#2{\expandafter#1\csname#2\endcsname}

\def\ThrowAwayComment#1{\begingroup
    \def\CurrentComment{#1}%
    \let\do\makeinnocent \dospecials
    \makeinnocent\^^L% and whatever other special cases
    \endlinechar`\^^M \catcode`\^^M=12 \xComment}
{\catcode`\^^M=12 \endlinechar=-1 %
 \gdef\xComment#1^^M{\def\test{#1}
      \csarg\ifx{PlainEnd\CurrentComment Test}\test
          \let\html@next\endgroup
      \else \csarg\ifx{LaLaEnd\CurrentComment Test}\test
            \edef\html@next{\endgroup\noexpand\end{\CurrentComment}}
      \else \let\html@next\xComment
      \fi \fi \html@next}
}
\makeatother

\def\includecomment
 #1{\expandafter\def\csname#1\endcsname{}%
    \expandafter\def\csname end#1\endcsname{}}
\def\excludecomment
 #1{\expandafter\def\csname#1\endcsname{\ThrowAwayComment{#1}}%
    {\escapechar=-1\relax
     \csarg\xdef{PlainEnd#1Test}{\string\\end#1}%
     \csarg\xdef{LaLaEnd#1Test}{\string\\end\string\{#1\string\}}%
    }}

%  Define environments that ignore their contents.
\excludecomment{comment}
\excludecomment{rawhtml}
\excludecomment{htmlonly}
%\end{rawtex}

%  Hypertext commands etc. This is a condensed version of the html.sty
%  file supplied with LaTeX2HTML by: Nikos Drakos <nikos@cbl.leeds.ac.uk> &
%  Jelle van Zeijl <jvzeijl@isou17.estec.esa.nl>. The LaTeX2HTML documentation
%  should be consulted about all commands (and the environments defined above)
%  except \xref and \xlabel which are Starlink specific.

\newcommand{\htmladdnormallinkfoot}[2]{#1\footnote{#2}}
\newcommand{\htmladdnormallink}[2]{#1}
\newcommand{\htmladdimg}[1]{}
\newenvironment{latexonly}{}{}
\newcommand{\hyperref}[4]{#2\ref{#4}#3}
\newcommand{\htmlref}[2]{#1}
\newcommand{\htmlimage}[1]{}
\newcommand{\htmladdtonavigation}[1]{}

%  Starlink cross-references and labels.
\newcommand{\xref}[3]{#1}
\newcommand{\xlabel}[1]{}

%  LaTeX2HTML symbol.
\newcommand{\latextohtml}{{\bf LaTeX}{2}{\tt{HTML}}}

%  Define command to re-centre underscore for Latex and leave as normal
%  for HTML (severe problems with \_ in tabbing environments and \_\_
%  generally otherwise).
\newcommand{\latex}[1]{#1}
\newcommand{\setunderscore}{\renewcommand{\_}{{\tt\symbol{95}}}}
\latex{\setunderscore}

%  Redefine the \tableofcontents command. This procrastination is necessary 
%  to stop the automatic creation of a second table of contents page
%  by latex2html.
\newcommand{\latexonlytoc}[0]{\tableofcontents}

% -----------------------------------------------------------------------------
%  Debugging.
%  =========
%  Remove % on the following to debug links in the HTML version using Latex.

% \newcommand{\hotlink}[2]{\fbox{\begin{tabular}[t]{@{}c@{}}#1\\\hline{\footnotesize #2}\end{tabular}}}
% \renewcommand{\htmladdnormallinkfoot}[2]{\hotlink{#1}{#2}}
% \renewcommand{\htmladdnormallink}[2]{\hotlink{#1}{#2}}
% \renewcommand{\hyperref}[4]{\hotlink{#1}{\S\ref{#4}}}
% \renewcommand{\htmlref}[2]{\hotlink{#1}{\S\ref{#2}}}
% \renewcommand{\xref}[3]{\hotlink{#1}{#2 -- #3}}
% -----------------------------------------------------------------------------
% ? Document specific \newcommand or \newenvironment commands.
% ? End of document specific commands
% -----------------------------------------------------------------------------
%  Title Page.
%  ===========
\renewcommand{\thepage}{\roman{page}}
\begin{document}
\thispagestyle{empty}

%  Latex document header.
%  ======================
\begin{latexonly}
   CCLRC / {\sc Rutherford Appleton Laboratory} \hfill {\bf \stardocname}\\
   {\large Particle Physics \& Astronomy Research Council}\\
   {\large Starlink Project\\}
   {\large \stardoccategory\ \stardocnumber}
   \begin{flushright}
   \stardocauthors\\
   \stardocdate
   \end{flushright}
   \vspace{-4mm}
   \rule{\textwidth}{0.5mm}
   \vspace{5mm}
   \begin{center}
   {\Large\bf \stardoctitle}
   \end{center}
   \vspace{5mm}

% ? Heading for abstract if used.
   \vspace{10mm}
   \begin{center}
      {\Large\bf Abstract}
   \end{center}
% ? End of heading for abstract.
\end{latexonly}

%  HTML documentation header.
%  ==========================
\begin{htmlonly}
   \xlabel{}
   \begin{rawhtml} <H1> \end{rawhtml}
      \stardoctitle
   \begin{rawhtml} </H1> \end{rawhtml}

% ? Add picture here if required.
% ? End of picture

   \begin{rawhtml} <P> <I> \end{rawhtml}
   \stardoccategory \stardocnumber \\
   \stardocauthors \\
   \stardocdate
   \begin{rawhtml} </I> </P> <H3> \end{rawhtml}
      \htmladdnormallink{CCLRC}{http://www.cclrc.ac.uk} /
      \htmladdnormallink{Rutherford Appleton Laboratory}
                        {http://www.cclrc.ac.uk/ral} \\
      \htmladdnormallink{Particle Physics \& Astronomy Research Council}
                        {http://www.pparc.ac.uk} \\
   \begin{rawhtml} </H3> <H2> \end{rawhtml}
      \htmladdnormallink{Starlink Project}{http://star-www.rl.ac.uk/}
   \begin{rawhtml} </H2> \end{rawhtml}
   \htmladdnormallink{\htmladdimg{source.gif} Retrieve hardcopy}
      {http://star-www.rl.ac.uk/cgi-bin/hcserver?\stardocsource}\\

%  HTML document table of contents. 
%  ================================
%  Add table of contents header and a navigation button to return to this 
%  point in the document (this should always go before the abstract \section). 
  \label{stardoccontents}
  \begin{rawhtml} 
    <HR>
    <H2>Contents</H2>
  \end{rawhtml}
  \renewcommand{\latexonlytoc}[0]{}
  \htmladdtonavigation{\htmlref{\htmladdimg{contents_motif.gif}}
        {stardoccontents}}

% ? New section for abstract if used.
  \section{\xlabel{abstract}Abstract}
% ? End of new section for abstract

\end{htmlonly}

% -----------------------------------------------------------------------------
% ? Document Abstract. (if used)
%  ==================
\stardocabstract
% ? End of document abstract
% -----------------------------------------------------------------------------
% ? Latex document Table of Contents (if used).
%  ===========================================
% \newpage
 \begin{latexonly}
   \setlength{\parskip}{0mm}
   \latexonlytoc
   \setlength{\parskip}{\medskipamount}
   \markright{\stardocname}
 \end{latexonly}
% ? End of Latex document table of contents
% -----------------------------------------------------------------------------
\newpage
\renewcommand{\thepage}{\arabic{page}}
\setcounter{page}{1}



% User defined

\newcommand{\KAPPAref}{\xref{KAPPA}{sun95}{}}
\newcommand{\CCDPref}{\xref{CCDPACK}{sun139}{}}
\newcommand{\GWMref}{\xref{GWM}{sun130}{}}
\newcommand{\KAPPAcmd}[1]{\xref{#1}{sun95}{#1}}
\newcommand{\CCDPcmd}[1]{\xref{#1}{sun139}{#1}}




\section{Introduction}

Running applications on large data sets 
is inevitably more demanding than on smaller ones.
Resource usage is heavier, and as well as longer 
elapsed times and increased degradation of machine performance, 
this can lead ultimately to failure of the job. 
CCDBIG does not give a benchmark result as such,
but provides a tool to gauge resource usage 
for data reduction of frames of varying size,
so that the capability of a given platform to handle data sets
of a given size can be assessed, 
and the reasons for eventual failure can be determined.

How the results of such an investigation are outside the
scope of this document,
but at the coarsest level, if the process fails or the machine crashes
when trying to run a job at a given size, then it's too big. 
At a more sophisticated level, if a job takes ``too long'',
or degrades performance of the machine to an unacceptable degree,
then it may be too big. 
In either of these cases, examining the log file should give some 
insight into which resource is the cause of the problem.
The approach (either requirements of the job,
or the platform it is being run on) can then be modified
to find a happier combination.

This guide is a brief instruction for use
of the CCDBIG script and interpretation of its output.
For further discussion of the issues involved in running large
data reduction jobs in general, and using CCDPACK in particular,
see \xref{SC/5}{sc5}{ccdbig}.


\section{Running CCDBIG}

Ideally, CCDBIG should be run on a machine which is not
heavily loaded, and furthermore one which is not being used
for important processes.
The latter is desirable, because if the CCDPACK applications
are being tested to destruction then at the least they will
cause very heavy swapping between memory and disk, which 
dramatically degrades performance of the machine 
(particularly interactive response time),
and they can sometimes cause termination of other processes and
even system crashes.

To run the script, the recommended procedure is
to change to an empty directory, on a local disk with 
ample free space, and then:
\begin{quote}
\verb"% setenv CCDBIG_DIR /star/bin/ccdpack" \\
\verb"% cp $CCDBIG_DIR/ccdbig ." \\
\hspace*{3em} (edit {\tt ccdbig} as required) \\
\verb"% ./ccdbig"
\end{quote}
The portion of the script which you might want to edit 
is after the initial comment section, and looks like this:
\begin{quote}
\begin{verbatim}
###################################################################
# Set up the parameters of the reduction sequences.
# These can be changed to test behaviour of the programs under
# different circumstances.

      # Do we want variances calculated and propagated (TRUE or FALSE)?
            set variance = TRUE

      # Do we want to treat ARD mask within CCDPACK (TRUE or FALSE)?
      # (else explicitly impose mask on data using ARDMASK).
            set keepard = TRUE

      # Set list of image sizes of frames (pixels along a side)
            set image_sizes = ( 1000 2000 3000 4000 5000 6000 )

      # Set list of object densities (objects per million pixels)
            set object_densities = ( 50 )

      # Set logging interval (seconds)
            set interval = 15

      # Set filename for logging resource usage
            set timelogfile = ccdbig_time.log

# End of parameter setup.
###################################################################
\end{verbatim}
\end{quote}
The significance of these options is as follows:
\begin{itemize}
%
\item {\tt variance}: 
If set to TRUE then the variance component of the NDFs will be  
calculated where appropriate 
(in \CCDPcmd{MAKEBIAS}, \CCDPcmd{DEBIAS} and \CCDPcmd{MAKEMOS}) 
and propagated.
Setting to FALSE decreases memory, disk and CPU time usage.
%
\item {\tt keepard}:
If set to TRUE then the information in the example ARD mask file
{\tt ccdtest\_ard.dat} will be used by the 
CCDPACK applications where appropriate;
this increases memory and CPU time usage, especially in \CCDPcmd{DEBIAS}.
If FALSE, then the ARD mask will be applied explicitly 
between stages of the reduction process 
by the \KAPPAref\ application \KAPPAcmd{ARDMASK};
this decreases the memory requirements of \CCDPcmd{DEBIAS}.
%
\item {\tt image\_sizes}:
The data reduction process is performed in turn on 
test CCD frames of $N \times N$ pixels, where $N$ takes each
of the values given in this list.
%
\item {\tt object\_densities}:
The number of objects generated in the test data can be altered
with this value.  If more than one number is given,  more than one
run will be performed at each frame size.
%
\item {\tt interval}:
This determines how often the logging process examines the 
application processes. 
A smaller value will improve the resolution of the statistics,
but will place a heavier load on the system.
%
\item {\tt timelogfile}:
This is the name of the file to which the resource usage summary is logged.
\end{itemize}

When run the script will ask for a display device;
if the response {\tt xwindows} is given then progress
can be monitored graphically in a \GWMref\ window.



\section{Interpretation of results}

\subsection{Structure of the output file}

As it runs, the logging process will append to a log file 
(by default {\tt ccdbig\_time.log}).
Initially a header will be written indicating some of the
operating parameters and details of the machine which is
being run on.
One subsequent line will be written for each program as it is run,
giving
the size of the image, 
the number of objects in the data frame,
the name of the application being run,
the CPU time and
elapsed time in seconds,
and
the maximum total (virtual memory) size and
maximum resident (real memory) size of the process in kilobytes.
A section of a log file could therefore look something like this:
\begin{quote}
\begin{verbatim}
SunOS cass58 5.6 Generic sun4u sparc SUNW,Ultra-1
 11:18am  up 6 day(s),  3:04,  3 users,  load average: 0.17, 0.09, 0.05
Tue May 19 11:18:45 BST 1998
21665   /data/cass58a/mbt/ccdbig
Variance:  FALSE
Keepard:   TRUE
Logging interval:   15

Pixels Objects     Command
                              Elapsed(s)     CPU(s)     RSS(k)    Size(k)

   4000   1800 ccdgenerate:          897        235     252000     257752
   4000   1800    makebias:          119         72      66576      69312
   4000   1800      debias:         2168        126     400216     444520
   4000   1800    makeflat:          506        121     170656     173760
   4000   1800     flatcor:          101         15     111064     173760
   4000   1800     findobj:           34         23      60288      66400
   4000   1800     tranndf:          371        306     154744     177544
   4000   1800 makemosnorm:          914        824      88176      95640
   4000   1800  makmoscomb:          124         14       5120      11456
\end{verbatim}
\end{quote}

The meanings of the values logged are as follows:
\begin{itemize}
%
\item {\bf Pixels}:
The test data frames are $N \times N$ pixels in size.
This number is $N$.
%
\item{\bf Objects}:
This is the number of objects placed in the star field;
each frame occupies a subsection of this area and will 
contain around 0.4 times as many.
%
\item {\bf Command}:
Name of the application to which the statistics apply.
This is a label determined by the {\tt ccdbig} script and in general
is the name of a \CCDPref\ or \KAPPAref\ application, 
except for {\tt makemosnorm} and {\tt makemoscomb},
which are the normalisation and combination parts respectively
of \CCDPcmd{MAKEMOS}
(see the {\tt ccdbig} script for details).
\item {\bf Elapsed}:
This is the ``wall-clock'' time between the start of the process
in question and its termination. 
Large data reduction processes are typically I/O bound, so
for most of the applications the discrepancy between this and the
CPU time will be accounted for mainly by waiting for I/O,
either simple writes and reads to and from disk files, 
or swapping virtual memory between disk and core.
On a heavily loaded system however it will reflect processor 
usage by other processes as well.
%
\item {\bf CPU}:
Number of seconds spent by the program executing.
This should be reasonably constant regardless of system load.
%
\item {\bf RSS}:
Resident set size is the amount of real memory used. 
This will not exceed the physical memory installed in the machine.
%
\item {\bf Size}:
The amount of virtual memory used by the whole process.
This can be as large as the whole of virtual memory plus the
whole of swap space. 
As it approaches and exceeds the physical memory available however
(where availability takes account of requirements of other 
processes running concurrently)
the machine's performance will degrade significantly as much
time is spent swapping process pages to and from disk.
\end{itemize}


\subsection{Caveats}

Determining CPU time and elapsed time usage under Unix 
is relatively straightforward. 
However there is no tidy and portable way of
assessing memory usage and the solution used here is
somewhat messy and error-prone.
For details of the method used and a better insight into
the problems which can occur, see the inline comments in 
the script {\tt reslog}.
Broadly speaking however, the following comments apply:
\begin{itemize}
%
\item
The logging script will not work well for assessing applications
with a short run time or small memory footprint.  
Since the purpose of these scripts is to assess resource usage
for large data reduction jobs we do not consider this a serious problem.
%
\item
When very large jobs are running, 
the system can behave badly,
response times can be very slow,
and processes can fail unexpectedly, even ones which 
do not themselves have extreme requirements.
%
\item
The logging script relies heavily on the details of output from 
the {\tt ps} command, amongst others; therefore it is 
likely to be sensitive to changes in operating system and environment.
\end{itemize}
For all the above reasons, CCDBIG is not a foolproof application,
so its results should be regarded critically; 
if there are anomalous results they should be checked further 
(a monitoring tool like {\tt top} may be of use here)
before being believed!


\section{Acknowledgements}

The basic application script {\tt ccdbig}
is a slightly adapted version of the {\tt ccdexercise} script
provided with \CCDPref\ by Peter Draper (Starlink).




\end{document}
