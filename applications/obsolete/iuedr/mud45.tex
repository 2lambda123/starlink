\documentstyle[11pt,twoside]{article}
\pagestyle{myheadings}

%------------------------------------------------------------------------------
\newcommand{\stardoccategory}  {Starlink Miscellaneous User Document}
\newcommand{\stardocinitials}  {MUD}
\newcommand{\stardocsource}    {mud45.1}
\newcommand{\stardocnumber}    {45.1}
\newcommand{\stardocauthors}   {Paul Rees, Jack Giddings, Dave Mills \& Martin
                                Clayton}
\newcommand{\stardocdate}      {12 March 1996}
\newcommand{\stardoctitle}     {IUEDR---Users Guide}
%------------------------------------------------------------------------------

\newcommand{\stardocname}{\stardocinitials /\stardocnumber}
\markright{\stardocname}
\setlength{\textwidth}{160mm}
\setlength{\textheight}{240mm}
\setlength{\topmargin}{-5mm}
\setlength{\oddsidemargin}{0mm}
\setlength{\evensidemargin}{0mm}
\setlength{\parindent}{0mm}
\setlength{\parskip}{\medskipamount}
\setlength{\unitlength}{1mm}

\setcounter{tocdepth}{4}
\setcounter{secnumdepth}{4}

% -----------------------------------------------------------------------------
%  Hypertext definitions.
%  ======================
%  These are used by the LaTeX2HTML translator in conjunction with star2html.

%  Comment.sty: version 2.0, 19 June 1992
%  Selectively in/exclude pieces of text.
%
%  Author
%    Victor Eijkhout                                      <eijkhout@cs.utk.edu>
%    Department of Computer Science
%    University Tennessee at Knoxville
%    104 Ayres Hall
%    Knoxville, TN 37996
%    USA

%  Do not remove the %\begin{rawtex} and %\end{rawtex} lines (used by
%  star2html to signify raw TeX that latex2html cannot process).
%\begin{rawtex}
\makeatletter
\def\makeinnocent#1{\catcode`#1=12}
\def\csarg#1#2{\expandafter#1\csname#2\endcsname}

\def\ThrowAwayComment#1{\begingroup
    \def\CurrentComment{#1}%
    \let\do\makeinnocent \dospecials
    \makeinnocent\^^L% and whatever other special cases
    \endlinechar`\^^M \catcode`\^^M=12 \xComment}
{\catcode`\^^M=12 \endlinechar=-1 %
 \gdef\xComment#1^^M{\def\test{#1}
      \csarg\ifx{PlainEnd\CurrentComment Test}\test
          \let\html@next\endgroup
      \else \csarg\ifx{LaLaEnd\CurrentComment Test}\test
            \edef\html@next{\endgroup\noexpand\end{\CurrentComment}}
      \else \let\html@next\xComment
      \fi \fi \html@next}
}
\makeatother

\def\includecomment
 #1{\expandafter\def\csname#1\endcsname{}%
    \expandafter\def\csname end#1\endcsname{}}
\def\excludecomment
 #1{\expandafter\def\csname#1\endcsname{\ThrowAwayComment{#1}}%
    {\escapechar=-1\relax
     \csarg\xdef{PlainEnd#1Test}{\string\\end#1}%
     \csarg\xdef{LaLaEnd#1Test}{\string\\end\string\{#1\string\}}%
}}

%  Define environments that ignore their contents.
\excludecomment{comment}
\excludecomment{rawhtml}
\excludecomment{htmlonly}
%\end{rawtex}

%  Hypertext commands etc. This is a condensed version of the html.sty
%  file supplied with LaTeX2HTML by: Nikos Drakos <nikos@cbl.leeds.ac.uk> &
%  Jelle van Zeijl <jvzeijl@isou17.estec.esa.nl>. The LaTeX2HTML documentation
%  should be consulted about all commands (and the environments defined above)
%  except \xref and \xlabel which are Starlink specific.

\newcommand{\htmladdnormallinkfoot}[2]{#1\footnote{#2}}
\newcommand{\htmladdnormallink}[2]{#1}
\newcommand{\htmladdimg}[1]{}
\newenvironment{latexonly}{}{}
\newcommand{\hyperref}[4]{#2\ref{#4}#3}
\newcommand{\htmlref}[2]{#1}
\newcommand{\htmlimage}[1]{}
\newcommand{\htmladdtonavigation}[1]{}

%  Starlink cross-references and labels.
\newcommand{\xref}[3]{#1}
\newcommand{\xlabel}[1]{}

%  LaTeX2HTML symbol.
\newcommand{\latextohtml}{{\bf LaTeX}{2}{\tt{HTML}}}

%  Define command to recentre underscore for Latex and leave as normal
%  for HTML (severe problems with \_ in tabbing environments and \_\_
%  generally otherwise).
\newcommand{\latex}[1]{#1}
\newcommand{\setunderscore}{\renewcommand{\_}{{\tt\symbol{95}}}}
\latex{\setunderscore}

%  Redefine the \tableofcontents command. This procrastination is necessary
%  to stop the automatic creation of a second table of contents page
%  by latex2html.
\newcommand{\latexonlytoc}[0]{\tableofcontents}

% -----------------------------------------------------------------------------
%  Debugging.
%  =========
%  Un-comment the following to debug links in the HTML version using Latex.

% \newcommand{\hotlink}[2]{\fbox{\begin{tabular}[t]{@{}c@{}}#1\\\hline{\footnotesize #2}\end{tabular}}}
% \renewcommand{\htmladdnormallinkfoot}[2]{\hotlink{#1}{#2}}
% \renewcommand{\htmladdnormallink}[2]{\hotlink{#1}{#2}}
% \renewcommand{\hyperref}[4]{\hotlink{#1}{\S\ref{#4}}}
% \renewcommand{\htmlref}[2]{\hotlink{#1}{\S\ref{#2}}}
% \renewcommand{\xref}[3]{\hotlink{#1}{#2 -- #3}}
% -----------------------------------------------------------------------------
%  Add any document specific \newcommand or \newenvironment commands here
\renewcommand{\floatpagefraction}{0.8}

% -----------------------------------------------------------------------------
%  Title Page.
%  ===========
\renewcommand{\thepage}{\roman{page}}
\begin{document}
\thispagestyle{empty}

%  Latex document header.
%  ======================
\begin{latexonly}
   CCLRC / {\sc Rutherford Appleton Laboratory} \hfill {\bf \stardocname}\\
   {\large Particle Physics \& Astronomy Research Council}\\
   {\large Starlink Project\\}
   {\large \stardoccategory\ \stardocnumber}
   \begin{flushright}
   \stardocauthors\\
   \stardocdate
   \end{flushright}
   \vspace{-4mm}
   \rule{\textwidth}{0.5mm}
   \vspace{5mm}
   \begin{center}
   {\Large\bf \stardoctitle}
   \end{center}
   \vspace{5mm}

%  Add heading for abstract if used.
%   \vspace{10mm}
%   \begin{center}
%      {\Large\bf Description}
%   \end{center}
\end{latexonly}

%  HTML documentation header.
%  ==========================
\begin{htmlonly}
   \xlabel{}
   \begin{rawhtml} <H1> \end{rawhtml}
      \stardoctitle
   \begin{rawhtml} </H1> \end{rawhtml}

%  Add picture here if required.

   \begin{rawhtml} <P> <I> \end{rawhtml}
   \stardoccategory \stardocnumber \\
   \stardocauthors \\
   \stardocdate
   \begin{rawhtml} </I> </P> <H3> \end{rawhtml}
      \htmladdnormallink{CCLRC}{http://www.cclrc.ac.uk} /
      \htmladdnormallink{Rutherford Appleton Laboratory}
                        {http://www.cclrc.ac.uk/ral} \\
      Particle Physics \& Astronomy Research Council \\
   \begin{rawhtml} </H3> <H2> \end{rawhtml}
      \htmladdnormallink{Starlink Project}{http://www.starlink.ac.uk/}
   \begin{rawhtml} </H2> \end{rawhtml}
   \htmladdnormallink{\htmladdimg{source.gif} Retrieve hardcopy}
      {http://www.starlink.ac.uk/cgi-bin/hcserver?\stardocsource}\\

%  HTML document table of contents.
%  ================================
%  Add table of contents header and a navigation button to return to this
%  point in the document (this should always go before the abstract \section).
  \label{stardoccontents}
  \begin{rawhtml}
    <HR>
    <H2>Contents</H2>
  \end{rawhtml}
  \renewcommand{\latexonlytoc}[0]{}
  \htmladdtonavigation{\htmlref{\htmladdimg{contents_motif.gif}}
        {stardoccontents}}

%  Start new section for abstract if used.
%  \section{\xlabel{abstract}Abstract}

\end{htmlonly}

% -----------------------------------------------------------------------------
%  Document Abstract. (if used)
%  ==================
% -----------------------------------------------------------------------------
%  Latex document Table of Contents (if used).
%  ===========================================
\begin{latexonly}
   \setlength{\parskip}{0mm}
   \markboth{Contents}{\stardocname}
   \latexonlytoc
   \setlength{\parskip}{\medskipamount}
\end{latexonly}
% -----------------------------------------------------------------------------



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\renewcommand{\thepage}{\arabic{page}}
\setcounter{page}{1}
\section{\xlabel{introduction}\label{se:introduction}INTRODUCTION}
\markboth{Introduction}{\stardocname}

IUEDR is a programme that contains facilities which can be used by
Astronomers to reduce their IUE Data.

IUEDR addresses the problem of working from the IUE Guest Observer
Tape through to a calibrated spectrum that can be used in scientific
analysis.  In this respect it aims to be a complete system for IUE
Data Reduction.

This Guide provides an informal description of the facilities in IUEDR, and
of how to use them to reduce IUE data.  There is also a separate IUEDR
Reference Manual (\xref{SG/3}{sg3}{}), giving more formal descriptions of the
individual commands.


\subsection{Summary of Facilities}

This Section provides a brief summary of what can be done using IUEDR\@.  It
should help you to decide whether IUEDR can help with your IUE work.

\begin{description}

\item [\htmlref{\bf Tape Analysis:}{subse:tape_anal}]
      The contents of IUE tapes can be examined interactively to find
      what images are present, and so to plan the data reduction.

\item [\htmlref{\bf Reading IUE Images:}{se:readiue}]
      RAW, GPHOT and PHOT images can be read from IUE tape into IUEDR
      datasets stored on disk.  These datasets are provided with default
      calibrations.

\item [\htmlref{\bf Image Display:}{se:drimage}]
      IUEDR datasets can be displayed on a computer screen for
      assessment of validity and quality.  'Bad' parts of the image can
      be marked off.

\item [\htmlref{\bf Spectrum Extraction:}{se:spec_extr}]
      This uses techniques that are an enhancement of those present in
      the TRAK programme (Giddings, 1982)\@.  Spectra exposed in either
      resolution mode (HIRES or LORES) can be extracted from RAW, GPHOT
      or PHOT images (the latter being the newer style Photometric
      images that retain geometric distortion)\@.  It is possible to
      correct photometric LORES images obtained with the SWP and LWR
      cameras for defects in the original ITF calibration.

\item [\htmlref{\bf Spectrum Calibration:}{se:spec_calib}]
      Fully calibrated spectra can be produced.  This includes various
      forms of wavelength corrections, absolute calibration, and (for
      HIRES), ripple correction.  There is also a semi-empirical
      correction for the HIRES (order-overlap) background problem.

\item [\htmlref{\bf Graphical Display:}{se:disp}]
      Graphical display facilities are provided to aid spectrum
      extraction and calibration operations.  A number of different
      types of graphics terminals can be used.

\item [\htmlref{\bf Spectrum Averaging:}{se:map}]
      It is possible to combine the spectra from groups of \'{E}chelle
      orders (HIRES) or from different apertures (LORES) by mapping and
      averaging them onto an evenly spaced wavelength grid.

\item [\htmlref{\bf Output Products:}{se:spec_output}]
      The spectra can be output to Starlink NDF files which can be read
      by \xref{DIPSO}{sun50}{} and other Starlink software.   This
      includes individual extracted order and aperture spectra or
      combined spectra. Files can also be created in the same format as
      the TRAK programme.

\end{description}

The User Interface takes the form of a dialogue consisting of commands (typed
in at the terminal) and prompts supplied by the programme to ask for the
information it needs.


\subsection{How to Use this Guide}

This is perhaps best done by reading it! However, you will probably feel a
little intimidated by its bulk, and might be thinking `That's an awful lot to
read when all I want is to see my IUE spectrum!'\@.  Agreed, this User Guide
is rather a lot to read; however, this is not without reason:

\begin{enumerate}

\item IUEDR aims to provide a complete environment that allows you to work
      from a Ground Station tape through to a calibrated spectrum.  You
      should should not need to use any other IUE specific data reduction
      programmes on the way.

\item Since IUE images are really quite varied in their contents and
      calibrations, IUEDR must offer a degree of flexibility to cope with this.
      This flexibility is largely in your hands, and so you need to know how to
      control it.

\item The User Guide offers information and advice on various topics
      associated with IUE and should be fairly self-contained.

\end{enumerate}

That hasn't made it any shorter.

Like most most programmes of any substance, there is a minimal amount of
information you need to know in order to get started.  In the case of IUEDR
`getting started' means that you can begin using the programme to produce
useful results, and know how to explore the documentation to find out
more.

Section~\ref{se:tutorial} is aimed at providing this initial information: it
takes the form of a tutorial introduction.

Section~\ref{se:user_int} gives a more thorough account of the User
Interface: the Parameter Mechanism, Graphics, Tapes, Datasets and File
Organisation.

Section~\ref{se:nature} then gives a brief description of the form and content
of IUE observational data.  Experience shows that many IUE observers are often
quite unaware of the form in which their data has been stored, and of what
could possibly be wrong with it (and require correction)\@.

Then there follow a number of Sections dealing in some detail with various
commands, showing how to use them, and what to look for to maintain
rigorous quality control.  Interspersed with descriptions of usage,
are sections giving information of a more technical nature, which should
help to provide an understanding of what is actually being done with the
data.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{tutorial}\label{se:tutorial}TUTORIAL INTRODUCTION}
\markboth{Tutorial Introduction}{\stardocname}

Let us begin with a quick introduction to IUEDR\@.  The aim is to show you how
to get started and produce some results.  At this stage it is important that
you are not bogged down with details and special cases.

One drawback of such an approach is that you will not be aware of the full
story for any command or facility introduced in this way, and this may in some
cases be misleading.  An attempt has been made to minimise these effects,
but be warned.

In what follows, it is expected that you be familiar with common unix commands,
although you don't have to be an expert.  If you are coming to unix for the
first time, then ask your Site Manager to help you get started.


\subsection{Getting Started}

The first thing to do is find out how to run IUEDR\@.  Your \verb+.login+ file
(which is executed each time you log in to the computer), should contain the
following lines:

\begin{verbatim}
   if ( -e /star/etc/login ) then
      source /star/etc/login
   endif
   iuedrsetup
\end{verbatim}


Once these preliminaries are out of the way, you can run IUEDR by typing:

\begin{verbatim}
   % iuedr
\end{verbatim}

which will begin by printing some information and then prompt for a command
using the \verb+>+ character.  In the examples of IUEDR commands given in here,
this prompt character will sometimes be omitted (for the sake of clarity)\@.
The first command to learn is the one to get you out of the programme:

\begin{verbatim}
   > QUIT
\end{verbatim}

Never use the abort mechanism to do this (CONTROL C); if you do then its your
own fault if something is lost!

After the minimum IUEDR session, although no work has actually been done,
and nothing achieved, there is nevertheless something to see.
A file called \verb+session.lis+ has been created in the directory where you
are working.
This is a text file containing a Log of what happened during the IUEDR session.
You can inspect it at the terminal using:

\begin{verbatim}
   % more session.lis
\end{verbatim}

or your favourite text editor.
Alternatively, it can be printed using:

\begin{verbatim}
   % lpr session.lis
\end{verbatim}

When you begin to use IUEDR seriously, then this Log File will help you to
remember what you did in any particular session.

IUEDR has on-line HELP information available for each command.  It operates
exactly the same as the VMS HELP facility, and can be invoked by typing:

\begin{verbatim}
   % iuehelp
\end{verbatim}

at the shell prompt or

\begin{verbatim}
   > HELP
\end{verbatim}

at the IUEDR prompt.
It operates interactively and you can use it to explore things that will
not be covered immediately in this Tutorial.
You can leave this HELP facility by hitting the \verb+RETURN+ key until the
\verb+>+ prompt returns (meaning you are back in IUEDR proper)\@.


\subsection{Reading an Image from Tape}

The next major step is to get one of your IUE images from tape into an IUEDR
dataset (from which you can extract the spectrum)\@.  This is done with the
\xref{\verb+READIUE+}{sg3}{READIUE} command.  But before describing this,
we need to show how to handle tapes in IUEDR\@.

You will need to be logged into a machine with a suitable tape drive available.
You will also need to know the name of the tape device (for example,
\verb+/dev/nrmt0h+)\@.  Ask your site manager which drives you can use.
Always remember to remove your tape when you have finished and preferably ensure
it is write-protected before use.

Assuming that you are in IUEDR and have a tape mounted properly, you can read
an image from tape by typing:

\begin{verbatim}
   > READIUE
\end{verbatim}

Unfortunately, that's not all you need to do.  All IUEDR commands ({\it{e.g.,}}
\xref{\verb+READIUE+}{sg3}{READIUE}) have a number of parameters associated
with them.  Some of
these parameters will take default values but others will be initially
undefined.
\xref{\verb+READIUE+}{sg3}{READIUE} has lots of parameters (bad point),
but it will only prompt you for the
ones it doesn't have values for (good point)\@.  Here is the command again,
and a schematic example of the dialogue that followed:

\begin{verbatim}
   > READIUE
   DRIVE - Tape Drive or File Name. > /dev/nrmt0h
   FILE - File Number. > 1
    (It prints the first few lines of the IUE header)
    VICAR Image is 768 records, each consisting 1536 bytes
    This is either a PHOT or a GPHOT Image
   TYPE - Dataset Type (RAW, PHOT, GPHOT). > GPHOT
    Assumed to be GPHOT Image.
   ITFMAX - Pixel value on tape for ITF saturation. > 19632
   DATASET - Dataset name. > LWR14931
   CAMERA - Camera Name (LWP, LWR, SWP, SWR). > LWR
   IMAGE - Image Number. /14931/ >
   RESOLUTION /'LORES'/ >
   APERTURES - Aperture name. > LAP
   EXPOSURES - Spectrum exposure time(s) (seconds). /2/ >
   YEAR - Year number (A.D.). /1981/ >
   MONTH - Month Number (1-12). /9/ >
   DAY - Day Number in Month. /8/ >
   OBJECT - Object Identification Text. /'LWR14931'/ > HD 111123
   THDA - IUE Camera Temperature (C). > 0
   ITF - This is the ITF generation used in the image calibration. > 2
    ITF2 Photometric Calibration assumed for LWR Camera.
    Large Aperture assumed for Absolute Calibration.
    No Spectrum Template Data.
   BADITF - Whether bad LORES ITF requires correction. > T
    Reading Image from File.
    ITFMAX=19632 used to detect ITF saturation.
    Writing LWR14931.UEC (Calibration File).
    Writing LWR14931_UED (Image File).
   >
\end{verbatim}

After \xref{\verb+READIUE+}{sg3}{READIUE} was typed, the command prompted for
the \xref{\verb+FILE+}{sg3}{FILE}
parameter.  The Prompt line starts with the parameter name and the
prompt string continues up to and including the \verb+>+ character; everything
beyond that is the reply typed in at the terminal.

You can probably deduce the meaning of most of the
\xref{\verb+READIUE+}{sg3}{READIUE} parameters
from the example above.  Some require a little more explanation:

\begin{description}

\item [\xref{{\tt FILE}}{sg3}{FILE}]
      This is the file number on the tape containing the image.
      IUEDR deals in terms of file numbers, it knows the tape position because
      it rewinds the tape at the start of each session.

\item [\xref{{\tt TYPE}}{sg3}{TYPE}]
      This is used to distinguish new style PHOT images from the
      older GPHOT ones.

\item [\xref{{\tt DATASET}}{sg3}{DATASET}]
      This is the name of a file to contain the dataset.  In
      fact, as you can see from the printout at the end, several files are
      created, using \xref{\verb+DATASET+}{sg3}{DATASET} for the main part of
      the file name, and
      having different types ({\it{e.g.,}} \verb+.UEC+)\@.

\item [\xref{{\tt APERTURES}}{sg3}{APERTURES}]
      This specifies which spectrograph apertures where used.
      It can be \verb+SAP+, \verb+LAP+ or \verb+BAP+\@. The latter means both
      \verb+SAP+ and \verb+LAP+\@.

\item [\xref{{\tt EXPOSURES}}{sg3}{EXPOSURES}]
      These are the exposure times (in seconds) for each
      aperture; the order is (\verb+SAP+,\verb+LAP+) in the case of
      \verb+APERTURES=BAP+\@.

\item [\xref{{\tt THDA}}{sg3}{THDA}]
      This is the IUE camera temperature at the time of
      observation.  If it is not known, don't worry, it is normally not too
      crucial.  A value of 0.0 indicates that it is not known.  If you find out
      what it is later, you can always change it (without reading the image
      again!)\@.

\item [\xref{{\tt BADITF}}{sg3}{BADITF}]
      This specifies whether any LORES ITF adjustments are
      required.  These adjustments account for non-linearity and other errors
      that were present in the Ground Station ITF processing.  You'll have to
      read on to find out whether it applies or not.  If you don't know, type
      {\bf no}; you can always change it later.

\end{description}

The parameters prompted for will not be the same in every case.  For example,
HIRES needs no \xref{\verb+BADITF+}{sg3}{BADITF} parameter value.

The printout at the end says which files have been created for
the dataset ({\it{e.g.,}} \verb+LWR2779.UEC+)\@.  Inside IUEDR you refer to the
dataset by its main name, in this case \verb+LWR2779+, and let it worry about
files.  Outside IUEDR you should beware trying to edit or change these files
in any way: they make very cryptic reading, and if you change them you might
loose their contents.


\subsection{Responding to Parameter Prompts}

Normally, when you are prompted for a parameter, you will be able to give a
reasonable value.  Sometimes, the meaning of the parameter is not clear, or you
don't want to give a value (there is no value), or you just want to stop the
command and start again.

When situations like this arise, whatever you do, don't panic! There are a
number of special responses that you can make when prompted for a
parameter value:

\begin{latexonly}
\begin{tabular}{ll}
Response & Meaning\\
{\tt ?}  & Ask for HELP information on parameter\\
{\tt !}  & Provide no value for this parameter\\
{\tt !!} & Abort Command\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>Response  Meaning</B>
   ?      Ask for HELP information on parameter
   !      Provide no value for this parameter
   !!     Abort Command
</PRE>
\end{rawhtml}
\end{htmlonly}

After providing HELP information, you will be asked again to provide a value
for the parameter.  Normally, providing no value (\verb+!+) for a parameter is
equivalent to aborting the command, since it may play a crucial role.  The
abort (\verb+!!+) response terminates the command, but it does not necessarily
undo what has happened up to that point in the command.  Most commands are
harmless and can be aborted without any side-effects.  The Starlink ADAM
parameter system (See \xref{SG/4}{sg4}{} for a full description of ADAM and
the parameter system)\@.


\subsection{Inspecting the Dataset}

Suppose we are continuing the previous session.  We can take a look at the
header for our dataset by typing:

\begin{verbatim}
   > SHOW DATASET=LWR14931
\end{verbatim}

This will print out some information about the dataset.  Much of which
corresponds to the \xref{\verb+READIUE+}{sg3}{READIUE} parameters, but also
things which, for the time being, will not mean very much.

In our example of using the \xref{\verb+SHOW+}{sg3}{SHOW} command, notice how
we specified the
\xref{\verb+DATASET+}{sg3}{DATASET} parameter on the command line.  Apart
from \verb+DATASET+, \xref{\verb+SHOW+}{sg3}{SHOW} has two other parameters
which take on defaults.

If we had not specified \xref{\verb+DATASET+}{sg3}{DATASET} on the command
line, then its value from the \xref{\verb+READIUE+}{sg3}{READIUE} command
would have been remembered, and the result would have been identical.


\subsection{Forced Prompting}

All parameters are shared amongst the various commands.  So
\xref{\verb+DATASET+}{sg3}{DATASET} has
the same meaning in, for example, the
\xref{\verb+READIUE+}{sg3}{READIUE} and \xref{\verb+SHOW+}{sg3}{SHOW} commands.
Unless something changes the \verb+DATASET+ parameter, we need not specify it
again (for the remainder of the session), no matter what command we type.

A side-effect of this is that sometimes you will not be prompted for a
parameter that you might have changed if you knew what it was.

To give you greater control over the way in which parameter values are
assigned, you can force all parameters to be prompted for.  In our \verb+SHOW+
example above, we could type:

\begin{verbatim}
   > SHOW PROMPT
\end{verbatim}

Would cause \verb+SHOW+ to prompt in the following way:

\begin{verbatim}
   V - List of items to be printed. /'H'/ > <RETURN>
   DATASET - Dataset name. /'LWR14931'/ > <RETURN>
\end{verbatim}

The \verb+<RETURN>+ terminology is used above to indicate that the
\verb+RETURN+ key is typed.  When being prompted for a parameter that already
has a value, this means `use the current value'\@.  Hitting return when there
is no value will not get you very far (try it)\@.


\subsection{Producing a LORES Spectrum}

Continuing the current session, the next thing to do is produce a
spectrum.  Since we are dealing with a fairly typical LORES image, we can
probably do this immediately, using:

\begin{verbatim}
   > TRAK APERTURE=LAP
\end{verbatim}

Since there are two possible apertures, we selected \verb+LAP+ explicitly using
the \xref{\verb+APERTURE+}{sg3}{APERTURE} parameter on the command line.  As usual, if we had missed
this, it would have prompted.  In what follows, parameters that need to be
specified will be shown on the command line, rather than let them be prompted
for.

In using \xref{\verb+TRAK+}{sg3}{TRAK} in this way we are relying on the default values for all of
the other parameters (of which there are many!)\@.  We are also relying on its
ability to automatically track along the spectrum to account for small
shifts of the spectrum from its standard position.

In our LORES example, this rather trusting approach to using TRAK is
probably safe in the case of point source objects which have a reasonably
strong signal.  However, you should find out how to use TRAK for less typical
cases.

\xref{\verb+TRAK+}{sg3}{TRAK} starts off by printing some information about what it will do.  Then
there is a pause (sometimes a long pause) while it extracts the spectrum.  When
it is finished, it prints a table summarising what it found.


\subsection{Spectrum Display}

We can plot the calibrated spectrum using, for example:

\begin{verbatim}
   > PLFLUX DEVICE=XW
\end{verbatim}

The \xref{\verb+DEVICE+}{sg3}{DEVICE} parameter is used to identify which graphics device we want
to plot on.  In this case the plot is intended for an X Window.  Other
\verb+DEVICE+ possibilities are described in Section~\ref{subse:graphics}\@.

The \xref{\verb+CULIMITS+}{sg3}{CULIMITS} command can be used to `zoom' the display by selecting a
rectangular region of the last plot with \xref{\verb+PLFLUX+}{sg3}{PLFLUX} (See
Section~\ref{subse:culimits})\@.

If you want to produce a hard copy of this spectrum, you can type:

\begin{verbatim}
   > PLFLUX DEVICE=PS_L
\end{verbatim}

This will produce a file \verb+gks??.ps+ where \verb+??+ is the version number
of gks running on your system.
When you leave IUEDR at the end of a session, these files can be spooled to a
PostScript printer to be actually printed (this assumes you want the
printouts) using (in the case of gks version 7.4)

\begin{verbatim}
   % lpr gks74.ps
\end{verbatim}


\subsection{Image Shifts}

The automatic centroid tracking in the \xref{\verb+TRAK+}{sg3}{TRAK} command is not always
optimal, and there is often a need to provide an initial estimate for a global
shift of the spectrum on the image.  In our LORES example we can find this shift
by:

\begin{verbatim}
   > SCAN
   > PLSCAN
   > CGSHIFT
\end{verbatim}

\xref{\verb+SCAN+}{sg3}{SCAN}
performs a scan across the image along a line perpendicular to the
dispersion direction.  For our LORES example, which is assumed to have some
continuum, this will result is a spectrum consisting of a peak for each
aperture traversed.  The \xref{\verb+PLSCAN+}{sg3}{PLSCAN}
 command plots this scan on the current
graphics device, and \xref{\verb+CGSHIFT+}{sg3}{CGSHIFT}
 makes the graphics cursor appear.
\verb+CGSHIFT+ allows you to mark where the signal peak is using the cursor.

(Each workstation will have it's own pointing device, these days usually a
mouse, or if you're lucky a trackerball.  Which ever you have, it'll have two
or three buttons which for the purposes of this document are numbered 1 to 3.
[Usually] by default, button number one is under the first finger of a
right-handed mouse user.  Left handed users will find that most X Window
session managers can be configured to reverse the button order so that the
``one-to-three'' numbering scheme is a bit more natural.)

So the cursor should be moved to point at the peak (which should in this case
be near the centre of the plot), and button \verb+1+ pressed.  \verb+CGSHIFT+
will then use this position to calculate a value for the global spectrum shift.
If you hit button \verb+1+ too soon, you can repeat this step again; the
sequence is terminated by button \verb+2+\@. \verb+CGSHIFT+ will take the {\em
last} cursor position you gave it to use for the spectrum shift, and this is
then stored in the dataset.

There is quite a lot more to the \xref{\verb+SCAN+}{sg3}{SCAN}
 and \xref{\verb+CGSHIFT+}{sg3}{CGSHIFT}
 commands than
is described here, you can find about this in later parts of the Guide.

The spectrum shift is normally not too important for LORES; however,
since the sequence just described is really quite simple (and fast), it
probably makes sense to go through:

\begin{verbatim}
   > SCAN
   > PLSCAN
   > CGSHIFT
   > TRAK
\end{verbatim}

for each LORES spectrum as a matter of routine.  The scan plot can often
show you things that would not otherwise have been apparent.  For example, if
there is any gross asymmetry or significant structure in the profile, then (in
the case of LAP) this might be due to spatial structure in the object (or it
might not)\@.


\subsection{Spectrum Output}

Now that we have produced a calibrated spectrum, the next thing to do is
analyse it.  By analyse we mean that measurements are made on it (line
strengths, continuum shapes, {\it etc.})\ and that it is compared to other
spectra.

None of these Analysis facilities are yet available in IUEDR\@.  However,
they are available in a separate programme, called \xref{DIPSO}{sun50}{}\@.
DIPSO offers excellent facilities for the analysis of spectra once they
have been transformed into standard format.

Continuing our LORES example (\verb+LWR14931+), we can create a file suitable
for use with DIPSO by:

\begin{verbatim}
   > OUTSPEC
\end{verbatim}

which picks up defaults for the \xref{\verb+DATASET+}{sg3}{DATASET}
 and \xref{\verb+APERTURE+}{sg3}{APERTURE}
 parameters,
and invents a fairly meaningful file name (and tells you about it)\@.  The
\xref{\verb+OUTSPEC+}{sg3}{OUTSPEC}
 command creates a file with format \htmlref{`SPECTRUM
0'}{subap:spectrum} in DIPSO's
terminology; you will need to know this when you read it into that
programme.\footnote{Actually Starlink NDFs have replaced SPECTRUM 0 format,
but the terminology is retained, {\it{i.e.,}} the DIPSO SP0RD command is used
to read the file produced by IUEDR\@.}

Beyond this point you will need to look at the documentation for DIPSO,
which is released as part of the Starlink Software Collection. This programme
is described in \xref{Starlink Document SUN/50}{sun50}{}.


\subsection{Working with HIRES data}

Having used the simpler case of LORES to introduce a number of aspects of
IUEDR facilities, we must now turn to examine how HIRES data are handled.

Most things are the same for LORES and HIRES datasets; indeed many of the
same commands are used, even if they behave slightly differently for the two
cases.

Assume that we have created a HIRES dataset ({\it{e.g.,}} \verb+SWP6766+) using
\xref{\verb+READIUE+}{sg3}{READIUE}\@.  Since the spectrum shift is more
important for HIRES, we begin by finding it using:

\begin{verbatim}
   > SCAN ORDERS=[66,69]
   > PLSCAN
   > CGSHIFT
\end{verbatim}

where \xref{\verb+DATASET+}{sg3}{DATASET}
 and \xref{\verb+DEVICE+}{sg3}{DEVICE}
 are assumed predefined.  This sequence
is almost the same as for our LORES example, except that we have specified that
the scan cover \'{E}chelle orders 66 to 69.  This means that when
\xref{\verb+PLSCAN+}{sg3}{PLSCAN}
produces the scan plot it will contain only a few peaks (instead of about 60!)
which are well resolved.  \xref{\verb+CGSHIFT+}{sg3}{CGSHIFT}
 operates in much the same way as
before, except that when you position the cursor on a peak and press mouse
button\verb+1+, it figures out which \'{E}chelle order it is, and works out a
spectrum shift from that.  Again there is a cursor sequence, terminated by
pressing mouse button \verb+2+ and with the {\em last\,} spectrum shift being
saved in the dataset.

Although you can measure a spectrum shift from each order peak, there is
only one spectrum shift (at any one time) for the whole dataset.
Therefore, since the shift may actually vary with order number, you
should repeat the above sequence starting with, for example:

\begin{verbatim}
   > SCAN ORDERS=[115,112]
\end{verbatim}

which will let you work with the higher numbered orders (which are much
closer together on the image)\@.

Once the global spectrum shift has been determined, you can then extract the
spectrum from the image using \xref{\verb+TRAK+}{sg3}{TRAK}\@. In the HIRES
case, \verb+TRAK+
differs in that you must specify which \'{E}chelle orders are to be extracted.
To extract a single order:

\begin{verbatim}
   > TRAK ORDER=89
\end{verbatim}

To extract a group of orders, type, for example:

\begin{verbatim}
   > TRAK ORDER=125 NORDER=60
\end{verbatim}

which will extract orders 125 through to 66.  Spectrum extraction using
the \verb+TRAK+ command is not very fast, and you will notice this all the more
working with HIRES data.

The HIRES spectrum is broken up into individual \'{E}chelle orders, so that
when we display it, for example using \xref{\verb+PLFLUX+}{sg3}{PLFLUX},
then the \xref{\verb+ORDER+}{sg3}{ORDER}
parameter is used to specify which one we want.  Consider the example:

\begin{verbatim}
   > TRAK ORDER=89 NORDER=2
   > PLFLUX
\end{verbatim}

When \verb+TRAK+ extracts the spectrum for more than one order, it leaves the
\verb+ORDER+ parameter with the value corresponding to the last one it
processed.  So, in the above example, \xref{\verb+PLFLUX+}{sg3}{PLFLUX}
 plots order number 88.

\xref{\verb+OUTSPEC+}{sg3}{OUTSPEC}
 also works for HIRES, but it only outputs the spectrum for a
single \'{E}chelle order:

\begin{verbatim}
   > OUTSPEC ORDER=89
\end{verbatim}

This has only limited application: normally you want to merge all of the
\'{E}chelle order spectra into a single entity.  So let's see how this is done.


\subsection{Merging HIRES Spectra}

Suppose we have extracted the spectra for all the relevant orders in our
example HIRES image.  We can combine these spectra using:

\begin{verbatim}
   > MAP ORDERS=[125,66] ML=[1100,2100] MSAMP=0.05
\end{verbatim}

which will map the \'{E}chelle orders in the range 66 to 125 onto an evenly
spaced wavelength grid between 1100 and 2100\AA , with step size 0.05\AA\@.
This example effectively merges the whole spectrum into one.  Clearly you can
also use \xref{\verb+MAP+}{sg3}{MAP}
 in a more selective way.  By specifying a smaller range for
the \xref{\verb+ML+}{sg3}{ML}
 parameter you can get a better sampled spectrum
for the wavelength region you are interested in.

At any one time there is only one Mean Spectrum (as produced by \verb+MAP+)\@.
You can plot the mean spectrum using:

\begin{verbatim}
   > PLMEAN
\end{verbatim}

which operates much like \xref{\verb+PLFLUX+}{sg3}{PLFLUX}\@.  You can also
output it to a Starlink NDF file using:

\begin{verbatim}
   > OUTMEAN
\end{verbatim}

So if you are interested in (say) the profiles of a few broad spectral
features, you can \verb+MAP+ each one and output them to separate NDF files.


\subsection{Further Reading}

At this stage of reading you should have a rough idea of how IUEDR
operates.  It would be useful for you to try out some of the things already
described on your own data.  This will give you a feel for how the programme
works that no amount of written documentation can simulate.  Initially,
you may find it helpful and safer to force prompting for all parameters;
as you get more confident and understand what is happening, you will probably
take advantage of the default mechanism and let your work flow.

The IUEDR Reference Manual \xref{(SG/3)}{sg3}{} provides identical information
to that available in the HELP facility.  However, you may find wandering
through HELP more effective in some cases.

An excellent introduction to IUEDR, \xref{{\sl IUE Analysis---A
Tutorial}}{sg7}{} (SG/7)
is worth a read at least once.  This is the best way to start out with IUEDR,
except perhaps, for finding someone to give you a few pointers in person.

To keep this Tutorial brief, a number of facilities and features have been
omitted totally.  If you intend to use IUEDR seriously, and especially if you
are dealing in non-standard kinds of image then it is essential that you {\em
not} stop reading at this point.

By working through the remainder of this Guide, you will find the answers to
some of the questions raised so far, and some questions you didn't know were
there!


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{user_interface}\label{se:user_int}USER INTERFACE}
\markboth{User Interface}{\stardocname}

This Section on the User Interface is aimed at describing the more general
aspects of using IUEDR\@.  Specific commands will be used in the examples, but
their detailed descriptions will be delayed until later Sections.


\subsection{Commands and Parameters}

Essentially, the User Interface consists a set of Commands, and a set of
Parameters associated with these Commands.

The Parameters are Global in scope.  This means that
({\it{e.g.,}})\ \xref{\verb+DATASET+}{sg3}{DATASET}
 has the same meaning in all commands.  If the value
associated with \verb+DATASET+ is not changed or cancelled, then it retains
its value between commands.

This facility of remembering parameter values between commands is, in some
cases not very useful.  This is because the value of a parameter may only be
meaningful to a single invocation of a single command.  Therefore, some
commands cancel the values of parameters that they use, so that new values
will be requested next time they are run.

The values associated with parameters can be set at any time.  For example:

\begin{verbatim}
   > SET DATASET=SWP14178
   > SET DEVICE=XWINDOWS
   > SET XL=[1150,1950]
   > SET PLFLUX
\end{verbatim}

sets values for \verb+DATASET+, \xref{\verb+XL+}{sg3}{XL}
 and \xref{\verb+DEVICE+}{sg3}{DEVICE}
 parameters, and
then uses the \xref{\verb+PLFLUX+}{sg3}{PLFLUX}
 command to plot the flux spectrum.  Nothing actually
happens until the \xref{\verb+PLFLUX+}{sg3}{PLFLUX}
 command is typed.  So if the wrong \verb+DATASET+
value was typed (and accepted), this can be changed before the \verb+PLFLUX+
command.

In general, no distinction is made between upper and lower case letters, so
that the following would be interpreted identically:

\begin{verbatim}
   > PLFLUX
   > Pf
   > pF
   > pf
\end{verbatim}

This goes for commands, parameters, file names, and so on.  The one place
where the case is retained is in textual strings used to identify data.
For example:

\begin{verbatim}
   > SET OBJECT="Vega (Alpha Lyrae)"
\end{verbatim}

would be left as it is.  The convention of using upper case in the examples
here is purely to aid visibility.

The values of parameters can also be set on the same line as the command.
For example, we can achieve identical results to the case shown above with:

\begin{verbatim}
   > PLFLUX DATASET=SWP14178 DEVICE=XWINDOWS XL=[1150,1950]
\end{verbatim}

The choice of when to set parameter values is normally up to you.  The first
parameter (in this case \xref{\verb+DATASET+}{sg3}{DATASET}
) must be separated from the command (in
this case \xref{\verb+PLFLUX+}{sg3}{PLFLUX}
) by one or more blanks.  Parameters can be separated by
either one or more blanks (or tabs), or a \verb+,+ (Comma) and zero or more
blanks (or tabs)\@.

If a command finds that a parameter has not been set, or has an unacceptable
value, then it will normally prompt you for a value.  To continue elaboration
of the above example, suppose \xref{\verb+DATASET+}{sg3}{DATASET},
\xref{\verb+DEVICE+}{sg3}{DEVICE}
 and \xref{\verb+XL+}{sg3}{XL}
 were
all previously undefined:

\begin{verbatim}
   > PLFLUX
   DATASET - Dataset name. > SWP14178
   DEVICE - GKS/SGS graphics device name. > XWINDOWS
   XL - X-axis plotting limits, [0,0] means auto-scale. > 1150,1950
\end{verbatim}

Note that we can leave off the parentheses around the \verb+XL+ value list
when it is being prompted for.  If any of these responses to prompts were
unacceptable, then the command will re-prompt.  If the decision is made to not
continue with this command, then it can be aborted by the response:

\begin{verbatim}
   DATASET - Dataset name. > !!
\end{verbatim}

to a prompt.


\subsection{Control of Prompting and HELP information from commands}

The normal case will be that parameters such as \xref{\verb+DATASET+}{sg3}{DATASET}
 and
\xref{\verb+DEVICE+}{sg3}{DEVICE}
 will be set very rarely (perhaps once at the start of the session
in response to a prompt), so that commands will use their current values.  This
makes it easy to work without continually specifying the same thing over and
over again.

In some cases, the command may automatically prompt you for certain
parameters, even if they have values.  This is done to help you see what will
be done, and give you the chance to stop it if necessary.

In other cases, it may be safest if you ask to be prompted for parameters
even if they have values.  Suppose the \verb+DATASET+, \verb+DEVICE+ and
\verb+XL+ parameters have been previously set:

\begin{verbatim}
  > PLFLUX PR
  DATASET - Dataset name. /'SWP14178'/ > <RETURN>
  DEVICE - GKS/SGS graphics device name. /'XWINDOWS'/ > <RETURN>
  XL - X-axis plotting limits, [0,0] means auto-scale. /1150,1950/ > <RETURN>
\end{verbatim}

The \verb+PR+ syntax forces prompts for all parameters.  The default value is
printed with each prompt.  Typing the \verb+RETURN+ key causes the default to be
accepted, alternatively a replacement value can be typed.


\subsection{Response to Parameter Prompts}

Help about a parameter can also be supplied while you are being
prompted:

\begin{verbatim}
  XL - X-axis plotting limits, [0,0] means auto-scale. /[1150,1950]/ > ?

   <information about the XL parameter>

  XL - X-axis plotting limits, [0,0] means auto-scale. /[1150,1950]/ > <RETURN>
\end{verbatim}

Here is a summary of special responses to parameter prompts:

\begin{latexonly}
\begin{tabular}{ll}
{\tt !!}  & Abort command\\
{\tt !}   & Cancel parameter value (leave it undefined)\\
{\tt ?}   & Ask for on-line HELP information\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>Response  Meaning</B>
   !!     Abort Command
   !      Cancel parameter value (leave it undefined)
   ?      Ask for on-line HELP information
</PRE>
\end{rawhtml}
\end{htmlonly}

\subsection{Multiple Parameter Values}

Normally, a parameter will consist a single value of some specific type.
However, sometimes a list of values is possible.  For example:

\begin{verbatim}
   ORDERS - This delineates a range of Echelle orders. > [66,125]
\end{verbatim}

may be used to delimit a range of Orders.  If the parameter has only a single
value:

\begin{verbatim}
   ORDERS - This delineates a range of Echelle orders. > 89
\end{verbatim}

then this may be interpreted as:

\begin{verbatim}
   ORDERS - This delineates a range of Echelle orders. > [89,89]
\end{verbatim}

by the command (see the description of the specific command for whether
this is really the case)\@.

At present, there are no cases where a list of names/strings is required.


\subsection{Help Information}

Help information is available for commands, parameters and other IUE related
topics.  The mechanism used to implement this is identical to the VMS HELP
facility, so that familiarity with that will be of benefit here.

To obtain general information on what help is available type:

\begin{verbatim}
   > HELP
\end{verbatim}

at the IUEDR prompt.
This will display what HELP topics are available, and prompt for which one is
required.  To leave HELP when in this mode, type the \verb+RETURN+ key until
you get back to the IUEDR \verb+>+ prompt.

If you know what topic you want help information for then this can be
obtained by typing, for example:

\begin{verbatim}
   > HELP PLFLUX
\end{verbatim}

You may have to press \verb+<RETURN>+ a couple of times to exit the help
facility once the information (in this case for
\xref{\verb+PLFLUX+}{sg3}{PLFLUX}) has been
displayed---alternatively you can explore the HELP information interactively
by selecting from the menus listed.  No matter what depth you have reached in
the help facility you can always return to the IUEDR \verb+>+ prompt by
pressing \verb+<RETURN>+ a few times.

The IUEDR HELP text can also be accessed from your shell using:

\begin{verbatim}
   % iuehelp
\end{verbatim}

you can specify a help topic in the same way from within IUEDR:

\begin{verbatim}
   % iuehelp plflux
\end{verbatim}

A hypertext version of the HELP text can be accessed by typing:

\begin{verbatim}
   % iuewww
\end{verbatim}


\subsection{\xlabel{script_mode}\label{subse:sc_and_ba}Running IUEDR in Script Mode}

It is possible to run IUEDR in a script mode, with command and
parameter inputs coming from a file.  For example:

\begin{verbatim}
   % iuedr < swp14178.cmd > swp14178.lis
\end{verbatim}

where the file \verb+swp14178.cmd+ contains the programme input, and where
textual output is sent to the file \verb+swp14178.lis+\@.

IUEDR will finish and return to the command shell when it exhausts its standard
input, or when it encounters a command \xref{\verb+QUIT+}{sg3}{QUIT}
 or \xref{\verb+EXIT+}{sg3}{EXIT}
 in its input.


\subsection{Log File}

At the start of each Interactive session a file \verb+session.lis+ is created.
This file is used to keep a record of what has been done during the session.

The following textual information is currently written to the log file:

\begin{enumerate}

\item All command line input.

\item All IUEDR internal error messages.

\item All textual output produced by commands.

\item All parameter values as used by each command.

\end{enumerate}

The contents of this Log can be useful in keeping track of what has been
done to produce a given result (only minimal information about past data
processing is retained in the datasets themselves)\@.

It will sometimes be necessary and helpful to print off a copy of the Log
File.  This should not be the automatic choice, since the Trees have a right
to live too!  If only some parts of the Log File are needed in hard copy
form, then the unwanted parts can be deleted (using a text editor) prior to
printing.


\subsection{Reading Tapes}

In IUEDR, tape reading commands use the parameter
\xref{\verb+DRIVE+}{sg3}{DRIVE}, to refer to the
Tape Drive.

IUEDR commands that read from tape like to know about the tape position, and
to refer to absolute file numbers.  For example:

\begin{verbatim}
   > LISTIUE FILE=2
\end{verbatim}

will perform an IUE tape analysis starting at file number 2.  This is also
convenient for you, since the guessing and frantic computation of how many file
marks to skip to get from one image to another is precluded.

The only practical way the tape position can be determined is if the tape is
rewound when it is first needed by a tape command.  This may seem harsh;
however, if you intend reading the contents of several files on the tape,
this can all be done in a single session.


\subsection{\xlabel{graphics}\label{subse:graphics}Graphics}

IUEDR has a number of commands that take advantage of the availability of
graphical display.  This does not mean that access to a graphics terminal is
mandatory, however, it helps by providing a clear view of what is going on.

At any given time there is a single current display device, which is
described by the \xref{\verb+DEVICE+}{sg3}{DEVICE}
 parameter.

\begin{latexonly}
The \verb+DEVICE+ parameter is initially undefined, so that the first command
that needs it will cause it to be prompted for.  Once \verb+DEVICE+ has a
value, you will not be prompted for it again, and it will keep its value until
you change it.  The graphics device display names available under GKS 7.4 are
listed in Table~\ref{ta:sgs}\@.

\begin{table}
\caption[Graphics Display Devices Names]{Graphics Display Device Names.}
\begin{tabular}{ll}
{\tt DEVICE}           & Description\\
{\tt mfile\_output}    & Metafile output\\
{\tt cgm\_output}      & CGM output\\
{\tt tek\_4010}        & Tektronix 4010\\
{\tt tek\_4014}        & Tektronix 4010\\
{\tt cifer\_2634}      & Cifer 2634\\
{\tt cifer\_t5}        & Cifer T5\\
{\tt pericom\_7800}    & Pericom 7800\\
{\tt pericom\_mg}      & Pericom MG series and Graphpack\\
{\tt pericom\_mg\_ral} & Pericom MG (RAL mods)\\
{\tt graphon}          & GraphOn 235\\
{\tt canon\_l}         & Canon laser printer (landscape)\\
{\tt canon\_p}         & Canon laser printer (portrait)\\
{\tt canon\_ltex}      & \TeX\ landscape (Canon printer)\\
{\tt canon\_ptex}      & \TeX\ portrait (Canon printer)\\
{\tt ps\_p}            & Postscript A4 portrait\\
{\tt ps\_l}            & Postscript A4 landscape\\
{\tt epsf\_p}          & Encapsulated postscript (portrait)\\
{\tt epsf\_l}          & Encapsulated postscript (landscape)\\
{\tt pscol\_p}         & Colour postscript A4 portrait\\
{\tt pscol\_l}         & Colour postscript A4 landscape\\
{\tt epsfcol\_p}       & Colour encapsulated postscript (portrait)\\
{\tt epsfcol\_l}       & Colour encapsulated postscript (landscape)\\
{\tt regis}            & Regis monochrome terminal\\
{\tt regis\_colour}    & Regis colour terminal\\
{\tt xwindows}         & X-windows\\
{\tt x2windows}        & X-windows\\
{\tt x3windows}        & X-windows\\
{\tt x4windows}        & X-windows\\
{\tt xoverlay}         & X-overlay\\
{\tt x2overlay}        & X-overlay\\
{\tt x3overlay}        & X-overlay\\
{\tt x4overlay}        & X-overlay\\
\end{tabular}
\label{ta:sgs}
\end{table}

If you have a different version of GKS at your Site then the list of available
devices may well be different.  You can determine which are available on any
particular machine by:

\begin{verbatim}
   > SGS
\end{verbatim}

Which will print a list similar to Table~\ref{ta:sgs}\@.
\end{latexonly}

\begin{htmlonly}
The \xref{\verb+DEVICE+}{sg3}{DEVICE}
 parameter is initially undefined, so that the first command
that needs it will cause it to be prompted for.  Once \verb+DEVICE+ has a
value, you will not be prompted for it again, and it will keep its value until
you change it.  The graphics device display names available under GKS 7.4 are
listed in the Table below.
\begin{rawhtml}
<PRE>
<B>DEVICE            Description</B>
mfile_output      Metafile output
cgm_output        CGM output
tek_4010          Tektronix 4010
tek_4014          Tektronix 4010
cifer_2634        Cifer 2634
cifer_t5          Cifer T5
pericom_7800      Pericom 7800
pericom_mg        Pericom MG series and Graphpack
pericom_mg_ral    Pericom MG (RAL mods)
graphon           GraphOn 235
canon_l           Canon laser printer (landscape)
canon_p           Canon laser printer (portrait)
canon_ltex        TeX landscape (Canon printer)
canon_ptex        TeX portrait (Canon printer)
ps_p              Postscript A4 portrait
ps_l              Postscript A4 landscape
epsf_p            Encapsulated postscript (portrait)
epsf_l            Encapsulated postscript (landscape)
pscol_p           Colour postscript A4 portrait
pscol_l           Colour postscript A4 landscape
epsfcol_p         Colour encapsulated postscript (portrait)
epsfcol_l         Colour encapsulated postscript (landscape)
regis             Regis monochrome terminal
regis_colour      Regis colour terminal
xwindows          X-windows
x2windows         X-windows
x3windows         X-windows
x4windows         X-windows
xoverlay          X-overlay
x2overlay         X-overlay
x3overlay         X-overlay
x4overlay         X-overlay
</PRE>
\end{rawhtml}
If you have a different version of GKS at your Site then the list of available
devices may well be different.  You can determine which are available on any
particular machine by:

\begin{verbatim}
   > SGS
\end{verbatim}

Which will print a list similar to the Table above.
\end{htmlonly}

Most of these graphics devices have a cursor associated with them.

A cursor-command can use either the keyboard keys or mouse keys.
The meaning of the keyboard keys \verb+1+, \verb+2+ and \verb+3+ corresponds
to the mouse keys running from left to right.

It is a convention, in commands that take a cyclic sequence of cursor hits,
that the right-most key (number 3) is used as a terminator.

The normal action of the plotting commands is that they erase the screen
before plotting what they want to plot.  Whether this is done is controlled by
the \xref{\verb+RS+}{sg3}{RS}
 parameter.  \verb+RS+ initially has the value \verb+YES+, which
means that:

\begin{verbatim}
   > PLFLUX DATASET=SWP14178
   > PLFLUX DATASET=SWP14179
\end{verbatim}

produces two graphs in succession, with the screen erased prior to plotting
each one.  The value of \verb+RS+ can however be set so that:

\begin{verbatim}
   > SET RS=NO
   > PLFLUX DATASET=SWP14178
   > PLFLUX DATASET=SWP14179
\end{verbatim}

will produce a graph with axes and annotation based on \verb+SWP14178+, but with
the \verb+SWP14179+ spectrum plotted on top.  In fact, further commands will
continue to add to this composite plot until an explicit erase command is given:

\begin{verbatim}
   > ERASE
\end{verbatim}

or until the value of \verb+RS+ is set \verb+YES+:

\begin{verbatim}
   > SET RS=YES
\end{verbatim}

Care is needed when working with \verb+RS=NO+, since successive commands
plotting different kinds of data ({\it{e.g.,}} Calibrated Flux and Net Flux)
may appear
to plot nothing (because all of the second dataset lies outside the axes
defined for the first)\@.

Very often it is easiest to let the various plot commands decide on display
limits that contain the whole of what is being plotted.  If this produces too
much detail, then it is sometimes possible to reduce the size of the dataset
being plotted.

It is, however, inevitable that only a selected coordinate range will be
required for some work.  In most plot commands, the coordinate limits are
specified by the \xref{\verb+XL+}{sg3}{XL}
 and \xref{\verb+YL+}{sg3}{YL}
 parameters.  These are given initial
defaults:

\begin{verbatim}
   XL=[0,0]
   YL=[0,0]
\end{verbatim}

Which means that the plot is to be scaled so that it contains all of the
data.  To specify a particular X-coordinate (horizontal) range you could use:

\begin{verbatim}
   > PLFLUX XL=[1150,1350]
\end{verbatim}

This will plot in the range 1150--1350\AA\@.  Since \verb+YL=[0,0]+ the
Y-range is still determined automatically.  To specify both ranges:

\begin{verbatim}
   > PLFLUX XL=[1500,1600] YL=[0,5E-13]
\end{verbatim}

The case of only specifying \verb+YL+ is unlikely to find much application,
but it is possible.

When a plot has been displayed using (for example)
\xref{\verb+PLFLUX+}{sg3}{PLFLUX}, it is
possible to obtain measurements of coordinates from the plot using the
graphics cursor:

\begin{verbatim}
   > CURSOR
\end{verbatim}

This will display the cursor against the plot.  Successive hits of the \verb+1+
key will cause the coordinates to be printed on the terminal.  The cursor cycle
can be stopped by the \verb+3+ key.  The coordinates printed are in value space
({\it{e.g.,}} wavelength and flux)\@.

Auto-scaling of plots is such a convenient way of working that when
\xref{\verb+XL+}{sg3}{XL} or
\xref{\verb+YL+}{sg3}{YL}
 are set to specific ranges, care should be taken to set these back to
\verb+[0,0]+ for later work.

When plots are sent to a PostScript \xref{\verb+DEVICE+}{sg3}{DEVICE}
 they are not printed
automatically.  Typically the files can be printed (outside of IUEDR)
by:

\begin{verbatim}
   % lpr gks74.ps
\end{verbatim}

You should note that the \verb+.ps+ files must be created properly by IUEDR,
and that this is not possible if the session ends abnormally.  For example, if
you type the \verb+CONTROL_Y+ or
\verb+CONTROL_C+ keys, or the programme crashes (rare), or
the machine crashes during a session (also rare), then the \verb+.ps+ files
may be incomplete (they will spool OK, but are unlikely to produce complete
plots)\@.


\subsection{Reference Manual}

The \xref{IUEDR Reference Manual (SG/3)}{sg3}{} contains the descriptions for
each Command.
A printed version of this Manual should be available at your site.  It is
sufficiently voluminous that personal copies may be considered a luxury.

If a printed version is not available, or you want personal copies of the
Manual entries for some of the commands, then the source is stored in the
directory \verb+$IUEDR_BASE+.


\subsection{Other Documentation}

There are several further (small) documents related to IUEDR\@.
The first gives a brief list of problems known to be associated with existing
IUEDR commands.
This is primarily orientated towards deficiencies rather than bugs.
It can be found in the file:

\begin{verbatim}
   $IUEDR_DOC/problems.doc
\end{verbatim}

The other documents give a lists of changes that have been made to IUEDR\@.
This includes corrections (to alleviate problems) to existing commands, and
also the introduction of new commands and facilities.
It can be found in the files:

\begin{verbatim}
   $IUEDR_DOC/ver10.doc
   $IUEDR_DOC/ver11.doc
   $IUEDR_DOC/ver12.doc
   $IUEDR_DOC/ver13.doc
   $IUEDR_DOC/ver14.doc
   $IUEDR_DOC/ver20.doc
   $IUEDR_DOC/ver20a.doc
   $IUEDR_DOC/ver30.doc
   $IUEDR_DOC/ver31-9.doc
   $IUEDR_DOC/ver32.doc
\end{verbatim}

Version 3.0 was the first UNIX version of IUEDR and may be worth perusing if
you are familiar only wit the VMS version.  Version 3.2 contains several new
commands and new calibration data and is also worth reading.


\subsection{Data Files}

In IUEDR, a `Dataset' is the data associated with an observation based on a
single image.  A dataset is specified by the root name of a file ({\it{i.e.,}}
the extension such as \verb+.UEC+ is {\bf not} included)\@.  The
\xref{\verb+DATASET+}{sg3}{DATASET}
parameter is used to hold the dataset file name.  Here are some examples:

\begin{verbatim}
   > SET DATASET=SWP14178
   > SET DATASET=/mjc/iuedr/SWP14178
\end{verbatim}

For each dataset there are a number of separate files, distinguished
by their extensions:

\begin{latexonly}
\begin{tabular}{ll}
{\tt <dataset>.UEC} & Calibration File\\
{\tt <dataset>\_UED.sdf} & Image Data \& Quality File\\
{\tt <dataset>\_UES.sdf} & Uncalibrated Spectrum File\\
{\tt <dataset>\_UEM.sdf} & Calibrated Mean Spectrum File\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<dataset>.UEC        Calibration File
<dataset>_UED.sdf    Image Data &amp; Quality File
<dataset>_UES.sdf    Uncalibrated Spectrum File
<dataset>_UEM.sdf    Calibrated Mean Spectrum File
</PRE>
\end{rawhtml}
\end{htmlonly}

Of these, only the \verb+UEC+ and \verb+_UED.sdf+ files are mandatory
Here is a brief indication of what each file contains:

\begin{description}

\item [{\tt UEC}] This file contains all of the identification and calibration
      information associated with the image and spectra derived from it.

\item [{\tt UED}] This file contains the intensities for pixels and data
      quality values for `bad' pixels contained in the image subset.

\item [{\tt UES}] This file contains the uncalibrated (raw) spectra.  It is
      self-contained in the sense that it does not need to exist.  If it
      exists, but the spectrum is no longer wanted, it can be deleted.

\item [{\tt UEM}] This file contains the calibrated mean spectrum.  It is
      self-contained, in the sense that it does not need to exist.  If it
      exists, but the mean spectrum is no longer wanted, then the file can be
      deleted.

\end{description}

When data are first needed for a dataset, then the contents of the appropriate
files are read into the programme (they are not left open).
If, during a session, the data associated with a particular file change
({\it{i.e.,}}  a new spectrum is produced), then the file is marked as
requiring a new version.
When the session ends, or when the current dataset changes, or in response to
a:

\begin{verbatim}
   > SAVE
\end{verbatim}

command, the files marked as changed are rewritten.

You will always be told when a file is read or written.  This may appear
pedantic; but its does help you to keep track of what new files have been
created during a session.  Also, since some files take a while to
read/write, the information acts to alleviate fears that nothing is
happening.

If you exceed your disk file quota while IUEDR is writing a file, then the
file will exist, but will be incomplete.  Such incomplete files are unlikely
to be readable by IUEDR, so they should be deleted.  You should then be able
to find some spare disk space and get the files written again (using the
\xref{\verb+SAVE+}{sg3}{SAVE}
 command)\@.

If you exceed disk quota when running the
\xref{\verb+READIUE+}{sg3}{READIUE} command, you should
delete all of the files already created by that command and start again
(having found some space to put the new files)\@.


\subsection{File Organisation}

It is not a requirement that you run IUEDR in any particular
directory.  However, it will help you to keep track of what is going on if
you create a directory for IUEDR work.  Such a directory can be created
using the \verb+mkdir+ command, for example:

\begin{verbatim}
   % mkdir username_iuedr
\end{verbatim}

where \verb+username+ is your Starlink Username.  You can then make this your
current working directory by:

\begin{verbatim}
   % cd username_iuedr
\end{verbatim}

The \verb+ls+ command is useful for seeing which files have been created
recently.
For example:

\begin{verbatim}
   % ls -lF
\end{verbatim}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{nature_of_data}\label{se:nature}THE NATURE OF IUE DATA}
\markboth{The nature of IUE Data}{\stardocname}

This Section describes, briefly, the form and content of Guest Observer
(GO) tapes created at the IUE Ground Stations using IUESIPS\@.
Some general aspects related to data reduction are discussed.
The topics addressed are:

\begin{itemize}

\item How to determine which tape file contains the image or spectrum to be
      read.

\item How to determine which version of IUESIPS has been used for data
      processing at the Ground Station.

\item Which ITF tables were used, and whether any problems exist that require
      corrective measures on the part of the user.

\item What other problems can arise.

\end{itemize}

The first line of attack given a GO tape is to perform an analysis of it.
The \xref{\verb+LISTIUE+}{sg3}{LISTIUE}
 command can be used for this.
This will provide a listing of the IUE tape header for each file on the tape
along with an opinion of what it contains (image, spectrum, {\it etc.})\ and
which version of IUESIPS was used.
\verb+LISTIUE+ is described in Section~\ref{subse:tape_anal}\@.


\subsection{The structure of IUE Guest Observer tapes}

IUE tapes are written by IUESIPS as a series of VICAR format files.

The number and content of the tape files for an IUE observation depend on
the spectrograph resolution used, the number of apertures through which
exposures have been made (low resolution only!), and the version of IUESIPS
used by the Ground Station to process the data.  The tape files for an
observation can be summarised in the following Table:

\begin{latexonly}
\begin{tabular}{lllllll}
IUESIPS    & \#1     & \#1     & \#1     & \#2     & \#2     & \#2    \\
Resolution & HIRES   & LORES   & LORES   & HIRES   & LORES   & LORES  \\
Aperture   & SAP/LAP & SAP/LAP & SAP+LAP & SAP/LAP & SAP/LAP & LAP+SAP\\
File       &         &         &         &         &         &        \\
1          & RAW     & RAW     & RAW     & RAW     & RAW     & RAW    \\
2          & GPHOT   & GPHOT   & GPHOT   & PHOT    & PHOT    & PHOT   \\
3          & MESP    & RIS     & RIS     & MESP    & LBLS    & LBLS   \\
4          &         & LBLS    & LBLS    &         & MESP    & MESP   \\
5          &         & MESP    & MESP    &         &         & LBLS   \\
6          &         &         & RIS     &         &         & MESP   \\
7          &         &         & LBLS    &         &         &        \\
8          &         &         & MESP    &         &         &        \\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
IUESIPS     #1       #1       #1       #2       #2       #2
Resolution  HIRES    LORES    LORES    HIRES    LORES    LORES
Aperture    SAP/LAP  SAP/LAP  SAP+LAP  SAP/LAP  SAP/LAP  LAP+SAP
File
1           RAW      RAW      RAW      RAW      RAW      RAW
2           GPHOT    GPHOT    GPHOT    PHOT     PHOT     PHOT
3           MESP     RIS      RIS      MESP     LBLS     LBLS
4                    LBLS     LBLS              MESP     MESP
5                    MESP     MESP                       LBLS
6                             RIS                        MESP
7                             LBLS
8                             MESP
</PRE>
\end{rawhtml}
\end{htmlonly}

This Table requires some explanation.  IUESIPS has undergone a number of
changes and improvements since the launch of the IUE satellite.  Most of
these have left the format of the GO tapes largely unchanged.  However,
recently, IUESIPS has been substantially upgraded, with a resulting change
in the form of the GO tapes.  The two forms of IUESIPS will be referred
to here as IUESIPS\#1 and IUESIPS\#2.

At VILSPA, IUESIPS\#2 was introduced 1 March 1981 (LORES) and 1 March 1982
(HIRES)\@.
However, the observation date may not necessarily indicate which software was
used.

A GO tape may contain several observations, each observation consisting of a
cluster of tape files.  Each tape file starts with a VICAR header which is
mostly printable text, and which contains comments written by IUESIPS
during the data processing.  The VICAR header can be used to identify the
nature of the observations and their subsequent processing.

\begin{latexonly}
The first file in each cluster is always the Raw Image (RAW), which is a
$768 \times 768$ array of Data Number (DN) pixels.
\end{latexonly}

\begin{htmlonly}
The first file in each cluster is always the Raw Image (RAW), which is a
768x768 array of Data Number (DN) pixels.
\end{htmlonly}

\begin{latexonly}
The second file in each cluster is always some kind of photometric image
consisting an array of $768 \times 768$ Flux Number (FN) pixels. (The pixels
are actually stored as Tape Numbers (TN) which can be related directly to FN
values.\@)  In the case of IUESIPS\#1 this is the geometrically and
photometrically corrected (GPHOT) image.  In the case of IUESIPS\#2 this is the
Photometric Image (PHOT)\@.  The main difference between these two types of
photometric image is that GPHOT has been resampled onto a new pixel grid in
which the geometry is corrected for camera distortion.  The distinction between
GPHOT and PHOT can only be made from knowledge of the other tape contents or
from an inspection of the comments in the VICAR header.
\end{latexonly}

\begin{htmlonly}
The second file in each cluster is always some kind of photometric image
consisting an array of 768x768 Flux Number (FN) pixels. (The pixels
are actually stored as Tape Numbers (TN) which can be related directly to FN
values.)  In the case of IUESIPS#1 this is the geometrically and
photometrically corrected (GPHOT) image.  In the case of IUESIPS#2 this is the
Photometric Image (PHOT).  The main difference between these two types of
photometric image is that GPHOT has been resampled onto a new pixel grid in
which the geometry is corrected for camera distortion.  The distinction between
GPHOT and PHOT can only be made from knowledge of the other tape contents or
from an inspection of the comments in the VICAR header.
\end{htmlonly}

The photometric image (PHOT or GPHOT) is followed by one or two groups of
(1 to 3) files.  If observations have been made at low resolution (LORES)
through both the small and large apertures (SAP and LAP respectively), then
there will be two such groups, otherwise and for high resolution (HIRES) there
will be a single group.

The Rotated Image Segment file (RIS here) occurs only for LORES data
processed with IUESIPS\#1; it is not described here.

The Line-by-line Spectrum (LBLS) file occurs for LORES only.  It is a set
of spectra extracted with a 1.4 pixel wide slit running parallel to the
object spectrum.  For each spectrum (order) the file contains data quality,
wavelength and gross signal.  The Line-by-line Spectrum is useful for
investigating extended (resolved) objects that have been observed through
the large aperture, and also as a starting point for re-extracting spectra that
have not been properly handled by the Ground Station processing.

The Merged Extracted Spectrum files (MESP) contain, for each order, data
quality, wavelength, gross, raw background, net and calibrated flux
signals.

It must be said, however, that some tapes containing IUE data may not follow,
rigidly, the file sequence outlined above.

\subsection{\xlabel{itf_problems}\label{subse:itf_prob}ITF problems}

If reliable scientific results are to be obtained from IUE data, then it is
important to know whether the photometric image (from which spectra have
been, or will be, extracted) has been properly calibrated during the Ground
Station processing.

A major problem area is that of the Intensity Transfer Function (ITF) tables
used to photometrically correct the image.  Several ITF tables have been
constructed for use with each of the operational IUE cameras.  In one of the
SWP ITF tables a fundamental error was present and GPHOT images produced with
it require correction if meaningful spectra are to be obtained.

The ITF tables only cover a limited DN range, and if pixels occur above this
range, then their corresponding FN is formally undefined.  However, in images
processed by IUESIPS before 1 February 1980, such pixels had their FN set
to that of the top ITF level.  Thus they are `saturated' in that their FN
represent only lower limits.  These pixels are referred to as being ITF
truncated.

Saturated pixels are flagged by a value of 32767 on the GPHOT image file,
and can easily be identified during spectrum extraction.  However, in order to
identify ITF truncated pixels, the top level in the ITF table must be
known, and this is only available in the IUE text header of the photometric
image (and following) files.

In GPHOT images processed by the Ground Station after 1 February 1980, pixels
above the top ITF level had their FN defined by linearly extrapolating the ITF
table.  Such pixels are likely to be less accurately calibrated, so
that for critical photometric work it may also be important to identify these.

In Photometric Images produced by IUESIPS\#2, the quality of the ITF
calibration is encoded into the relation between TN and FN\@.  There have, so
far, been 2 LWR and 3 SWP ITF tables.  The actual ITF table used can be
identified from those lines in the IUE/VICAR header text which end in
\verb+1PC+\@.  Here is an example:

\begin{verbatim}
PCF C/** DATA REC. 11 1   1   1 768 8448 5 3  6.1  5.0 2536   .00000
          0       1753       3461       6936       9000      10575
      14299      17709      21546      25156      28674
     11.000     11.000     11.000     11.000     11.000     11.000
     11.000     11.000     11.000     11.000     11.000
TUBE   3 SEC EHT  6.1 ITT EHT  5.0 WAVELENGTH 2536 DIFFUSER 0
         C     MODE : FACTOR   .178E 00
\end{verbatim}

(The trailing \verb+1PC+ parts of these lines have been omitted for
technical reasons.\@)  The number \verb+11+ on the first line (beginning
\verb+PCF C/**+) is the number of levels present in the ITF table.  There then
follow two tables of 11 numbers.  The first table contains numbers, called
`ITFNs' here, which are related to the FN values in the ITF table by:

\begin{latexonly}
\begin{displaymath}
{\rm ITFN} = {\rm FN} \times (100 \times {\rm factor} / {\rm SF})
\end{displaymath}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<CENTER>
\end{rawhtml}
ITFN = FN $\times$ (100 $\times$ factor / SF )
\begin{rawhtml}
</CENTER>
\end{rawhtml}
\end{htmlonly}

where `factor' is the \verb+FACTOR+ given in the last \verb+1PC+ line (in this
case 0.178), and SF is the scale factor which is given for each ITF level in
the second table (in this case they are all 11.0)\@.  In practice, since the
factor is only given to 3 significant figures, these relations do not allow the
FN corresponding to the top ITF level to be derived, accurately, from this
table alone.

For GPHOT images, the relation between FN and TN is:

\begin{latexonly}
\begin{displaymath}
{\rm TN} = {\rm FN} + 2000
\end{displaymath}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<CENTER>
TN = FN + 2000
</CENTER>
\end{rawhtml}
\end{htmlonly}

whereas for PHOT images a more complex relation exists (this will not be given
here, since it is not relevant to the current discussion)\@.

In the case of images where there are ITF truncated pixels, the actual value
can be determined empirically, since it will be the largest TN amongst
those that are not DN saturated.

Here is a summary table that will help identify the ITF used from the
\verb+1PC+ table:

\begin{latexonly}
\begin{tabular}{llll}
ITF        & Max.~TN & ITFN Table                      & Dates\\
{\tt LWR1} & 20000   & \verb+0  1800  3700  5600  ... 30000+ &
                                                07-APR-78 to 14-JUN-78\\
{\tt LWR2} & 27220   & \verb+0  2303  4069  8008  ... 42032+ &
                                                14-JUN-78 to Present\\
{\tt SWP1} & 19983   & \verb+0  1800  3600  5500  ...      + &
                                                07-APR-78 to 14-JUN-78\\
{\tt SWP2} & 19740   & \verb+0  1753  3461  6936  ... 28674+ &
                                                14-JUN-78 to 07-AUG-79\\
{\tt SWP3} & 19632   & \verb+0  1684  3374  6873  ... 28500+ &
                                                07-AUG-79 to Present\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
ITF   Max. TN  ITFN Table                       Dates
LWR1  20000    0  1800  3700  5600  ... 30000   07-APR-78 to 14-JUN-78
LWR2  27220    0  2303  4069  8008  ... 42032   14-JUN-78 to Present
SWP1  19983    0  1800  3600  5500  ...         07-APR-78 to 14-JUN-78
SWP2  19740    0  1753  3461  6936  ... 28674   14-JUN-78 to 07-AUG-79
SWP3  19632    0  1684  3374  6873  ... 28500   07-AUG-79 to Present
</PRE>
\end{rawhtml}
\end{htmlonly}

The dates given are approximate, and apply to VILSPA\@.  However, the date of
an image should {\bf not} be used to identify the ITF table since it may have
been reprocessed at a later date, either at the Ground Station, or on one of
the SERC computers.  Here are some further notes on individual ITF tables:

\begin{enumerate}

\item LWR1 was the `Preliminary LWR ITF'\@.  It was only used to process early
      GPHOT images.

\item LWR2 was the `Final LWR ITF', however, it contains some minor errors
      which affect the photometric accuracy.
      This ITF has been used for processing GPHOT and PHOT images.
      For LORES, a correction algorithm is available that operates in
      conjunction with non-IUESIPS spectrum extraction programmes.

\item SWP2 was the `Faulty SWP ITF'\@.  This has been used for creating GPHOT
      images.  It contained a mistake which involved a 25\% error in the `20\%'
      exposure intensity level (Holm 1979)\@.  Further, smaller errors
      also existed at the `10\%' and `40\%' intensity levels.  The
      IUE Project Policy has been to supply reprocessed GPHOT images for HIRES
      observations that were originally calibrated using this ITF\@.  For LORES,
      various algorithms have been suggested that can operate on GPHOT or
      LBLS in conjunction with non-IUESIPS spectrum extraction programmes.
      These LORES correction algorithms typically remove the photometric
      errors to the 1\% level (Snijders 1980)\@.

\item SWP3 is currently the `Final SWP ITF'\@.  It removes errors present
      in SWP2.  It was used for PHOT images, and late GPHOT images.

\end{enumerate}


\subsection{Other problems}

No IUE image is perfect.  There are a number of different effects which
can produce features on IUE images (and in spectra extracted from them)
which are not related to the actual object being observed.  Some of these
represent repeatable phenomena, and can in principle be corrected for.  Others
involve random, or otherwise unpredictable events.

In most cases there is little that can be done other than to be aware of
the problem, and to avoid using affected parts of the spectrum.

\subsubsection{Geo-Coronal Lyman Alpha}

This is scattered light produced by the Earth's Corona.  It consists of an
effectively monochromatic source of Lyman Alpha radiation with wavelength
1215.59\AA\@.  The source is extended, so that for observations
exposed through the large aperture it forms a broad patch on the image across
the signal of a point-source spectrum.  The intensity of the
Geo-Coronal signal is related to satellite position and orientation, and to the
length of exposure.  The actual amount of flux is also a function of the
aperture used.  In long exposure LORES images, which are normally made through
the large aperture, the signal can obliterate any underlying spectrum.

In some cases, the Geo-Coronal signal can be removed.  However, normally the
best that can be done is to recognise the problem, and to avoid using the
affected region, especially for quantitative measurements.

\subsubsection{Microphonics}

This is a periodic interference modulation of the image signal.  The
characteristics and source of this interference are different for each of the
IUE cameras.  For the LWR camera only a few image lines are affected,
whilst for SWP the effect can cover the whole image.  It only appears on
some images.

The effect on the extracted spectrum is to produce a periodic `noise',
which will have a lower frequency than the normal random pixel noise.

The Microphonics phenomenon, and possible corrective solutions have been
discussed by North\-over (1981)\@.
Normally all that can be done is to recognise
the effect where it occurs, and to account for it in a qualitative way when
interpreting the spectra.  In bad cases, re-observation may be required.

\subsubsection{Background removal for HIRES}

During the processing of some HIRES spectra at the Ground Station, the
dispersion constants are not always well matched to the actual image.  In such
cases, the background (taken as the inter-order signal) may well be
over-estimated, with the consequence that the fluxes will be in error.  The
error is not just scalar.  The shape of the spectrum, and of features in
it can be seriously affected.  Significant negative fluxes can also be
generated.  In such cases, it is necessary to re-extract the spectrum from the
image.

Even if the spectrum is located correctly, there remain problems in the
background removal for HIRES\@.  This is particularly so for the high-numbered
\'{e}chelle orders (shorter wavelength), which are sufficiently close
that their signals overlap the inter-order region.  The inter-order signal is an
over-estimate for the background which underlies the order.  Consequently,
significant negative fluxes can be generated in the cores of strong
absorption lines.

\subsubsection{Particle events and Hot Spots}

Fast moving particles which hit the IUE cameras can produce strong bright
spots on the image.  In most cases these spots are symmetric.  Sometimes they
can appear like `Comets'\@.  The effect of such spots can easily be removed from
the background signal.  However, when they fall on top of the spectrum, they
can present problems.  If they are not symmetrically positioned on the
spectrum profile then visual inspection of the image can be used to decide
on their reality.  If they are right on top of the spectrum then their
reality must be decided on more subjective grounds; repeated observations can
help a great deal here.

Certain pixels in the image always contain Bright Spots.  What has been
said about particle events applies equally well to these.  The difference is
that they will always affect the same spectral region.  This fact has
lead to the Ground Stations marking the features produced by these in the
extracted spectrum.

\subsubsection{Gaps in Raw Image}

It sometimes happens that, when the data are transmitted from the
satellite to the Ground Station, certain parts of the image are missing
or corrupt.  The effect would normally manifest itself in terms of
several consecutive image lines having zero DN values (and would appear black
on a Photowrite picture)\@.  There is little that can be done about such cases,
except to be aware that they can occur, and to avoid using the affected parts
of the spectrum.


\subsection{Further Reading}

The information presented in this Section duplicates much of what can already
be found in various IUE Project papers (some of which are supplied to the
Guest Observer)\@.  The intention, here, has been, however, to assemble
in one place, some of the basic information needed for reducing IUE data.
Some aspects have only been mentioned to draw attention to their existence.

More detailed information can be found in the IUE Newsletters issued,
separately, by NASA, ESA and PPARC\@.

Also, the `IUE-VILSPA User's Guide, Volume II, Image Processing' supplied by
the Ground Station is a mine of information.  Some versions of this
might, however, not yet be consistent with the later releases of IUESIPS
software.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{tapes}\label{se:tapes}TAPES}
\markboth{Tapes}{\stardocname}

At present, the only way in which IUEDR datasets can be created is by reading
images from IUESIPS (VICAR format) tapes.  With this in mind, the current
Section deals with various topics associated with IUE Tapes.  The actual
process of reading an image from tape to create a dataset is described in
Section~\ref{se:readiue}\@.


\subsection{\xlabel{tape_analysis}\label{subse:tape_anal}Tape Analysis}

There are a number of good reasons why it is important to know about the
contents of an IUE tape:

\begin{enumerate}

\item It is necessary to know which tape files contain the
      images/spectra that are required.

\item Information about the ITF used (and possible associated problems)
      is only available by looking at the IUE/VICAR text headers.

\item Certain parameters, such as the IUE Camera Temperature
      (\xref{\verb+THDA+}{sg3}{THDA}), and
      observation data, may be obtained from the IUE text header.

\end{enumerate}

Assuming that the tape has been mounted properly (before the IUEDR
session), then the \xref{\verb+LISTIUE+}{sg3}{LISTIUE}
 command can be used to find out what is on the
tape.

\verb+LISTIUE+ lists the VICAR header of each file it analyses, and guesses at
the kind of data it contains using the file size, and assuming that it was
written by IUESIPS\@.

To list all files on a tape:

\begin{verbatim}
   > LISTIUE FILE=1 NFILE=-1 NLINE=-1
\end{verbatim}

The \xref{\verb+NFILE+}{sg3}{NFILE}
 parameter specifies the number of files to be analysed; the
use of \verb+-1+ here means all files through to the end of tape.  The
\xref{\verb+NLINE+}{sg3}{NLINE}
 parameter specifies the number of header text lines to be printed,
the negative number indicates `all'\@.

Use of \xref{\verb+LISTIUE+}{sg3}{LISTIUE}
 in this way will produce a lot of output and take a long
time (tape reading is slow)\@.
To make matters worse, at present there is no mechanism to redirect this
output to a file.  The only practical solution is to analyse a single tape per
IUEDR session, and use the Log File as a permanent record of the tape headers.

It is recommended that a permanent printout of the file headers be produced
for each tape.  However, \verb+LISTIUE+ can be used in a rather more interactive
manner.  This is helpful in cases where there is only a single file of
interest on the tape, or where the tape analysis listing is not at hand.  To
list only a single specified file:

\begin{verbatim}
   > LISTIUE FILE=2 NFILE=1 SKIPNEXT=NO
\end{verbatim}

The \xref{\verb+SKIPNEXT+}{sg3}{SKIPNEXT}

parameter above has been set so that only the header part of the file is read.
In fact, this is the default value for \verb+SKIPNEXT+, so that we
could have omitted it in the above command.  Since \verb+NFILE=1+ is the default
value, and \xref{\verb+LISTIUE+}{sg3}{LISTIUE}
 leaves it with this value (always), we could also have
omitted the \xref{\verb+NFILE+}{sg3}{NFILE}
 parameter above.

The \verb+SKIPNEXT=NO+ option means that the tape is left positioned close to
the start of the file just analysed, with the consequence that it can be read
almost immediately afterwards (without much tape movement)\@.  The
\verb+SKIPNEXT+
parameter is only used if \verb+NFILE=1+.

If \xref{\verb+NFILE+}{sg3}{NFILE}
 is not \verb+1+, then the normal action of \xref{\verb+LISTIUE+}{sg3}{LISTIUE}
 (if
it completes without error) is to set \verb+NFILE=1+ and leave the
\xref{\verb+FILE+}{sg3}{FILE}
parameter so that it points at the next tape file (which is where the tape is
actually positioned)\@.

In the case \verb+NFILE=1+ and \verb+SKIPNEXT=NO+, the \verb+FILE+ parameter
is left unchanged.

These changes to parameter values after \xref{\verb+LISTIUE+}{sg3}{LISTIUE}
 has completed are
designed to make the command easy to use.  In addition, the \xref{\verb+FILE+}{sg3}{FILE}
 and
\xref{\verb+NLINE+}{sg3}{NLINE}
 parameters are also used by the other tape reading commands
({\it{e.g.,}} \xref{\verb+READIUE+}{sg3}{READIUE} described below)\@.

As we shall see, \verb+READIUE+ acts much like \xref{\verb+LISTIUE+}{sg3}{LISTIUE}
 in its tape
handling aspects, and in listing the VICAR header.  However, we cannot, as might
be expected, use \verb+READIUE+ to inspect the VICAR header (and extract
necessary information) directly.  This is because some information ({\it{e.g.,}}
\xref{\verb+THDA+}{sg3}{THDA}
) is only available in the VICAR header of the MELO/MEHI (merged
extracted spectrum) files, which follow the image on the tape.

A word of warning: \xref{\verb+LISTIUE+}{sg3}{LISTIUE}
 is not entirely fool-proof.  The convention
is that the end of useful information on a tape is indicated by two
consecutive tape marks (referred to as an end-of-volume (EOV) mark)\@.
When using \xref{\verb+NFILE=-1+}{sg3}{NFILE},
\verb+LISTIUE+ will stop when it reaches an EOV
mark; however, then the tape is left positioned {\bf beyond} the EOV\@.  The
\xref{\verb+FILE+}{sg3}{FILE}
 parameter is left pointing at the last valid file on the tape
({\it{i.e.,}}  that before the EOV)\@.
It is therefore possible, through subsequent \xref{\verb+LISTIUE+}{sg3}{LISTIUE}
 or \xref{\verb+READIUE+}{sg3}{READIUE}
commands to attempt to read beyond EOV, with unpredictable results.

Some tapes may not even be terminated with a proper EOV mark.  In this case
problems may occur.  If the number of tape files is known, then this should be
specified explicitly with the \xref{\verb+NFILE+}{sg3}{NFILE}
 parameter.  If it is not, then it is
probably safest to go through the tape one file at a time.

Finally (?) if things get confused, you can type:

\begin{verbatim}
   > MTREW
\end{verbatim}

which will move the tape to its start position.  It will also set
\verb+FILE=1+ to be consistent.


\subsection{Magnetic Tape Utilities}

Tape handling is normally handled implicitly, with references being made to
the tape file number ({\it{e.g.,}} in the
\xref{\verb+LISTIUE+}{sg3}{LISTIUE} and
\xref{\verb+READIUE+}{sg3}{READIUE} commands) that
should be used.  However, sometimes it is useful simply to move up or down
a tape, or find out the current position.  For example, during a `think'
period, it may save time if the tape is rewound to its start position.

To this end, IUEDR has a number of tape utility commands; we have already
encountered \xref{\verb+MTREW+}{sg3}{MTREW}\@.  In all these commands, the
tape drive is specified by the \xref{\verb+DRIVE+}{sg3}{DRIVE} parameter,
which will generally take its default value.

A tape can be positioned at the start of a particular file by, for example:

\begin{verbatim}
   > MTMOVE FILE=2
\end{verbatim}

which leaves the tape at the start of file number 2.

The current tape position can be displayed by:

\begin{verbatim}
   > MTSHOW
\end{verbatim}

which will show the file number, block number, and whether the block number
is relative to the start or end of the file.

The tape can be skipped a specified number of tape marks by:

\begin{verbatim}
   > MTSKIPF NSKIP=4
\end{verbatim}

where \xref{\verb+NSKIP+}{sg3}{NSKIP}
 specifies the number of tape marks to be skipped.  If
\verb+NSKIP+
is negative, then tape marks are skipped in the reverse direction
(towards the start of the tape)\@.  \verb+NSKIP+ defaults to \verb+1+ after each
invocation of \xref{\verb+MTSKIPF+}{sg3}{MTSKIPF}, so that the normal
default is to skip forward over the next tape mark.

If it is necessary to access data beyond a standard End-of-Volume (EOV) mark
(two consecutive tape marks), then the only way that this can be done is by:

\begin{verbatim}
   > MTSKIPEOV
\end{verbatim}

\xref{\verb+MTSKIPF+}{sg3}{MTSKIPF}
 will not skip over EOV marks, however many times you try; instead,
the tape is left positioned between the two tape marks that form the EOV mark.
Commands that expect to find EOV marks in the middle of a tape (not
many do!) may handle this condition automatically.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{datasets}\label{se:datasets}DATASETS}
\markboth{Datasets}{\stardocname}

This Section gives a description of what goes to make up the main data parts
of IUEDR datasets.  This includes the Image, Raw Spectrum and Mean Spectrum.


\subsection{Data Quality}

Any data value that is potentially `wrong' can have associated with it a {\em
data quality} value.  As its name implies, this is a qualitative description of
the data value.  It is not in any sense an error estimate.  It finds
application in circumstances where an error estimate is not meaningful.

For example, pixels that have Data Number (DN) which are digitally
saturated, provide only a lower limit to the actual intensity; the
upper limit is unbounded (although it could be construed in the context
of other (unsaturated) pixels)\@.

Another example is where a pixel has an accurate intensity, but is not
needed in a particular situation.  We can cite the case of reseau affected
pixels: the intensities of such pixels are not meaningful during spectrum
extraction.  However, when it comes to finding the positions of reseau marks,
the pixels are highly meaningful.

When a data process ({\it{e.g.,}} spectrum extraction) combines the intensities
from a number of pixels to produce a single value, we consider the data
quality of original pixels to propagate through the data process.  The way
this is done will be specific to each kind of data process, however it does
mean that a record is retained of what kind of data are used to produce a
given result.

The way in which data quality has been implemented in IUEDR is to have a
8-bit (BYTE) value associated with each image pixel and spectrum
intensity.  The convention is that data quality (DQ) is 0 for a `perfect'
value.  The details of how DQ information is stored in these 8-bits are
specific to each kind of data (images, spectra\ldots)\@.  However, there are
some common features.

Each DQ value is broken up into a number of bit fields.  Each bit field
contains one or more consecutive bits, and is used to form a positive
integer.  Single bit fields are used to contain a flag (1=TRUE,
0=FALSE) for some feature ({\it{e.g.,}} `pixel in fiducial')\@.
Multiple bit fields are used to contain code numbers.

Most of the data quality dealings are handled by the commands in a
user-transparent way.  However, the capability exists for the user to set data
quality for various kinds of data.  This facility is present as a
means of using `wrong' data when any result is better than nothing, and also
as a means of marking as `wrong' data values that seem wrong, and are not
wanted.

User editing of data quality is always a reversible process.


\subsection{Images}

An image is the primary data object associated with a dataset.  The
following kinds of images can currently be read:

\begin{latexonly}
\begin{tabular}{lll}
Type   & Size      & Description \\
RAW    & (768,768) & IUE Raw Image (non-photometric, distorted)\\
GPHOT  & (768,768) & IUE GPHOT Image (photometric, undistorted)\\
PHOT   & (768,768) & IUE PHOT Image (photometric, distorted)\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>Type     Size        Description</B>
RAW      (768,768)   IUE Raw Image (non-photometric, distorted)
GPHOT    (768,768)   IUE GPHOT Image (photometric, undistorted)
PHOT     (768,768)   IUE PHOT Image (photometric, distorted)
</PRE>
\end{rawhtml}
\end{htmlonly}

\begin{latexonly}
All images are stored in 16-bit format, with pixel data numbers (DNs) in the
range $-32767$ to +32767.  To allow for greater dynamic range than this, the
actual pixel flux number FN is scaled from DN by:
\end{latexonly}

\begin{htmlonly}
All images are stored in 16-bit format, with pixel data numbers (DNs) in the
range -32767 to +32767.  To allow for greater dynamic range than this, the
actual pixel flux number FN is scaled from DN by:
\end{htmlonly}

\begin{displaymath}
{\rm FN} = D_{SCALE} \times {\rm DN} + {\rm D}_{0}
\end{displaymath}

\begin{latexonly}
The value DN$ = -32768$ is reserved for marking pixels that have no
intensity value ({\it{i.e.,}}  are undefined)\@.  Such pixels {\bf cannot} be
used in any numerical computation (except to note that they were not used)\@.
\end{latexonly}

\begin{htmlonly}
The value DN = -32768 is reserved for marking pixels that have no
intensity value ({\it{i.e.,}}  are undefined)\@.  Such pixels {\bf cannot} be
used in any numerical computation (except to note that they were not used)\@.
\end{htmlonly}

Each pixel has image coordinates (S, L), where S is sample number (horizontal
axis), and L is line number (vertical axis)\@.

Only a subset of pixels in the image is retained.  This subset is defined by a
range of image lines, (LMIN, LMAX), and a range of samples for each of these
lines, (SMIN(L), SMAX(L))\@.  This subset is defined when the image is created.

For IUE images, the subset is bounded by a circle representing the camera
faceplate.  For Low Resolution, the subset is further bounded to include
only a narrow strip that contains the spectrum.

In the current implementation, only pixels within the image subset are
retained on disk.

Each image pixel has an associated data quality value, which is broken up
into the following fields:

\begin{latexonly}
\begin{tabular}{ll}
Bit(s) & Meaning\\
1      & Pixel undefined\\
2      & Pixel unusable\\
3      & Pixel marked unusable by user\\
4      & [field not used]\\
5      & Pixel intensity from extrapolated ITF table\\
6      & Pixel intensity truncated at top of ITF table\\
7      & Pixel intensity was digitally saturated\\
8      & Pixel affected by Reseau mark\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>Bit(s)   Meaning</B>
  1      Pixel undefined
  2      Pixel unusable
  3      Pixel marked unusable by user
  4      [field not used]
  5      Pixel intensity from extrapolated ITF table
  6      Pixel intensity truncated at top of ITF table
  7      Pixel intensity was digitally saturated
  8      Pixel affected by Reseau mark
</PRE>
\end{rawhtml}
\end{htmlonly}

Fortunately, most pixels in most images have DQ=0 ({\it{i.e.,}} are simply
inaccurate rather than wrong)\@.  This means that disk space can be saved by
keeping only a list of pixels that have non-zero DQ\@.


\subsection{Uncalibrated Spectra}

The Spectrum Extraction process creates a spectrum for one or more orders
(HIRES) or apertures (LORES)\@.  Each of these spectra are stored as floating
point arrays of Vacuum Wavelength and Net Flux.

The Net Flux is defined as the integral of FN (above background) on the image
covering a standard wavelength interval.  This wavelength interval corresponds
to a distance of 1.414 geometric pixels along the spectrum dispersion
direction.

This choice of wavelength interval may seem rather obscure, however, it
is designed so that (in many cases) the standard IUESIPS calibrations can be
used directly.

This standard wavelength interval is just used for normalisation purposes; it
is no reflection on the actual interval at which the spectrum is sampled (as
the latter can be varied arbitrarily)\@.

By storing the uncalibrated spectrum in this way, changes to calibrations
are easily effected, and the `final' spectrum can always be readily generated.

Each spectrum point has an associated data quality value, which is broken up
into the following fields:

\begin{latexonly}
\begin{tabular}{ll}
Bit(s) &  Meaning\\
1      &  Point undefined\\
2      &  Point unusable\\
3      &  Point marked unusable by user\\
4      &  [field not used]\\
5--8   &  Severity of `worst' image pixel used for point\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>Bit(s)   Meaning</B>
  1      Point undefined
  2      Point unusable
  3      Point marked unusable by user
  4      [field not used]
 5-8     Severity of `worst' image pixel used for point
</PRE>
\end{rawhtml}
\end{htmlonly}

The Severity code is a small positive integer with one of the
following values

\begin{latexonly}
\begin{tabular}{ll}
Severity & Meaning\\
0        & point is OK\\
1        & point affected by extrapolated ITF\\
2        & point affected by microphonics\\
3        & point affected by spike\\
4        & point affected by bright point\\
5        & point affected by reseau mark\\
6        & point affected by ITF truncation\\
7        & point affected by saturation\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>Severity   Meaning</B>
   0       point is OK
   1       point affected by extrapolated ITF
   2       point affected by microphonics
   3       point affected by spike
   4       point affected by bright point
   5       point affected by reseau mark
   6       point affected by ITF truncation
   7       point affected by saturation
</PRE>
\end{rawhtml}
\end{htmlonly}

These are roughly in order of importance when considering the effect of using
such pixels to produce the spectrum intensity.


\subsection{Mean Spectra}

In the case of HIRES it is often convenient to combine the spectra from
individual \'{E}chelle orders into a single (hopefully) continuous spectrum.

In the case of LORES similar combination of spectra from more than one
aperture can be employed to reduce noise.

The Mean Spectrum is formed from one or more calibrated spectra, each of which
is interpolated onto an evenly spaced wavelength grid.

All the wavelength and flux calibrations are `frozen' into the Mean
Spectrum.  This means that, for example, if the absolute calibration
needs to change, then the Mean Spectrum must be reconstructed from
its component parts.

Each point in the Mean Spectrum has an associated data quality value.  The
possible values correspond to those of the Uncalibrated Spectrum (given in the
previous Section)\@.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{readiue}\label{se:readiue}READING DATA FROM TAPE}
\markboth{Reading Images from Tape}{\stardocname}

The \xref{\verb+READIUE+}{sg3}{READIUE} command reads a RAW, GPHOT or PHOT
image from an IUESIPS tape file, and creates an IUEDR Dataset.

\subsection{Ways of Using {\tt READIUE}}

\xref{\verb+READIUE+}{sg3}{READIUE} has a large number of parameters.
There are two basic approaches to supplying the values for these parameters.

The first approach involves typing:

\begin{verbatim}
   > READIUE PROMPT
\end{verbatim}

and then responding to the prompt for each parameter as it is requested.
The second approach is to create a file using a text editor, and run this as a
script:

\begin{verbatim}
   > iuedr < SWP14178.cmd
\end{verbatim}

This second approach is probably the most practical of the two.  For one
thing, if something goes wrong (a parameter is specified wrongly, or the
system crashes) then the error can be corrected and the script run again,
without the need to type in all the parameter values again.  Also, since most
scripts will be very similar, new files can be adapted from existing ones
with a few judicious edits.


\subsection{The {\tt READIUE} Parameters}

The \xref{\verb+READIUE+}{sg3}{READIUE} parameters are all described in the
Manual; however, some would benefit further explanation here.

The \xref{\verb+DRIVE+}{sg3}{DRIVE}, \xref{\verb+FILE+}{sg3}{FILE}
and \xref{\verb+NLINE+}{sg3}{NLINE} parameters are used in the same
way as for \xref{\verb+LISTIUE+}{sg3}{LISTIUE}\@.  If the header text
has been inspected and relevant information obtained, then a value
\verb+NLINE=10+ will keep the output to a minimum, yet still print enough
of the header to remind you of what the observation is about.

The \xref{\verb+DATASET+}{sg3}{DATASET} parameter value should correspond to
the main part of a file name.  The name is limited to 9 characters, and
should ideally describe the observation in terms of the
\xref{\verb+CAMERA+}{sg3}{CAMERA} and \xref{\verb+IMAGE+}{sg3}{IMAGE}
 used.

The distinction between a RAW and a Photometric Image (GPHOT or PHOT) can
be determined automatically from the tape. However, the distinction between
PHOT and GPHOT requires that the \xref{\verb+TYPE+}{sg3}{TYPE}
 parameter be specified.

The \xref{\verb+CAMERA+}{sg3}{CAMERA}, \xref{\verb+IMAGE+}{sg3}{IMAGE},
\xref{\verb+APERTURES+}{sg3}{APERTURES} and
\xref{\verb+RESOLUTION+}{sg3}{RESOLUTION} parameters should always be
specified correctly. Apart from providing identification information for
the observation, they are used in providing default calibration data.

The \verb+APERTURES+ parameter determines how many apertures have been exposed.
Values of \verb+SAP+ or \verb+LAP+ indicate a single aperture, whereas
\verb+BAP+ indicates both of these.  In the case of \verb+BAP+, it should be
noted that two values will be required for the
\xref{\verb+EXPOSURES+}{sg3}{EXPOSURES} parameter
(exposure time in seconds)\@.

The \xref{\verb+THDA+}{sg3}{THDA}, \xref{\verb+YEAR+}{sg3}{YEAR},
\xref{\verb+MONTH+}{sg3}{MONTH} and \xref{\verb+DAY+}{sg3}{DAY}
parameters are used for temperature and time dependent calibration
corrections.

The \xref{\verb+BADITF+}{sg3}{BADITF} parameter determines whether a
simple correction is made to
remove errors in the intensity caused by use of inaccurate or wrong ITF tables.
This ITF correction is only available for LORES\@.  For the SWP camera at
LORES, this corrects for quite major errors in the Faulty (2nd) production
ITF\@.  For the LWR camera at LORES, this corrects for minor errors in the 2nd
production ITF\@.

The \xref{\verb+ITFMAX+}{sg3}{ITFMAX} parameter is only needed for GPHOT
images.  It is used in
determining whether pixels have suffered from ITF saturation or
extrapolation.  A suitable value can be determined from the GPHOT VICAR
header text (see Section~\ref{subse:itf_prob} of this Guide, and/or the
Manual)\@.

The \xref{\verb+NGEOM+}{sg3}{NGEOM} parameter is there for the sake of
flexibility.  It is the
number of terms used (per axis) in the 2-D Chebyshev Polynomial series that
describes the geometric distortion for RAW and PHOT images.  A default value is
provided, and should not be altered unless vital.

The \xref{\verb+OBJECT+}{sg3}{OBJECT} parameter is a line of text used
to describe the object of
the observation.  This text is used for display purposes ({\it{e.g.,}} above
plots), and should include the object identification.
It does no harm to append the Camera and Image as in the above example.

It is a good idea to provide correct values for these
\xref{\verb+READIUE+}{sg3}{READIUE} parameters.
However, it should be noted that some of these can be changed after dataset
creation.  These include the \xref{\verb+OBJECT+}{sg3}{OBJECT},
\xref{\verb+EXPOSURE+}{sg3}{EXPOSURE}, \xref{\verb+THDA+}{sg3}{THDA}
and \xref{\verb+NGEOM+}{sg3}{NGEOM} parameters.


\subsection{What happens when {\tt READIUE} runs}

As \xref{\verb+READIUE+}{sg3}{READIUE}
 accesses each of the parameters needed to determine what
kind of dataset is being read, it cancels them.  This means that if
\verb+READIUE+ is run again (perhaps for a second image on the tape), then new
values will have to be specified for these parameters.

This parameter cancellation is aimed at avoiding hidden mistakes when not
using the force prompt mode.  However, not all possible cases can be covered,
so you should be careful to see what is going on.

Since \verb+READIUE+ is instrumental in changing the current dataset, it cancels
the values for the \xref{\verb+ORDER+}{sg3}{ORDER}
 and \xref{\verb+APERTURE+}{sg3}{APERTURE}
 parameters, which might
otherwise have meaningless values left over from earlier images.


\subsection{\xlabel{readsips}\label{se:readsips}Reading Spectra from tape
            with {\tt READSIPS}}
\markboth{Reading Spectra from Tape}{\stardocname}

The \xref{\verb+READSIPS+}{sg3}{READSIPS}
 command reads a MELO/MEHI product from an IUESIPS\#1 or
IUESIPS\#2 tape.  Operation is much like \xref{\verb+READIUE+}{sg3}{READIUE},
except that some
parameters and associated information are not needed.  Only calibration
(\verb+*.UEC+) and spectrum (\verb+*_UES.sdf+) files are created.  The values
for certain parameters may be obtained from the tape, in which case you
will not be prompted for them.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{display}\label{se:disp}DISPLAYING IMAGES \& PLOTTING SPECTRA}
\markboth{Displaying Images \& Plotting Spectra}{\stardocname}


\subsection{\xlabel{drimage}\label{subse:drimage}Displaying Images with
            {\tt DRIMAGE}}

The image dataset read from tape with \xref{\verb+READIUE+}{sg3}{READIUE}
can be visually inspected on a suitable image display device using the
\xref{\verb+DRIMAGE+}{sg3}{DRIMAGE} command.  For example:

\begin{verbatim}
   > DRIMAGE DATASET=SWP14178 DEVICE=XWINDOWS
\end{verbatim}

will draw a labelled picture of the image data in \verb+SWP14178_UED.sdf+ in
an X-Window on the current workstation screen.

If the \xref{\verb+DATASET+}{sg3}{DATASET}
 and \xref{\verb+DEVICE+}{sg3}{DEVICE}
 parameters are not given by the user
then IUEDR will prompt for them.

The output from \xref{\verb+DRIMAGE+}{sg3}{DRIMAGE}
 can be controlled by the \xref{\verb+XP+}{sg3}{XP}, \xref{\verb+YP+}{sg3}{YP}

and \xref{\verb+ZL+}{sg3}{ZL}
 parameters.  \verb+XP+ and \verb+YP+ specify the pixel subset to
be drawn.  If either of \verb+XP+ or \verb+YP+ are undefined, then the full
extent of the image is adopted as default.  An example of specific image area
display is:

\begin{verbatim}
   > DRIMAGE XP=[380,420] YP=[220,180]
\end{verbatim}

which displays an expanded subset of the image.  \verb+DRIMAGE+ expands or
compresses the image to fit on the display so that:

\begin{itemize}

\item Maximum display space is used.

\item The complete image subset (as specified by \verb+XP+ and \verb+YP+) is
      displayed.

\end{itemize}

Expansion is performed by duplicating image pixels.  Compression is
performed by averaging adjacent image pixels.  The shape of the image
is always preserved; therefore, it is sensible to keep the \verb+XP+ and
\verb+YP+ ranges of a similar size to avoid rather odd shaped pictures.

The image intensities displayed are limited by the values of the \verb+ZL+
parameter, and relate to picture intensities by:

\begin{latexonly}
\begin{tabular}{ll}
Parameter   & Brightness\\
{\tt ZL(1)} & Black\\
{\tt ZL(2)} & White\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>Parameter    Brightness</B>
  ZL(1)      Black
  ZL(2)      White
</PRE>
\end{rawhtml}
\end{htmlonly}

Image intensities between \verb+ZL(1)+ and \verb+ZL(2)+ follow a linear
grey-scale.  If the \verb+ZL+ parameter is undefined, the full intensity range
of the image is displayed.  However, specific intensity ranges can be selected,
as in:

\begin{verbatim}
   > DRIMAGE ZL=[-1000,1000]
\end{verbatim}

which will enhance the contrast for intensities around zero FN (assuming a
GPHOT or PHOT image).  Alternatively:

\begin{verbatim}
   > DRIMAGE ZL=[32000,-2000]
\end{verbatim}

will display a `negative' image (black is bright, white is faint)\@.
The \xref{\verb+FLAG+}{sg3}{FLAG}
 parameter controls whether bad pixels are colour coded
(c.f.\ \xref{\verb+QUAL+}{sg3}{QUAL}
 for plotting commands)\@.  The details of colour coding are
available in the Manual/HELP text.

\subsubsection{\xlabel{culimits}\label{subse:culimits}Selecting a Region of an Image for Display}

The \xref{\verb+CULIMITS+}{sg3}{CULIMITS}
 command uses the cursor to select a subset of a displayed
image or plot for future display or plotting respectively.  The command
consists of two cursor hits, specifying the start and end coordinates of the
region, effectively the opposite corners of a rectangle on the display.
The sequence of the hits is not important, the image is always displayed
unreflected.

For a displayed image, \xref{\verb+CULIMITS+}{sg3}{CULIMITS}
uses its measurements to set values for the \xref{\verb+XP+}{sg3}{XP}
and \xref{\verb+YP+}{sg3}{YP} parameters.
For any other plot, it sets values for the \xref{\verb+XL+}{sg3}{XL}
and \xref{\verb+YL+}{sg3}{YL} parameter.


\subsection{\xlabel{plotting_parameters}\label{subse:plot}Spectrum Plotting Command Parameters}

The Plotting commands \xref{\verb+PLFLUX+}{sg3}{PLFLUX},
\xref{\verb+PLNET+}{sg3}{PLNET} {\it etc.} have additional
parameters to those described elsewhere in this Guide.  These allow control
over line styles (solid, dashed, {\it etc.}) and colours (on displays with
colour capability).

The line style is controlled by the \xref{\verb+LINE+}{sg3}{LINE}
and \xref{\verb+LINEROT+}{sg3}{LINEROT} parameters.
The \verb+LINE+ parameter can take on one of the following names:

\begin{latexonly}
\begin{tabular}{ll}
Line          & Style\\
{\tt SOLID}   & Solid (continuous) line\\
{\tt DASH}    & Dashed line\\
{\tt DOTDASH} & Dot-dash line\\
{\tt DOT}     & Dotted line\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>Line       Style</B>
SOLID      Solid (continuous) line
DASH       Dashed line
DOTDASH    Dot-dash line
DOT        Dotted line
</PRE>
\end{rawhtml}
\end{htmlonly}

These line styles represent a cycle which can be used instead of (or as well
as) colour as a means of differentiating several spectra on a single graph.  To
step through the cycle (\verb+SOLID+, \verb+DASH+,  \verb+DOTDASH+, \verb+DOT+,
\verb+SOLID+, \verb+DASH+,\ldots ) for a particular graph, the \verb+LINEROT+
parameter should have the value \verb+TRUE+\@.  Thus:

\begin{verbatim}
   > SET DEVICE=S5670
   > SET LINEROT=TRUE
   > SET PLFUX ORDER=89
   > SET PLFUX ORDER=90 RS=NO
\end{verbatim}

which plots order 89 as a solid line and order 90 as a dashed line.
Alternatively, the initial line style can be chosen explicitly, as in:

\begin{verbatim}
   > SET LINEROT=TRUE
   > SET PLFUX ORDER=89 LINE=DASH
   > SET PLFUX ORDER=90 RS=NO
\end{verbatim}

which plots order 89 as a dashed line and order 90 as dot-dashed line.
The line style can, of course be selected explicitly for each plot command,
using \xref{\verb+LINE+}{sg3}{LINE}
 (regardless of \xref{\verb+LINEROT+}{sg3}{LINEROT}), as in:

\begin{verbatim}
   > PLFLUX ORDER=89 LINE=DASH
   > PLFLUX ORDER=90 LINE=SOLID RS=NO
\end{verbatim}

For a given graph there is a current position in the cycle of line
styles.  This is initially set to \verb+SOLID+, although it can be
over-ridden by the \verb+LINE+ parameter.  The rule is that if
\verb+LINEROT=TRUE+ then this current position is changed after plotting to the
next line style.  This behaviour is consistent with the
\xref{\verb+PLGRS+}{sg3}{PLGRS} and \xref{\verb+PLCEN+}{sg3}{PLCEN}
commands which plot more than a single set of points at a time.

The colour used for lines within a graph is controlled by the
\xref{\verb+COL+}{sg3}{COL} and \xref{\verb+COLROT+}{sg3}{COLROT}
 parameters.  The effect of the (\verb+COL+, \verb+COLROT+)
combination is similar to that of (\verb+LINE+, \verb+LINEROT+) described
above, and will not be re-iterated.  The difference is that \verb+COL+ takes
integer values from 1 to  10,  corresponding to a pre-selected set of line
colours (yellow, green, {\it etc.})\@.  So for example:

\begin{verbatim}
   > PLFLUX ORDER=89 COL=4
   > PLFLUX ORDER=90 COL=2
\end{verbatim}

will plot order 89 as green and order 90 as yellow.  The initial
defaults for \xref{\verb+LINEROT+}{sg3}{LINEROT} and
\xref{\verb+COLROT+}{sg3}{COLROT} are:

\begin{verbatim}
   LINEROT=FALSE
   COLROT=TRUE
\end{verbatim}

Users not using a colour display should therefore set \verb+LINEROT=TRUE+\@.

Commands \xref{\verb+PLFLUX+}{sg3}{PLFLUX}, \xref{\verb+PLNET+}{sg3}{PLNET},
\xref{\verb+PLMEAN+}{sg3}{PLMEAN} and \xref{\verb+PLGRS+}{sg3}{PLGRS}
 have an additional style parameter \xref{\verb+HIST+}{sg3}{HIST}\@.
This specifies whether the spectra are plotted as a histogram.
For example:

\begin{verbatim}
   > PLFLUX ORDER=89 HIST=YES
   > PLFLUX ORDER=90 HIST=NO RS=NO
\end{verbatim}

plots order 89 as a histogram and order 90 as a poly-line.  The initial default
is \verb+HIST=TRUE+\@.  The \xref{\verb+PLSCAN+}{sg3}{PLSCAN} and
\xref{\verb+PLCEN+}{sg3}{PLCEN} commands always plot their curves as
poly-lines.

Commands \xref{\verb+PLFLUX+}{sg3}{PLFLUX}, \xref{\verb+PLNET+}{sg3}{PLNET},
\xref{\verb+PLMEAN+}{sg3}{PLMEAN} and \xref{\verb+PLGRS+}{sg3}{PLGRS} also
have
quality flag display parameter, \xref{\verb+QUAL+}{sg3}{QUAL}, which controls
whether the data
quality information associated with faulty points is plotted.  The default is
\verb+QUAL=YES+ which leads to symbols being plotted at the positions of faulty
points in the spectrum.  The key to these symbols is given in the Manual/HELP
text.  Use of \verb+QUAL=NO+ would normally be needed if the symbols from
faulty points are obscuring the `good' data!


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{dataset_calibrations}\label{se:data_calib}AN OVERVIEW OF DATASET CALIBRATIONS}
\markboth{Dataset Calibrations}{\stardocname}

This Section gives a brief description of the calibration data that can be
associated with (and contained in) an IUEDR dataset.


\subsection{Initial Calibrations}

On creation through the \xref{\verb+READIUE+}{sg3}{READIUE}
 command, the dataset is supplied with a
number of calibrations which are stored with it in the Calibration File
({\it{e.g.,}} \verb+SWP14178.UEC+)\@.  These calibrations are selected from
standard sources on the basis of the parameters supplied to \verb+READIUE+
({\it{e.g.,}} \xref{\verb+CAMERA+}{sg3}{CAMERA},
\xref{\verb+APERTURE+}{sg3}{APERTURE},
\xref{\verb+RESOLUTION+}{sg3}{RESOLUTION}, {\it etc.})\@.

Details of these calibrations, and how to change them will be given
further on. Here is a summary of these (and other) calibrations:

\begin{description}

\item [{\bf Fiducials:}]
      This is a description of the grid of fiducial marks formed
      on the image by reseaux marks on one of the in-focus camera surfaces.
      The image coordinates, (S, L), of each fiducial are given.  In some
      cases, the coordinates are a function of the camera temperature
      (\xref{\verb+THDA+}{sg3}{THDA})\@.
      A global fiducial size is also specified so that pixels affected by
      them can be marked.

\item [{\bf Geometry:}]
      This is the relation between raw image coordinates, (S, L),
      and geometric image coordinates, (X, Y), as defined by the fiducial
      positions.  It is represented by a 2-D Chebyshev polynomial.  The
      distance between two pixels in the geometric image coordinate system is
      called a {\em geometric pixel.}

\item [{\bf Dispersion:}]
      This is a specification of the relation between geometric
      image coordinates, (X, Y), and spectrograph coordinates, (R, $\lambda$),
      where $\lambda$ is vacuum wavelength, and R is distance from the spectrum
      on the image measured perpendicular to dispersion (in geometric
      pixels)\@.  For HIRES this coordinate relation is defined for each
      \'{e}chelle order.  For LORES, the coordinate relation is defined for
      each aperture.

\item [{\bf \'{E}chelle Ripple:}]
      This is the ripple calibration needed for HIRES.

\item [{\bf \'{E}chelle Wavelength Clipping:}]
      This consists a pair of wavelengths
      delineating the start and end of good data for each \'{e}chelle
      order.

\item [{\bf Absolute Calibration:}]
      This is the global absolute calibration function.
      It is {\bf not} supplied automatically for HIRES since there are, at
      present, too many factors that affect it (both in the image and in the
      spectrum extraction technique)\@.

\item [{\bf \'{E}chelle Order Overlap:}]
      This is a correction for the effects of
      order-overlap that occurs when \'{e}chelle orders get too close on the
      image.  It is {\bf not} supplied automatically by
      \xref{\verb+READIUE+}{sg3}{READIUE}, since
      it is a strong function of the image kind and spectrum extraction
      technique.

\item [{\bf ITF Correction:}]
      This is an empirical correction to the pixel
      intensities (applied during spectrum extraction), needed to account for
      errors during ITF calibration by IUESIPS.  It is {\bf not} supplied
      automatically by \xref{\verb+READIUE+}{sg3}{READIUE}\@.

\end{description}

For most cases, the problem of calibration is handled automatically by the
programme, and little intervention from the user is required.  However, to
obtain reliable, accurate results it is sensible to be aware of what is
going on.


\subsection{Freezing Calibrations into Results}

The approach to calibration in IUEDR is that calibrations are stored with
the dataset and applied when needed.  This means that calibrations
can be changed, and that the effects of such change can be propagated to
other calibrations and results.  However, there are a number of boundaries
through which calibration changes cannot be propagated.  These
calibration boundaries are delineated by major processes:

\begin{description}

\item [{\bf Spectrum Extraction:}]
      This is where the image pixel intensities are
      combined to produce a raw spectrum.  This raw spectrum does not have
      embedded in it any wavelength or flux calibrations.  Embedded in
      the raw spectrum are such calibrations as determined which pixels would
      contribute to it, and how (Fiducials, Geometry, Dispersion)\@.  The raw
      spectrum can be created by ({\it{e.g.,}})\ the
      \xref{\verb+TRAK+}{sg3}{TRAK} command, and
      is stored in a separate file ({\it{e.g.,}} \verb+SWP14178_UES.sdf+)\@.

\item [{\bf Spectrum Combination:}]
      This is where the raw spectrum for several
      \'{E}chelle orders (HIRES), or several apertures (LORES) are combined to
      produce a mean spectrum.  Prior to being combined to form this mean,
      each raw spectrum is fully calibrated (wavelength, flux)\@.  Thus
      {\bf all} calibrations are embedded in the mean spectrum.  The mean
      spectrum can be created by ({\it{e.g.,}})\ the \xref{\verb+MAP+}{sg3}{MAP}
      command, and is stored in a separate file ({\it{e.g.,}}
      \verb+SWP14178_UEM.sdf+)\@.

\end{description}


\subsection{Inspecting and Changing Calibrations}

Under favourable conditions, you could produce a spectrum using only the
\xref{\verb+READIUE+}{sg3}{READIUE} and \xref{\verb+TRAK+}{sg3}{TRAK}
 commands, responding to prompts for undefined
parameters.  However, working `blind' in this way is not advisable, even if it
appears to work.

The primary command used for inspecting the calibration data associated
with a dataset is \xref{\verb+SHOW+}{sg3}{SHOW}\@. By typing:

\begin{verbatim}
   > SHOW
\end{verbatim}

we get the default action (assuming that \xref{\verb+DATASET+}{sg3}{DATASET}
is defined), which is equivalent to:

\begin{verbatim}
   > SHOW V=H
\end{verbatim}

The \xref{\verb+V+}{sg3}{V}
 parameter is a string of characters that specifies which
calibrations are to be printed.
In the example above, \verb+H+ stands for the basic header information used to
identify the dataset.
If we wanted to print the Absolute and Ripple Calibrations, then:

\begin{verbatim}
   > SHOW V=AR
\end{verbatim}

and so on.  The full specification of how \xref{\verb+SHOW+}{sg3}{SHOW}
 works can be found in its
Manual entry, and various examples will be given in later Sections.

The primary commands for changing the values of calibration parameters
are \xref{\verb+SETD+}{sg3}{SETD}, \xref{\verb+SETA+}{sg3}{SETA}
 and \xref{\verb+SETM+}{sg3}{SETM}\@.

The \verb+SETD+ command allows changes to be made to calibration parameters
that affect the whole dataset. For example, we can change the value of
\xref{\verb+THDA+}{sg3}{THDA} by:

\begin{verbatim}
   > SETD THDA=7.4
\end{verbatim}

The \verb+SETD+ has a number of parameters, each of which is associated with
some aspect of calibration.  We can inspect all of these, and change some or
all by forcing the command to prompt for each parameter:

\begin{verbatim}
   > SETD PR
\end{verbatim}

Hitting the \verb+RETURN+ key for each prompt will result in no changes.  This
approach is another way of finding out the values of calibration parameters.

This way of using \verb+SETD+ can equally be applied to the \verb+SETA+ and
\verb+SETM+ commands.

The \verb+SETA+ command sets calibration parameters associated with a particular
aperture.  For example, we can change the arbitrary flux scale factor
associated with an aperture by:

\begin{verbatim}
   > SETA APERTURE=SAP FSCALE=0.5
\end{verbatim}

We might want to do this so that \verb+SAP+ and \verb+LAP+ flux levels agree
sufficiently that we can average the two spectra.  We need not
necessarily have to specify the \xref{\verb+APERTURE+}{sg3}{APERTURE}
 parameter explicitly, as in the
example above; it may already have been set.

The \xref{\verb+SETM+}{sg3}{SETM}
 command sets calibration parameters associated with a particular
\'{E}chelle order.  It is only applicable to HIRES datasets.  \verb+SETM+ is
mostly used in getting the Ripple Correction to produce a contiguous spectrum
from adjacent \'{E}chelle orders when the standard calibrations are not good
enough.  It is also used for setting the wavelength limits containing good data.
For example, we can delimit the spectrum in a particular order by:

\begin{verbatim}
   > SETM ORDER=89 WCUT=[1539,1559.5]
\end{verbatim}

As for \verb+APERTURE+ in \xref{\verb+SETA+}{sg3}{SETA}
, we need not necessarily have to set the
\xref{\verb+ORDER+}{sg3}{ORDER}
 parameter explicitly, since it may already have the correct value
(but if in doubt, get it to prompt)\@.  When using
\xref{\verb+SETM+}{sg3}{SETM} a NULL response
(\verb+!+) to any particular parameter ({\it{e.g.,}}
\xref{\verb+RIPK+}{sg3}{RIPK}) will lead to
removal of any individual value associated with that order.

Acceptance of the default leads to retention of that parameter value. If the
value was obtained from a global default then no individual value is associated
with the order.  Otherwise and if the value actually changes, an individual
value is stored.

This all sounds complicated, but in essence should behave sensibly.  If in
doubt as to what values are retained, use the appropriate
\xref{\verb+SHOW+}{sg3}{SHOW} command to inspect the calibration(s).

The \verb+SETD+, \verb+SETA+ and \verb+SETM+ commands are quite safe.  If you
have forced prompting for all parameters and find yourself prompted for a
parameter, the meaning of which escapes you, then {\bf don't panic.}  By
hitting the \verb+RETURN+ key, the current value, given as the default in the
prompt, will be retained and nothing will be changed.

More specific examples of using the \xref{\verb+SHOW+}{sg3}{SHOW},
\xref{\verb+SETD+}{sg3}{SETD}, \xref{\verb+SETA+}{sg3}{SETA}
 and \xref{\verb+SETM+}{sg3}{SETM} commands will be given below.

A number of other commands exist for changing entire calibrations (rather than
their details). These will be described in context below.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{extraction_calibrations}\label{se:extr_calib}CALIBRATIONS
         AFFECTING SPECTRUM EXTRACTION}
\markboth{Calibrations affecting Spectrum Extraction}{\stardocname}

This is a description of what calibrations affect the spectrum
extraction process, how to see just what they are, and how to change them
(and know whether they should be changed!)\@.  This will appear to repeat some
things already described.


\subsection{Fiducials and Geometry}

\begin{latexonly}
The Fiducials are formed by a $13\times 13$ regular grid of reseau marks that
are positioned in an early stage of the IUE camera (before any significant
image distortion occurs). On the image, fiducials appear as small (roughly
$2\times 2$ pixel) dark spots.
\end{latexonly}

\begin{htmlonly}
The Fiducials are formed by a 13x13 regular grid of reseau marks that
are positioned in an early stage of the IUE camera (before any significant
image distortion occurs). On the image, fiducials appear as small (roughly
2x2 pixel) dark spots.
\end{htmlonly}

We need to know the positions of these fiducials for two reasons:

\begin{enumerate}

\item Specification of the geometric distortion, for non-geometric images
      ({\it{e.g.,}} types RAW and PHOT)\@.

\item Marking image pixels which are affected by fiducials, and thus are not
      photometrically correct if they occur in the spectrum.

\end{enumerate}

The fiducial positions are {\bf not} determined from the image itself; instead,
standard positions are supplied by \xref{\verb+READIUE+}{sg3}{READIUE}\@.
The sources of these standard positions are:

\begin{description}

\item [{\bf SWP:}]
      Thompson, Turnrose and Bohlin (1982)\@.  These positions are
      dependent on the camera temperature, \xref{\verb+THDA+}{sg3}{THDA}\@.
      The dependence is linear and small.

\item [{\bf LWR:}]
      Thompson, Turnrose and Bohlin (1982)\@.  These positions are fixed.

\item [{\bf LWP:}]
      Settle (1982, private communication)\@.  These positions are fixed.

\end{description}

These fiducial positions should be sufficiently accurate for the purposes
of representing the large-scale geometric distortion, and for indicating which
image pixels are affected.

For the SWP camera, although the \xref{\verb+THDA+}{sg3}{THDA}
 dependence is linear for each
individual fiducial position, the direction of movement varies across the
image.  Thus \verb+THDA+ affects the nature of the geometric distortion, rather
than merely a simple shift.

The fiducials are considered to affect image pixels within a square area
of half-width \xref{\verb+FIDSIZE+}{sg3}{FIDSIZE}
 pixels.  A single value of \verb+FIDSIZE+ is used
for {\bf all} fiducials, and this can be changed by:

\begin{verbatim}
   > SETD FIDSIZE=2.0
\end{verbatim}

There should not be any real need to change \verb+FIDSIZE+\@.

The other thing affecting the fiducial characteristics is
\xref{\verb+THDA+}{sg3}{THDA}, which can be set by:

\begin{verbatim}
   > SETD THDA=7.2
\end{verbatim}

The reason for changing \verb+THDA+ might be that it was not known when the
image was read from tape using the \xref{\verb+READIUE+}{sg3}{READIUE}
 command.  For the SWP camera,
since \verb+THDA+ affects the geometric distortion, any change is followed by a
redetermination of the relation between (S, L) and (X, Y)\@.

If the fiducial positions or sizes are changed, then the set of image pixels
marked as being affected is updated. This can take a while.

The geometric image distortion is represented by a 2-D Chebyshev Polynomial
relating the (S, L) and (X, Y) coordinate systems.  Since standard fiducial
positions (with only small \xref{\verb+THDA+}{sg3}{THDA}
 perturbations) are used, there is
little need for concern over this geometry representation.  However, for
completeness, the number of terms along each axis can be specified by:

\begin{verbatim}
   > SETD NGEOM=5
\end{verbatim}

This is the default value provided by \xref{\verb+READIUE+}{sg3}{READIUE},
and should be quite adequate.

Only information about the large-scale geometric distortion can be provided
by the fiducial positions.  There is much evidence for geometric distortion
on distance scales below that of the fiducial spacing.  In addition, time
and temperature dependent effects occur.  These small-scale distortion effects
are handled empirically by the spectrum extraction process ({\it{e.g.,}} the
\xref{\verb+TRAK+}{sg3}{TRAK}
 command)\@.


\subsection{Spectrograph Dispersion}

The spectrograph dispersion calibration relates the geometric image
coordinates, (X, Y), to spectrograph coordinates, (R, $\lambda$)\@.  There is
an (R, $\lambda$) coordinate system defined for each spectrograph aperture.  In
addition, for HIRES, there is a separate (R, $\lambda$) coordinate system for
each \'{E}chelle order, M\@.

For HIRES, the coordinate systems are related by:

\begin{displaymath}
X =
P_{X}(APERTURE) +
A_{X}(APERTURE) +
D({\rm M}, \lambda ; A_{1}, A_{2},\ldots A_{7}) +
\frac{dx}{dr}({\rm M}, \lambda) \times R
\end{displaymath}

\begin{displaymath}
Y =
P_{Y}(APERTURE) +
A_{Y}(APERTURE) +
D({\rm M}, \lambda ; B_{1}, B_{2},\dots B_{7}) +
\frac{dy}{dr}({\rm M}, \lambda) \times R
\end{displaymath}

where

\begin{displaymath}
D({\rm M}, \lambda; C_{1}, C_{2},\ldots C_{7}) =
C_{1} +
C_{2}\times {\rm M} \times \lambda +
C_{3}\times {({\rm M} \times \lambda)}^{2} +
C_{4}\times {\rm M} +
C_{5}\times \lambda +
C_{6}\times \lambda \times {\rm M}^{2} +
C_{7}\times {\rm M} \times \lambda^{2}
\end{displaymath}

The pair, $(A_{X}, A_{Y})$, represent a coordinate offset that is fixed for each
spectrograph aperture, and is nominally (0, 0) for SAP\@.

The pair, ($P_{X}$, $P_{Y}$), represent a {\em peculiar} coordinate offset for
each aperture which must be determined empirically (see below); they are
typically no more than a few pixels.

The gradients, ($dx/dr$, $dy/dr$), are defined to be perpendicular to the
dispersion direction, and are determined empirically.

The constants $A_{1}$ to $A_{7}$ and $B_{1}$ to $B_{7}$ correspond to those of
Thompson, Turnrose and Bohlin (1982)\@.

For LORES the coordinate relation is similar to that above (for HIRES),
except that we set $M=1$ and only use the $A_{1}$, $A_{2}$, $B_{1}$ and $B_{2}$
terms in the $D$ function.

Following the work of Thompson, Turnrose and Bohlin (1982), the $A_{1}$ and
$B_{1}$ `constants' are allowed to vary with Date and
\xref{\verb+THDA+}{sg3}{THDA} in order to
account, empirically, for observed movement of the spectrograph format on the
image.  This variation is linear in both variables.

The following sources have been used for these dispersion constants:

\begin{description}

\item [{\bf SWP, LWR:}]
      Thompson, Turnrose and Bohlin (1982)\@.  These include Date
      and \xref{\verb+THDA+}{sg3}{THDA} variation.

\item [{\bf LWP:}]
      The constants for this camera have been determined from IUE
      Header Text details.

\end{description}

For LORES, the spectrum position, as defined by these dispersion
relations, falls on a straight line.  For HIRES, this is effectively the
case, although slight non-linearity does occur.


\subsection{ITF Correction}

At present IUEDR does not have the facility for creating photometric images
from the RAW image.  However, not all photometric images produced by
the Ground Station processing are photometrically accurate.

For HIRES images with poor ITF calibration, there is, at present, nothing that
can be done to improve the situation, other than to get a new photometric image
produced ({\it{e.g.,}} from the Ground Station)\@.

For LORES images with poor ITF calibration, there are some simple (empirically
determined) corrections that can be applied to photometric images to
improve their accuracy.

Using the terminology introduced in Section~\ref{subse:itf_prob} which
described how to identify which ITF table has been used, the following
indicates the available LORES corrections:

\begin{description}

\item [{\bf 1st SWP ITF:}]
      This was used for only a small number of images, and
      although it is probably not very accurate, no corrections exist for it.

\item [{\bf 2nd (Faulty) SWP ITF:}]
      This was introduced as an `improvement' over the
      previous ITF\@.  Unfortunately, this 2nd ITF contained a major error
      (mistake), which lead to gross inaccuracies in photometric measurements.
      A correction exists for images produced with this ITF, which accounts for
      this error, and also for other minor errors that were determined later
      ({\it{e.g.,}} IUE-VILSPA User Guide II Image Processing, Appendix A)\@.

\item [{\bf 3rd (Final) SWP ITF:}]
      In this ITF the errors introduced with the 2nd
      ITF are removed.  No further correction is needed.

\item [{\bf 1st LWR ITF:}]
      This was used for only a small number of images, and
      although it is probably not very accurate, no corrections exist for it.

\item [{\bf 2nd LWR ITF:}]
      This contains only minor photometric errors, for
      which a correction procedure is available (Snijders, 1982, private
      communication)\@.

\end{description}

So we can see that the only ITFs for corrections are available and needed
are the 2nd SWP and 2nd LWR. Whether these corrections are applied to an
the image in IUEDR is determined by the \xref{\verb+BADITF+}{sg3}{BADITF}
parameter which appears in the \xref{\verb+READIUE+}{sg3}{READIUE} and
\xref{\verb+SETD+}{sg3}{SETD} commands.  Normally, it would be
specified in the \verb+READIUE+ parameters, but if it is given a wrong value,
then this can be rectified by, for example:

\begin{verbatim}
   > SETD BADITF=YES
\end{verbatim}

which indicates that the appropriate (camera dependent) ITF correction is to be
used.

The correction is done when the spectrum is extracted, so that switching
between the two modes is possible, perhaps for experimental purposes.


\subsection{Spectrum Shifts}

There are a number of reasons why arbitrary shifts, ($P_{X}$, $P_{Y}$), are
needed in order to locate a spectrum on an image:

\begin{enumerate}

\item Even if Date and \xref{\verb+THDA+}{sg3}{THDA}
 variations are included, the actual value
      of \verb+THDA+ may not be available.  This is particularly true for
      IUESIPS\#1 where the value of \verb+THDA+ is not in the header text of
      any of the tape files.

\item The object may have been positioned inaccurately in LAP\@.

\end{enumerate}

Given that the image contains a significant signal above background, it is
possible to determine values of ($P_{X}$, $P_{Y}$) which account for shifts in
the R-coordinate.

(Shifts in the $\lambda$-coordinate (Wavelength) are not important for spectrum
extraction, and can be handled afterwards.\@)

The method used to determine these ($P_{X}$, $P_{Y}$) shifts is to perform a
scan across the spectrum on the image along a line (roughly) perpendicular to
the dispersion direction.  The result of such a scan is a `spectrum'
consisting a peak for each aperture/order traversed, superposed on the
background intensity level.  The positions of these peaks can be used, in
conjunction with the existing dispersion relations, to determine ($P_{X}$,
$P_{Y}$)\@.

The cases of HIRES and LORES are best described separately.

\subsubsection{Determining LORES Spectrum Shifts}

In the LORES case the scan is performed along a line of constant
wavelength.  To produce such a scan type:

\begin{verbatim}
   > SCAN
\end{verbatim}

If the spectrum has a fairly continuous signal, then the default
parameters should produce a reasonable scan.  If the
\xref{\verb+DATASET+}{sg3}{DATASET} and
\xref{\verb+APERTURE+}{sg3}{APERTURE}
 parameters have not already been specified, then they will be
prompted for.  Also, remember that {\bf each} aperture has its own values for
spectrum shift.  The scan can be plotted by:

\begin{verbatim}
   > PLSCAN
\end{verbatim}

which may prompt you for \xref{\verb+DEVICE+}{sg3}{DEVICE}
 (graphics device name) if you have not
specified it already.  The plot will consist, rather often, of a single
peak centred on R=0.0.  By default \xref{\verb+SCAN+}{sg3}{SCAN}
 picks a wavelength for the scan
in the middle of the spectrum; this can be specified instead by the
\xref{\verb+SCANWV+}{sg3}{SCANWV}
 parameter.  Also, the scan width (FWHM of a triangle folding
profile in pixels) can be specified by the \xref{\verb+SCANAV+}{sg3}{SCANAV}
 parameter. So:

\begin{verbatim}
   > SCAN SCANWV=1550 SCANAV=20
\end{verbatim}

produces a 20 pixel width scan at 1550\AA\@. The choice of
\xref{\verb+SCANAV+}{sg3}{SCANAV} will be
dictated by the need to produce a scan with sufficient
signal-to-noise, tempered by the fact that wide scans take longer to create.

If the scan plot reveals a peak that is dead on R=0.0, then no spectrum
shifts need be applied. Otherwise use:

\begin{verbatim}
   > CGSHIFT
\end{verbatim}

This displays the graphics cursor on the plot produced by the
\xref{\verb+PLSCAN+}{sg3}{PLSCAN} command. The cursor should be moved to
mark where you think the spectrum peak is
and the \verb+1+ key typed.  This will produce a marker symbol on the plot
corresponding to the cursor position, and print details of the indicated
($P_{X}$, $P_{Y}$) shift on the terminal.  The cursor will then reappear and
further measurements can be made, with the sequence terminated by typing the
\verb+4+ key.  The {\bf last} shift measurement is adopted and stored in the
dataset.
The `peculiar' spectrum shift can be seen by means of the
\xref{\verb+SHOW+}{sg3}{SHOW} command:

\begin{verbatim}
   > SHOW V=D
\end{verbatim}

which lists various calibration parameters associated with
spectrograph dispersion.  It can also be specified directly using the
\xref{\verb+SETA+}{sg3}{SETA} command:

\begin{verbatim}
   > SETA GSHIFT=[0.0,0.0]
\end{verbatim}

which is sometimes useful for getting back to where you started.

After \xref{\verb+CGSHIFT+}{sg3}{CGSHIFT}
 has been used on a scan plot, the scan becomes undefined.
This is because the spectrum shift has been applied to the dispersion
constants, and so a measurement of R from the plot will not indicate a
correct shift, ($P_{X}$, $P_{Y}$), the next time around.  Confused? Don't
worry about it.  If the need arises to redetermine the shift, just repeat the
\xref{\verb+SCAN+}{sg3}{SCAN} and \xref{\verb+PLSCAN+}{sg3}{PLSCAN}
 commands before using \xref{\verb+CGSHIFT+}{sg3}{CGSHIFT} again.

A scan plot where the spectrum shift has been previously defined is useful
in determining the extent of the spectrum perpendicular to dispersion.  Such
information is useful for spectrum extraction, especially when
non-standard observations have been made (multiple exposures in LAP
{\it etc.})\@.

You can make cursor coordinate measurements on {\bf any} plot using the
\xref{\verb+CURSOR+}{sg3}{CURSOR}
 command.  Like most cursor commands, a sequence of \verb+1+,
\verb+2+ or \verb+3+ key hits can be made, each giving the graph coordinates of
the current cursor position.  The sequence ends on the \verb+4+ key hit.

\subsubsection{Determining HIRES Spectrum Shifts}

The basic principles here are the same as for LORES, but the details differ.

In the HIRES case, each \'{E}chelle order is inclined at a slightly different
angle across the image, so that there is no simple line that is perpendicular
to dispersion.  Each order has its own (R, $\lambda$) coordinate system.  We
could pick a single order and perform a scan around that; however, this would
be a bit too restrictive.

Consequently, a coordinate system, (U, V), is defined such that the
U-coordinate runs roughly perpendicular to the `average' \'{e}chelle order, and
the V-coordinate runs parallel to the `average' order.  The coordinate system
is located such that U=V=0 at the centre of the camera faceplate circle.
\xref{\verb+SCAN+}{sg3}{SCAN}
 performs a scan for selected V-coordinate along the
U-direction.  The U-coordinate limits are specified by a range of \'{E}chelle
orders:

\begin{verbatim}
   > SCAN ORDERS=[100,105] SCANDIST=0.0
\end{verbatim}

\begin{latexonly}
The V-coordinate is specified by the \xref{\verb+SCANDIST+}{sg3}{SCANDIST}
 parameter.  The default
value (0.0) performs a scan across the centre of the image.  A value of
\verb+SCANDIST+ outside the range $-360$ to 360 will miss the entire spectrum.
The default value is recommended unless you really want to experiment\@!  As for
LORES, the scan width can be selected with the \xref{\verb+SCANAV+}{sg3}{SCANAV}
 parameter.
\end{latexonly}

\begin{htmlonly}
The V-coordinate is specified by the \xref{\verb+SCANDIST+}{sg3}{SCANDIST}
 parameter.  The default
value (0.0) performs a scan across the centre of the image.  A value of
\verb+SCANDIST+ outside the range -360 to 360 will miss the entire spectrum.
The default value is recommended unless you really want to experiment\@!  As for
LORES, the scan width can be selected with the \xref{\verb+SCANAV+}{sg3}{SCANAV}
 parameter.
\end{htmlonly}

The scan can be plotted using the \xref{\verb+PLSCAN+}{sg3}{PLSCAN}
 command, and then
\xref{\verb+CGSHIFT+}{sg3}{CGSHIFT}
 can be used to determine a value for the peculiar spectrum shift.
\verb+CGSHIFT+ for HIRES operates much the same as for LORES except that it
handles the idea that the scan can contain a number of different peaks
corresponding to different \'{E}chelle orders.

The cursor should be positioned on the centre of an order peak as normal, and
the \verb+1+ key typed.  \xref{\verb+CGSHIFT+}{sg3}{CGSHIFT}
 then uses the existing dispersion
relations to guess which \'{E}chelle order has been picked, and then determines a
spectrum shift on the basis of that.  Any number of different cursor
measurements on different orders can be performed in a cycle, each producing a
new spectrum shift.  However, only the {\bf last} spectrum shift is retained.
Remember also that there is only a single spectrum shift for the whole image,
not for individual orders.

In principle, each \'{e}chelle order, and any V-coordinate scan should
produce the same value of spectrum shift, ($P_{X}$, $P_{Y}$)\@.  In practice,
small-scale geometry distortions (not defined by the fiducial
positions), and other obscure effects may preclude this.  The spectrum
extraction process will normally handle these small scale effects,
however, it is best to give it a good starting value for ($P_{X}$, $P_{Y}$)\@.

It is not practical to determine shifts for all of the \'{E}chelle orders, nor
is it necessary.  The strategy to adopt is to get the shift right for the
closely spaced (short wavelength, high numbered) orders, since this is where
spectrum extraction is more difficult.

One problem that can arise, especially when determining the shift from closely
spaced \'{e}chelle orders, is that \xref{\verb+CGSHIFT+}{sg3}{CGSHIFT}
 guesses the {\bf wrong}
\'{e}chelle order number.  This is a very bad problem, because if you then
tell it to extract (say) order 89, it might get order 90 or 88.  Very
confusing.  The first thing to do if this happens is to:

\begin{verbatim}
   > SETA PROMPT
\end{verbatim}

firstly to see what the current GSHIFT value is, and then to set it to
[0.0,0.0] if it is not already that.  The next thing is to perform a scan on
a low order number, where the orders are well spaced.  For example:

\begin{verbatim}
   > SCAN ORDERS=[70,72]
\end{verbatim}

Then \xref{\verb+PLSCAN+}{sg3}{PLSCAN}
 to produce a plot.  Now use \xref{\verb+CGSHIFT+}{sg3}{CGSHIFT}
 as normal.
If \verb+CGSHIFT+ still picks the wrong order, set the shift zero again with
\xref{\verb+SETA+}{sg3}{SETA}
 and then:

\begin{verbatim}
   > CGSHIFT ORDERS=71
\end{verbatim}

What \xref{\verb+CGSHIFT+}{sg3}{CGSHIFT}
 does is to only pick orders that lie in the range defined
by the \xref{\verb+ORDERS+}{sg3}{ORDERS}
 parameter.  Normally the \verb+ORDERS+ parameter is the
same for the \xref{\verb+SCAN+}{sg3}{SCAN}
 and \xref{\verb+CGSHIFT+}{sg3}{CGSHIFT}
 commands; however, there is
nothing to stop you changing it between commands.  So in the example above, if
you point the cursor at what you think is order 71 it can only guess that it
{\em is}  order 71, and the resultant shift will be correct.

How you identify the number of an \'{E}chelle order from its scan profile is
beyond the bounds of this Guide, however, perhaps things will never reach that
stage.

At any given time, there is only a single value for the spectrum shift.  The
spectrum extraction command ({\it{e.g.,}} \xref{\verb+TRAK+}{sg3}{TRAK}) will
normally be able to
handle small variations of shift for different \'{E}chelle orders.
However, if needed, each order can be extracted separately, with the shift
being determined on an individual basis.
Hopefully, this will not be needed\@!


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{spectrum_extraction}\label{se:spec_extr}SPECTRUM EXTRACTION}
\markboth{Spectrum Extraction}{\stardocname}

Spectrum Extraction is the process of determining the spectrum from its
projection on the image.

This can be done using the \xref{\verb+TRAK+}{sg3}{TRAK}
 command, which operates by extracting
each spectrum (aperture or \'{E}chelle order) separately.  It has, inevitably,
a large number of parameters.  However, initially these are defaulted to
handle the simplest case: that of point source spectra with good
signal-to-noise.

The \xref{\verb+LBLS+}{sg3}{LBLS} command is also available for spectrum
extraction.
This produces a line-by-line spectrum similar to the corresponding IUESIPS
product.  The LBLS is a 2-dimensional array with wavelength along one axis and
distance from spectrum centre along the other.  Applications include:

\begin{itemize}

\item Access to spatial information present in extended objects observed
      through LAP\@.

\item Inspecting the region of the image along a spectrum in order
      to establish the reality of features.

\end{itemize}


\subsection{\xlabel{trak}\label{subse:trak}Spectrum Extraction using
            {\tt TRAK}}

\subsubsection{Simple use of {\tt TRAK} for LORES}

Assuming that the dataset defined by the \xref{\verb+DATASET+}{sg3}{DATASET}
parameter exists, then the simplest way of using
\xref{\verb+TRAK+}{sg3}{TRAK} is:

\begin{verbatim}
   > TRAK APERTURE=SAP
\end{verbatim}

The \xref{\verb+APERTURE+}{sg3}{APERTURE} parameter may not be needed if it
already has the correct value.

\subsubsection{Simple use of {\tt TRAK} for HIRES}

To extract a single \'{E}chelle order:

\begin{verbatim}
   > TRAK ORDER=89
\end{verbatim}

If \xref{\verb+ORDER+}{sg3}{ORDER}
 already has the correct value then it need not be specified.

\xref{\verb+TRAK+}{sg3}{TRAK}
 can extract a sequence of \xref{\verb+NORDER+}{sg3}{NORDER}
 \'{E}chelle orders, starting
at \xref{\verb+ORDER+}{sg3}{ORDER}:

\begin{verbatim}
   > TRAK ORDER=89 NORDER=9
\end{verbatim}

This will extract orders 89 to 81.  \xref{\verb+TRAK+}{sg3}{TRAK}
 always sets \verb+NORDER=0+
after use, so that the default action is always to extract a single \'{E}chelle
order.  If more that one order is extracted, then the \xref{\verb+ORDER+}{sg3}{ORDER}
 parameter
is given the value of the last one ({\it{e.g.,}} \verb+ORDER=81+ after the last
example)\@.

Two possible approaches exist for working through a HIRES image:

\begin{enumerate}

\item Extract individual orders that contain interesting features.

\item Extract all orders in one go.

\end{enumerate}

One thing to bear in mind is that the available technique for
correcting the inter-order background in respect of order-overlap requires
that the adjacent \'{E}chelle orders be available.  So for continuum
sources, if you only want (say) \'{E}chelle order 115, but need the
order-overlap correction, then you will have to extract orders 114 and 116 as
well.

\subsubsection{Textual Information from {\tt TRAK}}

When \xref{\verb+TRAK+}{sg3}{TRAK}
 runs, it prints information about how it will extract the
spectrum, based on the supplied parameters (most of which will take default
values as in the examples so far)\@.

When the spectrum has been extracted, a textual summary is given of what it
found, including: statistics of pixels used (and their quality), and mean
values for the object and background signals, and a mean value for the centroid
shift.

\subsubsection{The Last Extracted Spectrum}

After a successful \xref{\verb+TRAK+}{sg3}{TRAK}
 command has finished, there is additional
information available about the current spectrum.  This information
includes:

\begin{enumerate}

\item The smooth background spectrum.  Also, the gross spectrum which
      is constructed from the smooth background and the net spectrum.

\item The variation of signal centroid position along the spectrum.

\item The level above background corresponding to 1 Standard
      Deviation.  This is determined from the statistics of background pixels
      relative to their local mean (as defined by the smooth background)\@.

\end{enumerate}

If several \'{E}chelle orders have been extracted with a single
\xref{\verb+TRAK+}{sg3}{TRAK}
command, then this information is only available for the last one extracted.

None of this information is stored on disk.

\subsubsection{Plotting the Gross and Background Spectrum}

The raw spectrum can be plotted by:

\begin{verbatim}
   > PLGRS
\end{verbatim}

This plots the gross and smooth background spectra.  In fact both of these
are simulated quantities, since \xref{\verb+TRAK+}{sg3}{TRAK}
 only produces a net spectrum above
background.

For LORES, the background for short exposures will be close to zero.

For HIRES, the background will normally have a shape that follows the ripple
shape of the object spectrum.  In cases where there is no continuum, however,
the background should be fairly flat.

\subsubsection{Plotting the Centroid Spectrum}

\xref{\verb+TRAK+}{sg3}{TRAK}
 always determines the centroid of the object signal (above
background) on the image, and the difference between this and the
positions given by the dispersion relations, the centroid spectrum, can be
plotted by:

\begin{verbatim}
   > PLCEN
\end{verbatim}

This centroid spectrum should appear as a smooth, fairly straight line centred
about R=0.0\@.  In practice, it will often have some apparently random shape,
wandering around some mean R-coordinate.  This mean R-coordinate should
not be too far from 0.0, especially if the spectrum shift was determined
using the \xref{\verb+SCAN+}{sg3}{SCAN}, \xref{\verb+PLSCAN+}{sg3}{PLSCAN}
 and \xref{\verb+CGSHIFT+}{sg3}{CGSHIFT} commands.

The shape of the centroid spectrum is normally a reflection of small-scale
geometric distortion effects that could not be determined from the fiducial
positions.  However, sometimes its shape is distorted by other effects,
including:

\begin{enumerate}

\item Bright spots and other image features that should not be there.

\item The edges of the camera faceplate, where the intensities are
      meaningless.

\end{enumerate}

In regions of the spectrum where there is no signal above background, the
centroid is not defined.  However, since the centroid spectrum is smoothed,
small regions of this kind are interpolated across.  In the case of very
broad regions with no signal, the centroid spectrum will show a gap.

\subsubsection{{\tt TRAK} Parameters that affect Centroid Tracking}

As has already been mentioned, \xref{\verb+TRAK+}{sg3}{TRAK}
 always determines the centroid
spectrum.  However, whether it actually uses this to re-extract the spectrum
is controlled by the \xref{\verb+CENIT+}{sg3}{CENIT}
 parameter.

The initial default is \verb+CENIT=1+, which means that the spectrum is
extracted once, using the coordinate system defined by the dispersion
relations, then the centroid spectrum is used to produce an empirical
correction to the dispersion relations, and the spectrum is re-extracted.

This second extraction using the centroid spectrum can be inhibited by
setting \verb+CENIT=0+\@. Reasons for doing this might be:

\begin{enumerate}

\item There is an image defect which upsets the centroid spectrum, and no
      tracking is better than wrong tracking.

\item It saves time (roughly a factor of 2)\@.  This time-saving is only
      reasonable, if the resultant spectrum is unaffected by the omission of
      the centroid tracking.  This is normally only the case for LORES spectra,
      where any spectrum shifts have been previously determined, and where a
      suitable extraction slit has been selected (see below)\@.

\end{enumerate}

There is seldom any good reason for inhibiting centroid tracking for HIRES,
since without it, the inter-order signal, used for background estimation, will
be inaccurate, especially for the closely spaced \'{E}chelle orders.

The centroid spectrum is smoothed by folding it with a triangle function.
The FWHM of this function is specified in geometric pixels by the
\xref{\verb+CENAV+}{sg3}{CENAV} parameter.
There is normally little reason to change \xref{\verb+CENAV+}{sg3}{CENAV}
from its default value.
However, if the object signal is weak, or there is a lot of
background noise, it may be necessary to increase \verb+CENAV+\@.  The
criterion to adopt is that the R-coordinate variation in the smooth centroid
spectrum should not be more than a pixel (or two)\@.

The criterion for whether the centroid spectrum is significant is determined
by the \xref{\verb+CENSD+}{sg3}{CENSD}
 parameter.  This is the number of standard deviations above
zero, beyond which a signal is considered to be significant.  By
decreasing it, you can let signals of lower significance be used.  There
is normally little justification for playing with \verb+CENSD+\@.

Sometimes the object signal is too weak to produce a centroid spectrum at
all; or it may appear as fragments that correspond to the high points in the
spectrum.  This situation can be relieved by increasing
\xref{\verb+CENAV+}{sg3}{CENAV}\@.
However, at some point it is necessary to concede that there is nothing there!

\subsubsection{Spectrum Significance}

The Net spectrum can be plotted by:

\begin{verbatim}
   > PLNET
\end{verbatim}

This contains no intensity calibrations, but (like all plots against
wavelength) it includes all of the calibration processes that affect
wavelength.

The fully calibrated Flux spectrum can be plotted by:

\begin{verbatim}
   > PLFLUX
\end{verbatim}

The various calibrations which go to produce the flux spectrum from the net
spectrum are described in Section~\ref{se:extr_calib}\@.

When the \xref{\verb+PLNET+}{sg3}{PLNET} or \xref{\verb+PLFLUX+}{sg3}{PLFLUX}
 command follows \xref{\verb+TRAK+}{sg3}{TRAK}, the 1
Standard Deviation level above zero is also plotted.  This can provide some
idea of how significant the signal is.  However, this is in no sense an
`error-bar' that can be applied to higher signal levels.

\subsubsection{{\tt TRAK} parameters that control the object and background
channels}

\xref{\verb+TRAK+}{sg3}{TRAK}
 determines the background level by two channels that run parallel
to and on either side of the object spectrum.  The object spectrum is then
determined by the intensity above background in a channel that contains the
object signal.

(You can think of a channel as a slit that is scanned along the spectrum,
or off to one side.\@)

The widths and positions of the object and background channels are determined
by the parameters: \xref{\verb+AUTOSLIT+}{sg3}{AUTOSLIT},
\xref{\verb+APERTURE+}{sg3}{APERTURE}, \xref{\verb+EXTENDED+}{sg3}{EXTENDED},
\xref{\verb+CONTINUUM+}{sg3}{CONTINUUM}, \xref{\verb+GSLIT+}{sg3}{GSLIT},
\xref{\verb+BDIST+}{sg3}{BDIST} and \xref{\verb+BSLIT+}{sg3}{BSLIT}\@.  Not
all of these parameters need be specified.

The actual channel widths and positions adopted are printed by the
\xref{\verb+TRAK+}{sg3}{TRAK} command.

When \verb+AUTOSLIT=TRUE+, then the channels are determined
automatically.  This is the initial default, and is recommended for all but
a few special cases (to be elaborated below)\@.

When \verb+AUTOSLIT=FALSE+, you can specify the channel details as required.

For LORES extractions, when \verb+AUTOSLIT=TRUE+ the
\xref{\verb+APERTURE+}{sg3}{APERTURE} and \xref{\verb+EXTENDED+}{sg3}{EXTENDED}
parameters are used.  If \verb+EXTENDED=TRUE+ and \verb+APERTURE=LAP+ then a
wide object channel is used so that all the object signal is integrated.
Otherwise, a point-source object channel is used.  The background channels are
then chosen to fall appropriately on either side of the object ({\it{i.e.,}}
with a gap separating them)\@.

When \verb+AUTOSLIT=FALSE+, the channels are determined entirely by the
\xref{\verb+GSLIT+}{sg3}{GSLIT}, \xref{\verb+BDIST+}{sg3}{BDIST} and
\xref{\verb+BSLIT+}{sg3}{BSLIT} parameters.

\xref{\verb+GSLIT+}{sg3}{GSLIT}
 defines the object channel limits as expressed in
R-coordinates: So, for example:

\begin{verbatim}
   > GSLIT=[-6.4,6.4]
\end{verbatim}

\begin{latexonly}
specifies an object channel covering the R-coordinate range $-6.4$ to +6.4,
as measured in geometric pixels.  In this example, the channel has a total
width of 12.8 pixels.  The R-coordinate system is the same as used for
scan plots, so that if you do not know how wide a slit is needed, then you can
measure it yourself using the graphics cursor.
\end{latexonly}

\begin{htmlonly}
specifies an object channel covering the R-coordinate range -6.4 to +6.4,
as measured in geometric pixels.  In this example, the channel has a total
width of 12.8 pixels.  The R-coordinate system is the same as used for
scan plots, so that if you do not know how wide a slit is needed, then you can
measure it yourself using the graphics cursor.
\end{htmlonly}

If a symmetric object channel is needed, then this can be specified by
giving only a single value to \xref{\verb+GSLIT+}{sg3}{GSLIT}:

\begin{verbatim}
   > GSLIT=6.4
\end{verbatim}

which produces the {\bf same} result as the previous example, and is a lot
simpler to type.

The need for asymmetric object channel limits lies in the realm of
experimentation, but it is there if you want it.  But remember that the
centroid spectrum is determined from pixels that fall in the object channel,
so beware cases where \verb+CENIT=1+ and where the object channel does not
cover the object signal properly: in such cases the centroid spectrum will not
be very meaningful.

The background channels have half-widths specified by the values in the
\xref{\verb+BSLIT+}{sg3}{BSLIT} parameter:

\begin{verbatim}
   > BSLIT=[2.5,4.3]
\end{verbatim}

In this case, the left background channel has half-width 2.5, and the
right background channel has half-width 4.3 pixels.  As for
\xref{\verb+GSLIT+}{sg3}{GSLIT}, a single value for
\xref{\verb+BSLIT+}{sg3}{BSLIT} implies that both background channels have the
same half-width.

The R-coordinates of the centres of the background channels are specified by
the \xref{\verb+BDIST+}{sg3}{BDIST} parameter:

\begin{verbatim}
   > BDIST=[-8,9]
\end{verbatim}

Just as for \verb+BSLIT+, the first value is for the left channel, and the
second value is for the right channel.  A single value for
\xref{\verb+BDIST+}{sg3}{BDIST} implies that the channels are placed
symmetrically about R=0.0\@.

The degree of control offered by the \xref{\verb+GSLIT+}{sg3}{GSLIT},
\xref{\verb+BSLIT+}{sg3}{BSLIT} and \xref{\verb+BDIST+}{sg3}{BDIST}
parameters is probably not necessary for point source objects, and
also for extended objects (through LAP) {\em if} the signal from the whole
object is wanted.

However, if the LAP contains, for example, two separate spectra, which
partially overlap, then careful selection of object and background
channels is needed to isolate these.

In the case of HIRES, there are a number of constraints that may need to be
applied to the positions and widths of the object and background channels to
account for the proximity of adjacent \'{E}chelle orders.

Towards short wavelengths, where the \'{E}chelle orders become very close, they
begin to partially overlap, so that the region between them can contain
signal above the normal background level.

The inter-order regions provide the only direct estimate of the background
level, despite being contaminated by object signal.  So it is important, in
methods as used by \xref{\verb+TRAK+}{sg3}{TRAK}, to measure this
inter-order signal accurately.

One further constraint is that, when orders overlap, we cannot integrate
their signals separately.  In effect, we are limited to incomplete
integrals.  Provided these incomplete integrals cover a constant and
known fraction of the object signal, then all is not lost.

We can split the possible channel configurations into three groups, each
described by the values of the \xref{\verb+CONTINUUM+}{sg3}{CONTINUUM}
and \xref{\verb+EXTENDED+}{sg3}{EXTENDED} parameters:

\begin{description}

\item [{\tt EXTENDED=NO, CONTINUUM=<any>}] In this case the background
      channels are given a full width of 1 pixel, and are positioned so that
      they run along the inter-order line.  The object channel has limits
      defined by the \xref{\verb+GSLIT+}{sg3}{GSLIT} parameter, subject
      to the constraint that it
      lies between the two background channels.  In the case of
      \xref{\verb+AUTOSLIT=YES+}{sg3}{AUTOSLIT}, the
      \xref{\verb+GSLIT+}{sg3}{GSLIT} value is provided automatically,
      and is based on the \xref{\verb+ORDER+}{sg3}{ORDER} number.

\item [{\tt EXTENDED=YES, CONTINUUM=NO}] This case corresponds an
      emission-line object without continuum.  Even if the object is not
      actually `extended', the signal on the image extends beyond the
      inter-order line.  Thus to obtain complete integrals of the emission
      line intensities, it is necessary to extend the object channel.  This
      can be done by specifying the \xref{\verb+GSLIT+}{sg3}{GSLIT} parameter.
      Likewise, the
      background channels can be positioned anywhere through the
      \xref{\verb+BSLIT+}{sg3}{BSLIT}
      and \xref{\verb+BDIST+}{sg3}{BDIST} parameters.  In the case of
      \verb+AUTOSLIT=YES+, an
      appropriate value for \xref{\verb+GSLIT+}{sg3}{GSLIT} is supplied, and
      the background
      channel is positioned along the inter-order.

\item [{\tt EXTENDED=YES, CONTINUUM=YES}] This is a messy case.  The
      background channels are constrained to run along the inter-order.
      The object channel can, however, be freely specified using the
      \xref{\verb+GSLIT+}{sg3}{GSLIT} parameter.
      In the case of \xref{\verb+AUTOSLIT=YES+}{sg3}{AUTOSLIT}, an
      appropriate value of \xref{\verb+GSLIT+}{sg3}{GSLIT} is supplied.

\end{description}

In cases where the background and/or object channels need to be
specified explicitly, the appropriate coordinates/widths can be
determined (say) from a scan plot using the graphics cursor.

Even if there is no continuum, care is needed to avoid situation where the
background channel for one order includes emission lines from another.
Probably the best approach to adopt for emission-line objects is to let
the background run along the middle of the inter-order channel
(\verb+CONTINUUM=YES+, \verb+EXTENDED=YES+), and  let  the  background
smoothing/discrimination mechanism reject any contaminating signals.

\subsubsection{{\tt TRAK} parameters that affect the Background subtraction}

The way in which the background is smoothed in \xref{\verb+TRAK+}{sg3}{TRAK}
 is determined by the \xref{\verb+BKGAV+}{sg3}{BKGAV},
\xref{\verb+BKGIT+}{sg3}{BKGIT} and \xref{\verb+BKGSD+}{sg3}{BKGSD} parameters.

The \xref{\verb+BKGAV+}{sg3}{BKGAV} parameter specifies the FWHM of a
triangle function used to
fold pixel intensities; it is measured in geometric pixels along the
wavelength direction.  The initial default for this parameter is a
reasonable compromise.

Since the background {\bf should} be fairly smooth, there is in principle no
reason why \xref{\verb+BKGAV+}{sg3}{BKGAV}
 cannot be increased to produce a heavily smoothed
background.  However, even for LORES where the background is expected to be
flat, there is some structure to be accounted for (due to ITF defects)\@.

In the case of HIRES, there is a contribution to the background from
overlapping object signal, so that structure in the object spectrum can
lead to structure in the background spectrum.  However, this structure is
not significant since it does not relate to what is going on `underneath' the
object channel.

Therefore, the amount of smoothing that is specified by the
\xref{\verb+BKGAV+}{sg3}{BKGAV}
parameter should be enough that it produces a background spectrum free from
spurious structure, whilst not distorting any significant underlying shape.

The background is determined through an iterative process:

\begin{enumerate}

\item The smooth background is formed by folding `good' pixel
      intensities with a triangle function.

\item The variation of standard deviation of pixel intensities about this
      smooth background is then determined.

\item Pixels that are more than \xref{\verb+BKGSD+}{sg3}{BKGSD} local
      standard deviations from the
      smooth background are marked `bad' (and thus are not used in subsequent
      iterations)\@.

\item Goto (1)\@.

\end{enumerate}

The number of iterations is controlled by the \xref{\verb+BKGIT+}{sg3}{BKGIT}
parameter.

For \verb+BKGIT=0+ only steps (1) and (2) are performed (once)\@.  So that only
previously marked pixels are stopped from contributing to the smooth
background.

For \verb+BKGIT=1+ steps (1) to (3) are performed, and then steps (1) and (2)
are repeated.  So that some spike discrimination takes place.

Higher values of \verb+BKGIT+ are allowed, and lead to further iterations,
however, this is not normally needed.

\subsubsection{Setting up a script to run {\tt TRAK}}

The first thing to to is create a file containing the commands to be
performed.  The file created might contain:

\begin{verbatim}
   SET DATASET=SWP16528
   SET ORDER=125
   SET NORDER=60
   TRAK
\end{verbatim}

This file of commands can be run by

\begin{verbatim}
   % iuedr < script_file
\end{verbatim}

Care is needed when running IUEDR from a script since it is possible to
work interactively on the same dataset that is being processed using the
script.  IUEDR cannot keep track of such simultaneous use, so it is
up to you to avoid this situation.


\subsection{\xlabel{lbls}\label{subse:lbls}Spectrum Extraction using
            {\tt LBLS}}

Like the \xref{\verb+TRAK+}{sg3}{TRAK}
 command, the LBLS array is produced either for a LORES
aperture or a HIRES order, as in:

\begin{verbatim}
   > LBLS APERTURE=LAP
\end{verbatim}

or

\begin{verbatim}
   > LBLS ORDER=89
\end{verbatim}

The initial defaults for parameters which affect the operation of LBLS
are described by:

\begin{verbatim}
   > LBLS RL=[0,0] RSAMP=0.707 GSAMP=1.414 CUTWV=NO
\end{verbatim}

The \xref{\verb+RL+}{sg3}{RL}
 parameter values are used along with \xref{\verb+RSAMP+}{sg3}{RSAMP}
 in determining
the grid of R coordinates (measured in geometric pixels perpendicular to
dispersion)\@.  The case \verb+RL=[0,0]+ means that the range of R coordinates
will be decided by the \xref{\verb+LBLS+}{sg3}{LBLS}
 command, based on available information
(camera, resolution, aperture, {\it etc.})\@.

The \xref{\verb+RSAMP+}{sg3}{RSAMP}
 value indicates the spacing between positions on the R-grid
(in geometric pixels)\@.  The R-grid can be specified explicitly by, for
example:

\begin{verbatim}
   > LBLS RL=[-10,10] RSAMP=1.0
\end{verbatim}

The default R-grid is only really useful for HIRES, since it guarantees that it
will cover the area around the \'{E}chelle order properly.

There is a practical limit to the extent of the R-grid, so that (for example):

\begin{verbatim}
   > LBLS RL=[-50,50] RSAMP=0.1
\end{verbatim}

would not be possible.  The actual limit is not easily described,  but
is designed not to be exceeded by serious attempts to use
\xref{\verb+LBLS+}{sg3}{LBLS}\@.

The wavelength grid is determined by the \xref{\verb+GSAMP+}{sg3}{GSAMP}
and \xref{\verb+CUTWV+}{sg3}{CUTWV} parameters, which share value and
meaning with their use in the \xref{\verb+TRAK+}{sg3}{TRAK} command.

The intensity of a point in the spectrum is defined as the integral of image
intensity over a rectangle with the point at its centre.  This rectangle has a
dimension along the dispersion  direction ($\lambda$) corresponding to
\xref{\verb+RSAMP+}{sg3}{RSAMP}
  geometric pixels, and a dimension in the direction perpendicular
to dispersion (R) of (GSLIT(2)-GSLIT(1)) geometric pixels.

The integral over this rectangle is formed by folding pixel intensities with a
2-D function of the form:

\begin{displaymath}
F(dr, d\lambda) = F_{r}(dr) \times F_{\lambda}(d\lambda)
\end{displaymath}

where

\begin{displaymath}
F_{r}(dr) = {\rm MAX}(1.0, r_{\rm PEAK} \times
            (1.0 - dr / r_{\rm FWHM}))
\end{displaymath}

and

\begin{displaymath}
F_{\lambda}(d\lambda) = {\rm MAX}(1.0, \lambda_{\rm PEAK} \times
(1.0 - d\lambda / \lambda_{\rm FWHM}))
\end{displaymath}

$dr$ and $d\lambda$ are the absolute distances of the pixel from the rectangle
centre measured along the R and $\lambda$ directions (in geometric pixels).
The integral is then:

\begin{displaymath}
{\rm AREA} \times \frac {
\sum ( {\rm FN(P)} \times F_{r}(dr) \times F_{\lambda}(d\lambda) )}
{\sum ( F_{r}(dr) \times F_{\lambda}(d\lambda) )}
\end{displaymath}

where AREA is the effective area of the rectangle, and the ratio of summations
over pixels are the weighted mean intensity per pixel, and FN(P) is the
intensity of pixel P\@.

The functions $F_{\lambda}(\lambda)$ and $F_{r}(dr)$ are in fact truncated
triangles with bases of half width RBASE and WBASE, and peaks $R_{\rm PEAK}$
and $\lambda_{\rm PEAK}$\@.

The parameters describing these folding functions are obtained from the
following criteria:

\begin{itemize}

\item The full width at 0.5 intensity must be at least 0.707 geometric pixels.

\item The product of full widths at 0.5 intensity must be at least 1.0
      geometric pixels.

\item Precedence is given to resolution in the wavelength direction.

\end{itemize}

This is achieved by the following (FORTRAN) sequence:

\begin{verbatim}
   WMID = MAX( 0.707, GSAMP )
   RMID = MAX ( ( 1.0 / WMID ), RSAMP )
\end{verbatim}

where \xref{\verb+GSAMP+}{sg3}{GSAMP}
 and \xref{\verb+RSAMP+}{sg3}{RSAMP}
 are the values of their corresponding
Parameters.\\  (In the case of \xref{\verb+TRAK+}{sg3}{TRAK}
 \verb+RSAMP=(GSLIT(2)=GSLIT(1))+.\@)

Then for W ($\lambda$):

\begin{verbatim}
   WBASE = WMID + 0.707
   WFWHM = WBASE / 2.0
   WPEAK = 0.5 * WBASE / ( WBASE - WMID )
\end{verbatim}

and R

\begin{verbatim}
   RBASE = RMID + 0.707
   RFWHM = RBASE / 2.0
   RPEAK = 0.5 * RBASE / ( RBASE - RMID )
\end{verbatim}

In both \xref{\verb+TRAK+}{sg3}{TRAK}
 and \xref{\verb+LBLS+}{sg3}{LBLS}
 the intensities are scaled so that they
correspond to an integral of 1.414 geometric pixels along the wavelength
direction.  This means that, in the LORES case, the standard IUESIPS absolute
calibration functions can be applied without scaling.

The primary consequence of this algorithm is in the
\xref{\verb+LBLS+}{sg3}{LBLS} command.
Consider the example:

\begin{verbatim}
   > LBLS GSAMP=0.707 RSAMP=0.707
\end{verbatim}

The folding function along wavelength will have FWHM 0.707 geometric pixels,
however that perpendicular to dispersion will be:

\begin{verbatim}
   MAX( 1.414, RSAMP )
\end{verbatim}

If it is needed to obtain high spatial resolution, then wavelength resolution
must be forfeited by adopting a higher \xref{\verb+GSAMP+}{sg3}{GSAMP}
 value.

The sampling rate of the old IUESIPS LBLS data can be simulated (roughly) by:

\begin{verbatim}
   > LBLS RL=[-38.178,38.178] RSAMP=1.414 GSAMP=1.414 CUTWV=YES
\end{verbatim}

However, better resolution can be obtained with:

\begin{verbatim}
   > LBLS RL=[-16,16] RSAMP=1.0 GSAMP=1.0 CUTWV=YES
\end{verbatim}

\begin{latexonly}
Each pixel in the LBLS array represents a surface integral of size
\xref{\verb+RSAMP+}{sg3}{RSAMP} $\times$ \xref{\verb+GSAMP+}{sg3}{GSAMP}
geometric pixels (spatial $\times$ wavelength)\@.  However, the intensities
have been scaled (as with \xref{\verb+TRAK+}{sg3}{TRAK}) so that the
effective wavelength bin is equivalent to 1.414 geometric pixels.
This is so that, if the background were removed and pixels for a given
wavelength were summed then the existing IUESIPS absolute calibration could
be used directly (LORES at least).
\end{latexonly}

\begin{htmlonly}
Each pixel in the LBLS array represents a surface integral of size
\xref{\verb+RSAMP+}{sg3}{RSAMP}x\xref{\verb+GSAMP+}{sg3}{GSAMP}
geometric pixels (spatial times wavelength)\@.  However, the intensities
have been scaled (as with \xref{\verb+TRAK+}{sg3}{TRAK}) so that the
effective wavelength bin is equivalent to 1.414 geometric pixels.
This is so that, if the background were removed and pixels for a given
wavelength were summed then the existing IUESIPS absolute calibration could
be used directly (LORES at least).
\end{htmlonly}

\subsubsection{Output of Line-by-Line Spectra}

The \xref{\verb+OUTLBLS+}{sg3}{OUTLBLS}
 command can be used to output the current LBLS array to a
binary sequential file, as in:

\begin{verbatim}
   > OUTLBLS OUTFILE=LBLSR.DAT
\end{verbatim}

The contents of this file are best described by the FORTRAN 77 subroutine,
RDLBLS, and the programme, READLB, the source of which can be found in the
directory:

\begin{verbatim}
   $IUEDR_USER
\end{verbatim}

The RDLBLS source is well commented, and can be called directly (probably
without  change) from programmes which wish to access these LBLS files.

\subsubsection{Tabular Display of Line-by-line Spectra}

The \xref{\verb+PRLBLS+}{sg3}{PRLBLS}
 command can be used to tabulate the current LBLS array as in:

\begin{verbatim}
   > PRLBLS DATASET=SWP14931
\end{verbatim}

It should be born in mind that since the \xref{\verb+LBLS+}{sg3}{LBLS}
 command allows the array
size to be selected at creation, arrays with more than a certain number of
R-values cannot be printed sensibly.  However, every effort is made to print
the pixel intensities for a given wavelength on a single output line.


\subsection{Spectrum Extraction Templates}

The path of a spectrum across an IUE image is represented only to first
approximation by the (almost) linear function defined by the dispersion
constants.  Small-scale geometric distortions mean that the actual spectrum
path will depart from that specified by the dispersion constants.  We can think
of the spectrum as departing from the dispersion line in two ways:

\begin{itemize}

\item A linear shift with components in wavelength and perpendicular to
      dispersion.

\item A detailed shape.

\end{itemize}

Given a reasonable object signal, both of these can be defined during spectrum
extraction using a centroid approach.  However, there are situations where it
would be better to not determine the detailed shape from a particular image.

For example, the signal may be so weak that the effects of noise and blemishes
produce an unrealistic shape from the centroids.  In this case, we should like
to adopt a detailed shape from a calibration image (the shape doesn't change
much in time), and merely use the object signal in our image to shift this
into alignment.

In using the \xref{\verb+LBLS+}{sg3}{LBLS}
 command, no analysis is performed on the object signal
centroids, thus it is essential to know the precise location of the spectrum on
the image beforehand.  This can be obtained, as above, from a calibration
image, or more simply by running \xref{\verb+TRAK+}{sg3}{TRAK}
 on the same image.

The detailed spectrum shapes are called (spectrum) {\em templates.}  They
consist of a set of displacements, DR, perpendicular to dispersion at
specified wavelengths.

These templates can be associated with a \xref{\verb+DATASET+}{sg3}{DATASET}
 and stored in the
\verb+.UEC+ file.  By typing:

\begin{verbatim}
   > SHOW V=C
\end{verbatim}

the orders (HIRES) or apertures (LORES) for which templates are defined are
displayed.

There are a number of ways in which these templates can be defined.

\begin{itemize}

\item They may be supplied automatically by the
      \xref{\verb+READIUE+}{sg3}{READIUE} command, while
      the dataset is being read from tape.  However, this will not apply to
      datasets created prior to IUEDR Vn.~1.2.

\item They may be read into the dataset explicitly from a file using the
      \xref{\verb+NEWTEM+}{sg3}{NEWTEM} command.

\item They may be created by using the \xref{\verb+TRAK+}{sg3}{TRAK}
      command and associating the
      resultant centroid shifts with the template calibration in that dataset
      (the \xref{\verb+CENSV+}{sg3}{CENSV} parameter)\@.

\end{itemize}

The \xref{\verb+NEWTEM+}{sg3}{NEWTEM}
 command can be used to read templates into a dataset, as in:

\begin{verbatim}
   > NEWTEM TEMFILE=$IUEDR_DATA/swphilap
\end{verbatim}

which reads the file \verb+swphilap.tem+ from the \verb+$IUEDR_DATA+  directory.
Here is a list of the names of files containing various Template Calibrations:

\begin{latexonly}
\begin{tabular}{ll}
File               & Contents\\
{\tt swphilap.tem} & SWP, LAP, HIRES\\
{\tt swphisap.tem} & SWP, SAP, HIRES\\
{\tt lwrhilap.tem} & LWR, LAP, HIRES\\
{\tt lwrhisap.tem} & LWR, SAP, HIRES\\
{\tt lwphilap.tem} & LWP, LAP, HIRES\\
{\tt lwphisap.tem} & LWP, SAP, HIRES\\
{\tt swplo.tem}    & SWP, LORES\\
{\tt lwrlo.tem}    & LWR, LORES\\
{\tt lwplo.tem}    & LWP, LORES\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>File              Contents</B>
swphilap.tem      SWP, LAP, HIRES
swphisap.tem      SWP, SAP, HIRES
lwrhilap.tem      LWR, LAP, HIRES
lwrhisap.tem      LWR, SAP, HIRES
lwphilap.tem      LWP, LAP, HIRES
lwphisap.tem      LWP, SAP, HIRES
swplo.tem         SWP, LORES
lwrlo.tem         LWR, LORES
lwplo.tem         LWP, LORES
</PRE>
\end{rawhtml}
\end{htmlonly}

Due to lack of suitable calibration images, some of these files may not exist
at the present.

The internal format of these \verb+.TEM+ files will not be described at this
time.  However, it is possible for users to create template files, based on
their own calibration images.  This can be done using the
\xref{\verb+TRAK+}{sg3}{TRAK} and the
\xref{\verb+OUTEM+}{sg3}{OUTEM} commands.

\xref{\verb+OUTEM+}{sg3}{OUTEM}
 can be used to output the templates associated with a dataset to
a text file, as in:

\begin{verbatim}
   > OUTEM TEMFILE=SWP3196
\end{verbatim}

This creates a file \verb+SWP3196.tem+, which can subsequently be input to
other datasets (other images) using the \xref{\verb+NEWTEM+}{sg3}{NEWTEM}
 command.

It should be realised that \xref{\verb+TRAK+}{sg3}{TRAK} does not
automatically store centroid shifts in the dataset.
This must be done by specifying the \xref{\verb+CENSV+}{sg3}{CENSV}
parameter. For example:

\begin{verbatim}
   > TRAK CENSV=YES CENIT=1
\end{verbatim}

Note that the initial default is \verb+CENSV=NO+\@.

The standard templates (in the files listed  above) were created by
extracting spectra of various types with \verb+CENSV=YES+\@.

Both \xref{\verb+TRAK+}{sg3}{TRAK} and \xref{\verb+LBLS+}{sg3}{LBLS}
use the \xref{\verb+CENTM+}{sg3}{CENTM} parameter.  This is used
to indicate whether any available predefined spectrum templates are used to
modify the dispersion relations in specifying where the spectrum is on the
image.  In the case of \xref{\verb+TRAK+}{sg3}{TRAK}
 this may just represent an improved initial
guess to the spectrum shape, to be refined by centroid iterations
(\verb+CENIT=1+)\@.

Although \xref{\verb+TRAK+}{sg3}{TRAK}
 can very often determine the detailed spectrum shape from
the object signal, \xref{\verb+LBLS+}{sg3}{LBLS}
 cannot do this.  Also, in some cases, the object
signal is too weak to specify the detailed spectrum shape.

The \xref{\verb+CENSH+}{sg3}{CENSH}
 parameter for \xref{\verb+TRAK+}{sg3}{TRAK}
 controls whether, during centroid
iterations, the object signal is just used to shift the initial template
(\verb+CENSH=YES+) without changing its shape, or whether the detailed shape
can be refined (\verb+CENSH=NO+)\@.

For weak object signals, the best approach would be to use a standard
spectrum template (see below on how to get this), and just shift this
laterally to align with the data.  This can be done by, for example:

\begin{verbatim}
   > TRAK CENTM=YES CENSH=YES CENIT=1
\end{verbatim}

The assumption here is that the shapes of the calibration and object
spectra are similar, suffering only a linear displacement (perpendicular to
dispersion)\@.

In the case of HIRES where the spectrum contains gaps (strong absorption
features), the adoption of a pre-defined template allows precise signal
location; this is important in positioning the inter-order channels.

The initial template can be used simply as a good first approximation to the
detailed shape, using:

\begin{verbatim}
   > TRAK CENTM=YES CENSH=NO CENIT=1
\end{verbatim}

This approach is not recommended unless there are good reasons for thinking
that the pre-defined template has a different shape from the actual spectrum;
in which case, it is probably better to start from the dispersion constants:

\begin{verbatim}
   > TRAK CENTM=NO CENSH=NO CENIT=1
\end{verbatim}

which is the initial default.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{spectrum_calibration}\label{se:spec_calib}SPECTRUM
         CALIBRATION}
\markboth{Spectrum Calibration}{\stardocname}

Although default calibrations are provided for each dataset when it is created
({\it{e.g.,}}\ by \xref{\verb+READIUE+}{sg3}{READIUE}), not all of these are
necessarily appropriate (especially in detail)\@.  For example, although the
spectrum can be tracked automatically during spectrum extraction to account
for spectrum shifts perpendicular to dispersion, no corresponding wavelength
corrections can be made at that time.

Information about wavelength corrections is only effectively obtainable
once the spectrum has been produced, and the positions of features with known
wavelengths are measured.

Similar arguments also hold for ripple calibrations and background
order-overlap correction procedures (which at present are empirically based)\@.

Spectrum calibrations are not used during spectrum extraction, and so they
can be changed afterwards.


\subsection{Wavelength Shifts}

The only really certain method for determining the absolute accuracy of the
wavelength scale is to produce a plot with the \xref{\verb+PLNET+}{sg3}{PLNET}
or \xref{\verb+PLFLUX+}{sg3}{PLFLUX} commands and then measure the
position of a feature for which the `correct' wavelength is known.

How the correct wavelength is determined is in the scientific domain
({\it{i.e.,}} it is up to you).  However, given that a feature has been
identified, its position measured, and its laboratory wavelength is known,
some help is offered: The measured wavelength will differ from the laboratory
value due to the following effects:

\begin{itemize}

\item The component of radial velocity caused by satellite motion relative
      to the Sun.

\item The component of radial velocity caused by the object producing the
      spectral feature relative to the Sun.

\item A spectrum shift which is assumed to be caused by a simple linear
      shift of the spectrum on the image.

\end{itemize}

The Satellite radial velocity is effectively the same as that of the Earth.
Its effect is the same for all wavelengths and can be taken out by, for
example:

\begin{verbatim}
   > SETA VSHIFT=25.4
\end{verbatim}

\begin{latexonly}
which would specify a Satellite velocity of 25.4km${\rm S}^{-1}$ (in the
sense of the Satellite moving away from the object)\@.
\end{latexonly}

\begin{htmlonly}
which would specify a Satellite velocity of 25.4km/s (in the
sense of the Satellite moving away from the object)\@.
\end{htmlonly}

The Satellite radial velocity is normally only significant for HIRES\@.
However, if it is used for LORES, remember that there is a separate value
for each aperture.

It simplifies matters if the Object radial velocity correction is encorporated
directly in the laboratory wavelength, rather than try to use the
\xref{\verb+VSHIFT+}{sg3}{VSHIFT}
facility.  This is especially true if different features have different
velocities.

Once velocity effects are accounted for, the difference between the
laboratory and measured wavelengths can be used to provide a spectrum
shift.

For LORES this can be specified directly for each aperture by, for example:

\begin{verbatim}
   > SETA WSHIFT=2.4
\end{verbatim}

which provides a correction of 2.4\AA\ in the sense of adding this
correction to the existing wavelengths.  So, in effect:

\begin{displaymath}
\lambda_{\rm SHIFT} = \lambda_{\rm laboratory} - \lambda_{\rm measured}
\end{displaymath}

where $\lambda_{\rm SHIFT}$ is \xref{\verb+WSHIFT+}{sg3}{WSHIFT}\@.
Remember that there is a separate \verb+WSHIFT+ value for each aperture.

For HIRES, a linear shift of the spectrum on the image leads to different
wavelength shifts in different \'{E}chelle orders.  This is because the
dispersion (\AA /pixel) varies with the \'{E}chelle order number.  The
wavelength correction that can be applied is:

\begin{displaymath}
\lambda_{\rm SHIFT}(O) = {\rm E}_{\rm SHIFT} / O
\end{displaymath}

where $O$ is \xref{\verb+ORDER+}{sg3}{ORDER}\@.
Which is specified by, for example:

\begin{verbatim}
   > SETA ESHIFT=20.0
\end{verbatim}

which provides a wavelength correction of 0.2\AA\ at order number 100 (and so
on)\@.  Note that \xref{\verb+ESHIFT+}{sg3}{ESHIFT}
 is used instead of \xref{\verb+WSHIFT+}{sg3}{WSHIFT}
 for HIRES, and
that only a single correction value is used for all orders.  The value to be
given to \xref{\verb+ESHIFT+}{sg3}{ESHIFT}
 can be determined from the wavelength correction
measured for features in a number of \'{E}chelle orders, multiplied by their
order numbers.  A constant value for \verb+ESHIFT+ should be found from all
features and all orders (within measurement errors)\@.

It is important to get the wavelength scale right since this affects the
accuracy with which the wavelength dependent flux calibrations (Absolute,
Ripple) can be applied.


\subsection{Order Overlap Correction for HIRES}

The \xref{\verb+TRAK+}{sg3}{TRAK}
 command takes the background level from the image intensities
contained in the background channels.  For HIRES these background channels
will normally run along the inter-order position.  In the spectral regions
where the \'{E}chelle orders are very close, signal from the object itself can
spread into these background channels, with the result that the background
can be over-estimated.  This background over-estimation is quite severe in
cases where there is a fairly continuous spectrum ({\it{i.e.,}}  not just
emission lines)\@.

There are various ways in which this additional background can be removed.
The method adopted in IUEDR (for a start) is semi-empirical and based work by
Bianchi and Bohlin (1982)\@.

The default for each HIRES dataset is that this correction is not applied.
This is because it is only semi-empirical in nature, and requires some
attention from you in order to get a reliable result.

The correction is applied to the Net spectrum during the spectrum calibration
process.  So if you have extracted some orders using
\xref{\verb+TRAK+}{sg3}{TRAK}, the correction can be switched on and
adjusted without the need to repeat \verb+TRAK+\@.

\subsubsection{The Order Overlap Correction Technique}

Consider a plot of one of the scans produced by the
\xref{\verb+SCAN+}{sg3}{SCAN} command.  It
consists of a set of peaks corresponding to the \'{E}chelle orders traversed.

Where the orders are well separated their profiles do not overlap
significantly, and the inter-order signal is fairly close to the
effective background level.

Where the orders are fairly close, the inter-order signal is increased.

The approach is to start from the Net Intensity, $n$, produced by
({\it{e.g.,}})\ \xref{\verb+TRAK+}{sg3}{TRAK}, and account for two effects:

\begin{enumerate}

\item The effect of signal overlap on the background level used for
      spectrum extraction.

\item The contribution of signal from one order into another.

\end{enumerate}

This is done by assuming that the order profiles have wings which vary in
intensity with distance squared. The correction needed to produce the `true'
Net Intensity, $N$, is then:

\begin{displaymath}
N - n = F_{0} \times n^{o} + F_{1} \times (n^{-} + n^{+})
\end{displaymath}

where

\begin{displaymath}
F_{0} = 1.636 \times C(\lambda)
\end{displaymath}

\begin{displaymath}
F_{1} = C(\lambda) \times (0.5 + 1.636 \times C(\lambda))
\end{displaymath}

The $n^{o}$, $n^{-}$ and $n^{+}$ represent appropriate averages of
the uncorrected Net intensity in the order itself, and in the two adjacent
orders respectively.  $C(\lambda)$ is a `free' parameter which is a function of
wavelength, $\lambda$\@.  The form given here is a slight modification of that
given by Bianchi and Bohlin (1982)\@.

The most noticeable effect of the order overlap on the uncorrected
spectrum, n, is that absorption lines ({\it{e.g.,}} Interstellar Lyman Alpha)
which should be at zero intensity actually fall below zero.  Such lines offer
a means of determining $C(\lambda)$ empirically.  Bianchi and Bohlin have done
this for SWP PHOT images and find that a linear function of $\lambda$ is
viable, with:

\begin{displaymath}
C(1200) = 0.12
\end{displaymath}

and

\begin{displaymath}
C(1400) = 0.0
\end{displaymath}

$C(\lambda)$ is also zero for wavelengths above 1400\AA\@.

The actual value of $C(\lambda)$ will not be fixed for all HIRES images, but
will be affected by such variables as telescope focus, aperture and whether
the image is PHOT or GPHOT\@.  The spatial resolution of PHOT and GPHOT images
is different, since the latter have been resampled onto a new grid.

In the case of SWP images where there are lines in high numbered orders, it
should be possible to determine a reasonable value for $C(1200)$\@.  If this
is not the case, then a canonical value of 0.12 could be applied, without
too much problem.  In any case, some correction is bound to be an
improvement over none at all.

No work has been done to determine suitable values for $C(\lambda)$ in LWR and
LWP images.  However, in those camera, the effects of order-overlap appear to
be less harmful than in SWP\@.

\begin{latexonly}
The most appropriate form of averaging needed to produce $n^{o}$,
$n^{-}$ and $n^{+}$ has not been addressed properly when deriving the
correction formula given above.  Bianchi and Bohlin suggest it be similar to
that applied when the raw background is smoothed.  In their case (which refers
to IUESIPS\#2 spectra) this means folding with a triangle function of FWHM
$15 \times 0.707$ pixels.  Since in \xref{\verb+TRAK+}{sg3}{TRAK}
 the FWHM used for smoothing is
a free parameter, this direct relation cannot be followed without constraint.
Very small amounts of smoothing will cause structure to be transferred from the
background to the spectrum.  On the other hand, very large amounts of smoothing
will fail to take account of large-scale variations in the object signal.
\end{latexonly}

\begin{htmlonly}
The most appropriate form of averaging needed to produce $n^{o}$,
$n^{-}$ and $n^{+}$ has not been addressed properly when deriving the
correction formula given above.  Bianchi and Bohlin suggest it be similar to
that applied when the raw background is smoothed.  In their case (which refers
to IUESIPS\#2 spectra) this means folding with a triangle function of FWHM
15x0.707 pixels.  Since in \xref{\verb+TRAK+}{sg3}{TRAK}
 the FWHM used for smoothing is
a free parameter, this direct relation cannot be followed without constraint.
Very small amounts of smoothing will cause structure to be transferred from the
background to the spectrum.  On the other hand, very large amounts of smoothing
will fail to take account of large-scale variations in the object signal.
\end{htmlonly}

The constants 0.5 and 1.636 appearing in the correction formula above
are a consequence of the profile shape.  However, it can be shown that their
detailed values are not too important.  This is particularly so because
the absolute amount of correction is controlled by $C(\lambda)$ which is
determined empirically.

Also, notice that the primary source of correction is from the order
itself, rather than from the adjacent orders.  This is because the adjacent
orders provide contributions into both the inter-order and the order itself,
and these largely cancel.

On a note of some concern, it needs to be said that the assumption
that the profile can be represented by a function that varies inversely
with distance squared is inconsistent with the empirically determined
dependence if $C(\lambda)$ on $\lambda$\@.

\subsubsection{Adjusting the Order Overlap Correction}

The functional form of $C(\lambda)$ is controlled by the
\xref{\verb+HALC+}{sg3}{HALC}, \xref{\verb+HALWC+}{sg3}{HALWC},
\xref{\verb+HALW0+}{sg3}{HALW0} parameters that can be specified in the
\xref{\verb+SETD+}{sg3}{SETD} command.  Initially,
\xref{\verb+HALC+}{sg3}{HALC} is zero, which means that there is no
correction.  The formula used for $C(\lambda)$ is:

\begin{displaymath}
C(\lambda) =
{\tt HALC} \times (\lambda - {\tt HALW0}) / ({\tt HALWC} - {\tt HALW0})
\end{displaymath}

where \verb+HALC+ is the value of $C(\lambda)$ at \verb+W=HALWC+, and
\verb+HALW0+ is the wavelength where $C(\lambda)$ becomes zero.  You can put
the standard SWP values for these parameters into a HIRES dataset by:

\begin{verbatim}
   > SETD HALC=0.12 HALWC=1200 HALW0=1400
\end{verbatim}

The smoothing is controlled by the \xref{\verb+HALAV+}{sg3}{HALAV}
 parameter to \xref{\verb+SETD+}{sg3}{SETD}, its
standard value is 30.0 and need not be changed.

The value for \xref{\verb+HALC+}{sg3}{HALC}
 given above is a canonical one that can be adopted as
a start approximation.  To get a better value you will need some absorption
lines which are guaranteed to have flat bottoms at zero intensity.  This
criterion is normally only met by Interstellar Lyman Alpha (1215\AA )\@.

Let us assume that you have extracted all of the orders of interest
using \xref{\verb+TRAK+}{sg3}{TRAK}\@. Let us also assume, for the sake of
demonstration purposes that you have got a flat absorption line at 1215\AA\@.
The first thing to do is produce a mean spectrum covering the region:

\begin{verbatim}
   > MAP ML=[1180,1250] MSAMP=0.2 ORDERS=[125,66]
\end{verbatim}

This will give a fairly smooth spectrum which is needed to adjust things
so that the absorption line has zero intensity in its centre.  The details of
how this is done may vary.  For example, you may need more smoothing (a
larger value of \xref{\verb+MSAMP+}{sg3}{MSAMP}) if the image is very noisy
or the signal weak.
The largest possible range was given for \xref{\verb+ORDERS+}{sg3}{ORDERS}
because it is not critical and avoids the need to figure out exactly which
orders cover the wavelength region being mapped.

The mapped spectrum can be plotted using the \xref{\verb+PLMEAN+}{sg3}{PLMEAN}
 command, and an
improved value of \xref{\verb+HALC+}{sg3}{HALC}
 determined. Physically, when there is no
correction, \xref{\verb+HALC+}{sg3}{HALC}
 is the distance below zero of the line core expressed
as a fraction of the neighbouring continuum intensity.

If a new value of \xref{\verb+HALC+}{sg3}{HALC}
 (say 0.10) is required then you need to go
through the following sequence:

\begin{verbatim}
   > SETD HALC=0.10
   > MAP
   > PLMEAN
\end{verbatim}

where the parameter defaults for \xref{\verb+MAP+}{sg3}{MAP} are taken
from the previous invocation.

If your spectrum contains suitable lines over a wide wavelength range then it
may be possible for you to do some experimentation of your own, and determine
whether the wavelength dependence of $C(\lambda)$ adopted here is appropriate.
The criterion for selecting lines is that they should have flat zero intensity
cores of width greater than the spectral resolution.

If you feel that the amount of smoothing needs to change, then this can be done
by, for example:

\begin{verbatim}
   > SETD HALAV=10.0
\end{verbatim}

which sets the FWHM of the triangle function to be 10.0 geometric pixels.
Values of \xref{\verb+HALAV+}{sg3}{HALAV}
 that differ dramatically from the \xref{\verb+BKGAV+}{sg3}{BKGAV}
 parameter
of \xref{\verb+TRAK+}{sg3}{TRAK}
 will lead to a reduction in the accuracy of spectra corrected by
this method.

If you wish to apply this correction to LWR or LWP spectra you will need to
determine values for all of \xref{\verb+HALC+}{sg3}{HALC},
\xref{\verb+HALWC+}{sg3}{HALWC} and \xref{\verb+HALW0+}{sg3}{HALW0}\@.

One last point: remember that it is the action of the
\xref{\verb+SETD+}{sg3}{SETD} command that changes the values of these
parameters in the dataset.  Nothing actually happens if you just type,
for example:

\begin{verbatim}
   > SET HALC=0.13
\end{verbatim}


\subsection{\'{E}chelle Ripple Calibration}

The Ripple Calibration is that part of the overall flux calibration that
makes the spectra of adjacent \'{E}chelle orders join up and overlap properly.
It is only applicable for HIRES\@.

Although default ripple calibrations are stored in the (HIRES) dataset when
it is read (\xref{\verb+READIUE+}{sg3}{READIUE}), these can only be
considered as first approximations (sometimes not even that!)\@.
There appear to be effects which mean that different images require
slightly (and sometimes very) different ripple calibrations.

If the spectrum is fairly continuous and has good signal-to-noise, then the
assessment of ripple calibration can be based on how the orders join up when
plotted on the same graph.  For example:

\begin{verbatim}
   > PLFLUX ORDER=89
   > SET RS=NO
   > PLFLUX ORDER=90
   > PLFLUX ORDER=88
   > SET RS=YES
\end{verbatim}

will produce a composite plot of order 89 and its two neighbours.  (On the
display, they will be represented by different coloured lines, which
helps to distinguish them if they do actually overlap.\@)

There are two basic things to look for here:

\begin{enumerate}

\item Whether there is any asymmetry.  Consider the example above: if the
      short wavelength end of order 89 falls below the overlap with order 90,
      {\em and\,} its long wavelength falls above the overlap with order 88.
      Then the symmetry wavelength probably needs to be increased.

\item If there is no asymmetry, but the spectrum appears to curl up or down at
      the ends, then the ripple function coordinate scale needs to be changed.

\end{enumerate}

\subsubsection{Changing the Ripple Calibration Details}

The basic ripple function is given by:

\begin{displaymath}
R(x) =
{(\sin x / x )}^{2} \times
({\tt RIPC}(1) + {\tt RIPC}(2) \times x + {\tt RIPC}(3) \times x^{2}\dots)
\end{displaymath}

where

\begin{displaymath}
x = \pi \times {\tt RIPA} \times (\lambda - C_{\lambda}) \times {\tt ORDER} /
C_{\lambda}
\end{displaymath}

and $\pi =3.14159$, $C_{\lambda}={\tt RIPK}/{\tt ORDER}$\@.  Here $\lambda$ is
the wavelength, and \xref{\verb+RIPA+}{sg3}{RIPA} is a fudge factor which is
typically like 1.0.  The net spectrum is divided by $R(x)$ above.
Normally, and by default:

\begin{latexonly}
\begin{displaymath}
{\tt RIPC} = (1.0, 0.0, 0.0, ...)
\end{displaymath}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<CENTER>
<TT>RIPC</TT> = (1.0, 0.0, 0.0, ...)
</CENTER>
\end{rawhtml}
\end{htmlonly}

To affect the symmetry position of this function ($C_{\lambda}$ above), we need
to change the value of \xref{\verb+RIPK+}{sg3}{RIPK}\@.
\xref{\verb+RIPK+}{sg3}{RIPK} is normally called the
`Ripple Constant'; it represents the central wavelength for order number 1 (not
observed)\@.  \verb+RIPK+ should be constant for the whole \'{E}chelle spectrum.
If it is, then we can affect the symmetry wavelengths of all orders by, for
example:

\begin{verbatim}
   > SETD RIPK=137725.0
\end{verbatim}

In fact \verb+RIPK+ in the standard calibration is allowed to be a polynomial
function of \xref{\verb+ORDER+}{sg3}{ORDER}:

\begin{latexonly}
\begin{displaymath}
{\tt RIPK} = RIPK(1) + RIPK(2) \times {\tt ORDER} +\ldots
\end{displaymath}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<CENTER>
\end{rawhtml}
{\tt RIPK} = {\it RIPK(1)} + {\it RIPK(2)} $\times$ {\tt ORDER} + \ldots
\begin{rawhtml}
</CENTER>
\end{rawhtml}
\end{htmlonly}

If such a representation is not found to be good enough, then the value of
\verb+RIPK+ can be specified for individual orders by, for example:

\begin{verbatim}
   > SETM ORDER=89 RIPK=137700
\end{verbatim}

However, if this is done, then it must be remembered that changing the global
value (with \xref{\verb+SETD+}{sg3}{SETD}) will not have any effect for these
individual orders.

As can be seen from the functional form of $R(x)$, the scale between $x$
and $\lambda$ is controlled by \xref{\verb+RIPK+}{sg3}{RIPK}
 and by \xref{\verb+RIPA+}{sg3}{RIPA}\@.  Once any
asymmetry has been removed, the optimal flatness can be achieved through
variation of \verb+RIPA+\@.  The global value of \verb+RIPA+ can be specified
by, for example:

\begin{verbatim}
   > SETD RIPA=0.856
\end{verbatim}

By decreasing \verb+RIPA+, the ends of the orders can be made to fall, and
vice-versa.  If a global value for \verb+RIPA+ is not good enough, then it is
possible to specify its value for individual orders by, for example:

\begin{verbatim}
   > SETM ORDER=89 RIPA=0.83
\end{verbatim}

But just as for \verb+RIPK+, changes in the global value of \verb+RIPA+ will
not affect these individual orders.

The values of the \xref{\verb+RIPC+}{sg3}{RIPC}
 polynomial (in the function above) can be
specified for individual orders by, for example:

\begin{verbatim}
   > SETM ORDER=89 RIPC=[1.0,0.1]
\end{verbatim}

Although the functional effect of \verb+RIPC+ on the ripple shape is well
defined, no clear guidance can be given here as to how to use this facility.
It is expected that values for \verb+RIPC+ could be determined from some
automatic numerical analysis of the spectrum (one day)\@.

It must be remembered that it is important to start with a reasonably
accurate wavelength scale before any ripple calibration changes are
performed.

\subsubsection{Reading in a Ripple Calibration File}

When the dataset is created, the global ripple calibration parameters are read
from a file.  If, after changing the calibration (use of
\xref{\verb+SETD+}{sg3}{SETD} in the
previous Section), it is felt a return to start would be a good idea, then
this can be done by, for example:

\begin{verbatim}
   > NEWRIP RIPFILE=$IUEDR_DATA/swp
\end{verbatim}

The standard calibration files are stored in the \verb+$IUEDR_DATA+
directory.  These files have extension \verb+.rip+, so that the file
\verb+SWP.RIP+ would be read in the above example.  Here is a list
of Ripple Calibration files available in \verb+$IUEDR_DATA+

\begin{latexonly}
\begin{tabular}{ll}
File          & Contents\\
{\tt swp.rip} & SWP, HIRES\\
{\tt lwr.rip} & LWR, HIRES\\
{\tt lwp.rip} & LWP, HIRES\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>File       Contents</B>
swp.rip    SWP, HIRES
lwr.rip    LWR, HIRES
lwp.rip    LWP, HIRES
</PRE>
\end{rawhtml}
\end{htmlonly}

The format of these files will not be described at this time.

\subsubsection{\'{E}chelle Order Wavelength Clipping}

It is inevitable that the very ends of some orders will refuse to be
calibrated properly.  Or perhaps their signal is just too weak to be any use.
We shall see in Section~\ref{se:spec_edit} that these `bad' sections of
spectra can be edited out using the graphics cursor.  However, there is a
less laborious mechanism for achieving this.

Recalling the form of the ripple function, $R(x)$, described above, it can be
seen that it goes through zero for $x=-\pi$ and $x=+\pi$\@.  These $x$
values correspond to quite reasonable absolute wavelength boundaries, outside
of which the ripple calibration is not performed (and the spectrum is left
undefined)\@. These $x$ boundaries can be changed for the whole spectrum by,
for example:

\begin{verbatim}
   > SETD XCUT=[-2.5,2.5]
\end{verbatim}

which will mark as `bad' (and not calibrate) the ends of the \'{E}chelle orders
outside the specified range.  This may help remove the worst calibrated
parts of the spectrum; however, this may not be sufficiently
precise.

In addition to \xref{\verb+XCUT+}{sg3}{XCUT}, the ends of orders can be
bounded by specific wavelengths which can be given by, for example:

\begin{verbatim}
   > SETM ORDER=89 WCUT=[1539.0,1559.5]
\end{verbatim}

The appropriate wavelengths could, for example, be obtained using the graphics
cursor (\xref{\verb+CURSOR+}{sg3}{CURSOR} command) on a spectrum plot.
The current values for all of these cutoff wavelengths can be printed by:

\begin{verbatim}
   > SHOW V=R
\end{verbatim}

which also prints the Ripple Calibration.

Specifying \xref{\verb+WCUT+}{sg3}{WCUT}
 for each \'{E}chelle order would become really tedious.
Therefore, during dataset creation (\xref{\verb+READIUE+}{sg3}{READIUE})
a standard file can be read containing reasonable values for these
\xref{\verb+WCUT+}{sg3}{WCUT} values.  The following
sources have been used:

\begin{enumerate}

\item IUE+VILSPA User's Guide Volume II Image Processing: SWP and LWR (both
      apertures)\@.

\item The LWR versions: LWP (both apertures)\@.  This only a temporary measure.

\end{enumerate}

The \xref{\verb+CUTWV+}{sg3}{CUTWV}
 parameter controls whether the \'{E}chelle Wavelength Clipping
limits associated with a HIRES dataset are used as the start-end wavelengths
in the extracted spectrum.  The initial default is
\xref{\verb+CUTWV=NO+}{sg3}{CUTWV}, which
means that the extraction wavelength grid is determined by the intersection of
the dispersion line with the faceplate circle.  For example, the wavelength
grid for order 89 in LWR is:

\begin{verbatim}
   [2575.030,2620.598]
\end{verbatim}

In the case of the LWR camera, this leads to the bad photometry on the
faceplate ring disrupting the accuracy of the background (after smoothing).  By
setting \verb+CUTWV=YES+ for the above example, the wavelength grid would be:

\begin{verbatim}
   [2580.0,2615.0]
\end{verbatim}

Which entirely avoids the faceplate ring defects, but at the possible expense
of losing features at the ends of the order.  If you want to look at features
outside the Clipping limits for a particular order, then use
\xref{\verb+SETM+}{sg3}{SETM}, for example:

\begin{verbatim}
   > SETM WCUT=[2577.0,2617.0]
\end{verbatim}

If changes have been made to \verb+WCUT+ values using \verb+SETM+, then the
standard values can be restored by, for example:

\begin{verbatim}
   > NEWCUT CUTFILE=$IUEDR_DATA/swplap
\end{verbatim}

which reads the file \verb+swplap.cut+ from the \verb+$IUEDR_DATA+
directory.  Here is a list of the available Wavelength Clipping files
in \verb+$IUEDR_DATA+

\begin{latexonly}
\begin{tabular}{lll}
File             & Contents        & Notes\\
{\tt swpsap.cut} & SWP, SAP, HIRES & \\
{\tt swplap.cut} & SWP, LAP, HIRES & \\
{\tt lwrsap.cut} & LWR, SAP, HIRES & \\
{\tt lwrlap.cut} & LWR, LAP, HIRES & \\
{\tt lwpsap.cut} & LWR, SAP, HIRES & Taken from LWR\\
{\tt lwplap.cut} & LWP, LAP, HIRES & Taken from LWR\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>File          Contents           Notes</B>
swpsap.cut    SWP, SAP, HIRES
swplap.cut    SWP, LAP, HIRES
lwrsap.cut    LWR, SAP, HIRES
lwrlap.cut    LWR, LAP, HIRES
lwpsap.cut    LWR, SAP, HIRES    Taken from LWR
lwplap.cut    LWP, LAP, HIRES    Taken from LWR
</PRE>
\end{rawhtml}
\end{htmlonly}

The internal format of these \verb+.cut+ files will not be described at this
time.


\subsection{Absolute Calibration}

In the case of LORES, an appropriate Absolute Calibration is stored in the
dataset at the time it is created (the \xref{\verb+READIUE+}{sg3}{READIUE}
command)\@.  Provided the image is photometrically correct, then this
calibration should be adequate.

In the HIRES case, there is no automatic assignment of an absolute
calibration.  This is because there is an intimate relation between the
absolute calibration, the image resolution and the spectrum extraction
technique.  This arises since the signal from one order can overlap those
adjacent to it and cause only part of the spectrum to be integrated.
The existing published absolute calibrations ({\it{e.g.,}} Cassatella, Ponz and
Selvelli, 1981) apply to the approximate spectrum extraction algorithms in
IUESIPS, and so would not be appropriate if more accurate algorithms were used.

Another problem with HIRES absolute calibrations is that the ones published so
far do not cover the full wavelength range.  Since IUEDR refuses (with good
reason) to extrapolate calibrations, this causes the spectrum outside the
calibration wavelength range to vanish.

\subsubsection{Listing the Absolute Calibration}

The data associated with absolute calibration can be listed using:

\begin{verbatim}
   > SHOW V=A
\end{verbatim}

This gives the basic wavelength dependent sensitivity function, any
arbitrary scale factors, \xref{\verb+THDA+}{sg3}{THDA}
 dependence and exposure times.

\subsubsection{Reading an Absolute Calibration File into a Dataset}

It is possible to read the absolute calibration from a text file and store it
in the dataset, for example:

\begin{verbatim}
   > NEWABS ABSFILE=$IUEDR_DATA/swphi
\end{verbatim}

reads the standard SWP HIRES absolute calibration from a file
\verb+swphi.abs+ in the \verb+$IUEDR_DATA+ directory.  All the files in this
directory with type \verb+.abs+ contain an absolute calibration table.
Here is a list of these files:

\begin{latexonly}
\begin{tabular}{lll}
File             & Application     & Source\\
{\tt lwplo.abs}  & LWP, LAP, LORES & Cassatella \& Harris (1982).\\
{\tt lwplo1.abs} & LWP, LAP, LORES & Cassatella \& Harris (1982).\\
{\tt lwplo2.abs} & LWP, LAP, LORES & Cassatella, Lloyd and Gonzalez
                                     Riestra (1987).\\
{\tt lwphi.abs}  & LWP, LAP, HIRES & Cassatella {\it et al} (1988).\\
{\tt lwrhi.abs}  & LWR, LAP, HIRES & Bohlin \& Holm (1980) and Cassatella,\\
                 &                 & Ponz \& Selvelli (1981).\\
{\tt lwrlo.abs}  & LWR, LAP, LORES & Bohlin \& Holm (1980).\\
{\tt lwrlo1.abs} & LWR, LAP, LORES & Bohlin (1986) and\\
                 &                 & Clavel, Gilmozzi \& Prieto (1986).\\
{\tt lwrlo2.abs} & LWR, LAP, LORES & Oliversen and Garhardt (1987).\\
{\tt swphi.abs}  & SWP, LAP, HIRES & Bohlin \& Holm (1980) and Cassatella,\\
                 &                 & Ponz \& Selvelli (1981).\\
{\tt swplo.abs}  & SWP, LAP, LORES & Bohlin \& Holm (1980).\\
{\tt swplo2.abs} & SWP, LAP, LORES & Bohlin (1986), Bohlin \& Grillmair (1988).\\
{\tt swplo3.abs} & SWP, LAP, LORES & {\sl Not yet installed.}\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>File          Application        Source</B>
lwplo.abs     LWP, LAP, LORES    Cassatella &amp; Harris (1982).
lwplo1.abs    LWP, LAP, LORES    Cassatella &amp; Harris (1982).
lwplo2.abs    LWP, LAP, LORES    Cassatella, Lloyd and Gonzalez Riestra (1987).
lwphi.abs     LWP, LAP, HIRES    Cassatella <I>et al</I> (1988).
lwrhi.abs     LWR, LAP, HIRES    Bohlin &amp; Holm (1980) and Cassatella,
                                 Ponz &amp; Selvelli (1981).
lwrlo.abs     LWR, LAP, LORES    Bohlin &amp; Holm (1980).
lwrlo1.abs    LWR, LAP, LORES    Bohlin (1986) and
                                 Clavel, Gilmozzi &amp; Prieto (1986).
lwrlo2.abs    LWR, LAP, LORES    Oliversen and Garhardt (1987).
swphi.abs     SWP, LAP, HIRES    Bohlin &amp; Holm (1980) and Cassatella,
                                 Ponz &amp; Selvelli (1981).
swplo.abs     SWP, LAP, LORES    Bohlin &amp; Holm (1980).
swplo2.abs    SWP, LAP, LORES    Bohlin (1986), Bohlin &amp; Grillmair (1988).
swplo3.abs    SWP, LAP, LORES    <I>Not yet installed.</I>
</PRE>
\end{rawhtml}
\end{htmlonly}

The format of these files will not (at this time) be described; however, if the
need arises to provide different or additional calibrations, then this can be
done.


\subsection{Other Changes that affect the Absolute Calibration}

The exposure time is the quantity having the most direct effect on the
absolute calibration.  This is specified by the
\xref{\verb+EXPOSURES+}{sg3}{EXPOSURES} parameter
when the dataset is read using \xref{\verb+READIUE+}{sg3}{READIUE}\@.

IUE exposure times are nominally in integral numbers of seconds.  However,
due to a quantisation effect in the shutter mechanism the effective exposure
times are slightly less than their nominal values.  The following relation
exists:

\begin{latexonly}
\begin{displaymath}
    {\rm effective} = INT({\rm nominal} / 0.4096) \times 0.4096
\end{displaymath}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<CENTER>
\end{rawhtml}
effective = {\it INT} (nominal / 0.4096 ) $\times$ 0.4096
\begin{rawhtml}
</CENTER>
\end{rawhtml}
\end{htmlonly}

where the nominal and effective exposures are measured in seconds, and
the {\it INT} function gives the truncated integer value.  This modification
of exposure time is only going to be significant for values less than about 1
minute.  For very short exposures, other corrections to the nominal exposure
time will be needed.

The exposure time for a particular aperture can be changed by, for example:

\begin{verbatim}
   > SETA APERTURE=LAP EXPOSURE=4.096
\end{verbatim}

Another factor affecting absolute calibration is the reduction in
transmission caused by the small aperture.  There is typically a
reduction of 50\%\ in the SAP transmission relative to LAP; however,
this figure is not very stable, being affected by target positioning and
telescope focus.  If both SAP and LAP spectra are available then the SAP
fluxes can be scaled empirically until they agree with LAP\@.  This might be
done by, for example:

\begin{verbatim}
   > PLFLUX APERTURE=LAP RS=YES
   > PLFLUX APERTURE=SAP RS=NO
   > SETA FSCALE=2.0
   > PLFLUX
   > SETA FSCALE=1.8
   > PLFLUX
   > SET RS=YES
\end{verbatim}

This involves plotting the LAP spectrum, and then plotting SAP on top.  By
varying the \xref{\verb+FSCALE+}{sg3}{FSCALE}
 parameter, the two spectra can be made to have the
same absolute level.  Normally this can be done using visual estimates of best
fit.

Another factor affecting the absolute calibration is
\xref{\verb+THDA+}{sg3}{THDA}\@.  If the
\verb+THDA+ value was given wrongly when using
\xref{\verb+READIUE+}{sg3}{READIUE}, then it can
later be changed by, for example:

\begin{verbatim}
   > SETD THDA=7.2
\end{verbatim}

The effects of \verb+THDA+ on absolute calibration are normally quite small (or
unknown in the case of LWP)\@.  So it is not too tragic if \verb+THDA+ is not
known.

The accuracy of the wavelength scale can have a significant effect on the
absolute calibration is regions where it has a strong gradient.  This is
particularly so for the ends of the wavelength range, where the
spectrograph/camera sensitivity drops rapidly.

Sometimes, especially when there are no measurable features with known
wavelength, the wavelength scale can be adjusted by getting the ends of the
spectrum to behave sensibly.  However, this is only valid if you know what
shape the spectrum should be.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{map}\label{se:map}SPECTRUM AVERAGING USING {\tt MAP}}
\markboth{Spectrum Averaging}{\stardocname}

\xref{\verb+MAP+}{sg3}{MAP}
 is a command that allows the spectra extracted from a particular
image to be combined.  This is done by creating an evenly spaced wavelength
grid and then mapping the individual spectra onto it using linear interpolation.

In the case of HIRES, \verb+MAP+ can be used to combine the individual
\'{E}chelle order spectra into a single (hopefully continuous) spectrum suitable
for further analysis.

In the case of LORES, \verb+MAP+ can be used to average the spectra from SAP and
LAP\@.

In either case, \verb+MAP+ can be used as a means of resampling the spectrum
onto different grids than were used during spectrum extraction.


\subsection{Some general aspects of the {\tt MAP} command}

The wavelength grid is specified by the \xref{\verb+ML+}{sg3}{ML}
 and \xref{\verb+MSAMP+}{sg3}{MSAMP}
 parameters.
\verb+ML+ has two values giving the start and end wavelengths in the grid.
The \verb+MSAMP+ parameter specifies the wavelength spacing in the grid.
Sensibly \verb+MSAMP+ should divide an integral number of times into the
wavelength range defined by \verb+ML+; however, if it does not, then the upper
wavelength limit is modified appropriately.  An example of usage is:

\begin{verbatim}
   > MAP ML=[1150,1950] MSAMP=1.0
\end{verbatim}

which specifies a grid from 1150 to 1950\AA , with a spacing of 1\AA\@.
\xref{\verb+MAP+}{sg3}{MAP}
 will provide defaults for these parameters based on the
characteristics of the \xref{\verb+DATASET+}{sg3}{DATASET}; how this is done
is different for the
LORES and HIRES cases and explanation will be delayed until later.  However, you
should be aware that \verb+MAP+ will take these defaults without a word if
\xref{\verb+MSAMP+}{sg3}{MSAMP} and \xref{\verb+ML+}{sg3}{ML}
 are otherwise undefined.  You can see and change
the default/current values using the parameter prompt mechanism.

The normal way of running \xref{\verb+MAP+}{sg3}{MAP}
 is to produce a new mean spectrum with each
invocation of the command.  However, this is controlled by the
\xref{\verb+RM+}{sg3}{RM} parameter.  This operates in much the same was as
the \xref{\verb+RS+}{sg3}{RS} parameter does
when plotting: When \verb+RM=YES+ then the mean spectrum is created from new;
but when \verb+RM=NO+ the command combines the spectrum with any existing mean
spectrum.  For example:

\begin{verbatim}
   > MAP APERTURE=SAP RM=YES ML=[1150,1950] MSAMP=1
   > MAP APERTURE=LAP RM=NO
   > SET RM=YES
\end{verbatim}

will average both apertures of a LORES spectrum.  Setting \verb+RM=YES+
afterwards is a safety measure to avoid confusion later on.  Note also that it
is not necessary (or meaningful) to specify \xref{\verb+ML+}{sg3}{ML}
 or \xref{\verb+MSAMP+}{sg3}{MSAMP}
 the
second time \xref{\verb+MAP+}{sg3}{MAP}
 is run in this example, since the wavelength grid is
taken from the first run.

When more than one spectrum is mapped onto the grid, they are combined by
forming a weighted average.  The averaging weights are defined as:

\begin{latexonly}
\begin{displaymath}
   {\rm WEIGHT} = ({\rm uncalibrated\; flux}) / ({\rm calibrated\; flux})
\end{displaymath}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<CENTER>
WEIGHT = (uncalibrated flux) / (calibrated flux)
</CENTER>
\end{rawhtml}
\end{htmlonly}

This is designed so that in overlapping wavelength regions, the weight is
proportional to the FN of the original spectrum.  In the case of adjacent
\'{E}chelle orders which overlap in wavelength, it makes the transition from one
order to the next a smooth process.  The final parameters to be described
are \xref{\verb+FILLGAP+}{sg3}{FILLGAP} and
\xref{\verb+COVERGAP+}{sg3}{COVERGAP}\@.  \verb+FILLGAP+ has the same meaning
for LORES and HIRES\@.  Consider the following schematic input and output
spectra:

\begin{verbatim}
   Index    (1)   (2)   (3)   (4)   (5)   (6)   (7)   (8)

   INPUT     G-----G-----G-----U-----U-----G-----G-----G

   OUTPUT       G-----G-----P-----U-----P-----G-----G

   Index       (a)   (b)   (c)   (d)   (e)   (f)   (g)
\end{verbatim}

The two spectra are on grids with the same spacing, but are offset (in this
case by half a step size)\@.  The symbols \verb+G+, \verb+U+ and \verb+P+
represent the quality of the intensity values; \verb+G+ means `good', \verb+U+
means `undefined' and \verb+P+ means `partial'\@.

The first case to consider is that of point (a), the intensity of which is
formed by folding the (1) and (2) intensities with a triangle function of FWHM
(in this case) corresponding to the maximum distance of (b) to (a) or (2) to
(1).  Since (1) and (2) are both `good', so is (a)\@.

The second case is that of point (c) the intensity of which is formed by
folding (3) and (4)\@.  However, (4) is `undefined', and so it's intensity does
not get used.  Hence the interpolated value for (c) is incomplete.

The third case is that of point (d) which would have been formed from (4)
and (5) but both of these are `undefined', and so then is (d)\@.

The first and third cases shown here are fairly unambiguous.  However, in
the second case, it is not certain whether we should use the `partial' points
(denoted (c) and (e) in the above example)\@.  Since partial points are formed
from less input points, they will have different error values, and also their
effective wavelengths will not correspond to the output grid.  The
importance of this is perhaps clearer when we consider that (say) up to 5 input
intensities may be folded to produce each output intensity.  In this case,
the `partial' points may display noise characteristics as bad as the input
spectrum, whereas the `good' points will display reduced noise.

The \xref{\verb+FILLGAP+}{sg3}{FILLGAP} parameter determines whether these
partial output points are
to be given intensity values; \verb+FILLGAP=YES+ means that they are assigned
values, and \verb+FILLGAP=NO+ means that they are not.  \verb+FILLGAP=NO+ (the
initial default) tends to expand the size of spectrum gaps (caused by
fiducials, saturation, {\it etc.}),\ but will provide more reliable results.

The \xref{\verb+COVERGAP+}{sg3}{COVERGAP}
 parameter is aimed at providing a similar function to
\verb+FILLGAP+, but operating at a higher level.  Consider this schematic
representation of two \'{E}chelle order spectra which overlap:

\begin{verbatim}
   Order 89 -------------------------    ---------
   Order 88                        --------------------------
\end{verbatim}

Let us assume that the gap in order 89 survives the mapping process
({\it{e.g.,}} \verb+FILLGAP=NO+)\@.  Then \verb+COVERGAP+ determines whether
this gap can be filled by the spectrum of order 88 which overlaps it.  If
\verb+COVERGAP=YES+ then the gap is covered, otherwise it is not.

It may be argued that an important role of overlapping spectra is to fill in
gaps.  But consider the example above: the gap in order 89 may be where the
signal-to-noise is very high, yet the corresponding region of order 88
(which would cover it) may be very noisy.  This would lead to a narrow, noisy
region in the final average spectrum.  Worse still, consider the case
where the calibration of order 88 in this gap region is in error by (say)
10\%\@.  This would lead to a feature in the average spectrum (either
emission or absorption) which would be totally anomalous.

The \xref{\verb+FILLGAP+}{sg3}{FILLGAP}
 and \xref{\verb+COVERGAP+}{sg3}{COVERGAP}
 parameters are not unnecessary frills.
The problems outlined above do produce real artifacts in mean spectra.  These
parameters allow you to assess the trade-off between a reliable spectrum and a
complete one (with possible defects)\@.

The current mean spectrum is stored in a file with name ending in
\verb+_UEM.sdf+ and name corresponding to the dataset.
Thus a mean spectrum created in one IUEDR session is available in later
sessions automatically.

One point to remember is that there is only ever one current mean spectrum.  If
you create a new mean, then the previous one (if any) is replaced.


\subsection{Using {\tt MAP} for LORES}

In the case of LORES, the \xref{\verb+MAP+}{sg3}{MAP}
 command only maps the spectrum from a
single aperture onto the specified wavelength grid.  If either of the
\xref{\verb+ML+}{sg3}{ML} or \xref{\verb+MSAMP+}{sg3}{MSAMP}
 parameters are undefined, then values are taken from the
original spectrum grid.  If both \verb+ML+ and \verb+MSAMP+ take on default
values, then the mapped spectrum is identical to the original.

The primary use of \verb+MAP+ for LORES spectra is in forming an average of
the two apertures (SAP and LAP) when both are exposed to the same object. This
can lead to a spectrum with improved signal-to-noise.

When averaging SAP and LAP, it is important that their wavelength scales are
consistent (even if they contain constant errors).  Otherwise, the average
spectrum will suffer reduced resolution.

It is also important to get the SAP flux level to correspond to that of LAP\@.
The LAP fluxes should be on an absolute scale; however, since the IUE small
aperture only admits part of the object signal, an arbitrary scale factor
needs to be applied (see the \xref{\verb+FSCALE+}{sg3}{FSCALE}
 parameter in \xref{\verb+SETA+}{sg3}{SETA})\@.

Given that the spectra from the two apertures are indeed similar (and hence
justify being averaged), then the following commands could be used:

\begin{verbatim}
   > MAP APERTURE=LAP RM=YES COVERGAP=YES
   > MAP APERTURE=SAP RM=NO COVERGAP=YES
   > SET RM=YES
\end{verbatim}

Since the spectra are similar, it is probably valid to fill gaps in one
spectrum using the other.

A further us of \xref{\verb+MAP+}{sg3}{MAP}
 for LORES is where the spectrum of (say) a single
aperture is needed on a different grid to that used during spectrum
extraction.


\subsection{Using {\tt MAP} for HIRES}

The primary use of \xref{\verb+MAP+}{sg3}{MAP}
 for HIRES is undoubtedly that of combining the
spectra from individual \'{E}chelle orders so that they produce a single
(possibly) uninterrupted spectrum.  A single spectrum is much easier to handle
than a whole set of them (whether in IUEDR or some other programme)\@.

\xref{\verb+MAP+}{sg3}{MAP}
 could be run in the same way as described for LORES, adding in a
separate \'{E}chelle order with each command invocation.  However, this would be
very tedious.  Therefore, for HIRES, \verb+MAP+ has an additional parameter,
\xref{\verb+ORDERS+}{sg3}{ORDERS}, which specifies a range of
\'{E}chelle orders to be combined. For example:

\begin{verbatim}
   > MAP ORDERS=[125,65] ML=[1100,2125] MSAMP=0.1
\end{verbatim}

would map all orders in the range 125 to 65 onto the grid specified by
\xref{\verb+ML+}{sg3}{ML} and \xref{\verb+MSAMP+}{sg3}{MSAMP}\@.
If \verb+MSAMP+ is undefined, then it takes a
default based on the smallest wavelength spacing of the orders to be used.
\verb+MSAMP+ does, however, become defined after the first use of
\xref{\verb+MAP+}{sg3}{MAP}, so that this default is not always automatic.

It does not matter if some of the orders in the range specified by
\xref{\verb+ORDERS+}{sg3}{ORDERS} do not exist; it is only a guide, and
means that orders outside that range cannot be used.  Also, perhaps
obvious, orders that do not overlap the wavelength grid are not used, so
there is no inefficiency in (say):

\begin{verbatim}
   > MAP ORDERS=[65,125] ML=[1525,1575] MSAMP=0.1
\end{verbatim}

even though only orders 88 to 90 contribute.

The first example above would take a long time to perform, and would
probably produce a final result which could be output to another programme
for analysis.  The second example shows how small sections of spectrum
can be produced, perhaps while looking at specific features or groups of
features.

By repeated use of \xref{\verb+MAP+}{sg3}{MAP}
 it is possible to construct mean spectra with very
accurately defined inputs.  For example:

\begin{verbatim}
   > MAP RM=YES ML=[1150,1350] MSAMP=0.1 ORDERS=[120,114]
   > MAP RM=NO ORDERS=[112,101]
   > SET RM=YES
\end{verbatim}

will produce a mean spectrum from which order 113 is omitted.  The cases
where this is useful are not clear, but the capability is there if you want it.


\subsection{Display and Editing of the Mean Spectrum}

This can be done with the \xref{\verb+PLMEAN+}{sg3}{PLMEAN}
 command.  \verb+PLMEAN+ operates much
like all the other plotting commands (\xref{\verb+PLFLUX+}{sg3}{PLFLUX},
\xref{\verb+PLNET+}{sg3}{PLNET}, {\it etc.})\@.

Once the mean spectrum is plotted, then it can be edited using the
\xref{\verb+EDMEAN+}{sg3}{EDMEAN} command.  \verb+EDMEAN+ works identically to
\xref{\verb+EDSPEC+}{sg3}{EDSPEC} (to be described below), except that it
operates on the mean spectrum.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{spectrum_editing}\label{se:spec_edit}SPECTRUM \& IMAGE
         EDITING}
\markboth{Spectrum Editing}{\stardocname}

During the spectrum extraction process ({\it{e.g.,}} the
\xref{\verb+TRAK+}{sg3}{TRAK} command)
some points in the spectrum will contain contributions from bad pixels.  These
pixels may be bad for a number of reasons ({\it{e.g.,}} affected by fiducial or
saturation, {\it etc.})\@.

In spectrum extraction algorithms like \xref{\verb+TRAK+}{sg3}{TRAK}, the
spectrum intensity is
an integral, so not using these `bad' pixels leaves the integral incomplete and
hence meaningless.  Therefore `bad' pixels are used (provided that they
actually have some kind of intensity value), but the data quality for such
affected spectrum points are marked so that this is known.

It may be that the effect of bad pixels is minimal; or it may be that any
spectrum (within reason) is better than nothing at all.

Also consider this: there may be parts of the image which have erroneous
intensity values, the effect of which becomes visible only after spectrum
extraction.  An example is that of a particle spike on the image.  We
might go back to the image and mark the offending region as bad (one day,
soon), or alternatively we can mark the region of spectrum as bad.

So there are two kinds of ways in which we want to affect the data quality
of points in the spectrum.  This process is called `Spectrum Editing'\@.
Despite the name, it should be pointed out that in no case is it allowed to
change the values of spectrum intensities - this would be a very dubious
exercise.  All that is allowed is to make points appear and disappear.

There are two kinds of spectrum that can be edited:

\begin{enumerate}

\item The individual spectra produced by \xref{\verb+TRAK+}{sg3}{TRAK}:
      individual apertures
      (LORES) or \'{E}chelle orders (HIRES)\@.  This is done with the
      \xref{\verb+EDSPEC+}{sg3}{EDSPEC} command.


\item The mean spectrum produced by \xref{\verb+MAP+}{sg3}{MAP}\@.
      This is done with the \xref{\verb+EDMEAN+}{sg3}{EDMEAN} command.

\end{enumerate}

\xref{\verb+EDSPEC+}{sg3}{EDSPEC} and \xref{\verb+EDMEAN+}{sg3}{EDMEAN}
operate in much the same way, but some separate description is required at
the outset.


\subsection{Spectrum Editing using {\tt EDSPEC}}

In order to use \xref{\verb+EDSPEC+}{sg3}{EDSPEC}, first the spectrum must
be plotted on a device
which has a graphics cursor; either the \xref{\verb+PLNET+}{sg3}{PLNET}
 or \xref{\verb+PLFLUX+}{sg3}{PLFLUX} commands can be used.
\verb+PLNET+ is preferable in some respects since it always
shows points marked bad during spectrum extraction as special symbols, even if
they are marked good again by \verb+EDSPEC+\@.

The spectrum plotted by \xref{\verb+PLNET+}{sg3}{PLNET} or
\xref{\verb+PLFLUX+}{sg3}{PLFLUX} and subsequently edited by
\xref{\verb+EDSPEC+}{sg3}{EDSPEC} is specified by the
\xref{\verb+DATASET+}{sg3}{DATASET}, \xref{\verb+APERTURE+}{sg3}{APERTURE}
 (LORES only) and \xref{\verb+ORDER+}{sg3}{ORDER}
 (HIRES only) parameters.  Here is a LORES example:

\begin{verbatim}
   > PLNET APERTURE=LAP
   > EDSPEC
\end{verbatim}

where \xref{\verb+DATASET+}{sg3}{DATASET} is assumed specified.  In most
cases it would not be necessary to specify
\xref{\verb+APERTURE+}{sg3}{APERTURE}\@.  Here is a HIRES example:

\begin{verbatim}
   > PLNET ORDER=89
   > EDSPEC
\end{verbatim}

When \xref{\verb+EDSPEC+}{sg3}{EDSPEC} is run, all subsequent interactions
are done using the graphics cursor (more on that later)\@.

In the HIRES case, some care is needed.  You should not try to edit from a
plot containing several \'{E}chelle orders superposed.  This is because you
may be marking points in one order, while looking at another.


\subsection{Spectrum Editing using {\tt EDMEAN}}

Since there is only one mean spectrum, all that is needed is:

\begin{verbatim}
   > PLMEAN
   > EDMEAN
\end{verbatim}

With all subsequent interaction done using the graphics cursor (as for
\xref{\verb+EDSPEC+}{sg3}{EDSPEC}, and described next)\@.


\subsection{Cursor-driven Spectrum Editing using the {\tt EDMEAN} and
{\tt EDSPEC} Commands}

Although \xref{\verb+EDSPEC+}{sg3}{EDSPEC} and
\xref{\verb+EDMEAN+}{sg3}{EDMEAN} operate on different kinds of spectra,
their actual operation is essentially identical.

The following cursor hit sequences can be used in a cycle:

\begin{latexonly}
\begin{tabular}{ll}
Hit Key(s) &  Action\\
1 then 1   &  marks all points in the x-range GOOD\\
2 then 2   &  marks all points in the x-range BAD\\
1          &  marks the nearest point (in x-direction) GOOD\\
2          &  marks the nearest point (in x-direction) BAD\\
3          &  causes the cursor cycle to terminate\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>Hit Key(s)   Action</B>
1 then 1     marks all points in the x-range GOOD
2 then 2     marks all points in the x-range BAD
   1         marks the nearest point (in x-direction) GOOD
   2         marks the nearest point (in x-direction) BAD
   3         causes the cursor cycle to terminate
</PRE>
\end{rawhtml}
\end{htmlonly}

Mouse buttons can be used for cursor hits where:

\begin{latexonly}
\begin{tabular}{ll}
Mouse button    & Keyboard key\\
left button     & 1\\
middle button   & 2\\
right button    & 3\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>Mouse button      Keyboard key</B>
left button            1
middle button          2
right button           3
</PRE>
\end{rawhtml}
\end{htmlonly}

The points or ranges of points that have their data quality changed in this way
are printed on the terminal.

When the cursor cycle is terminated (the \verb+3+ hit key), if the data quality
has changed then the change is made to the copy of the array in the programme.

To see the effect of the edits, the spectrum should be re-plotted with the
\xref{\verb+PLNET+}{sg3}{PLNET}, \xref{\verb+PLFLUX+}{sg3}{PLFLUX}
or \xref{\verb+PLMEAN+}{sg3}{PLMEAN} command (as appropriate)\@.

If the data quality changes, then this leads to the file containing it
to be marked as requiring a new version.


\subsection{Editing Images}

The \xref{\verb+EDIMAGE+}{sg3}{EDIMAGE} command allows the data quality of
an image displayed with the \verb+DRIMAGE+ command to be edited using
the cursor.  The edits affect the user-setable data quality bit
associated with each pixel in the image.  To invoke \verb+EDIMAGE+ type:

\begin{verbatim}
   > EDIMAGE
\end{verbatim}

\verb+EDIMAGE+ uses the cursor in a similar way to the
\xref{\verb+EDSPEC+}{sg3}{EDSPEC} and
\verb+EDMEAN+ commands except that both the x- and y-coordinates of
pixels/regions are defined.

The data quality for a pixel consists a series of switches indicating
whether it is affected by various phenomena:

\begin{itemize}

\item ITF Extrapolation.

\item ITF Truncation.

\item ITF Saturation.

\item Proximity of fiducial (reseau mark)\@.

\end{itemize}

These switches cannot be changed; however, there is an additional
user-setable  switch for each pixel.  Any pixels affected by the above
phenomena (except ITF extrapolation) have the user-switch set {\bf BAD}\@.
Additional pixels/regions can be set BAD (or GOOD) using the
\xref{\verb+EDIMAGE+}{sg3}{EDIMAGE} command.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{tabulation}\label{se:tabular}TABULATION OF SPECTRA}
\markboth{Tabulation of Spectra}{\stardocname}

A number commands are available which allow various kinds of data to be output
in tabular form.

The outputs are intended for `visual' examination, and their format cannot be
guaranteed to remain the same; therefore, they should not be read into
programmes!


\subsection{{\tt PRSCAN} Tabulate a Cross-dispersion Scan}

This command can be used to print a table containing the intensities in the
current scan (as produced by the \xref{\verb+SCAN+}{sg3}{SCAN} command).
For example:

\begin{verbatim}
   > SCAN
   > PRSCAN
\end{verbatim}


\subsection{{\tt PRGRS} Tabulate Extraction Results}

This command can be used to output detailed information (gross, net, smooth
background, calibrated flux) available following spectrum extraction with the
\xref{\verb+TRAK+}{sg3}{TRAK} command.  For example:

\begin{verbatim}
   > TRAK
   > PRGRS
\end{verbatim}


\subsection{{\tt PRSPEC} Tabulate Net and Calibrated Flux Spectra}

This command prints out the net and calibrated fluxes for a spectrum (LORES
aperture or HIRES order), as in:

\begin{verbatim}
   > PRSPEC DATASET=SWP3196 APERTURE=LAP
\end{verbatim}

or

\begin{verbatim}
   > PRSPEC DATASET=SWP6766 ORDER=89
\end{verbatim}

which prints a table consisting of Wavelength, Net and Calibrated Fluxes,
along with any data quality information.


\subsection{{\tt PRMEAN} Tabulate Mean Spectra}

This command can be used to tabulate the mean spectrum, as in:

\begin{verbatim}
   > PRMEAN
\end{verbatim}

It is important to realise, when using this command that some mean spectra may
involve 20000 points, and that this would lead to over 20000 lines of output!


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{spectrum_output}\label{se:spec_output}OUTPUT OF SPECTRA TO
         OTHER PROGRAMMES}
\markboth{Output of Spectra to other Programmes}{\stardocname}

IUEDR stops short of providing a total facility for IUE data reduction and
analysis.  In particular, things like spectral arithmetic, continuum and
profile fitting, and `Astronomical' measurement functions are not
provided.

However, these functions are available by using other programmes on Starlink,
for example, \xref{DIPSO}{sun50}{}\@.
This  is a very versatile programme that allows the manipulation, display and
measurement of spectra.  It would be out of place to give a thorough
description of DIPSO here.  However, if you are dealing with calibrated 1-D
spectra from almost any source (IUE, IPCS, Model Atmospheres, {\it etc.})
then you will probably find it very useful.

It is the purpose of this Section to show how to create various kinds of
files that are suitable for input to the Spectrum Analysis programmes
available on Starlink.


\subsection{Spectrum Output Commands}

IUEDR provides a family of similar commands which produce Starlink NDF files
(Extensible N-Dimen\-sional Data Format, described in
\xref{SUN/33}{sun33}{})\@.  These files
can be accessed by most Starlink software ({\it{e.g.,}} \xref{DIPSO}{sun50}{},
\xref{FIGARO}{sun86}{},
\xref{KAPPA}{sun95}{})\@.
In addition, the Starlink file-format conversion package CONVERT (See
\xref{SUN/55}{sun55}{}),
can be used to translate NDFs to several other file formats.

The commands provided are as follows:

\begin{description}

\item [{\bf Output of Mean Spectra:} {\tt OUTMEAN}]
      This stores the current mean spectrum in an NDF\@.

\item [{\bf Output of uncalibrated Net Spectra:} {\tt OUTNET}]
      The current net spectrum is output.
      All of the calibrations concerned with intensity are omitted.
      \xref{\verb+OUTNET+}{sg3}{OUTNET} should be helpful for
      cases where calibrations will be handled independently.

\item [{\bf Output of Single order or aperture Spectra:} {\tt OUTSPEC}]
      The spectrum
      associated with the current \xref{\verb+APERTURE+}{sg3}{APERTURE}
      (LORES) or \xref{\verb+ORDER+}{sg3}{ORDER} (HIRES) is output to an
      NDF\@.

\item [{\bf Output of Scan data:} {\tt OUTSCAN}]
      The data produced by a \xref{\verb+SCAN+}{sg3}{SCAN} command can be
      output to an NDF\@.  A scan profile is quite
      spectrum-like and so these data can easily be read by other packages for
      visualisation purposes {\it etc.}  It should be pointed out that in a
      scan, the ordinate ($x$-axis) can include negative values, and that such
      `spectra' may not be handled sensibly in some programmes.

\end{description}

The above commands can also be used to produce
\htmlref{SPECTRUM}{subap:spectrum} format files
which can be read by \xref{DIPSO}{sun50}{}\@.  The type of output file is
selected by the \xref{\verb+SPECTYPE+}{sg3}{SPECTYPE} parameter for example:

\begin{verbatim}
   > OUTMEAN SPECTYPE=0
\end{verbatim}

Will produce an NDF file of the current mean spectrum for
\xref{\verb+DATASET+}{sg3}{DATASET}\@.
If \verb+DATASET+ is undefined ({\it{e.g.,}} you have just started the IUEDR
session) then it will be prompted for.  \xref{\verb+SPECTYPE+}{sg3}{SPECTYPE}
can be specified for any of the \xref{\verb+OUTMEAN+}{sg3}{OUTMEAN},
\xref{\verb+OUTSPEC+}{sg3}{OUTSPEC}, \xref{\verb+OUTNET+}{sg3}{OUTNET}
and \xref{\verb+OUTSCAN+}{sg3}{OUTSCAN} commands.

The possible values of \verb+SPECTYPE+ are:

\begin{latexonly}
\begin{tabular}{ll}
{\tt SPECTYPE} & Output format\\
0              & Starlink NDF\\
1              & SPECTRUM type 1 `SP1'\\
2              & SPECTRUM type 2 `SP2'\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>SPECTYPE    Output format</B>
   0        Starlink NDF
   1        SPECTRUM type 1 `SP1'
   2        SPECTRUM type 2 `SP2'
</PRE>
\end{rawhtml}
\end{htmlonly}

These file formats are described in Appendix~\ref{ap:output},
where the NDF components used by IUEDR are described and the
contents of SPECTRUM format files explained.

\subsubsection{Creating LORES Output Files}

The spectrum for a particular LORES aperture can be output to a file using, for
example:

\begin{verbatim}
   > OUTSPEC APERTURE=SAP
\end{verbatim}

or

\begin{verbatim}
   > OUTNET APERTURE=SAP
\end{verbatim}

The \xref{\verb+APERTURE+}{sg3}{APERTURE} parameter may not need to be
specified if it has the right
value, or if there is only one aperture.  The name of the file created is
specified by the \xref{\verb+OUTFILE+}{sg3}{OUTFILE} parameter, for which a
default value is
constructed from the Camera, Image and Aperture; the file extension defaults to
\verb+.DAT+ in the case of \htmlref{SPECTRUM}{subap:spectrum} files and
\verb+.sdf+ for NDFs.  If this
default file name is not appropriate, then you can force prompt on the
\verb+OUTFILE+ parameter, and change its value to correspond to the required
name.

\xref{\verb+OUTSPEC+}{sg3}{OUTSPEC} and \xref{\verb+OUTNET+}{sg3}{OUTNET}
 will always tell you the name of the file just written.

\subsubsection{Creating HIRES Output Files}

For HIRES, the \verb+OUTSPEC+ command creates a file containing the spectrum
of a single \'{E}chelle order.  For example:

\begin{verbatim}
   > OUTSPEC ORDER=89
\end{verbatim}

or

\begin{verbatim}
   > OUTNET ORDER=89
\end{verbatim}

will create a file containing \'{E}chelle order 89.  As for LORES, the name of
the file created is specified by the \xref{\verb+OUTFILE+}{sg3}{OUTFILE}
 parameter, for which a default is constructed from Camera, Image and Order.
For \htmlref{SPECTRUM}{subap:spectrum} format
output the default file extension is constructed from the order number (in the
example above it would be \verb+.89+)\@.  When \verb+SPECTYPE=0+ the file
is given a name constructed as

\begin{verbatim}
   <CAMERA><IMAGE>_<ORDER>.sdf
\end{verbatim}

For example

\begin{verbatim}
   SWP14931_89.sdf
\end{verbatim}

In the above case.

\xref{\verb+OUTSPEC+}{sg3}{OUTSPEC}
 will find only limited application for HIRES, but it is there
if you want it.

\subsubsection{Creating Mean Spectrum SPECTRUM Files}

The mean spectrum in IUEDR can be output to a file, using the
\xref{\verb+OUTMEAN+}{sg3}{OUTMEAN}
command.  For example:

\begin{verbatim}
   > OUTMEAN
\end{verbatim}

The file name is specified by the \xref{\verb+OUTFILE+}{sg3}{OUTFILE}
parameter, for which a default is constructed using the Camera and Image
values.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{auto_hires}\label{se:auto_hires}AUTOMATED HIRES DATA
         REDUCTION}
\markboth{Automated HIRES Data Reduction}{\stardocname}

Two commands to automate the reduction of HIRES data are available.  These
commands, \xref{\verb+AGSHIFT+}{sg3}{AGSHIFT} and
\xref{\verb+AESHIFT+}{sg3}{AESHIFT} use simple iterative procedures to
achieve the effects of \xref{\verb+CGSHIFT+}{sg3}{CGSHIFT} and
\xref{\verb+SETA ESHIFT+}{sg3}{ESHIFT} respectively.

\subsection{AGSHIFT: Automated GSHIFT Measurement}

Before using \xref{\verb+AGSHIFT+}{sg3}{AGSHIFT}
 a section across the echellogramme must first be
made available using the SCAN command.  \verb+AGSHIFT+ should normally be
used with the same values for the \xref{\verb+DATASET+}{sg3}{DATASET}
 and \xref{\verb+ORDERS+}{sg3}{ORDERS} parameters as the  preceding
\xref{\verb+SCAN+}{sg3}{SCAN} command.

The following sequence of \xref{\verb+SCAN+}{sg3}{SCAN} and \verb+AGSHIFT+
commands will nearly  always produce a suitable
\xref{\verb+GSHIFT+}{sg3}{GSHIFT} value.

Normally when you have several images which are of similar type objects you
should be able to display one \xref{\verb+SCAN+}{sg3}{SCAN}
 across all the orders and inspect
the plot for a suitably distinct order near the long-wavelength (low order
numbered) end of the plot, say number 66, which will be present in the
spectra of all the objects.

The automated script should consist of:

\begin{itemize}

\item A \xref{\verb+SCAN+}{sg3}{SCAN} of {\bf just} order 66 followed by
      two \xref{\verb+AGSHIFT+}{sg3}{AGSHIFT}s of
      {\bf just} the single order.  This procedure gives a good starting
      estimate for the \xref{\verb+GSHIFT+}{sg3}{GSHIFT} value.

\item The next step is to re-\verb+SCAN+ the whole spectrum and \verb+AGSHIFT+
    {\bf twice.} This process produces a mean \verb+GSHIFT+ for all the orders
    in the spectrum.
    A rejection filter is employed to remove spurious values which might occur
    if some orders are not present in the \verb+SCAN+\@.  In addition a small
    extra
    weight is given to the \verb+GSHIFT+ values measured for orders 100 to 110
    as
    these high order number (short wavelength) orders are closely spaced and
    hence using the correct \verb+GSHIFT+ is most critical at this area of the
    spectrum---if an erroneous value is used the extraction algorithm may miss
    the order or get the wrong order.

\item In many cases the value of \verb+GSHIFT+ after four \verb+AGSHIFT+s
    should be fine, if
    it is felt necessary an additional \verb+SCAN+ and double-\verb+AGSHIFT+
    pass can be applied to the critical orders 100 to 110.  A look at some
    IUEDR log files
    shows that the sixth \verb+AGSHIFT+ invariably leads to no change in the
    \verb+GSHIFT+ value---the best fit has already been found.

\end{itemize}

In summary the procedure is:

\begin{verbatim}
SETA GSHIFT=[0,0]
SCAN ORDERS=[66,66]
AGSHIFT
AGSHIFT
SCAN ORDERS=[125,66]
AGSHIFT
AGSHIFT
SCAN ORDERS=[110,100]
AGSHIFT
AGSHIFT
\end{verbatim}

If you are working interactively it's going to be quicker to do a single
\xref{\verb+CGSHIFT+}{sg3}{CGSHIFT}
 than work through this process.  For multiple script-driven
reductions this procedure has proved quite robust in tests.  The initial
single-order \xref{\verb+SCAN+}{sg3}{SCAN}
 is often essential to get a reasonable starting value
for \xref{\verb+GSHIFT+}{sg3}{GSHIFT}.

\subsection{AESHIFT: Automated ESHIFT Measurement}

When working interactively, several features of known wavelength are
identified in the individual, unmerged order spectra.  The observed wavelengths
of these features are measured using a combination of
\xref{\verb+PLNET+}{sg3}{PLNET} and \xref{\verb+CURSOR+}{sg3}{CURSOR}
commands.  The user then makes an estimate of the
\xref{\verb+ESHIFT+}{sg3}{ESHIFT}
 value based on the measured differences between observed
and laboratory wavelengths of the features.  A simple
\xref{\verb+SETA+}{sg3}{SETA} sets the shift for the dataset.
To achieve this effect in automated scripts the \verb+AESHIFT+ command is
used.

The first step is to select several suitable absorption features across the
spectra of your target objects.  Ideally these should be as distinct as
possible and not too close together---a gap of 1 Angstrom should be OK\@.
Choose features in orders spread across the whole echellogramme if possible.

Once you have used \xref{\verb+TRAK+}{sg3}{TRAK} to extract the orders you
can apply \xref{\verb+AESHIFT+}{sg3}{AESHIFT} to estimate and set the
\xref{\verb+ESHIFT+}{sg3}{ESHIFT} parameter:

\begin{verbatim}
AESHIFT CENTREWAVE=[1190.4518,1250.584,1253.811,1304.3702,1526.7066,1608.4511]\
        DELTAWAVE=1
\end{verbatim}

Note that at the moment there is no way to split a command line to IUEDR!

The above command has been applied successfully to O type stars.

\xref{\verb+AESHIFT+}{sg3}{AESHIFT}
 looks for the selected lines and measures the observed
wavelength of each.  The median \xref{\verb+ESHIFT+}{sg3}{ESHIFT}
 for all the lines given is then
applied to the dataset.

\subsection{Bringing It All Together}

Here's a complete template reduction procedure used for SWP HIRES images of
O type stars:

\begin{verbatim}
SETA GSHIFT=[0,0] ESHIFT=0
SETD HALC=0.12
SCAN ORDERS=[66,66]
AGSHIFT
AGSHIFT
SCAN ORDERS=[125,66]
AGSHIFT
AGSHIFT
SCAN ORDERS=[110,100]
AGSHIFT
AGSHIFT
NEWTEM TEMFILE=SWPHILAP.TEM
TRAK ORDER=125 NORDER=60 GSAMP=0.7071 CENTM=T CENSV=T
AESHIFT CENTREWAVE=[1190.4518,1250.584,1253.811,1304.3702,1526.7066,1608.4511]\
        DELTAWAVE=1
BARKER ORDERS=[125,66]
MAP ORDERS=[125,66] RM=T ML=[1100,2000] MSAMP=0.1 FILLGAP=T COVERGAP=T
SAVE
\end{verbatim}

A template for the \xref{\verb+TRAK+}{sg3}{TRAK}
task written out from IUEDR with \xref{\verb+OUTEM+}{sg3}{OUTEM}
has been used to deal with one order where the fluxes are quite small.

The following is an example C shell script which can be used with the above
data reduction template to reduce all the spectra in a directory.  The images
should be read into IUEDR with \xref{\verb+READIUE+}{sg3}{READIUE}
 in a separate pass.

\begin{verbatim}
#!/bin/csh

#+
#  Name:
#     extract.csh

#  Purpose:
#     Apply IUEDR commands from a template file to all datasets
#     in the working directory.

#  Language:
#     C shell script.

#  Description:
#     Commands from a template file are applied to each IUEDR dataset
#     found in the working directory.
#
#     Usage:
#       % extract.csh <template_file> <processed_extension>
#
#     The name of the template file can be supplied on the command line
#     or defaults to "template.cmd".
#
#     This script assumes that data reduced to mean spectra (_UEM.sdf)
#     have been processed by this script.  The "processed extension" can be
#     supplied on the command line if this is not the case.
#
#     The template file should be error checked (prototyped) on one dataset
#     prior to using this script...or you may waste a lot of CPU time!
#
#     A line of the form:
#       SET DATASET=CAMnnnnn
#
#     is pre-pended to the template prior to running IUEDR, therefore the
#     template should not set the DATASET parameter explicitly.
#
#     Datasets in the working directory are detected by the presence of
#     an IUEDR Calibration file (.UEC).
#
#     No error checking is supported by this script.

#  Authors:
#     MJC: Martin Clayton (Starlink)
#     {enter_new_authors_here}

#  History:
#     21-MAR-1995 (MJC):
#       Original Version.
#     17-APR-1995 (MJC):
#       Fixed template detection bug.
#     {enter_further_changes_here}

#  Bugs:
#     {note_any_bugs_here}

#-

#
#  Where IUEDR is installed.
set LOCAL_IUEDR = '/star/bin/iuedr';

#
#  Name of the file generated by this script.
set LOCAL_SCRIPT = 'iuedr_command.cmd';

#
#  Default template file name.
set LOCAL_TEMPLATE = 'template.cmd';

#
#  Which IUEDR datafile indicates a dataset has already been processed.
#  Probably one of _UES.sdf, _UEM.sdf.
set LOCAL_PROCESSED = '_UEM.sdf';

#.

#
#Use template name given.
if ( "$1" != "" ) then
   set LOCAL_TEMPLATE = $1;
endif

#
#Use processed rule given.
if ( "$2" != "" ) then
   set LOCAL_PROCESSED = $2;
endif

#
#Check for template command procedure.
if ( -e $LOCAL_TEMPLATE ) then

#Check that IUEDR environment has been defined.
   if ( ! ${?IUEDR_BASE} ) then
      source $LOCAL_IUEDR/iuedrsetup;
   endif

#Process each dataset in turn.
   foreach dataset ( *.UEC )

#   Don't reprocess if done already.
      if ( -e $dataset:r$LOCAL_PROCESSED ) then
         echo "!  $dataset already processed.";

      else

#      Create dataset-specific command procedure.
         echo "SET DATASET=$dataset:r" > $LOCAL_SCRIPT;
         cat $LOCAL_TEMPLATE >> $LOCAL_SCRIPT;

#      Run IUEDR.
         $IUEDR_BASE/iuedr3 < $LOCAL_SCRIPT;

#      Delete the temporary IUEDR script.
         rm -f $LOCAL_SCRIPT;
      endif
   end

else
   echo "! Error: No $LOCAL_TEMPLATE in this directory."
endif

exit ( 0 );
# End.
\end{verbatim}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{acknowledgements}\label{se:past}ACKNOWLEDGEMENTS}
\markboth{Acknowledgements}{\stardocname}

The form and content of the IUEDR programme are derived from a context that
requires some acknowledgment:

\begin{enumerate}

\item The User Interface is an implementation of a (very minimal) subset
      of that developed by Sid Wright (UCL) in connection with PROTOSTAR and the
      Starlink Environment.

\item The approach taken to graphics follows strongly from work by the
      Author on the PLT programme which was developed and used on the SERC ICF
      Prime 750 Computer at RAL\@.  In addition, a number of ideas have been
      abstracted from PROTOSTAR\@.

\item The IUE Spectrum Extraction algorithms are an extension of ideas
      developed for the STAK and TRAK programmes.

\item The approach to handling tapes has been taken directly from
      PROTOSTAR\@.

\end{enumerate}

Jack Giddings\\
Department of Physics and Astronomy,\\
University College London,\\
Gower Street,\\
London, WC1E 6BT.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{references}\label{se:refs}References}
\markboth{References}{\stardocname}

Bianchi L.\ and Bohlin R., 1982, (Unpublished Paper presented at the IUE 3 Agency
Meeting)\@.

Bohlin R.\ and Holm A.~V., 1980, NASA Newsletter, No.~10, 37--44.

Cassatella, Ponz and Selvelli, 1981, ESA IUE Newsletter, No.~10, 31--47.

Giddings J.~R., 1982, ESA IUE Newsletter, No.~12, 22-26.

Holm A.~V., 1979, NASA IUE Newsletter, No.~7.

Northover K., 1981, ESA IUE Newsletter, No.~11.

Snijders M.~A.~J., 1980, SRC IUE Newsletter, No.~5.

Thompson R.~W., Turnrose B.~E., and Bohlin R.~C.: 1982, Astron.~Astrophys.~107,
11--22.

\appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\xlabel{output_formats}\label{ap:output}FILE OUTPUT FORMATS}
\markboth{File Output Formats}{\stardocname}


\subsection{\xlabel{ndf_iuedr}\label{subap:ndf}NDF Components Present in
            IUEDR Output}

This Section gives a summary of the NDF components present in IUEDR files for
those who may wish to access the files from their own programmes.
The structure and content of an NDF can be inspected using the {\tt hdstrace}
utility (See
\xref{SUN/102}{sun102}{})\@.  Values for components have been given where they
are constant for all files of the particular type.

\subsubsection{Raw image data file {\tt \_UED}}

\begin{latexonly}
A simple NDF, each point in the $768\times 768$ image is described by a datum
and a quality flag.  The image is given the generic title `IUE image'\@.
\end{latexonly}

\begin{htmlonly}
A simple NDF, each point in the 768x768 image is described by a datum
and a quality flag.  The image is given the generic title `IUE image'.
\end{htmlonly}

\begin{verbatim}
IUEDR  <NDF>

   DATA_ARRAY(768,768)  <_WORD>

   QUALITY        <QUALITY>       {structure}
      QUALITY(768,768)  <_UBYTE>

   TITLE          <_CHAR*9>       'IUE image'
\end{verbatim}

\subsubsection{Net Spectra File {\tt \_UES}}

This NDF contains IUEDR specific extensions, which are written and read by the
programme when processing spectra.  In the description below {\tt no} is
the number of orders processed with the \xref{\verb+TRAK+}{sg3}{TRAK}
 command.  {\tt mo} is
the number of data points in the longest order processed.
{\tt WAVES} contains the wavelengths for each flux datum in each order.
{\tt ORDERS} holds a list of the order numbers processed.
{\tt NWAVS} stores the actual number of points in each of the {\tt no} orders.

\begin{verbatim}
IUEDR  <NDF>

   DATA_ARRAY(mo,no)   <_REAL>

   QUALITY        <QUALITY>       {structure}
      QUALITY(mo,no)   <_UBYTE>

   MORE           <EXT>           {structure}
      IUEDR_EXTRA    <EXTENSION>     {structure}
         WAVES(mo,no)   <_REAL>
         ORDERS(no)     <_INTEGER>
         NWAVS(no)      <_INTEGER>

   TITLE          <_CHAR*80>
   LABEL          <_CHAR*4>       'Flux'
\end{verbatim}

\subsubsection{Mean Spectrum File {\tt \_UEM}}

This holds\ldots\\
{\tt WAVES} is wavelengths of flux data points.\\
{\tt WEIGHTS} is a weight of some sort.\\
{\tt XCOMB1} is the start wavelength.\\
{\tt DXCOMB} is the wavelength step from point to point.

\begin{verbatim}
IUEDR  <NDF>

   DATA_ARRAY(17001)  <_REAL>

   QUALITY        <QUALITY>       {structure}
      QUALITY(17001)  <_UBYTE>

   MORE           <EXT>           {structure}
      IUEDR_EXTRA    <EXTENSION>     {structure}
         WAVES(17001)   <_REAL>
         WEIGHTS(17001)  <_REAL>
         XCOMB1         <_DOUBLE>
         DXCOMB         <_DOUBLE>

   AXIS(1)        <AXIS>          {structure}
      DATA_ARRAY(17001)  <_REAL>
      UNITS          <_CHAR*40>      '(A)'
      LABEL          <_CHAR*40>      'Wavelength'

   TITLE          <_CHAR*80>
   UNITS          <_CHAR*40>      '(FN/s)'
   LABEL          <_CHAR*40>      'Flux'
\end{verbatim}

\subsubsection{\xlabel{SPECTRUM_formats}\label{subap:spectrum}SPECTRUM Format
               Output Files}

SPECTRUM is a data analysis programme written by Steve Adams at UCL\@.
Although the programme is no longer used (I guess it might be in use
somewhere\ldots) the file formats it introduced
where adopted by the popular
spectrum analysis programme \xref{DIPSO}{sun50}{}.

The basic input to a SPECTRUM file is a single spectrum (wavelength, flux)\@.
The wavelengths should be in increasing order, and evenly spaced.

There are three variants of the SPECTRUM file format.  Using its terminology:

\begin{latexonly}
\begin{tabular}{ll}
Format number & File characteristics\\
0             & Unformatted (Binary)\\
1             & Fixed Format Text\\
2             & Free-field Format Text\\
\end{tabular}
\end{latexonly}

\begin{htmlonly}
\begin{rawhtml}
<PRE>
<B>Format number   File characteristics</B>
      0         Unformatted (Binary)
      1         Fixed Format Text
      2         Free-field Format Text
</PRE>
\end{rawhtml}
\end{htmlonly}

IUEDR {\bf no longer} produces output of the SP0 type.  Instead NDFs are used.
In practice this is invisible to the user as the \xref{DIPSO}{sun50}{} SP0RD
command (read SPECTRUM format 0 file) now reads NDFs!  The other two formats
are still available.  A Description of the old SP0 format is included here in
case anyone needs to read an existing file in this format (DIPSO can still read
SP0 format via the OSP0RD command)\@.

Using a FORTRAN77 notation, the contents of a SPECTRUM file can be
expressed as:

\begin{verbatim}
   PARAMETER(MAXWAV=8000) ! maximum number of wavelengths
   CHARACTER*79 CLINE1    ! first line of text
   CHARACTER*79 CLINE2    ! second line of text
   INTEGER NWAV           ! number of wavelengths
   REAL WAV(MAXWAV)       ! wavelengths
   REAL FLUX(MAXWAV)      ! fluxes
\end{verbatim}

Both \verb+CLINE1+ and \verb+CLINE2+ are totally unstructured text strings,
and are used to describe the spectrum.  The convention is that
\verb+FLUX(I)=0.0+ when its value is undefined.

Here, briefly, is the code needed to read the SPECTRUM formats:

Format number 0 is an unformatted (binary) file read by:

\begin{verbatim}
   OPEN(UNIT=1, ACCESS='SEQUENTIAL', FORM='UNFORMATTED')
   READ(1) CLINE1(1:79)
   READ(1) CLINE2(1:79)
   READ(1) NWAV
   READ(1) (WAV(I),FLUX(I),I=1,NWAV)
   CLOSE(UNIT=1)
\end{verbatim}

Format number 1 is a fixed format text file read by:

\begin{verbatim}
   OPEN(UNIT=1, ACCESS='SEQUENTIAL')
   READ(1,'(A79)') CLINE1(1:79)
   READ(1,'(A79)') CLINE2(1:79)
   READ(1,'(20X,I6)') NWAV
   READ(1,'(4(F8.3,E10.3))') (WAV(I),FLUX(I),I=1,NWAV)
   CLOSE(UNIT=1)
\end{verbatim}

Format number 2 is a free-field text file read by:

\begin{verbatim}
   OPEN(UNIT=1, ACCESS='SEQUENTIAL')
   READ(1,'(A79)') CLINE1(1:79)
   READ(1,'(A79)') CLINE2(1:79)
   READ(1,*) NWAV
   READ(1,*) (WAV(I),FLUX(I),I=1,NWAV)
   CLOSE(UNIT=1)
\end{verbatim}

The sections of FORTRAN 77 code shown above are not intended to be serious
attempts to write a SPECTRUM file reading programme.  Instead they are designed
to define the contents as succinctly as possible.

\typeout{ }
\typeout{*****************************************************}
\typeout{ }
\typeout{Reminder: run this document through Latex three times}
\typeout{to resolve cross references.}
\typeout{ }
\typeout{*****************************************************}
\typeout{ }

\end{document}
