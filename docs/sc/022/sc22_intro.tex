\chapter{Introduction}
\label{sec:intro}

% set up page numbers in arabic numerals and restart from 1
\renewcommand{\thepage}{\arabic{page}}
\setcounter{page}{1}

\section{This cookbook}

This guide is designed to instruct POL-2 users on the best ways to
reduce and visualize their data using \starlink\ packages: \smurf
\cite{smurf}, \Kappa , \polpack and \gaia.

This guide covers the following topics.
\begin{itemize}
\itemsep0em
\item \cref{Chapter}{sec:intro}{Chapter 1} -- Computer resources needed before getting started.
\item \cref{Chapter}{sec:pol2}{Chapter 2} -- A description of POL-2 and its observing modes.
\item \cref{Chapter}{sec:dr}{Chapter 3} -- POL-2 Data Reduction - The Theory
\item \cref{Chapter}{sec:rundr}{Chapter 4} -- POL-2 Data Reduction - Running pol2map
\item \cref{Chapter}{sec:display}{Chapter 5} -- POL-2 Image Display
\item \cref{Chapter}{sec:advanced}{Chapter 6} -- POL-2 Advanced Data Reduction

\end{itemize}

Throughout this document, a percent sign (\texttt{\%}) is used to
represent the Unix shell prompt. What follows each \texttt{\%} will be
the text that should be typed by the user to initiate the described action.

\section{\xlabel{computing} Before you start: computing resources}
\label{sec:computing}

Compared to SCUBA-2 observations, POL-2 observations are far less memory-intensive to reduce.
POL-2 time-series data is down-sampled to 2Hz as a part of the reduction process. Assuming a typical 35
minute POL-2 observation, the reduction requires 35 GB of memory (in comparison to SCUBA-2
maps that may require up to 96 GB of memory).

The main consideration for POL-2 reductions is processing power. PCA calculations in
\makemap\ can be lengthy so fast processors with lots of cores are advised.


\section{\xlabel{software}Before you start: software}

This manual uses software from \starlink\ packages: \smurf\
\cite{smurf}, \Kappa\ \cite{kappa}, \polpack \cite{polpack} and \gaia\ \cite{gaia}.
Starlink software must be installed on your system, and Starlink
aliases and environment variables must be defined before attempting
to reduce any SCUBA-2 data (see section \ref{sec:starinit}).


\subsection{Data formats}
\label{sec:ndf}

Data files for POL-2 are structurally the same as for SCUBA-2, and use
the Starlink N-dimensional Data Format (NDF,
see Jenness et al.\ 2014\cite{ndf}), a hierarchical format which allows
additional data and metadata to be stored within a single file. \Kappa\
contains \xref{many commands}{sun95} {ap_classified}\ for examining and
manipulating NDF structures. The introductory sections of the \Kappa\
document (\xref{SUN/95}{sun95}{}) contain much useful information on
the contents of an NDF structure and how to manipulate them.

A single NDF structure describes a single data array with associated
meta-data. NDFs are usually stored within files of type ``\verb+.sdf+''.
In most cases (but not all), a single \verb+.sdf+ file will contain just
one top-level NDF structure, and the NDF can be referred to simply by
giving the name of the file (with or without the ``\verb+.sdf+'' prefix).
In many cases, a top-level NDF containing JCMT data will contain other
``extension'' NDFs buried inside them at a lower level. For instance, raw
files contain a number of NDF components which store observation-specific
data necessary for subsequent processing. The contents of these (and
other NDF) files may be listed with \HDSTRACEref. Each file holding raw
JCMT data on disk is also known as a `sub-scan'.

The main components of any NDF structure are:
\begin{itemize}
\item An array of numerical data (which may have up to seven
dimensions---usually three for JCMT data);
\item An array of variance values corresponding to the numerical data
values;
\item An array holding up to eight Boolean flags (known as ``quality
flags'') for each pixel;
\item World Co-ordinate System information;
\item History;
\item Data units;
\item Other extensions items. These are defined by particular packages,
but usually include a list of FITS-like headers together with provenance
information that indicates how the NDF was created. Raw JCMT files also
include extensions that define the state of the telescope and instrument
at each time slice within the observation.
\end{itemize}

The \starlink\ \convert\ package contains commands \xref{\task{fits2ndf}}{sun55}{FITS2NDF} and
\xref{\task{ndf2fits}}{sun55}{NDF2FITS} that allow interchange between FITS
and NDF format.

\subsection{Initialising Starlink}
\label{sec:starinit}

The commands and environment variables needed to start up the required
Starlink packages (\smurf \cite{smurf}, \Kappa, \emph{etc.}) must first
be defined. For C shells (csh, tcsh), the commands are:

\begin{terminalv}
% setenv STARLINK_DIR <path to the starlink installation>
% source $STARLINK_DIR/etc/login
% source $STARLINK_DIR/etc/cshrc
\end{terminalv}

before using any Starlink commands. For Bourne shells (sh, bash, zsh), the commands are:

\begin{terminalv}
% export STARLINK_DIR=<path to the starlink installation>
% source $STARLINK_DIR/etc/profile
\end{terminalv}

\subsection{KAPPA and SMURF for data processing}
\label{sec:packinit}

The \starlink\ Sub-Millimetre User Reduction Facility package, or \textsc{Smurf},
contains the Dynamic Iterative Map-Maker, which will process
SCUBA-2 time-series data into images (see \smurfsun). \textsc{Kappa}, meanwhile, is
an application package comprising general-purpose commands mostly for
manipulating and visualising NDF data (see \kappasun). Before starting
any data reduction it is necessary to initiate both \textsc{Smurf} and
\textsc{Kappa}.

\begin{terminalv}
% smurf
% kappa
\end{terminalv}

After entering the above commands, the help information
for the two packages can be accessed by typing \texttt{smurfhelp} or
\texttt{kaphelp} respectively in a terminal, or by using the
\task{showme} facility to access the hypertext documentation. See
\cref{Section}{sec:help}{How to get help} for more information.



\begin{tip}
The .sdf extension on filenames need not be specified when running most
Starlink commands (the exception is \picard).
\end{tip}


\subsection{GAIA for viewing your images and vector maps}
Images and vector maps can be displayed and analysed using \gaia\ (see
\gaiasun) - an interactive GUI-driven tool that incorporates facilities
such as vector selection, vector binning, source detection, photometry
and the ability to query and overlay on-line or local catalogue data.
\begin{terminalv}
% gaia map.sdf
\end{terminalv}

Alternatively, the \Kappa\ package includes many visualisation commands
that can be run from the shell command-line or incorporated easily into your
own scripts---see Appendix ``\xref{Classified KAPPA commands}{sun95}{cl_datadisplay}''
in SUN/95.


\subsection{\xlabel{help}How to get help}
\label{sec:help}

\begin{table}[h!]
\begin{tabular}{p{2.3cm}|p{7.3cm}|p{5cm}}
\hline
\textbf{Help\newline command} & \textbf{Description} & \textbf{Usage}\\
\hline
\task{showme} & If the name of the Starlink document you want to view is known,
                use \task{showme}. When run, it launches a new webpage or tab
                displaying the hypertext version of the document. &
\texttt{\%~showme~sun95}\\
\hline
\task{findme} & \task{findme} searches Starlink documents for a keyword. When
                run, it launches a new webpage or tab listing the results. &
                \texttt{\% findme~kappa}\\
\hline
\task{docfind} & \task{docfind} searches the internal list files for keywords. It then
                 searches the document titles. The result is displayed using the
                 Unix \task{more} command. & \texttt{\%~docfind~kappa}\\
\hline
Run routines with prompts & Any routine can be run with the option
                            \texttt{prompt} after the command. This will
                            prompt for every parameter available. A
                            further description of any parameter
                            may be obtained by typing \texttt{?} at the relevant prompt. &
                            \texttt{\%~makemap~prompt~\newline\~\%~REF~-~Ref.~NDF~/!/$>$~?}\\
\hline
Google & A simple Google search such as ``\texttt{starlink kappa fitslist}''
will usually return links to the appropriate documents. However,
the results may include links to out-of-date versions of the
document hosted at non-Starlink sites. The user should always look for results in
\texttt{"www.starlink.ac.uk/docs} (or \texttt{"www.starlink.ac.uk/devdocs}
for the current development version of the document). & \\
\hline
\end{tabular}
\end{table}

