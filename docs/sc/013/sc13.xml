<?xml version="1.0"?>

<!DOCTYPE sc PUBLIC 
             "-//Starlink//DTD Starlink SC 0.7 (XML)//EN" 
             "dtd/sc-xml-0.7.dtd" [
  <!-- Figures -->
  <!ENTITY gausssine-gnuplot.eps
			SYSTEM "sc13-gausssine-gnuplot.eps"
			NDATA eps>
  <!ENTITY gausssine-gnuplot.gif
			SYSTEM "sc13-gausssine-gnuplot.gif"
			NDATA gif89a>
  <!ENTITY gausssine-idl.eps
			SYSTEM "sc13-gausssine-idl.eps"
			NDATA eps>
  <!ENTITY gausssine-idl.gif
			SYSTEM "sc13-gausssine-idl.gif"
			NDATA gif89a>

  <!-- Local text files included -->
  <!ENTITY version SYSTEM "VERSION">

  <!ENTITY ex-p1-f		SYSTEM "examples/p1.f.xml">
  <!ENTITY ex-p2-f		SYSTEM "examples/p2.f.xml">
  <!ENTITY ex-p3-f		SYSTEM "examples/p3.f.xml">
  <!ENTITY ex-fpdemo-c		SYSTEM "examples/fpdemo.c.xml">
  <!ENTITY ex-fpp-c		SYSTEM "examples/fpp.c.xml">
  <!ENTITY ex-islittleendian-c	SYSTEM "examples/islittleendian.c.xml">
  <!ENTITY ex-crash-c		SYSTEM "examples/crash.c.xml">
  <!ENTITY ex-mixed-c-c		SYSTEM "examples/mixed-c.c.xml">
  <!ENTITY ex-mixed-f-f		SYSTEM "examples/mixed-f.f.xml">
  <!ENTITY ex-maple-ms		SYSTEM "examples/maple.ms.xml">
  <!ENTITY ex-idl-functions-pro	SYSTEM "examples/idl-functions.pro.xml">

  <!-- abbreviations/abstractions -->
  <!ENTITY ctan "http://www.tex.ac.uk">
  <!ENTITY sc13webpage "http://www.astro.gla.ac.uk/users/norman/star/sc13/">

]>

<!-- Tell psgmls not to auto-indent verbatim elements -->
<?PSGML nofill verbatim ?>


<sc generalversion="DTD Starlink General 0.7" version="DTD Starlink SC 0.7"
  urllinkpolicy="automatic">
  <docinfo>
    <title>Theory and Modelling Resources Cookbook</title>
    <authorlist><author email="norman@astro.gla.ac.uk"
    webpage="http://www.astro.gla.ac.uk/users/norman/" id="ng">Norman
    Gray</author></authorlist>
    <!--
    <manualtype type=other>Cookbook
    <softwareversion> [ NO CORRESPONDING SOFTWARE ]
    -->

    <docnumber documenttype="sc">13</docnumber>

    <history>
      <version number="1" date="22-DEC-1998" author="ng">
        <px>Last LaTeX version</px></version>

      <change date="14-JUN-2000" author="ng"><px>Conversion to SGML</px></change>

      <change date="20-Jun-2000" author="ng"
      versionid="v1.1"><px>Incorporating comments from others.</px></change>

      <version number="2" date="02-Dec-2001" author="ng" versionid="v2-0"><px>Updating, link-checking, general refreshing.</px></version>

      <distribution string="2-1" date="04-Dec-2001" author="ng"
      versionid="v2-1"><px>Update to IEEE trap
      details</px></distribution> 

      <distribution string="2-2" date="01-Dec-2001" author="ng" versionid="v2-2">
        <px>Slight reworking after comments</px>
      </distribution>

      <distribution string="2-3" date="16-Jul-2002" author="ng" versionid="v2-3">
        <px>Minor edits -- typos and enhancements spotted now and
        again.</px>
      </distribution>

      <distribution string="2-4"
        date="22-Jul-2002" author="ng" versionid="v2-4"><px>Minor edits
          for clarity, and to restore missing
          references.</px></distribution>
      
      <distribution string="2-5"
        date="10-Mar-2003" author="ng" versionid="v2-5"><px>Minor edits,
          plus repackaging</px></distribution>

    </history>

    <copyright><p>Copyright 1999, 2001--2003, Central Laboratories for
        the Research Councils</p></copyright>

  </docinfo>

  <docbody>
    <abstract>
      <px>This cookbook is intended to assemble references to
        resources likely to be of interest to theorists and modellers.
        It's not a collection of standard recipes, but instead a
        repository of brief introductions to facilities.  It includes
        references to sources of authoritative information, including
        those Starlink documents most likely to be of interest to
        theorists.  </px>

      <px>Although the topics are chosen for their
        relevance to theoretical work, a good proportion of the
        information should be of interest to all of the astronomical
        computing community.</px>
    </abstract>

    <sect id="s.intro" export="export">
      <subhead>
        <title>Introduction</title>
      </subhead>

      <p>Theory work, unlike observational work, does not have a clear set
        of requirements for applications programs.  There is no instrument
        data to reduce, no observations to plan, and all the observational
        fuss of calibration, flat-fielding, dark frames, image centroids can
        be avoided.  All we need is a fast machine, and a compiler we can
        trust.</p>

      <p>Well, not quite all. This cookbook is intended to be useful at and
        after the point when you start to wrestle with the computing details
        of your scientific problem.  It's not a collection of standard
        recipes, but instead a repository of brief introductions to facilities
        you may not know existed, or didn't know how to get started on.  It
        includes references to sources of authoritative information, including
        those Starlink documents most likely to be of interest to theorists.
        It doesn't try to teach you all of anything, but aims to give you
        enough information to decide if the topic is useful, and if the
        included references are worth pursuing.
      </p>

      <p>Although the topics are chosen for their relevance to theoretical
        work (and for the purposes of this text, I'm taking the term to
        include all who develop their own modelling codes), a good proportion
        of the information should be of interest to 
        all of the astronomical computing community.
      </p>

      <subsect id="s.contributions" export="export">
        <subhead>
          <title>Call for contributions</title>
        </subhead>

        <p>For such a wide ranging project, I cannot hope to have given an
          ideally just account of every topic.  Please send comments,
          corrections, and expansions either to me at <code>norman@astro.gla.ac.uk</code>
          or to the Starlink software librarian at <code>starlink@jiscmail.ac.uk</code>.
          I'll maintain a web page for the cookbook at
          <url>&sc13webpage;</url>.  Updates
          to the cookbook and its example programs can be found there.
        </p>

        <p>I am particularly interested in comments on the following topics:
          <ul>

            <li><p>I'd like to include a section on Monte Carlo
                simulations, but don't feel qualified to comment
                myself.  Can anyone 
                give any pointers? 
              </p></li>

            <li><p>The cookbook is reasonably well-stocked with
                material on computation, but rather thin on more
                detailed astrophysical topics (<ref id="s.astro"/>).
                It does have a section on Stellar Atmosphere models
                (<ref id="s.models"/>); what else should be here?
                </p></li>

            <li><p>Do I need a section on parallelization, beyond the
                very brief (indeed evasive!) mention in <ref
                id="s.optim"/>?  </p></li>

          </ul>
        </p>

      </subsect>

    </sect>

    <sect id="s.computing" export="export">
      <subhead><title>Computing</title></subhead>

      <p>Everyone should start with the
        <docxref doc="SUG" text="Starlink User's Guide" />, which should be
        available at your site, and is on the web at
        <url>http://www.starlink.ac.uk/star/docs/sug.htx/sug.html</url>.
      </p>

      <subsect id="s.unix" export="export">
        <subhead>
          <title>Unix guides</title>
        </subhead>

        <p>Before you can do anything, you need to make friends with
          the machine.  The slogan to remember here is `unix
          <em>is</em> user-friendly, it's just picky about who its
          friends are'.  Keep calm, breath deeply, and make friends
          with a guru.
        </p>

        <p>Your first source of information might be <docxref
          doc="SUN/145" text="SUN/145" />, Starlink's Unix
          introduction.  This covers the basics of logging on, moving
          around, issuing commands, creating files, and starting
          programming.  It also includes references to other Starlink
          documents which can provide more detailed help on various
          aspects.
        </p>

        <p>There are very good online introductions to Unix at 
          <url>http://unixhelp.ed.ac.uk/</url>
          and
          <url>http://star-www.maps.susx.ac.uk/help/4ltrwrd/unixman.html</url>
        </p>

        <p>There are numerous books on Unix.  Two which seem to be at
          the right level are <cite>Unix Shells by Example</cite>
          <citation>quigley</citation> and <cite>Unix in a
          Nutshell</cite> <citation>nutshell</citation>.  Both cover
          the Bourne shell (<code>sh</code>) and the C shell
          (<code>csh</code>), plus other utilities such as
          <code>sed</code> and <code>awk</code> (see <ref
          id="s.sedawk"/>).  By the way, let me put in a plug for
          <code>bash</code> as a usable shell, as it includes all the
          best bits of the Bourne and C shells.  The only disadvantage
          of bash is that Starlink has, to some extent, standardised
          on <code>csh</code>, so that setup scripts, for example, are
          designed to work with <code>csh</code> alone; this is not
          often a real problem, since these scripts are generally
          simple enough that you can duplicate their effects `by
          hand'.
        </p>

        <p>You will occasionally see references to unix manual pages
          followed by a number.  This indicates which section of the
          manual the documentation can be found in (section 1 is
          normal user commands, section 3 is standard library calls,
          section 5 is file formats, and so on).  If you see a
          reference to <code>sed(1)</code>, for example, you'd read
          the manual page online with the command <code>man
          sed</code>.  A useful variant of the <code>man</code>
          command is <code>apropos</code>, for example <code>apropos
          find</code>.  This searches the list of man-pages, and lists
          all those commands which include a particular word in their
          short description.
        </p>

      </subsect>

      <subsect id="s.editors" export="export">

        <subhead>
          <title>Editors</title>
          <update versionid="v1.1">
            <px>Expanded the description of vi</px></update>
          <update versionid="v2-0"><px>Added more vi URLs, caught
          typos</px></update></subhead> 

        <p>One of the aspects of working on Unix which you'll have to deal with
          pretty early in your contact with it, is which editor to use.  An
          editor is the tool you use to create your documents or programs.  It's
          the tool you'll use more than any other.
        </p>

        <p>It's very much a personal decision, which editor you use, and when
          you're feeling understimulated, you can discuss the matter with your
          officemates (don't get blood on the machines, though, and remember to
          wash and dry your thumbscrews carefully after use -- you'll need them
          again when you discuss programming languages -- see
          <ref id="s.progs"/>).
        </p>

        <p><docxref doc="SUN/170" text="SUN/170" />, <cite>Editors on
          Unix</cite>, is an overview of some of the available
          options, listing their good and bad points.  In addition to
          this, Brian McIlwrath wrote an overview of available text
          editors in the September 1998 (issue 21) edition of the
          <webref
          url="http://www.starlink.ac.uk/bulletin/98sep/node15.html">Starlink
          Bulletin</webref>.
        </p>

        <p>Emacs is many people's favourite (and mine).  You can do
          just about anything in emacs -- it's a hugely productive
          environment -- but you may get cricks in your fingers from
          the odd key combinations.  Emacs itself can help you up the
          long learning curve: there's a very good tutorial built-in
          to emacs, and available by typing <code>C-h C-t</code>
          (that's control-H, control-T), plus extensive documentation
          behind <code>C-h C-i</code>.  Leave emacs with <code>C-x
          C-c</code> (obvious, really).
        </p>

        <p>Vi is another favourite.  It is indeed very powerful, but
          rather more of an acquired taste.  An advantage of vi is
          that it's small, and therefore quick to start up -- this
          makes it useful if you want to make a quick change to a
          file, or make similar changes to a number of files, and it
          makes it useful as a editor for Pine, or any other mail
          program.  An even bigger advantage of vi, however, is that
          it's available on every Unix system since the Ark, so if you
          can use vi, you can work on whichever Unix system you find
          yourself.  The main disadvantage is that it is exceedingly
          unintuitive.  There's quite a lot of help available for vi
          (it needs it, after all), but not, oddly enough, in the
          manual page, which describes in elaborate detail how to
          start up vi, but not what to do once you succeed.  You'll
          find a good introduction to vi in Chapter 6 of the
          <cite>Solaris 2.6 Advanced Users' Guide</cite>, and in
          Chapter 2 of the old <cite>SunOS 4 Documentation
          Tools</cite> manual, and probably in the corresponding
          manual for any other Unix you use (don't worry about these
          being out of date, by the way, vi doesn't change much...).
          Online introductions to, and references for, vi include the
          <webref url="http://unixhelp.ed.ac.uk/vi/ref.html">the
          unixhelp manual</webref>, <webref
          url="http://www.devshed.com/Server_Side/Administration/Vi101/Vi101/page1.html">vi101</webref>,
          and even the <webref
          url="http://www.thomer.com/thomer/vi/vi.html">vi-lovers home
          page</webref>!
        </p>

        <p>If you want to leave vi without saving what you've
          (accidentally?)  typed, you can do so by typing
          <code>:q!</code> (if it beeps at you, or if those characters
          simply appear in the typing buffer on screen, try pressing
          escape once or twice first).  By the way, it's pronounced
          `vee-eye', not `vye': pronounce it the wrong way and you'll
          lose all your credibility (of course, if you know the
          correct way to pronounce it, you'll lose all credibility
          with a different set of folk -- your choice).
        </p>

        <p>For VMS fans, there's <code>jed</code>, which is a simple
          and fairly sane editor which includes an emulation of the
          EDT editor of old.  It's available on Starlink systems, and
          documented in <docxref doc="SUN/168" text="SUN/168" />.
        </p>

        <p>Finally, there's <code>pico</code>, the editor used
          internally by the pine mailer.  You can't go wrong with this
          one, but I'd imagine it could be a little painful if you're
          writing much code with it.  Along the same lines, the
          <code>textedit</code> editor which comes with OpenWindows
          really isn't up to much.  It looks pretty, but has zero
          support for programming.  You'll be using an editor <em>a
          lot</em>, so it's worth investing time to learn to use a
          powerful one to its full extent.
        </p>

      </subsect>

      <subsect id="s.na" export="export">
        <subhead>
          <title>Numerical analysis</title>
        </subhead>

        <p>Anyone writing numerical code needs <em>some</em> awareness
          of numerical analysis, to avoid burning up CPU time with a
          hideously inappropriate and inaccurate algorithm.
        </p>

        <p>By far the most accessible introduction to numerical
          methods is <webref url="http://www.nr.com">Numerical
          Recipes</webref> <citation>nr</citation>, which comes in
          different editions, containing code in C, Fortran and
          Fortran 90.  Use the second edition: the first has a
          significant number of bugs.
        </p>

        <p>A large part of the book's popularity stems from the fact that its
          authors are scientists rather than numerical analysts, so that they
          are more concerned with producing reliable results than with a point
          of view which sometimes appears to see efficiency, unshakable
          robustness and algorithmic elegance as ends in themselves.  For
          further discussion, and some caveats, see <ref id="s.nr"/>.
        </p>

        <p>My advice is to use <cite>Numerical Recipes</cite> for your
          numerical programming until it runs out of steam on your
          particular problem.  Follow the references in there, or look
          at the <webref
          url="http://www.mathcom.com/corpdir/techinfo.mdir/scifaq/q165.html">booklist</webref>
          in the on-line Numerical Analysis FAQ.  Also (perhaps
          unexpectedly), I suggest you take a look at the Usenet
          newsgroup <code>comp.lang.fortran</code>, even if you don't
          actually use Fortran.  This is one of those happy few Usenet
          newsgroups with a high signal-to-noise ratio, and listening
          in on this can be profitable when the conversation turns to
          general numerical analysis.  A similar resource is the
          JISCmail <webref
          url="http://www.jiscmail.ac.uk/lists/COMP-FORTRAN-90.html">comp-fortran-90</webref>
          list.
        </p>

        <p>To support more specialised numerical computing, refer to the
          libraries section below, <ref id="s.lib"/>.
        </p>

        <subsubsect id="s.nr">
          <subhead>
            <title>Numerical Recipes</title>
          </subhead>

          <p><webref url="http://www.nr.com">Numerical
            Recipes</webref> <citation>nr</citation> does not claim to
            be a numerical analysis textbook, and it makes a point of
            noting that its authors are (astro-)physicists and
            engineers rather than analysts, and so share the
            motivations and impatience of the book's intended
            audience.  The declared premise of the NR authors is that
            you will come to grief one way or the other if you use
            numerical routines you do not understand.  They attempt to
            give you enough mathematical detail that you understand
            the routines they present, in enough depth that you can
            diagnose problems when they occur, and make more
            sophisticated choices about replacements when the NR
            routines run out of steam.  Problems <em>will</em> occur
            because the routines are not written to be bullet-proof,
            and if you use them thoughtlessly you can break them
            without much difficulty.  Also, the routines will likely
            prove inadequate if you have a very demanding application
            which needs a more efficient or more specialised routine
            than the ones available here.
          </p>

          <p>That is, the NR library is not filled with magic bullets,
            and if you try to use its contents as such, the only thing
            you'll shoot is your foot.  However, NAG and SLATEC don't
            supply magic bullets either (though `any sufficiently
            advanced library is indistinguishable from magic to the
            unsophisticated programmer', as Arthur C Clarke didn't
            quite say).  You might use the NR routines successfully
            for years, but if and when they fail you, you'll use the
            more sophisticated substitute all the better because
            you'll understand <em>why</em> the simpler original was
            inadequate.
          </p>

          <p>It is a consequence of the book's aims that the routines
            will not necessarily be the most intricately and obscurely
            efficient.  Efficiency matters a lot if you are running
            some huge hydro code taking months of Cray time, but I
            would claim that if your code takes less than a week of
            wall-time to run, then the efficiency gains from using
            opaque library routines is simply not worth the cost in
            debugging time.  No matter how robustly the library
            routine is written, you will be able to abuse it -- you
            will manage to break it somehow -- and when that happens
            your only recourse is to work through pages of Fortran IV
            trying to find the overflowing total, or the case you
            hadn't realised was marginal.
          </p>

          <p>If you need very high efficiency, then take a course on
            numerical analysis and spend time understanding the
            subtleties of the library routines.  Otherwise, read NR
            carefully (there are sometimes important caveats in the
            text), customise the routines to your problem, cross check
            the results you obtain, and keep alert.  If you have an
            aversion to documentation, use NAG or another library:
            using the NR routines as a black box is a numerical recipe
            for disaster.
          </p>

          <p>Despite NR's popularity, it has its critics.  These are
            typically that the NR routines do not use the most
            efficient modern algorithms, and that they sometimes go
            wrong in borderline situations.  While this may be true
            (and will be more true of the first edition than the
            second), it is largely a consequence of NR's declared
            intention of being accessible and intelligible.  Without
            making the point explicit, as far as I can see, the NR
            authors privilege intelligibility over high efficiency,
            and practicality over unabusable robustness; I don't
            believe it's entirely fair, therefore, to criticise them
            for not being ultra-efficient and bulletproof.  There is a
            collection of criticisms of the books by W Van Snyder at
            JPL, at <url>http://math.jpl.nasa.gov/nr/</url>, along
            with some suggestions for alternatives; there is a
            rebuttal from the NR authors at
            <url>http://www.nr.com/bug-rebutt.html</url>.
          </p>

          <p>From the NR home pages, you can browse and print out
            chapters from the books, but you can't download the source
            code.  Do remember that the NR code is copyrighted and
            <em>not</em> free; this may affect your ability to
            redistribute code which uses it.
          </p>

        </subsubsect>

        <subsubsect id="s.fp">
          <subhead>
            <title>Floating point representation</title>
          </subhead>

          <p>As with numerical analysis, the intricacies of how
            floating-point numbers are represented, and the quirks of
            their representation on different platforms, are a
            maelstrom into which you can fall, dazed, confused and
            unproductive.  However (and again as with numerical
            analysis), if your codes become elaborate enough, then you
            are going to have to take the plunge.
          </p>

          <p>Even if you have no plans to venture into the deep, there
            is a minimum awareness of the problems which can help you
            write more robust code.
          </p>

          <p>What follows here is rather detailed, but it does, I
            believe, represent the majority of what you might need to
            know about floating point representation; there is a good
            alternative introduction in <cite>Numerical Recipes</cite>
            <citation>nr</citation>, and an excellent and detailed
            introduction in Chapter 2 of Sun's <cite>Numerical
            Computation Guide</cite> <citation>sunncg</citation>
            (appendix E of the same book claims to be `What every
            computer scientist should know about floating point
            arithmetic', and is an edited reprint of
            <citation>goldberg91</citation>.  It makes interesting
            reading, but it's probably more than many natural
            scientists need to know).  My account here is not intended
            to supplant either of these sources.  Below, I'll talk
            exclusively of IEEE base-2 floating point numbers, as
            defined in IEEE standard <webref
            url="http://grouper.ieee.org/groups/754/">IEEE-754</webref>;
            there are other standards, but they're now of historical
            interest only, as just about all modern machines other
            than VAXes and older Crays use IEEE.  Most of what I say
            concerning accuracy will be about single precision;
            exactly the same issues arise with double precision, but
            you can sweep them under the carpet for longer.</p>

          <subsubsubsect id="s.endianness">
            <subhead><title>Endianness of floating-point
                numbers</title><update versionid="v2-4"><px>Paragraph
                  transformed into section</px></update></subhead>

            <p>The IEEE standard leaves it open to chip manufacturers
              to decide the order in memory of the four or eight bytes
              of a floating point number (the same is true of
              integers, though they're not part of the IEEE spec).
              This is denoted by the endian-ness (or `bytesex') of the
              machine.  Alpha and Intel chips are little-endian;
              Sparcs, the Motorola 68k family used in Macs, and
              Motorola PowerPC chips, are big-endian (there's also a
              `PGP-endian' ordering, but that really isn't likely to
              trouble anyone any more).  This generally does not
              matter if you stick to a single platform (other than in
              the context of programs such as those described in <ref
              id="a.islittleendian.c"/> and <ref id="a.fpp.c"/>), but
              it makes a difference if you want to share raw data
              files (see <ref id="ss.io"/>) between architectures.</p>

            <!-- XXX Add swap-bytesex.c to distribution? -->

          </subsubsubsect>

          <subsubsubsect id="s.accuracy">
            <subhead>
              <title>Accuracy</title>
              <update versionid="v2-0"><px>Added
                  a brief description of the format of
                  doubles</px></update>
            </subhead>

            <p>The central insight is that <em>you cannot represent an
                infinite number of reals in a finite number of bits
                without approximation</em>.  It is a consequence of
                this that the result of any calculation will lose
                precision when it is represented as a floating-point
                bit pattern, and that the extent and importance of
                this loss of precision <em>depends on the
                operands</em>.  Both of these seem obvious by
                themselves, but the consequences can be sufficiently
                non-obvious to trip you up.
            </p>

            <p>A non-special IEEE floating-point single-precision
              longword represents a number <mequation
              notation="latexmaths"><mlabel id="e.ieee1"/>
              (-1)^s\times 1.m \times 2^{e-127},</mequation> where <m
              notation="latexmaths">s</m> (the sign), <m
              notation="latexmaths">m</m> (the mantissa or
              significand) and <m notation="latexmaths">e</m> (the
              exponent) are base-2 numbers represented in 1, 8 and 23
              bits respectively, and <m notation="latexmaths">0&lt;
              e&lt; 255</m>; the offset 127 is called the
              <em>bias</em>.  These are encoded into the 32 bits of
              the longword as shown in table <ref id="f.fp"/>.</p>

            <table float="float" id="f.fp">
              <caption>
                <px>IEEE floating-point representations of numbers. 
                  This table is adapted from table 2--3 in <citation>sunncg</citation> and figure 1.3.1
                  in <citation>nr</citation>, which have fuller discussions of the issues here.  For
                  discussion of <m notation="latexmaths">b</m> and <m
                  notation="latexmaths">b-1</m> see the text.</px>
              </caption>
              <tabular frame="none">
                <tgroup cols="4">
                  <colspec align="right"/><colspec/><colspec/>
                  <tbody>
                    <row><entry/>
                      <entry><m notation="latexmaths">s</m></entry>
                      <entry><m notation="latexmaths">e</m></entry>
                      <entry><m notation="latexmaths">m</m></entry>
                    </row>
                    <row>
                      <entry><m notation="latexmaths">1={}</m></entry>
                      <entry>0</entry>
                      <entry>0 1 1 1 1 1 1 1</entry>
                      <entry>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 </entry>
                    </row>
                    <row>
                      <entry><m notation="latexmaths">2={}</m></entry>
                      <entry>0</entry>
                      <entry>1 0 0 0 0 0 0 0</entry>
                      <entry>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 </entry>
                    </row>
                    <row>
                      <entry><m notation="latexmaths">3={}</m></entry>
                      <entry>0</entry>
                      <entry>1 0 0 0 0 0 0 0</entry>
                      <entry>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 </entry>
                    </row>
                    <row>
                      <entry><m notation="latexmaths">2\epsilon={}</m></entry>
                      <entry>0</entry>
                      <entry>0 1 1 0 1 0 0 0</entry>
                      <entry>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 </entry>
                    </row>
                    <row>
                      <entry><m notation="latexmaths">1+2\epsilon={}</m></entry>
                      <entry>0</entry>
                      <entry>0 1 1 1 1 1 1 1</entry>
                      <entry>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 </entry>
                    </row>
                    <row>
                      <entry><m notation="latexmaths">b = 1.000220 ={}</m></entry>
                      <entry>0</entry>
                      <entry>0 1 1 1 1 1 1 1</entry>
                      <entry>0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 1 1 </entry>
                    </row>
                    <row>
                      <entry><m notation="latexmaths">(b-1) = 2.197266\times10^{-4}
                          ={}</m></entry>
                      <entry>0</entry>
                      <entry>0 1 1 1 0 0 1 0</entry>
                      <entry>1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0</entry>
                    </row>
                  </tbody>
                </tgroup>
              </tabular>
            </table>

            <p>Firstly, it is important to distinguish between the
              <em>range</em> and the <em>accuracy</em> of
              floating-point numbers.  The smallest and largest
              positive numbers which can be <em>represented</em> by
              normal IEEE single-precision numbers are <m
              notation="latexmaths">1.0_2\times2^{1-127}\approx1.175\times10^{-38}</m>
              and <m
              notation="latexmaths">1.1\dots1_2\times2^{254-127}\approx3.403\times10^{38}</m>,
              but this is very different from the accuracy to which
              these numbers are represented. These extreme values
              differ from the next representable ones up and down by
              <m
              notation="latexmaths">1\times2^{-23}\times2^{-126}\approx1.401\times10^{-45}</m>
              and <m
              notation="latexmaths">1\times2^{-23}\times2^{127}\approx2.028\times10^{31}</m>
              respectively, so that any number which differs from them
              by less than that amount is unrepresentable.  This
              accuracy limitation is expressed by the <em>machine
              epsilon</em>, <m
              notation="latexmaths">\epsilon=2^{-24}\approx5.960\times10^{-8}</m>
              (for IEEE single-precision), which is the maximum
              relative error incurred when a real number is
              represented in floating-point.  It is a consequence of
              this that <m notation="latexmaths">\epsilon</m> is the
              smallest number such that <m
              notation="latexmaths">1\oplus2\epsilon\neq1</m>, where
              the operator <m notation="latexmaths">\oplus</m>
              represents addition of floating-point
              numbers.<note><px>This is a slightly different
              convention from that used in, for example,
              <citation>nr</citation>, which defines<m
              notation="latexmaths">\epsilon</m> to be the smallest
              number for which <m
              notation="latexmaths">1\oplus\epsilon\neq1</m>.</px></note>
            </p>

            <p>Another way of thinking about this is as follows.  When
              two floating-point numbers are added, the exponent of
              the smaller one must be increased to match that of the
              larger, and the mantissa (or significand), <m
              notation="latexmaths">m</m>, must be shifted rightwards
              to compensate.  If the two numbers differ greatly in
              magnitude, then the smaller will lose significance in
              this operation, and if it is less than a factor <m
              notation="latexmaths">2\epsilon</m> of the larger one,
              the shift will push the number right off the end of the
              mantissa, and contribute nothing to the sum.  You can
              easily confirm that <m
              notation="latexmaths">2^{24}\oplus1.0=2^{24}=16777216.0</m>.
            </p>

            <p>The immediate practical consequence of this is that if,
              in the bowels of some calculation, you are adding up
              many small numbers (doing an inner product for very
              large vectors, for example), then the final total may be
              grossly inaccurate if you've fallen into this trap.
              Similarly, if you are subtracting numbers which are
              almost equal, perhaps in the course of debiasing or
              removing some DC offset, the subtraction may allow all
              or most of the leading accurate digits to cancel,
              leaving the result to be determined by digits possibly
              heavily contaminated by roundoff.  [<ref
              id="ta.rw">RW</ref>] </p><p>Consider the simple
              calculation <m notation="latexmaths">ab-ac</m>, with <m
              notation="latexmaths">a\approx1.000244</m>, <m
              notation="latexmaths">b\approx1.000220</m> and <m
              notation="latexmaths">c\approx1.000269</m>.  Here, the
              rounding in the two multiplications conspires to give a
              difference which has a huge relative error of <m
              notation="latexmaths">2.07\times10^{-3}</m>.  We can,
              however, address the problem by rewriting the
              calculation in ways which are equivalent for real
              arithmetic, but inequivalent for machine arithmetic.  If
              we do the subtraction before the multiplication, and
              calculate <m notation="latexmaths">a\otimes(b\ominus
              c)</m>, then we retain a little precision in the
              subtraction and end up with a relative error of <m
              notation="latexmaths">9.765625\times10^{-4}</m>.
              Finally, if we instead calculate <m
              notation="latexmaths">a\otimes((b-1)\ominus(c-1))</m>,
              then we do the subtraction with a full 23 bits of
              precision (compare <ref id="f.fp"/>), and lose as little
              as possible of this in the final multiplication, and end
              up with a relative error of only <m
              notation="latexmaths">2.532525\times10^{-7}</m>.  This
              is clearly a rather synthetic example, but it is not at
              all unrealistic, as it is equally clearly closely
              related to the common problem of calculating the
              discriminant <m notation="latexmaths">b^2-4ac</m> of the
              quadratic formula, when the quadratic is nearly
              degenerate.  </p><p>These problems are demonstrated in
              the short program <code>fpdemo.c</code> in <ref
              id="a.fpdemo.c"/>.  Note that the numbers <m
              notation="latexmaths">a=1+1/2^{12}</m>, <m
              notation="latexmaths">b=1+(1-)/2^{12}</m> and <m
              notation="latexmaths">c=1+(1+)/2^{12}</m> are (a)
              specifically chosen to demonstrate the effect, and (b)
              are calculated within the program, rather than being
              initialised from the decimal representations 1.000244,
              and so on.  If the latter were not true, then the
              improvement in relative error would disappear, since all
              precision would have been lost in this initialisation.
              If you wish to explore the representation of
              floating-point numbers on your machine, you can do so
              using the example program <code>fpp.c</code> in <ref
              id="a.fpp.c"/>.  </p><p>These problems are unfortunately
              both easy to run into, and hard to notice if you're not
              in the habit of looking for them whilst writing your
              code.  A brute-force way around them is to do sensitive
              parts of your calculation in double precision.  If you
              are doing the calculation in double precision and still
              running into the problem, then you will have to
              rearrange the calculation somehow, to contain the loss
              of precision.<note><px>For example, appendix E of
              <citation>sunncg</citation> displays `Kahan's summation
              formula', which allows you to perform a large sum
              without losing precision in the manner described
              above.</px></note> Note, however, that a compiler's
              optimizer can frustrate your efforts here, if you've
              given it a sufficiently high optimization level that it
              starts reorganising your code: in general <m
              notation="latexmaths">(a\oplus b)\oplus c \neq a\oplus
              (b\oplus c)</m>, and <m notation="latexmaths">a\ominus
              b\oplus(b\ominus c)\neq a\ominus c</m>, but a high
              optimization level may instruct the compiler to ignore
              this fact, which can be disastrous for the accuracy of
              your code.  Moral: make sure you know what the various
              optimization levels actually do before you invoke them.
              </p><p>As alluded to above, it is generally possible to
              sweep accuracy problems under the carpet by using
              double-precision floats.  These occupy eight bytes of
              storage rather than four, and the analogue of <ref
              id="e.ieee1"/> is <mequation
              notation="latexmaths">(-1)^s\times 1.m \times
              2^{e-1023},</mequation> where <m
              notation="latexmaths">s</m>, <m
              notation="latexmaths">m</m> and <m
              notation="latexmaths">e</m> are respectively 1, 52 and
              11 bits long, and the bias is 1023.  Thus the smallest
              and largest normal positive double-precision IEEE
              numbers are <m
              notation="latexmaths">1.0_2\times2^{1-1023}\approx2.225\times10^{-308}</m>
              and <m
              notation="latexmaths">1.1\dots1_2\times2^{2046-1023}\approx1.798\times10^{308}</m>,
              and the machine epsilon for double precision is <m
              notation="latexmaths">2^{-53}\approx1.11\times10^{-16}</m>.</p><p>On
              some platforms such as Solaris and Compaq, with the
              manufacturer's compilers, it is possible to use
              quadruple precision.  You should not use double or
              quadruple precision automatically, however, for a
              variety of practical and principled reasons.
              </p><p>Firstly, if your program already suffers from
              rather prodigal use of memory (ie, has very large
              arrays), then the doubling in the size of real arrays
              will only make the problem worse and, by probably
              increasing the amount of swapping, might make your
              program significantly slower.  </p><p>Secondly, although
              there are some issues to do with the relative speed of
              single- and double-precision calculations, these are
              probably not significant enough to be worth worrying
              about in all but the most long-running codes, and in any
              case would generally be swept up by the compiler (I'd
              welcome any correction or amplification on this
              point).<note><px>There used to be an issue here in that
              all of K&amp;R C's floating-point operations were
              defined to be done in double-precision -- this made
              things easy for compiler writers, at the expense of
              runtime.  This is no longer true in ANSI C.</px></note>
              </p><p>Thirdly, if your results change if you switch to
              double-precision, then there is an accuracy problem in
              your code, which would probably bear some investigation.
              If there is some part of your code which genuinely
              requires the extra precision -- say because you have to
              add numbers of hugely different scale in accumulating a
              large inner product -- then there is not much you can do
              about it, and that part of your code, at least, must
              have the extra precision.  Failing such an explanation,
              however, you can regard such behaviour as a miner's
              canary, indicating <em>some</em> potential problem with
              your code, which you might benefit from investigating
              further.  </p><p>Fourthly, remember that some algorithms
              are designed to work with single precision, and will no
              longer work properly if you search-and-replace
              <code>double</code> for <code>float</code> or
              <code>real*8</code> for <code>real*4</code>.  As just
              one example, one of the Numerical Recipes algorithms
              (<code>svdcmp</code>) includes a convergence test of,
              essentially, <code>if (val+err==val)</code>.  Whatever
              the merits or otherwise of this as a test, it is a cheap
              way of establishing whether <code>err</code> has reached
              machine precision, which will not work in the expected
              way if <code>val</code> and <code>err</code> are double
              precision.  </p><p>For further details on floating point
              representation, see, for example
              <citation>hauser96</citation>, and informal but very
              useful discussions (both available on the web) by
              William Kahan <citation>kahan96</citation> and Jim
              Demmel <citation>demmel</citation>.  The former is one
              of the authors of the IEEE-754 standard for
              floating-point numbers.  </p></subsubsubsect>

          <subsubsubsect id="s.otherfloat">
            <subhead>
              <title>Other floating-point topics</title>
              <update versionid="v2-1"><px>Added table of compilers
              and enabled IEEE traps</px></update>
              <update versionid="v2-2"><px>Mention that x.ne.x is true
              when x is a NaN</px></update>
            </subhead>

            <p>As well as defining the format in which normal floating-point numbers are
              stored, the IEEE-754 standard includes the definitions for several
              other (classes of) special values.
            </p>

            <p>When the exponent <m notation="latexmaths">e</m> (of a single-precision number) is zero,
              the longword is taken to represent the number
              <mequation notation="latexmaths">  <mlabel id="e.ieeedenorm"/>
                (-1)^s \times 0.m \times 2^{-126}</mequation>
              (compare <ref id="e.ieee1"/>).
              Unlike the usual floating-point numbers, which have an implied leading
              1 in the significand and 23 bits of precision, and which are referred
              to as `normalised', these have an implied leading 0 and less than 23
              bits of precision.  These are `denormal' or `subnormal' numbers, and
              are the result of an underflow, such as dividing the smallest
              normalised number by two.  This behaviour is known as `gradual
              underflow', and allows the precision in a calculation to degrade
              gracefully when it underflows.  It is distinct from `Store-0
              underflow' common before the IEEE standard, in which any expression
              which underflowed was replaced by zero.  This was, and remains, one of
              the more contentious parts of the IEEE standard.  Be warned that older
              Crays, which use their own floating-point format, have a Store-0
              underflow policy, and that the Alpha chip, although it generally
              implements IEEE floats, has a Store-0 underflow as its default mode,
              and will neither produce, nor accept as input, denormalised numbers.
            </p>

            <p>If the significand as well as the exponent is zero, the longword
              represents the number <m notation="latexmaths">(-1)^s \times 0</m>.  Note that the IEEE zero
              is <em>signed</em>, which allows <m notation="latexmaths">1/(+0)</m> and <m notation="latexmaths">1/(-0)</m> to be
              positive and negative infinity; this can be important when doing
              calculations near branch points.
            </p>

            <p>If the exponent is 255 and the significand is zero, the longword
              represents the value <m notation="latexmaths">(-1)^s\times\infty</m>.  That is, infinity has a
              special value, distinct from the largest possible normalised number.
              Positive infinity is generated by, for example <m notation="latexmaths">1/0</m>, or <m notation="latexmaths">\log 0</m>, 
              where infinity is the mathematically correct, but otherwise
              unrepresentable, value of a calculation.
            </p>

            <p>If the exponent is 255 and the significand is non-zero, the
              longword is <em>Not a Number</em>, usually represented by the string
              `NaN'.  A NaN is the result of an operation on invalid operands, such
              as <m notation="latexmaths">0/0</m> or <m notation="latexmaths">\log(-1)</m>.  NaNs have the properties that any
              operation which has a NaN as an operand has a NaN as its result; and
              any comparison on a NaN, such as <code>&lt;</code> or <code>==</code>,
              evaluates to False, including <code>NaN==NaN</code>.  The only exception
              is that, when <code>x</code> is a NaN, then <code>x != x</code> is
              true.  Why would you
              want to use such a peculiar number?  Generally you don't, and its
              appearance in a calculation is an error, which is why processors can
              be set to dump core when a NaN or an Infinity is produced.  However,
              it can be useful to turn off this behaviour if it is not off by
              default, and rather than elaborately avoid producing a NaN at each
              stage, make a check once at the end of a calculation, possibly
              invoking an alternative (possibly more expensive or special-cased)
              algorithm if any NaNs are found.
            </p>

            <p>Different compilers handle exceptional values in different
              ways; see <ref id="t.traptab"/>.  Of the three Starlink platforms,
              only the Alpha traps on exceptional values by
              default.</p>

            <table float="float" id="t.traptab">
              <caption>
                <px>Summary of compiler IEEE traps</px>
              </caption>

              <tabular>
                <tgroup cols="4">
                  <thead>
                    <row>
                      <entry>Compiler</entry>
                      <entry>traps enabled by default</entry>
                      <entry>see</entry>
                      <entry>suppress with</entry>
                    </row>
                  </thead>

                  <tbody>
                    <row>
                      <entry>Sun cc &amp; f77</entry>
                      <entry>none</entry>
                      <entry><code>-ftrap</code></entry>
                    </row>
                    <row>
                      <entry>Alpha cc</entry>
                      <entry>overflow, divide-by-zero, invalid operation</entry>
                      <entry>-fptm, -ieee</entry>
                      <entry>-ieee</entry>
                    </row>
                    <row>
                      <entry>Alpha f77</entry>
                      <entry>overflow, divide-by-zero, invalid operation</entry>
                      <entry>-fpe</entry>
                      <entry>-fpe1</entry>
                    </row>
                    <row>
                      <entry>gcc</entry>
                      <entry>none</entry>
                      <entry><code>-mfp-trap-mode</code> (Alpha-gcc)</entry>
                    </row>
                  </tbody>
                </tgroup>
              </tabular>
            </table>

            <p>We have only scratched the surface of a rather
              intricate topic here.  Both Suns and Alphas have
              extensive <code>f77</code> and <code>cc</code>
              man-pages, which hint at the broad range of
              floating-point options available when compiling and
              linking your code.  See <ref id="s.optimnan"/> for
              discussion of the efficiency tradeoffs when using IEEE
              exceptional values.</p>

          </subsubsubsect>

        </subsubsect>

      </subsect>

      <subsect id="s.progs" export="export">
        <subhead>
          <title>Programming languages</title>
          <update versionid="v2-0"><px>Mention of SUN/209 in the
          context of dynamic memory allocation in Fortran.</px></update>
        </subhead>

        <p>
          <blockquote>
            <px>I speak Spanish to God, Italian to women, French to
            men, and German to my horse. <em>Emperor Charles V</em>
            (attr.)</px></blockquote></p>

        <p>There is no One True Programming Language, nor even One True
          Compromise.
        </p>

        <p>The language you use to write code is as much a function of your
          background, environment and personal tastes, as it is a function of
          technical merit.  At some level or another, all programming languages
          are equivalent, but just as you'd look askance at anyone who wrote a
          stellar atmosphere code in TeX<note><px>Not impossible.  Since
              someone has already done the hard work of implementing a
              BASIC interpreter in TeX (honestly!), you'd simply have to
              port your code to BASIC and let it rip.</px></note>, it's clear that
          some languages are more suited for some tasks than others.
        </p>

        <p>The obvious issue at this point is the choice between
          Fortran and C.  Let me state first of all that, <em>for
          general scientific computing</em>, I do not believe the
          difference between the two is substantial enough, or the
          advantages of each are unqualified enough, that it warrants
          abandoning the language you're comfortable with and learning
          the other.
        </p>

        <p>The languages' respective strengths only become significant
          when you are deep within their `native territories': for
          Fortran this territory is that of numerically intensive
          codes with week-long runtimes, for C it is intricate
          manipulation of data structures.  Away from these extremes,
          the choice is at the level of which to choose for a
          particular application, given that you know both, and an
          ideal application might be said to be one with a Fortran
          heart whirring away in a C harness.
        </p>

        <p>Though Fortran and C are both simple languages, Fortran is
          simple in ways that an optimizing compiler can exploit.
          This means that for a numerically intensive application,
          where processing speed is very important, Fortran is the
          only suitable language.
        </p>

        <p>Why is this?  The reason can be illustrated by the two
          languages' loop semantics.  Fortran's loop is very simple: 
<verbatim>
   do 10, i=1,n
C  process array element a(i)
10 continue
</verbatim>
          The equivalent construction in C is
<verbatim>
    for (i=0; i&lt;n; i++) {
       /* process array element a[i] */
    }
</verbatim>
          The difference is what the two language compilers can say about the
          loop. The Fortran compiler can know that the loop
          will be performed exactly <m notation="latexmaths">n</m>
          times, since neither <code>i</code> nor <code>n</code> may be changed within the loop; also the array <code>a(i)</code>
          cannot overlap with any other array within the loop body.  On the
          other hand, in C, the loop
          <code>for (init; test; increment) { body }</code> is defined to be
          equivalent to 
          the loop <code>init; while (test) {
            body; increment; }</code>, so that both <code>i</code> and
          <code>n</code> could change within the loop, and since <code>a</code>
          could be a 
          pointer, it could point <em>anywhere</em>.  The Fortran
          compiler could 
          rewrite the first loop as
<verbatim>
      do 10, i=1,n,4
C     process array element a(i)
C     process array element a(i+1)
C     process array element a(i+2)
C     process array element a(i+3)
   10 continue</verbatim>
          cutting the number end-of-loop tests by a factor of four (this is a
          simple example of `loop unrolling', and presumes that <m
            notation="latexmaths">n</m> is divisible by 4).  The loop
          semantics could also make the elements of the loop 
          candidates for parallelization, if the compiler and hardware support
          that<note><px>Note that, with pipelining, RISC chips can typically
              support some degree of on-chip parallelization, even for a single
              CPU.</px></note>.
          The C compiler has to do a lot more investigative work before
          it can make any similar rearrangements.
        </p>

        <p>Even if there were no such fundamental differences, the fact would
          remain that Fortran vendors have always sold their products on the
          strength of their optimizers, so that it is both easier <em>and</em>
          profitable for Fortran compilers to produce very fast code.
        </p>

        <p>Though C's loop semantics are troublesome, it is really the pointer
          type which causes a lot of the trouble -- since a pointer is little
          more than an address, the compiler can have little clue what the
          programmer is aiming to do with it, and so has little choice but to
          make a literal translation of the C code into assembler.
        </p>

        <p>The pointer type is redeemed, however, because it is this which
          allows C to code complicated data structures so naturally: not only
          aggregate types, but linked lists, queues, and all the other ways of
          holding, reading, parsing and generally juggling data, so beloved of
          Computer Science 1.
        </p>

        <p>Fortran 90/95 goes some way towards addressing Fortran's
          weaknesses by introducing pointers (though the fact that
          they're living in a Fortran code doesn't make them any less
          troublesome to an optimizer), as well as proper data
          structures and some modularisation.  At the same time as
          Fortran does that, however, C++ uses object-orientation to
          further enhance C's advantages in data manipulation, going
          so far as to make functions auxiliary features of data
          structures.
        </p>

        <p>For general discussions of the issues involved in high-performance
          computing, see the book <cite>High Performance Computing</cite>
          <citation>dowd</citation>.
        </p>

        <p>Starlink ensures that C, C++, Fortran 77 and Fortran 90/95 compilers
          are available at all sites.
        </p>

        <subsubsect id="s.fortran77">
          <subhead>
            <title>Fortran 77</title>
            <update versionid="v1.1"><px>Added
                pointers to Fortran standard
                document.</px></update>
          </subhead>

          <p>Fortran 77 is probably the dominant current Fortran dialect,
            replacing earlier standards such as Fortran IV and Fortran 66<note><px>A
                statement like that can't be made without some qualification.
                Depending how you added it up, you could probably make a case that old
                Fortran dialects probably have more code actually running on CPUs,
                since many heavily-used libraries were written a long time
                ago.</px></note>.  There are several dialects of Fortran, containing
            various vendors' language extensions, but the only extensions which
            are usually portable are those in VAX Fortran, which includes the
            <code>enddo</code> statement for terminating do-loops, and the
            <code>%val()</code> function which is necessary to intermix Fortran
            and C code (see <ref id="s.candf"/>).
          </p>

          <p>The <webref url="http://www.fortran.com/fortran/F77_std/rjcnf.html">standards document for Fortran 77</webref> is not exactly bedtime reading,
            but can be quite useful when you have forgotten details of syntax,
            especially to make sure what you are writing is correct rather than
            just allowed by the compiler you are using at the time.  As an
            introduction to Fortarn 77, I've heard good things about
            <citation>metcalf85</citation>. [<ref
            id="ta.mbt">MBT</ref>]</p>

          <p>An important deficiency in Fortran is its lack of any
            standard way of dynamically allocating memory (as opposed
            to allocating arrays to be a fixed size at compile time).
            The Starlink CNF library, <docxref doc="SUN/209"
            loc="pointers" >SUN/209</docxref> is intended to make
            this reasonably easy, and includes a brief discussion of
            the underlying mechanism.  This is rather a can of worms,
            but the essential technique is to write a bit of C which
            obtains a pointer to a block of memory via a call
            <code>malloc</code>, return that pointer to the Fortran
            program as an integer, then use <code>%VAL()</code> to
            supply that integer as an argument to a function which is
            expecting an array.  This is non-standard (and not likely
            to become standard, now that Fortran 90 includes its own
            mechanisms for dynamic memory allocation), but it is a
            well-established technique and therefore probably more
            portable than you have any right to expect.</p>

          <!--
          <p>Dynamic memory allocation in Fortran: 
          How about a section on hacking dynamic memory allocation in Fortran 77,
          since it's the one thing that you really can't do if you stick to the
          standard?  I don't know whether it makes sense to go into detail, but it
          could be useful to mention what the options are, e.g. vaxisms 
          (or other non- standard constructs) and where you can expect 
          them to be supported, using Starlink CNF, writing your own fortran 
          wrapper for malloc, DIY allocation from a statically allocated 
          common block.  On the other hand it's a bit of a can of worms,
          perhaps it's getting a bit specific for a document like this. (MBT)
          -->

          <p>There is a large number of introductions to Fortran, but not, I
            believe, a single preeminent one.  The
            <cite>Starlink application programming standard</cite>,
            <docxref doc="SGP/16" text="SGP/16" />,
            is a collection of programming style guidelines for Fortran,
            and includes further references.
          </p>

          <p>There is a reasonable amount of online information on
            Fortran, which is well-covered at the `Fortran Market'
            (<url>http://www.fortran.com/fortran/info.html</url>),
            which includes several Fortran FAQs.
          </p>

        </subsubsect>

        <subsubsect id="s.fortran90">

          <subhead><title>Fortran 90/95
            </title></subhead>

          <p>Almost immediately after Fortran77 was standardised, work began on
            its successor.  Although this project was named Fortran 8X, the work
            took long enough that the final standard was named Fortran 90.
          </p>

          <p>The Fortran standard is maintained by ISO committee
            <webref url="http://www.nag.co.uk/sc22wg5/">JTC1/SC22/WG5</webref>,
            and the current version of the standard is
            <webref url="http://www.nag.co.uk/sc22wg5/IS1539-1_1997.html">ISO/IEC
              1539-1 : 1997</webref>.</p>

          <p>Fortran 90 was an attempt to respond to the numerous developments in
            language design, seen since Fortran's last standardisation in the
            sixties and seventies.  In contrast to Fortran 77, which aimed to
            standardise existing practice, Fortran 90 was an attempt to push
            forward the development of Fortran as a language.  A summary of the
            new features (adapted from <citation>metcalf96</citation>) is:
            <ul>
              <li>
                <p>Free format source code form (no more
                  column-counting).</p>
              </li>

              <li><p>A means for the language to evolve by labelling some features as
                  `obsolescent'.</p></li>

              <li><p>Array operations (for example,
                  <code>X(1:N)=R(1:N)*COS(A(1:N))</code>).</p></li>

              <li><p>Pointers.</p></li>

              <li><p>Improved facilities for numerical computation
                  including a set of numeric enquiry
                  functions.</p></li>

              <li><p>User-defined derived data types composed of arbitrary data
                  structures and operations upon those
                  structures.</p></li>

              <li><p>Facilities for defining collections called
                  `modules', useful for global data definitions and
                  for procedure libraries.  These support a safe
                  method of encapsulating derived data types.
                  Operator overloading and prototyping.</p></li>

              <li><p>Requirements on a compiler to detect the use of
                  constructs that do not conform to the syntax of the
                  language or are obsolescent.</p></li>

              <li><p>New control constructs such as the <code>select
                  case</code> construct, an <code>exit</code> and a
                  new form of the <code>do</code>.</p></li>

              <li><p>The ability to write internal prodedures and
                  recursive procedures, and to call procedures with
                  optional and keyword arguments.</p></li>

              <li><p>Dynamic storage (automatic arrays, allocatable
                  arrays, and pointers).</p></li>

              <li><p>Improvements to the input-output facilities,
                  including handling partial records and a
                  standardized <code>namelist</code>
                  facility.</p></li>

              <li><p>Many new intrinsic procedures, (date, precision,
            arrays, ...)</p></li>
            </ul>
          </p>

          <p>Fortran 90 is backwards compatible with Fortran 77, so
            that every <em>strictly</em> conformant Fortran 77 program
            is also a valid Fortran 90 program.  However, many of
            Fortran 77's odder features are strongly deprecated, and
            may disappear in the next revision of Fortran, due to
            appear sometime in the next decade.  Fortran 95 is a minor
            revision of Fortran 90.
          </p>

          <p>There is an increasing number of books on Fortran 90/95;
            for a booklist, refer to the Fortran Market at the URL
            above.  I am, of course, reluctant to recommend books I
            have not used myself, so I will simply note that I have
            heard good things about <citation>metcalf96</citation>,
            and that the first author was prominent in the
            negotiations concerning the development of the Fortran 90
            standard.</p>

          <p>If you plan to use Fortran 90/95, but avoid the
            deprecated parts of Fortran 77 altogether, you might be
            interested in <webref
            url="http://www.swcp.com/~walt/imagine1/">F</webref>,
            which is a subset of Fortran 90 with all the deprecated
            features removed.  You can obtain an F compiler from
            Imagine1, including a free educational version for
            Linux.</p>

          <p>Several Fortran compilers were reviewed in a short
            <webref
            url="http://www.liv.ac.uk/HPC/FortranCompilerStudyHTML/FortranCompilerStudyHTML.html">report</webref>
            of January 1997 by the high performance computing project
            at Liverpool.</p>

          <p>It is occasionally necessary to produce code in a mixture
            of Fortran and C.  See <ref id="s.candf"/>.</p>

        </subsubsect>

        <subsubsect id="s.c">
          <subhead>
            <title>C</title>
          </subhead>

          <p>There are hundreds of books on C, but the only
            <em>essential</em> one is the Kernighan and Ritchie book
            <citation>kr</citation> (also known as just `K&amp;R').
            This is a very short book, by the authors of the language,
            which combines a tutorial introduction with a detailed
            reference to the language and its standard libraries.  I
            believe it's the only C book you'll ever need.
          </p>

          <p>The book's compression makes it possible, and even
            advisable, to read it from beginning to end.  It avoids
            the bloat found in many other C books by not teaching you
            how to program, by never saying anything twice, and by
            never attempting the empty reassurance that `it's all
            easy, really'; its examples often illustrate more than one
            point at a time, and culminate in a sample implementation
            of the library function <code>malloc</code>.  Science
            textbooks don't talk down to you; I don't see why computer
            texts should be excused for doing so.
          </p>

          <p>It follows from this that K&amp;R is not necessarily the
            ideal recommendation for someone new to programming, who
            might need something a little more comprehensive.  My
            recommendation in that case is to find an introductory C
            (or even general programming) book which covers what you
            want without irritating you, and use that up to the point
            where you feel comfortable with K&amp;R.
          </p>

          <p>C allows the programmer a considerable degree of freedom
            in how an algorithm is expressed.  The fact that this
            freedom is easily abused makes style guides more common
            for C than for other languages.  Starlink has adopted
            <cite>The Elements of C Programming Style</cite> by Jay
            Renade and Alan Nash as its principal C programming
            standard, as well as producing a compact collection of
            programming style suggestions in <docxref doc="SGP/4"
            text="SGP/4" />.
          </p>

          <p>One way of making your life easier in this respect is to
            be consistent about using current standard ANSI-C.  See
            <ref id="s.compilers"/>.
          </p>

          <p>The C language as originally designed by Kernighan and
            Ritchie was standardised as ANSI-C in 1990 (K&amp;R 2nd
            edition describes the latter).  This standard is currently
            being revised by an ISO working group with the memorable
            name <webref
            url="http://std.dkuug.dk/JTC1/SC22/WG14/">ISO/IEC
            JTC1/SC22/WG14 -- C</webref>.  One of the motivations to
            the work is to provide better support for floating point
            calculations in C, such as defining a standard interface
            to the IEEE floating point exceptions.
          </p>

          <p>The excellent <webref
            url="http://www.eskimo.com/%7Escs/C-faq/top.html">C
            FAQ</webref> contains <em>substantially</em> more than you
            realised you wanted to know about C.  It contains detailed
            discussions of both common and arcane problems.
          </p>

        </subsubsect>

        <subsubsect>
          <subhead><title>C++ and object orientation</title></subhead>

          <p>C++ is an object-oriented version of C, and was finally
            standardised in 1997.  Compiler makers have tracked the developing
            standards, so that recent C++ compilers should conform pretty
            closely to the standard even if they formally pre-date it.
          </p>

          <p>Object-orientation is the notion that functions are
            <em>attached to</em> data, rather than simply operating on
            them.  For example, if a C program were to declare a data
            type <code>Array</code>, and initialise a variable of that
            type with <code>Array a;</code> then one can imagine a
            function to return the determinant of the array, declared
            as <code>float determinant (Array a);</code>.  In C++, the
            `function' to obtain the determinant could be declared as
            <em>part of the data type</em>, and obtained via the
            expression <code>a.determinant()</code>.  There are two
            main points to this.  Firstly, the so-called `member
            function' <code>determinant</code> can have privileged
            access to the internal representation of the data type
            <code>Array</code>, so that other parts of the program
            need not, and may not, manipulate that representation,
            erroneously or otherwise.  Secondly, and consequently, the
            representation and matching member functions can be
            <em>changed</em> with the guarantee that the rest of the
            program will be unable to tell the difference.  This is
            characterised in the remark that new programs have always
            been able to use old code (in libraries), but
            object-oriented approaches mean that old programs can use
            new code (when an implementation changes, while the
            interface remains the same).
          </p>

          <p>Of course, both of these points are to some extent true
            of traditional programming languages -- indeed I'd doubt
            that there's anything you can do in C++ which you couldn't
            do with some ingenuity in C -- but the point is that they
            are much easier, and much more natural, in C++.
          </p>

          <p>It may be clear at this point that C++ is not a
            beginner's language.  The result of grafting a high-level
            abstraction onto portable assembler is a language with far
            more syntax than is healthy.  Do not feel you need to
            learn C before C++-- they are closely enough related that
            the differences can be confusing.  My feeling, however, is
            that you should consider learning <ref
            id="s.java">Java</ref>first if you have the time: there is
            relatively little that needs to be unlearned going from
            Java to C++, and Java's simplicity makes it easier to come
            to grips with object-orientation, without drowning in a
            sea of punctuation.
          </p>

          <p>The excellent <webref
            url="http://www.parashift.com/c++-faq-lite/">C++
            FAQ</webref> includes book recommendations.  The canonical
            book for C++, with the same status K&amp;R has for C, is
            <cite>The C++ Programming Language</cite>
            <citation>stroustrup</citation>, by the language's author.
            However, I find Stroustrup's book rather irritating: it's
            rather badly organised, and the index is
            <em>dreadful</em>.
          </p>

          <p>Note, by the way, that the C++ compiler on Suns is named
            <code>CC</code>, on Alphas named <code>cxx</code>, and on
            Linux named both <code>c++</code> and
            <code>g++</code>.</p>

        </subsubsect>

        <subsubsect id="s.java">
          <subhead>
            <title>Java</title>
            <update versionid="v1.1"><px>Added a description of Java's model of
                compiling to interpreted bytecodes, to the extent that this relates to
                efficiency and speed.</px></update>
            <update versionid="v2-0"><px>Pointed out that JITs make Java a candidate for high-end codes,
                pointing to the Java Grande Forum for
            details.</px></update>
            <update versionid="v2-3"><px>Hoisted the Java section up a level, and added some remarks about
                efficiency and profiling.</px></update>
          </subhead>

          <p>Java was developed by Sun and at present (mid-2002)
            eclipsed only by XML as the current Big Thing.  Source
            code is compiled to machine-independent bytecode, which is
            then either interpreted, or compiled to machine code on
            the fly, by a Java Virtual Machine (JVM) on a particular
            platform.  The main interest to astronomy might be in
            developing machine- and architecture-independent
            interfaces either to codes or archives.  It's also, I
            think, of use as a stepping-stone to C++, since its
            object-oriented features are less obscured by syntax than
            they are in C++.  A very good textbook, written (you won't
            be surprised to guess) by two of the language's authors,
            is <cite>The Java Programming Language</cite>
            <citation>arnold98</citation>; once you've mastered the
            basics, there's a good deal of helpful advice in
            <cite>Effective Java</cite> <citation>bloch01</citation>.
            There are numerous resources at Sun's Java site at
            <url>http://java.sun.com</url>.
          </p>

          <p>Java is a mixture of an interpreted and a compiled
            language.  Java source code is compiled by the Java
            compiler into bytecodes, which are then interpreted by a
            Java Virtual Machine.  These bytecodes are low-level, but
            architecture-independent so that, in principle, only the
            virtual machine and its runtime need to be ported to a new
            machine, whereas the code should be completely portable.
            This does not work quite as well in practice as it does in
            principle, but it does mean that Java is not too far off
            the ideal of run-anywhere code.
          </p>

          <p>Since Java bytecodes are ultimately interpreted, Java
            programs have the potential to be rather inefficient.
            However, just-in-time compilers (JIT), which analyse
            running code and optimize the most heavily-used parts, and
            similar developments, should help the situation improve in
            the future.  This is possible because JITs have access to
            both the program source code and the running program, and
            so can combine the features of both an optimizer and a
            profiler, and thus optimize more aggressively than a
            traditional compiler could.  This, combined with Java's
            good built-in support for different platforms and for
            resource-discovery, means that, possibly somewhat
            surprisingly, Java has been suggested as a suitable
            language for high-end codes.  The <webref
            url="http://www.javagrande.org/">Java Grande
            Forum</webref> is concerned with investigating and
            promoting developments in this area.</p>

          <p>Note that it is relatively easy to write slow Java (for
            example, adding Strings is a <em>lot</em> slower than
            using a StringBuffer; input and output streams are not
            (extensively) buffered, so if you have a lot of I/O, you
            would be well advised to use
            <code>Buffered{Input,Output}Stream</code> objects wrapping
            your I/O objects; small-object creation is extensively and
            increasingly optimised, but it's still not dirt-cheap, so
            look out for that in a small loop).  That means that using
            a profiler (see <ref id="s.profiling"/>) is particularly
            important.  However, with Java, that's easy, because
            there's one built in to the JVM.  Give the option
            <code>-Xrunhprof:help</code> to find out how to invoke it.
            For example: <verbatim>java
            -Xrunhprof:cpu=samples,file=myprog.hprof
            myclass</verbatim> There's quite a lot of information in
            here (and the file format is under development), but as
            with all profilers, you'll see a list of the number of
            times various methods were called: the ones at the top of
            the list are the ones where the program spent most of its
            time, so work out why, and concentrate on making them
            faster.  Ignore the rest.</p>

          <p>Java is still developing.  At present (mid-2002) Java
            1.3.1 is long in the tooth but stable.  Version 1.4 is in
            beta, and on the point of being released properly; it
            includes a few changes to the language, most noticeably
            the inclusion of an <code>assert</code> construct.
          </p>

        </subsubsect>

        <subsubsect id="s.otherlang">
          <subhead><title>Other languages</title></subhead>

          <p>C and Fortran cover most of the bases for scientific computing, but
            there are one or two others which come in useful occasionally.
          </p>

          <subsubsubsect id="s.sedawk">
            <subhead><title>awk and sed</title></subhead>

            <p>Often, you can find yourself performing some repetitive
              editing task, for example massaging data into a form
              which a program can conveniently read.  Such tasks can
              conveniently, and reliably, be done by programs such as
              <code>awk</code> and <code>sed</code>.  Neither of these
              utilities is as well-known as it should be, as they can
              save a great deal of tedious and error-prone effort.
            </p>

            <p><code>sed</code> is a version of the <em>very</em>
              simple editor <code>ed</code>, which is specialised for
              performing edits on a stream of text.  For example, the
              following rather elaborate <code>sed</code> script
              prints all the section headings from a LaTeX document:
              <blockquote><px><verbatim>sed -n
              's/^\\\(sub\)*section{\(.*\)}.*$/\2/p'
              sc13.tex</verbatim></px></blockquote> This may look like
              gibberish, but it is simpler than it looks.  The option
              <code>-n</code> instructs <code>sed</code> not to print
              out input lines, which it does by default.  The
              <code>sed</code> expression in quotes calls the
              <code>s</code> command: whenever the `regular
              expression' between the first pair of slashes matches,
              the <code>s</code> command replaces it with the
              expression between the second pair and, because the
              <code>s</code> command is suffixed with a
              <code>p</code>, prints out the modified line.  The
              regular expression matches lines which start with a
              backslash, have zero or more occurrences of the string
              `sub', which is followed by the string
              `<code>section{</code>', then any sequence of
              characters, followed by a <code>}</code> then any
              characters, ending at the end of the line.  The caret
              <code>^</code> matches the beginning of a line, the
              backslash is a special character, so that it must be
              `escaped' by prefixing it with another backslash,
              <code>\\</code>, the grouping operators are
              <code>\(</code> and <code>\)</code>, the asterisk
              indicates that the previous (bracketed) expression may
              be present zero or more times, the dot matches any
              character, and the dollar matches the end of the line.
              As well as grouping, the parentheses save what they
              match, and the expression <code>\2</code> in the
              replacement text refers to what the second pair of
              parentheses matched, namely the text between the curly
              braces.  The overall result is that the matched string
              (the whole of the line) is replaced by the contents of
              the braces and then, because of the <code>p</code>
              suffix, printed.
            </p>

            <p>Another useful tool is <code>awk</code>, named after
              its designers Aho, Weinberger and Kernighan.  Like
              <code>sed</code>, it works through a text file,
              executing scraps of code whenever a line matches some
              condition.  Before it does anything with a line, it
              breaks it into fields, separated by whitespace by
              default.  Consider the following example<note><px>There
              are two versions of <code>ps</code> on Suns -- this
              example assumes you are using the
              <code>/usr/ucb/ps</code> version.</px></note>

<verbatim>
ps u | sed 1d | \
   awk '{print $4, $0; totmem+=$4}; END {printf "total memory: %f\n", totmem}'
</verbatim>
              This (not terribly useful) line generates a process
              listing using <code>ps</code>, uses <code>sed</code> to
              delete the first line (that is, it executes the command
              <code>d</code> on line number 1), and then passes the
              result through the <code>awk</code> program contained in
              quotes.  On every line, this prints field number 4 (the
              <code>%MEM</code> column in the listing) and field 0
              (which is <code>awk</code>-speak for the whole input
              line), and adds the value of the fourth field to a
              running total; on the line matching the pattern
              <code>END</code> -- that is, the pseudo-line at the end
              of the file -- <code>awk</code> prints out the
              accumulated total.
            </p>

            <p>You won't typically generate expressions as complicated
              as these on the fly (at least, not until you get
              <em>really</em> good).  This example is intended to
              suggest that you can, in aliases or in scripts, perform
              quite complicated transformations of text files.  For
              further details you could look at the <code>sed</code>
              or <code>awk</code> man-pages, which are complete but
              very compressed, or work through a tutorial in your
              system's printed documentation.  There are several
              guides to <code>sed</code> and <code>awk</code>, but you
              might be best off, initially, using an advanced
              introduction to Unix, such as
              <citation>quigley</citation> or
              <citation>nutshell</citation>.  The canonical
              documentation for regular expressions is on the
              <code>ed(1)</code> manual page.
            </p>

          </subsubsubsect>

          <subsubsubsect>
            <subhead><title>Perl</title><update
            versionid="v1.1"><px>Added pointer to the Schwartz
            reference, and a description of Perl's
            compile-then-interpret model.</px></update></subhead>

            <p>Perl is a general-purpose scripting language.  It
              started off as a text-reformatting facility, rather like
              a super-<code>awk</code>, but it has now grown to the
              point where it really is a programming language in its
              own right, capable of supporting quite substantial
              projects.  Perl programmers can call on a huge range of
              supporting code, collected at the Comprehensive Perl
              Archive Network, <webref
              url="http://www.cpan.org">CPAN</webref>, to do
              everything from internet programming to database access.
              Perl's expressive power makes it ideal for rapid
              development of all sorts of complex systems -- some huge
              proportion of the web's CGI scripts, for example, are
              written in Perl.  Unfortunately, the flexibility of
              Perl's syntax make it quite possible to write spaghetti,
              the like of which we have not seen since Fortran IV
              dropped out of fashion.  </p>

            <p>The Perl manual pages
              are reasonably clear.  O'Reilly publishes a good book on
              Perl, written by Larry Wall, its author
              <citation>wall</citation>.  This is a good reference
              book, but <citation>schwartz97</citation> is possibly a
              better tutorial introduction.  Perl regular expressions
              are <em>slightly</em> different from the ones used by
              <code>sed</code> and friends -- see the
              <code>perlre</code> manual page.  </p>

            <p>Perl is a
              semi-interpreted language.  Somewhat like Java, when the
              Perl interpreter first processes your Perl script, it
              compiles it to an internal code, which it then proceeds
              to interpret.  This means that Perl programs have a
              relatively long startup time, but run reasonably
              efficiently after that.  This is not a big issue in most
              applications.  </p>

            <p>The current (end-2001) version of
              Perl is 5.6 or thereabouts.  Perl 6 will be a
              significant step in the evolution of the language: it's
              in the offing, but still some way away.
              </p>

          </subsubsubsect>

        </subsubsect>

      </subsect>

      <subsect id="s.codetopics" export="export">
        <subhead>
          <title>Code topics</title>
        </subhead>

        <p>Several of the topics mentioned here are discussed at greater length
          in the Sun Fortran User's Guide <citation>sunf77</citation>, which is of interest
          even if you program only in C.
        </p>

        <subsubsect id="s.profiling">
          <subhead><title>Profiling</title></subhead>

          <p>Before you start doing any optimization at all, check which parts of
            your code are slowing the machine down -- there's no point in
            tweaking, for example, a one-time initialisation routine which takes
            only a tiny fraction of the program's runtime.  You do this by using a
            profiler.
          </p>

          <p>Different compilers will invoke a profiler (presuming
            they have one) in different ways.  The Sun and Digital
            Fortran compilers include profiling code if you give the
            option <code>-pg</code> to the <code>f77</code> command.
            Compile <em>and</em> link the program with this option (if
            you wish, you can compile only those modules you want to
            profile with the <code>-pg</code> option, but you must
            include the option in the final link command), and then
            run it.  This run will create a file <code>gmon.out</code>
            in your current directory.  Then you can run
            <code>gprof</code>.  Taking as example the programs in
            <ref id="a.profiling"/>, we can build and profile them as
            follows:
          
<verbatim>
% f77 -pg -o timewaster p1.f p2.f p3.f
p1.f:
MAIN silly:
p2.f:
mkidentity:
p3.f:
determinant:
Linking:
% timewaster
1.00000
% ls 
gmon.out        p1.o            p2.o            p3.o
p1.f            p2.f            p3.f            timewaster*
% gprof timewaster &gt;timewaster.gprof
</verbatim>
          </p>

          <p>The output file <code>timewaster.gprof</code> is many lines long, even
            though the program is so short!  The file contains a great deal of
            information, but buried amongst it is the following display (from the
            Sun profiler, trimmed):
<verbatim>
called/total       parents 
index  %time    self descendents  called+self    name    	index
called/total       children

0.05        0.64       1/1           main [2]
[1]     97.2    0.05        0.64       1         MAIN_ [1]
0.64        0.00  100000/100000      mkidentity_ [4]
0.00        0.00       1/1           __s_wsle_nv [167]
0.00        0.00       1/1           determinant_ [8]
0.00        0.00       1/1           __do_l_out [157]
0.00        0.00       1/1           __e_wsle [158]
 -----------------------------------------------
0.64        0.00  100000/100000      MAIN_ [1]
4]     90.1    0.64        0.00  100000         mkidentity_ [4]
</verbatim>
            This indicates that the subroutine <code>mkidentity</code>
            was called 100000 times from the main program, and that
            90.1% of the time -- a total of 0.64 seconds -- was spent
            in that routine.  Were this a real project, this would
            indicate that this routine would be a good one to examine
            for speedups.
          </p>

          <p>This example, and a further one using the
            <code>tcov</code> utility, were taken from
            <citation>sunf77</citation>, which might be consulted for
            further details.  <code>pixie</code> is the corresponding
            utility on Compaqs -- see its man-page for details [<ref
            id="ta.rw">RW</ref>].
          </p>

          <p><code>gprof</code> is not specific to Sun, but is
            available for other architectures, and other compilers
            (including <code>gcc</code>) as well.
          </p>

        </subsubsect>

        <subsubsect id="s.optim">
          <subhead><title>Optimization</title></subhead>

          <p>Just say no!  Or, if you need authority:
            <blockquote><attribution>Donald Knuth, in <cite>Literate
            Programming</cite></attribution><px>Premature optimization
            is the root of all evil.</px></blockquote>
          </p>

          <p>The first thing to ask yourself, when you are considering
            performance enhancements on your code is `do I really need
            to do this?'.  You should only attempt optimizations once
            you have either identified a particular part of your code
            which needs improving, or else you <em>know</em> that you
            can write the efficient version of the code correctly.  If
            the `efficient' version is unnatural, then the savings in
            runtime you achieve by reordering the code have a good
            chance of being wiped out by the time spent debugging a
            convoluted juggling act.  Within reason, prefer simplicity
            and robustness to efficiency<note><px>However, there is
            <em>no</em> excuse for Bubble Sort!</px></note> -- get
            your code working correctly and believably, and only then
            start worrying about speed.  That way, if you later
            establish that you need to work on part of the code, you
            at least have a trusted set of results to check the new
            version's against.  Another way of putting this is that
            it's easier to optimize correct code than it is to correct
            optimized code.
          </p>

          <p>If you're writing a code which will run for days or more,
            then it might be worthwhile investing a significant effort
            in tuning your code for performance.  Doing this properly
            might involve you learning more about your machine's
            architecture than you might enjoy, and as as result will
            make your program less portable to the next generation of
            whizz-bang hardware, or even the next compiler.
          </p>

          <p>It is generally worthwhile to use hand-optimized
            routines, if they are available for your compiler.  Where
            this can pay particularly good dividends is in the case of
            linear algebra, where the speed of a calculation can be
            significantly improved (`a factor of several') by routines
            carefully written to access memory in an optimal way.
            There is a standard interface to such routines called the
            BLAS (Basic Linear Algebra Subroutines), which your
            compiler documentation may mention.<!--XXX : find info
            about BLAS from the Sun and Alpha compiler docs, and check
            these Netlib URLs.  Mention LAPACK? --> Although it won't
            be as fast as a machine-specific implementation, the free
            <webref url="http://www.netlib.org/blas/">BLAS
            implementation at Netlib</webref> (<webref
            url="http://sunsite.doc.ic.ac.uk/packages/netlib/blas/index.html">UK
            mirror</webref>) should speed your codes up
            significantly. [<ref id="ta.mbt">MBT</ref>,<ref
            id="ta.rw">RW</ref>]
          </p>

          <p>The first lesson to learn about optimization is that the
            compiler can probably do it better than you can.
          </p>

          <p>Most compilers will have a <code>-On</code> option, to
            allow you to set how aggressive the compiler's
            optimization will be.  The GNU gcc compiler, for example,
            allows optimization levels 1, 2 and 3, and Solaris Fortran
            has five levels, which progressively enable more
            techniques for improving your program's execution speed.
            Compaq compilers have a `<code>-tune host</code>' option,
            to produce code optimized for a particular machine. [<ref
            id="ta.mbt">MBT</ref>]
          </p>

          <p>If your program starts behaving oddly, at some point you
            should start worrying about errant optimization, if you
            have that turned on.  Optimization works by the compiler
            recognising patterns in your code, and possibly
            rearranging the output assembly language to take advantage
            of these.  If it gets this wrong (because there's a bug),
            if your program relies on a particular floating-point
            behaviour, or if you're doing something sufficiently weird
            with your programming language that you manage to confuse
            the compiler, then you could trick it into doing the wrong
            thing.
          </p>

          <p>Specifically, if you have occasion to worry about the
            order in which expressions are evaluated -- for example to
            conserve precision, as described in <ref id="s.accuracy"/>
            -- then you should be very wary of optimization, as one of
            the first things an optimizer <em>might</em> do is to
            reorder expressions which are associative mathematically
            but not computationally.  If you have some code like this,
            it might be best to isolate a single routine in a module
            of its own and compile it separately with its own
            appropriate optimization level.
          </p>

          <p>Parallelization is another type of optimization.  Just
            say no several times to this, but if you have an
            application which really needs it, then buy a book and
            some aspirins.  See <ref id="s.ncbooks"/>.
          </p>

          <p>Although you should generally leave optimization to the
            compiler, there are some things you can do to at least
            avoid getting in its way.
          </p>

          <subsubsubsect>
            <subhead>
              <title>Avoid using the <code>register</code> keyword in
                C</title>
              <update versionid="v1.1"><px>Rewritten following
                comments</px></update>
            </subhead>

            <p>This is, historically, supposed to suggest to a
              compiler that a particular variable might be better
              stored in a register than in main memory, though the
              actual semantics defined in the C standard is that the
              keyword is an assertion that the program nowhere takes
              the address of the variable so qualified.  Such an
              assertion means, amongst other things, that the variable
              will never be visible from any other functions, which
              might trigger other optimizations. [<ref
              id="ta.sg">SG</ref>]
            </p>

            <p>You do not need to use this keyword to actually suggest
              to the compiler that it store the variable in a
              register, since the compiler might well do this anyway,
              and have a better idea of which (non-obvious, or
              temporary) variables to choose than you have.<!--XXX :
              discuss this with Sergio -->
            </p>

          </subsubsubsect>

          <subsubsubsect id="s.arrays">
            <subhead>
              <title>Walk through arrays in the correct order</title>
              <update versionid="v1.1"><px>Updated/corrected comments
              on page faults by adding MBT's comments on cache
              faults.</px></update>
            </subhead>

            <p>A multi-dimensional array is necessarily stored in
              memory as a linear array.  If you have to process this
              entire array, it will be fastest if you try to do so in
              the order in which the array is stored.  Fortran arrays
              are stored with the leftmost index varying fastest.
              That is, the Fortran array <code>integer i(2,2)</code>
              will be stored in memory in the order
              <code>i(1,1)</code>, <code>i(2,1)</code>,
              <code>i(1,2)</code> and <code>i(2,2)</code> </p>

            <p>Take,
              for example the Fortran array <code>integer
              ia(1000,1000)</code>.  If you run through this array
              with the first index changing fastest, as in the
              following fragment <blockquote><px><verbatim> do 10,
              j=1,1000 do 20, i=1,1000 call some_calc (ia(i,j)) 20
              continue 10 continue</verbatim></px></blockquote> then
              you will move through the array in the `natural' order.
              If, however, you process it in the other order, with the
              second index changing fastest, then when you move from
              <code>ia(i,j)</code> to <code>ia(i,j+1)</code>, the
              computer will have to jump 1000 places forward in the
              stored array, each time round the loop.  This would not
              matter <em>too</em> much if the entire array were stored
              in physical memory, but this will not be the case for
              any sizable matrix, so that to find the appropriate
              array element, the machine may have to reload part of
              its memory from a saved version on disk.  Such input is
              relatively slow, and if the calculation is laid out in
              such a way that this happens repeatedly in an inner
              loop, which is executed many times by an outer loop,
              then there can be a significant impact on your program's
              performance.  </p>

            <p>This system of swapping memory back
              and forth to disk is known as `virtual memory', and the
              machine's discovery that the memory it needs is swapped
              out is known as a `page fault', and is one of the
              important statistics about the run of your program.  You
              can obtain such statistics in copious detail by using
              the compiler's profiler (see <ref id="s.profiling"/>),
              or quickly by using the <code>time</code> command (see
              your system's <code>time</code> man-page for details --
              not all versions provide this information by default).
              </p>

            <p>Of course, it's not really as simple as just
              that.  Even when the entire array <em>is</em> stored in
              physical memory, or when you have rearranged your
              program to minimise the number of page faults, it can be
              important not to hop about in arrays too much.  Modern
              architectures will typically have a small amount (modern
              PCs around half a Mb, biggish servers around 8 Mb) of
              memory called `cache' which has much faster access time
              (typically an order of magnitude or more) than the bulk
              of the RAM.  The relationship between this and core RAM
              is strongly analogous to the relationship between core
              RAM and disk, in that cache-lines (which are like memory
              pages, but typically only a few words long) get swapped
              in and out of it when one word from the line is
              required.  The upshot of that is that it's important to
              avoid hopping about over distances much smaller than an
              I/O page since, even if you have no page faults, cache
              faults make a huge difference.  And of course it's not
              as simple as that either -- sometimes there are two
              levels of cache, some architectures implement some sort
              of prefetching, and so on.  Except with some rather
              sophisticated profilers (which generally have to be
              supported by a processor architecture which keeps a
              record of these things) it's not really possible to see
              how many cache faults you're getting, except by writing
              the code more efficiently and seeing what the difference
              is.  [<ref id="ta.mbt">MBT</ref>] </p>

            <p>Unlike Fortran,
              C arrays are stored with the <em>rightmost</em> index
              increasing fastest, so that the array <code>int
              i[2][2]</code> will be stored as <code>i[0][0]</code>,
              <code>i[0][1]</code>, <code>i[1][0]</code> and
              <code>i[1][1]</code>.  </p>

          </subsubsubsect>

          <subsubsubsect id="ss.io">

            <subhead>
              <title>I/O</title>
              <update versionid="v1.1"><px>Added
                  remarks and examples on raw IO</px></update>
              <update versionid="v2-0"><px>Checked
                  fwrite/fread syntax, and discussed unformatted IO in
                  Fortran.</px></update>
            </subhead>

            <p>Input and output are slow, and the faster processors become, the
              bigger is the cost of I/O relative to CPU cycles.  That means you
              should think twice before writing out intermediate results, for reuse
              later in the same calculation or another.  For example, it's quite
              easy to fall into the trap of `saving time' by reading in a
              precalculated table of values, without realising that it can take more
              time to read the file than it would take to recalculate the table from
              scratch each time.  Remember that computers don't get bored, and don't
              mind doing the same calculation repeatedly.
            </p>

            <p>If you do need to save values for later use, and don't
              mind doing it only semi-portably, you can save time and
              precision by using raw I/O rather than formatted ASCII
              [<ref id="ta.rw">RW</ref>].
              A C example is:

<verbatim>
FILE *ofile; float arr[10];

/* set arr[i] to have sensible values */

ofile = fopen ("output-c.dat", "w");
fwrite ((void*)arr, sizeof(arr[0]), 10, ofile);
fclose (ofile);
</verbatim>
              Note that we carefully cast the variable
              <code>arr</code> to type <code>void*</code>, and that we
              could replace this by <code>(void*)&amp;arr[0]</code> if
              we thought it was clearer.  Note also the minor trick of
              using <code>sizeof(arr[0])</code> rather than the more
              obvious <code>sizeof(float)</code>; they are equivalent,
              but the first will remain correct even if we change our
              mind about the size of the elements of the array
              <code>arr</code>.  You would read the contents of this
              file in using the function <code>fread</code>.</p>

            <p>The <code>fwrite</code> and <code>fread</code>
              functions are not portable in general, since they deal
              with floating point numbers merely as bundles of bits,
              and pays no attention to how these are interpreted.
              This means that such files are not portable between
              machines which interpret these bits differently, so that
              files written on a little-endian machine (see <ref
              id="s.fp"/>) will be gibberish if read on a big-endian
              machine, and vice-versa.  However, C's raw I/O is
              <em>semi</em>-portable, inasmuch as the
              <code>fwrite</code> function above does nothing other
              than copy <m notation="latexmaths">10\times4</m> bytes
              (in this case) from memory to disk; <code>fread</code>
              similarly copies bytes from disk to memory without any
              interpretation.</p>

            <p>The corresponding Fortran example is
<verbatim>
      real arr(10)
                
C     set arr() to have sensible values
      open (unit=99,file='output-f.dat',form='unformatted')
      write (99) arr
      close (99)
</verbatim>
              Note that Fortran unformatted output is not portable in
              any way.  Unlike C raw I/O, the Fortran compiler is free
              to store the information on disk in any way it likes,
              and the resulting file will not, in general, have <m
              notation="latexmaths">10\times4</m> bytes in it.  That
              is Fortran unformatted I/O is machine- <em>and
              compiler-</em> specific, and the file
              <code>output-f.dat</code> in this example will only be
              readable in general using a Fortran program built using
              the same compiler.</p>

          </subsubsubsect>

          <subsubsubsect id="s.optimnan">
            <subhead>
              <title>Use NaN and Infinity</title>
              <update versionid="v1.1"><px>Mention
                  speed tradeoffs, following
                  comments</px></update></subhead>

            <p>As described in <ref id="s.otherfloat"/>, any operation
              which has a <code>NaN</code> as input, produces a
              <code>NaN</code> as its result.  Similarly, the special
              values positive and negative <code>Infinity</code> are
              legitimate numbers which can appear in a calculation.
              Consider the following code fragment:

<verbatim> 
      do 10, i=-5000,5000
         do 20, j=-5000,5000
            if (j .ne. 0) then
               t(i,j) = real(i)/real(j)
            else
               t(i,j) = 0.0
            endif
   20    continue
   10 continue
</verbatim>

              The <code>if</code> test is to avoid a division-by-zero
              error.  If this loop were buried deep within a hierarchy
              of other loops, then the test could be the source of a
              significant fraction of the runtime.  It can, however be
              omitted, allowing the matrix <code>t(i,j)</code> to
              include numerous <code>Infinity</code>s and one
              <code>NaN</code> (due to 0/0).  Because both of these
              values are permissable floating-point operands, they can
              be allowed to percolate through the rest of the
              calculation without elaborate further tests, to be
              checked only at the end.  This is possible only if the
              floating-point environment is set up <em>not</em> to
              generate signals on floating-point exceptions (see also
              <ref id="s.otherfloat"/>).
            </p>

            <p>Note that calculations involving the exceptional values
              tend to run more slowly than those using normal values,
              so if your calculation produces a significant number of
              exceptional values -- like the artificial example above
              -- a switch to IEEE semantics might not produce a speed
              win overall.  Note also that the expression
              <code>(a.lt.b)</code> is <em>not</em> equivalent to
              <code>.not.(a.gt.b)</code>, since both
              <code>a.lt.b</code> and <code>a.gt.b</code> are false
              when one of the variables is an IEEE exceptional value:
              this could produce hard-to-find bugs if you were not
              alert to this when you were writing the code. [<ref
              id="ta.sg">SG</ref>]
            </p>

          </subsubsubsect>

          <subsubsubsect>
            <subhead><title>Remove debugging options</title></subhead>

            <p>It may or may not be obvious that debugging and
              profiling options, as discussed in <ref
              id="s.debugging"/> and <ref id="s.profiling"/>, will
              both slow your program down (especially in the latter
              case), and make it bigger.  You should compile your
              program, or at least the numerically intensive parts of
              it, without them when you are not debugging it. [<ref
              id="ta.mbt">MBT</ref>] </p>

          </subsubsubsect>

          <subsubsubsect>
            <subhead><title>Choose a fast compiler</title></subhead>

            <p>Random points:
              <ul>
                <li>
                  <p>This is a case where free software is not
                    necessarily better.  Both Sun and Compaq expend
                    resources on making their compilers as efficient
                    as possible.  If speed is important to your
                    application, you're probably best off using one of
                    these compilers.</p>
                </li>

                <li><p>On the Alpha, it's worth while using the
                    Fortran 90 compiler even for Fortran 77 code [<ref
                    id="ta.sg">SG</ref>].</p></li>

              </ul>
            </p>
          </subsubsubsect>

          <subsubsubsect id="s.ncbooks">
            <subhead><title>Further reading</title></subhead>

            <p>Take a look at the Sun Numerical Computation Guide
              <citation>sunncg</citation>, particularly the end of
              chapter 5, and at the collection of papers at
              <url>http://sunsite.doc.ic.ac.uk/sun/Papers/SunPerfOv+references/</url>,
              particularly the helpful paper about compiler switches:
              <code>you_and_your_compiler</code> (this is a generally
              useful collection of Sun papers, by the way).
            </p>

            <p>If you <em>do</em> need to spend significant effort
              tuning your code, then you should consult a textbook on
              the matter.  A good one is <cite>High Performance
              Computing</cite> <citation>dowd</citation>.  This
              reference touches on parallelizing your code, a topic
              which I have deemed sufficiently arcane not to be
              discussed at all in this introductory guide.
            </p>

          </subsubsubsect>

        </subsubsect>

        <subsubsect id="s.debugging">
          <subhead><title>Debugging</title></subhead>

          <p>One approach to debugging is the brute-force method:
            simply scatter tracing statements through your code and
            watch them fill your screen.  There are some types of
            debugging for which this is ideal -- for example, graphing
            a trace of intermediate values may reveal that an
            algorithm is showing signs of instability -- but it can be
            very cumbersome.
          </p>

          <p>Better, in many cases, is to use a debugger.  A debugger
            allows you to roam through your code, stopping in
            troublesome functions, examining data, and stepping
            through your code line-by-line.  There is a great deal you
            can do with a debugger, but they are not often the easiest
            tools to master.  However, there is a good deal you can do
            armed only with experience of the foothills of the
            debugger's learning curve.
          </p>

          <p>I will describe the Sun debugger <code>dbx</code>, here.
            The use of the GNU debugger, <code>gdb</code>, and the
            <code>dbx</code> debugger on Digital Unix, are broadly
            similar.
          </p>

          <p>First, compile <code>crash.c</code>, listed in <ref
            id="a.crash.c"/>, in the usual way (<kbd>cc -o crash
            crash.c</kbd>), run it, and watch it crash when it tries
            to dereference a zero pointer.  This leaves a
            <code>core</code> file in the current
            directory<note><px>If you don't get a core file, it might
            be that you have your shell set to prevent it -- possibly
            as a (reasonable) precaution to avoid filling up filespace
            with `useless' core files.  The command <kbd>ulimit
            -c</kbd> (<code>sh</code>-type shells only) will show the
            maximum size of core file: setting this to zero inhibits
            creating core files, and setting it to a very large number
            or to <kbd>unlimited</kbd> allows core files to be
            created.  On <code>csh</code>-type shells, the
            corresponding command is <kbd>limit coredumpsize
            unlimited</kbd></px></note>.  You can obtain rudimentary
            post-mortem information from this core file with
            <code>dbx</code>, as follows:

<verbatim>
% dbx crash core
[...]
program terminated by signal SEGV (no mapping at the fault address)
(dbx) where                                                                  
=&gt;[1] bananas(0x0, 0x1, 0xef691338, 0x10074, 0x2, 0xeffff8d0), at 0x10870
[2] main(0x1, 0xeffff94c, 0xeffff954, 0x20800, 0x1, 0x0), at 0x108fc
(dbx) quit
</verbatim>
            The <code>where</code> command to <code>dbx</code> shows
            where the program was when it crashed (the
            <code>[...]</code> shows where I have omitted some
            unenlightening chatter from the debugger).
          </p>

          <p>The other information <code>dbx</code> gives you is less
            useful -- the debugger doesn't know enough about your
            program to be more helpful.  You can, however, tell the
            compiler to pass on more information to the debugger when
            it processes your code; do this with the <code>-g</code>
            flag to the compiler, as in <kbd>cc -g -o crash
            crash.c</kbd>.  If you compile several modules to produce
            your executable, you'll need to give this option to the
            compilation of each module you wish to debug.  You'll also
            have to give this option at the link stage on SunOS4, but
            not on Solaris or for <code>gdb</code> on Linux.
          </p>

          <p>If we run <code>crash</code> again now, and look at the core file, we see
            that the debugger can provide us with more information.
<verbatim>
% dbx crash core
[...]
program terminated by signal SEGV (no mapping at the fault address)
Current function is bananas
12           printf ("banana split: %d\n", *zp);
(dbx) where                                                                  
=&gt;[1] bananas(i = 0), line 12 in "crash.c"
[2] main(), line 22 in "crash.c"
(dbx) print i
i = 0
(dbx) print buf
buf = "banana number 0
"
(dbx) print *zp
dbx: reference through nil pointer
(dbx) print zp
zp = (nil)
(dbx) quit
</verbatim>
            Note that we can examine the values of variables in scope
            at the point where execution stopped, and that
            <code>dbx</code> knows enough about C (or Fortran) to know
            the type of variables it is asked to print.  Printing the
            value of the pointer <code>zp</code> shows us why our
            program has crashed.
          </p>

          <p>The debugger is not only useful for such post-mortem
            diagnosis.  It is also (for some people, primarily) used
            for investigating a program's behaviour when it is running
            normally, albeit with bugs we wish to track down.  For
            example, start the debugger and tell it to stop when it
            enters the function <code>bananas</code>:
<verbatim>
% dbx crash
[...]
(dbx) stop in bananas
(2) stop in bananas
</verbatim>
            You can set multiple breakpoints (so called) not only in functions,
            but also at line numbers, or linenumbers within files (using
            <code>(dbx) stop at crash.c:12</code>).  Then tell the
            program to start running: 
<verbatim>
(dbx) run           
Running: crash 
(process id 29707)
Entering the bananas function: 1
stopped in bananas at line 6 in file "crash.c"
6       sprintf (buf, "banana number %d\n", i);    
(dbx) next
stopped in bananas at line 7 in file "crash.c"
7       if (i != 0)
(dbx) print i
i = 1
</verbatim>

            Note that, as well as output from the debugger itself, we
            also see output from the running program.  If the program
            required input from the user, it would receive it as
            normal.  The program stops at the first line of code
            within the <code>bananas</code> function.  We can move one
            line forward in the code, verify that the parameter
            <code>i</code> has its expected value, then tell the
            program to resume execution.

<verbatim>
(dbx) cont 
banana number 1
No bananas left!
stopped in bananas at line 6 in file "crash.c"
6       sprintf (buf, "banana number %d\n", i);    
(dbx) print i
i = 0
(dbx) cont 
signal SEGV (no mapping at the fault address) in bananas 
at line 12 in file "crash.c"
12           printf ("banana split: %d\n", *zp);
(dbx) quit
</verbatim>
          </p>

          <p>The Solaris debugger can be used through a GUI: give the
            command <kbd>debugger</kbd> to start this up.  The Digital
            GUI debugger is <code>ladebug</code>.  There is a GUI
            interface to <code>gdb</code>, called <code>xxgdb</code>.
          </p>

          <p>In general, you can't debug optimized code (that is, code
            compiled with the option <code>-O</code>), because the
            optimizer may rearrange lines or remove redundant
            variables.  However, both <code>dbx</code> and
            <code>gdb</code> do have support for debugging code with
            mild optimization, though there are some things, such as
            stepping from line to line, you might not be able to do.
          </p>

          <p>This introduction has merely scratched the surface of
            what you can do with the debugger, by showing you the bare
            minimum of commands you need to navigate around your
            running program.  There is a great deal more information
            available in Sun's debugging manual
            <citation>sundebug</citation>, or in <code>gdb</code>'s
            info pages (<code>info gdb</code>).
          </p>

        </subsubsect>

        <subsubsect id="s.candf">
          <subhead>
            <title>Intermixing Fortran and C</title>
          </subhead>

          <p>Because there are so many reliable subroutine libraries
            written in Fortran, you will sometimes need to call a
            Fortran routine from C.  Likewise, you might need to call
            a low-level C routine from a Fortran program.
          </p>

          <p>For a detailed overview of such `mixed language
            programming', see <docxref doc="SUN/209" text="SUN/209" />,
            <cite>CNF and F77 Mixed Language Programming</cite>, which
            gives a detailed introduction to calling each language
            from the other, as well as a set of C macros to help
            support this.  I will not duplicate the contents of that
            guide, but instead give a very compressed introduction to
            the problem.  This might be enough to get you going.
            There is a further discussion of the issues, and a
            compressed description of the solutions, at the Cambridge
            High Performance Computing Facility (HPCF), at
            <url>http://www.hpcf.cam.ac.uk/mixed.html</url>.  For a
            Sun-specific discussion, see Chapter 12 of
            <citation>sunf77</citation>.
          </p>

          <p>The biggest difference between C and Fortran is that `C
            is call-by-value, Fortran is call-by-reference'.  What
            that means is that when a C function is called, it
            receives the <em>values</em> of its arguments, so that any
            changes to them disappear when the function finishes, but
            when a Fortran function is called, it receives a
            <em>reference to</em> its arguments, so they can be
            altered easily within the function.  The consequence of
            this is that when you call a Fortran function from C, you
            should pass arguments using C's address-of
            operator,<code>&amp;</code>, and when you call a C
            function from Fortran, you will typically need to pass it
            the <em>value</em> of the variable using the
            <code>%val()</code> function (this is a non-standard VAX
            Fortran extension, but one which is now so ubiquitous that
            it's safe to use).  These remarks apply to unstructured
            types such as characters, integers and floats -- arrays
            and strings present other problems, as described below.
            It follows from what I've said that if a C function is
            declared as <code>void subr (int *p)</code>, it's
            expecting (the value of) a pointer to an integer, so that
            this could be called in the `normal' way from fortran:
            <code>call subr (ia)</code>, where <code>ia</code> is an
            integer variable.
          </p>

          <p>See <ref id="a.mixed"/> for example programs.</p>

          <subsubsubsect>
            <subhead><title>Arrays</title></subhead>

            <p>Fortran's arrays are simple: an array of any dimension
              is just a list of locations in memory, stored in the
              order <code>a(1,1)</code>, <code>a(2,1)</code>, and so
              on (see <ref id="s.arrays"/>); when a Fortran function
              is given an array argument, what it actually receives is
              a pointer to the `top-left' element.  If you're calling
              Fortran from C, you simply have to be aware of the
              switch on order, and then pass
              <code>&amp;a[0][0]</code>.
            </p>

            <p>If you have a C routine with a one-dimensional array
              argument (either <code>void func (int a[])</code> or
              <code>void func (int *a)</code>), and you want to call
              it from Fortran, you can call it simply by giving the
              array name as an argument: <code>call func (a)</code>.
            </p>

            <p>Passing a multi-dimensional array <em>to</em> a C
              function is potentially problematic.  However, you'll
              almost never need to do that, because Fortran very
              rarely needs to invoke C to do a numerical calculation.
              If the C declaration is <code>func (int a[][3])</code>,
              for example (that is, an array of three-element arrays),
              then a Fortran array <code>integer a(3,</code><m
              notation="latexmaths">n</m><code>)</code> could be
              passed simply, as <code>call func (a)</code>.  If, on
              the other hand, the C declaration were <code>func (int
              **a)</code> (that is, a pointer to pointer to integer,
              with the actual array elements separately allocated),
              then the above Fortran array could <em>not</em> be
              passed as shown (and no, smarty, <code>call func
              (%loc(a))</code> wouldn't work, even though it's the
              right type).  If you <em>do</em> need to call such a C
              function, you'll probably have to provide a suitable C
              wrapper for it, and call that from the Fortran code.
              C's array/pointer syntax is elegant, but not ideally
              suited for numerical work<note><px>A little known
              factoid for C enthusiasts: did you know that C's array
              reference syntax is commutative, since <code>a[i]</code>
              is defined to be equivalent to <code>*(a+i)</code> and
              is thus equal to <code>i[a]</code>?  This means that
              <code>a[3]</code> is the fourth element of the array
              <code>a</code>, and so is <code>3[a]</code>!  Bizarrely
              enough, the latter is a legitimate array reference, but
              one you're probably best not including in your own
              code.</px></note>.
            </p>

          </subsubsubsect>

          <subsubsubsect>
            <subhead><title>Strings</title></subhead>

            <p>C strings are simple objects: they are by definition
              arrays of characters, with the end of the string marked
              by a zero byte.  The internal structure of Fortran
              strings is not defined, so that they could be stored in
              whichever way is most convenient to the author of the
              compiler; typically, however, they are an array of
              characters with a length encoded with them.  The
              practical upshot of this is that you simply cannot pass
              strings back and forth between Fortran and C code in a
              <em>portable</em> way, and it is fortunate that you
              rarely need to do this.  On those occasions when you do
              need such a facility, you can use a library of
              conversion routines such as those described in <docxref
              doc="SUN/209" text="SUN/209" />.
            </p>

          </subsubsubsect>

          <subsubsubsect id="s.compilingcf">
            <subhead><title>Compiling and linking</title></subhead>

            <p>When a Fortran compiler produces object code,it
              <em>typically</em> adds an underscore to the end of each
              function name.  That is, the subroutine:

<verbatim>
      subroutine func1 (i)
      integer i
      call func2 (i)
      end
</verbatim>

              will produce object code with an external symbol
              <code>func1_</code> calling a subroutine named
              <code>func2_</code>.  You must be aware of this when you
              compile Fortran code which is to be linked with C
              functions.  There are two ways of dealing with this.
            </p>

            <p>First, you can call this subroutine from C by calling
              it with the correct name:
<verbatim>
int i1;
extern void func1_ (int *i);
/* call it */
func1_ (&amp;i1);
</verbatim>
            </p>

            <p>So far so good.  The problem arises when you want to
              call C from the Fortran function, since the Fortran
              function will expect to link against a function with a
              trailing underscore.  If the C function is written by
              you, then you could provide this, but if it is a library
              routine, you will have to tell the compiler not to add
              the underscore to the external name when it generates
              object code.  For Sun's <code>f77</code> compiler, you
              do this with the compiler option
              <code>-ext_names=plain</code>, for the GNU
              <code>g77</code> compiler it is with the
              <code>-fno-underscoring</code> option, and for
              <code>f77</code> on the Alpha, it is <code>-assume
              nounderscore</code> [<ref id="ta.rw">RW</ref>].  Note
              that this will apply to all function names in that
              module.  Sun's compiler also allows you to declare that
              a function is in a C module, using a pragma, but this is
              obviously non-portable, and so is not recommended.  On
              this subject, [<ref id="ta.rw">RW</ref>] points out that
              to get access to main() via f77 on decs, you need to set
              <code>-nofor_main</code> at link time.
            </p>

            <p>You should, in general, use the Fortran compiler to
              link the object files into an executable.  This calls
              the linker with all the correct Fortran libraries.  It
              is of course possible to do the same with the C
              compiler, but requires a much more elaborate call.
            </p>

          </subsubsubsect>

        </subsubsect>

        <subsubsect id="s.compilers">

          <subhead>
            <title>Compilers, and other stray remarks on code</title>
            <update versionid="v2-0"><px>Advice to use prototypes, to
            avoid another class of silly errors; added all-warnings
            switches for Sun and 
                Compaq.</px></update>
          </subhead>

          <p>Using Fortran's <code>implicit none</code> keyword is a
            Good Idea.  The tiny amount of typing time you save by
            relying on Fortran's automatic declaration of variables,
            is more than likely wiped out by the debugging time spent
            clearing up silly problems <code>implicit none</code>
            would have avoided from the beginning.</p>

          <p>Similarly, in C, use ANSI-C rather than older `K&amp;R'
            C, and use prototypes religiously.  That is, if you have a
            module <code>myfuncs.c</code>, then create a header file
            <code>myfuncs.h</code> containing the prototypes of the
            functions within it, and include it (<code>#include
            "myfuncs.h"</code>) both in any modules which use those
            functions and inside <code>myfuncs.c</code> as well.  That
            way, if you change the interface to any functions in that
            module, the compiler will prompt you to change the calls
            to that function <em>everywhere</em> that it is used.
            This way, the compiler can help you avoid a whole class of
            embarrassingly silly problems.</p>

          <p>Make your code portable.  Unless you are specifically
            targetting your code at a particular (supercomputer)
            processor, or magic parallelizing compiler, you will save
            yourself time in the long run by not making assumptions
            about the machine or compiler environment.  Especially
            given the imminent arrival of 64-bit machines, you are
            probably not doing yourself any favours by, for example,
            assuming that integers are four bytes.  Probably more
            pertinently, exploiting compiler-specific features might
            prevent you running your code on some new faster
            architecture.  If you do decide to use some non-portable
            features, you can make the future porting effort easier by
            having second or third thoughts about precisely how to use
            them, and by isolating them into a few subroutines, rather
            than scattering them throughout your code.  It follows
            that....</p>

          <p>Compiler Warnings Are Your Friend.  Try compiling your
            codes with compiler warnings switched on (with the option
            <code>-Wall</code> on GNU compilers, <code>+w2</code> on
            Sun Workshop compilers, and <code>-w0</code> on Compaqs).
            You might be surprised at the number of peculiarities and
            non-standard features this exposes, each of which is a
            potential portability problem for the future.  Don't treat
            compiler warnings as irrelvant nagging -- each of them is,
            to some extent, an error you have made, which has the
            possibility of turning round and biting you later.  I
            would particularly advise this if you develop using GNU
            compilers, as these seem particularly liberal about
            standards: <code>gcc</code> in particular seems happy to
            take any old nonsense, say `I know what you mean', and
            produce code from it -- in my experience it usually
            guesses my intentions correctly, but I don't want to rely
            on it.  You can also adjust the strictness of the C
            compiler's conformance to the ANSI-C standard by using
            compiler options (Sun: <code>-Xa</code> and
            <code>-Xc</code>; DEC: <code>-std1</code>; GNU:
            <code>-ansi</code> and <code>-pedantic</code>).  Having
            said all this, I don't want to overstate the importance of
            compiler warnings: the main plank of this advice is to
            spend time now to save time and aggravation later, but
            this tradeoff is unlikely to be in your favour if you
            spend time removing every last anomaly from your code.</p>

        </subsubsect>

      </subsect>

      <subsect id="s.linkfarms" export="export">
        <subhead><title>Link farms</title></subhead>

        <p>At the end of each section of this cookbook, I'll include a
          collection of web-based resources you can use to search for
          further information.  These will typically be either FAQs
          (lists of `frequently asked questions') or `link farms'
          (thematic collections of links with little further
          detail).</p>

        <subsubsect>
          <subhead><title>Unix documentation and standards</title></subhead>
          
          <p>
            <ul>
              <li>
                
                <p><quote><webref url="http://www.pasc.org/abstracts/posix.htm">POSIX</webref> is the term for a suite of applications program
                    interface standards to provide for the portability of source code
                    applications where operating systems services are required. POSIX is
                    based on the UNIX (Registered trademark administrated by the Open
                    Group) Operating System, and is the basis for the Single UNIX
                    Specification from The Open Group.</quote> [IEEE PASC (Portable
                  Application Standards Committee)]</p>

              </li>

              <li><p>This is currently (2001-06-20) undergoing revision by the 
                  <webref url="http://www.opengroup.org/austin">Austin
                  Group</webref></p></li>

              <li><p>The POSIX standard is 
                  <ol><li><p><quote>IEEE Std 1003.1 Standard for Information technology -- Portable
                          Operating Systems Interface (POSIX) -- Part 1: System Interface [C
                          language binding]</quote>, which is identical to <quote>ISO/IEC JTC1 IS 9945-1
                          Standard for Information technology -- Portable Operating Systems
                          Interface (POSIX) -- Part 1: System Interface [C language binding]</quote></p></li><li><p><quote>IEEE Std 1003.2 Standard for Information technology -- Portable
                          Operating Systems Interface (POSIX) -- Part 2: Shell &amp; Utilities</quote>,
                        which is identical to <quote>ISO/IEC JTC1 IS 9945-2 Standard for
                          Information technology -- Portable Operating Systems Interface (POSIX)
                          -- Part 2: Shell &amp; Utilities</quote>.</p></li></ol>
                  ...and these cost money (<webref url="http://standards.ieee.org/catalog/olis/licenses/licenses.html">lots</webref>) to buy on paper.
                </p></li>

              <li><p><webref url="http://www.opengroup.org/onlinepubs/007908799/">Single
                    Unix specification</webref>, from the Open Group (<webref url="http://www.opengroup.org/publications/catalog/web.htm">other
                    publications</webref>).  My understanding from the PASC document above is
                  that Single Unix is broader than POSIX, and covers more of the
                  environment (bit vague, here).  It feeds into the POSIX/ISO
                  standardisation process, but is not a formal standard itself.  Single
                  Unix does, however, have the great advantage of being available
                  online.</p></li>

              <li><p>The link with <webref url="http://www.UNIX-systems.org/">The Unix
                    System</webref> is, I fear, rather obscure to me, but it appears that
                  the latter is the public face of the Open Group's
                    labours.</p></li>
            </ul>
          </p>

          <p><url>http://www.geek-girl.com/unix.html</url>: The `Unix
            Reference Desk'.  This is a very useful collection of
            pointers to unix documentation.</p>

          <!-- Disappeared
          <p><url>http://www.softlab.ece.ntua.gr/unix/docs/</url>:  This is a Greek
          collection of documents (some of which are otherwise difficult to track
          down) in a mixture of text and postscript.
          -->

          <p><url>http://www.faqs.org/faqs/unix-faq/faq/</url>:
            the General Unix FAQ, full of arcana.  This is one of several FAQs
            which cover Unix and related issues; for some others, look at 
            <url>http://www.faqs.org/faqs/by-newsgroup/comp/comp.unix.questions.html</url>
          </p>

          <p><url>http://uk.yahoo.com/Computers_and_Internet/Software/Text_Editors/vi/</url>:
            Collection of links to vi documentation at Yahoo.
          </p>

        </subsubsect>

      </subsect>

    </sect>

    <sect id="s.theory" export="export">
      <subhead><title>Theory support</title></subhead>

      <subsect id="s.maple" export="export">

        <subhead><title>Computer algebra</title></subhead>

        <p>Starlink provides access to computer algebra by supporting
          the Maple package.  You might have access to Maple on your
          own Starlink node, but if not, you may use it on the machine
          <code>star.rl.ac.uk</code>, if you have an account there.
          If you are a Starlink user, you should apply for an account
          by mailing <code>star@star.rl.ac.uk</code>.
        </p>

        <p>Maple allows you to enter mathematical expressions using a
          fairly natural syntax, substitute into them, simplify them,
          differentiate and (with limits) integrate them, and finally
          go on to graph them.  As an added bonus, you can also
          produce output in C, Fortran and LaTeX.
        </p>

        <p>For example, consider the following example.
<verbatim>
star:nxg&gt; maple
    |\^/|     Maple V Release 4 (Rutherford Appleton Laboratory)
._|\|   |/|_. Copyright (c) 1981-1996 by Waterloo Maple Inc. All rights
 \  MAPLE  /  reserved. Maple and Maple V are registered trademarks of
 &lt;____ ____&gt;  Waterloo Maple Inc.
      |       Type ? for help.
&gt; gi := amp * exp(-(xparam^2/sa^2)/2);
                                                   2
                                             xparam
                         gi := amp exp(- 1/2 -------)
                                                 2
                                               sa
</verbatim>

          We start up Maple, and enter an expression for a gaussian.
          Maple makes an attempt to display the result intelligibly.
          If we had ended the expression with a colon rather than a
          semicolon, Maple would have suppressed the display.  Note
          that undefined variables represent themselves, and that
          Maple knows that <code>exp</code> is the exponential
          function, so that it knows, for example, how to
          differentiate it.
        </p>

        <p>Now define the variable <code>xparam</code>, and redisplay
          <code>gi</code>.
<verbatim>
&gt; xparam:= cos(theta)*(xc-x0);
      xparam := cos(theta) (xc - x0)

&gt; gi;
                                             2          2
                                   cos(theta)  (xc - x0)
                     amp exp(- 1/2 ----------------------)
                                              2
                                            sa
</verbatim></p>

        <p>Then differentiate the gaussian, and assign the result to
          <code>gid</code>.  The result is something you're happy not
          to have had to work out yourself.
</p>

        <p><verbatim>
&gt; gid := diff (gi, theta);
                                                                 2          2
                                2                      cos(theta)  (xc - x0)
        amp cos(theta) (xc - x0)  sin(theta) exp(- 1/2 ----------------------)
                                                                  2
                                                                sa
 gid := ----------------------------------------------------------------------
                                           2
                                         sa
</verbatim>
</p>

        <p>If that the purpose of this was to do a calculation
          somewhere, you might want to code this expression in
          Fortran.  Doing this by hand would be error-prone, but Maple
          can produce output in Fortran as well as this
          `prettyprinted' style.
<verbatim>
&gt; fortran (gid,optimized);
      t1 = cos(theta)
      t4 = (xc-x0)**2
      t6 = sa**2
      t7 = 1/t6
      t10 = t1**2
      t15 = amp*t1*t4*t7*sin(theta)*exp(-t10*t4*t7/2)</verbatim>

          The <code>optimized</code> argument tells Maple to try to
          produce Fortran code without repeated subexpressions.  You
          can save this to a file with the expression <code>fortran
          (gid, filename=`gaussian.f`, optimized);</code> You can
          produce output in C as well, though because the
          identifier<code>C</code> is potentially such a common one,
          you must explicity load the C library first.

<verbatim>
&gt; readlib(C):
&gt; C([gf=gid],optimized);
      t1 = cos(theta);
      t4 = pow(xc-x0,2.0);
      t6 = sa*sa;
      t7 = 1/t6;
      t10 = t1*t1;
      gf = amp*t1*t4*t7*sin(theta)*exp(-t10*t4*t7/2);</verbatim>

          There are two things to note here.  The first is that we
          have renamed the expression <code>gid</code> on the fly.
          The second is that the expression for <code>t4</code> is not
          the most efficient -- it is very bad to use the
          <code>pow()</code> function for raising expressions to small
          integer powers: much better would be <code>t4a=xc-x0;
          t4=t4a*t4a;</code>, as has happened automatically for
          <code>t10</code>.</p>

        <p>You can also produce results in LaTeX
<verbatim>
&gt; latex(gid);
{\it amp}\,\cos(\theta)\left ({\it xc}-{\it x0}\right )^{2}\sin(\theta
){e^{-1/2\,{\frac {\left (\cos(\theta)\right )^{2}\left ({\it xc}-{
\it x0}\right )^{2}}{{{\it sa}}^{2}}}}}{{\it sa}}^{-2}</verbatim>

          Maple has done the correct thing with the cosine and sine
          functions, and with the <m notation="latexmaths">\theta</m>
          variable, and it has got <em>all</em> the braces matching
          correctly, but it has expressed the exponential as a simple
          e-to-the-power which will look rather ugly (as well, the
          exponential should be written with <code>\mathrm{e}</code>).</p>

        <p>Leave Maple by giving the command <code>quit</code>.</p>

        <p><docxref doc="SUN/107" text="SUN/107" /> provides an
          introduction to Maple, and <docxref doc="SGP/47"
          text="SGP/47" /> is a comparison of Maple and Mathematica.
          Also, the Maple manual and tutorial are very clear.  There
          is help within Maple (type <code>?intro</code>), and this
          gives enough information to get you going.  Maple's web
          pages are at <url>http://www.maplesoft.com/</url>, but they
          don't currently (December 1998) give a lot of tutorial help.
          See also the example Maple program in <ref id="a.maple"/>.
        </p>

        <p>There's also a GUI for maple, which you can invoke with
        <code>xmaple</code>.</p>
        
        <p>As a final point, don't fall into the common trap of thinking that because
          you've produced your result using computer algebra, it must be right.
          This is as false of computer algebra as it is of numerical
          programming -- be inventive in thinking of cross-checks.
        </p>

      </subsect>

      <subsect id="s.visualisation" export="export">

        <subhead><title>Data visualisation</title></subhead>

        <p>Starlink supports two data visualisation packages, IDL and
          DX, but for relatively simple graphing of simple results,
          gnuplot will probably produce acceptable results in rather
          less time.  </p><p>The package SM, which is a descendent of
          Mongo, has numerous adherents, but I don't propose to
          discuss it, partly because I've never used it, partly
          because it's not part of Starlink's base set and so is not
          available at all sites, but mostly because if gnuplot runs
          out of steam, you might as well go straight to IDL, which is
          easily available through Starlink.  </p><p><docxref
          doc="SG/8" text="SG/8" />, <cite>An Introduction to
          Visualisation Software for Astronomy</cite>, is an overview
          of visualisation systems, which mentions both IDL and
          DX.</p>

        <subsubsect id="s.gausssine-g">
          <subhead><title>gnuplot</title></subhead>

          <p>Gnuplot is valuable because it's so simple -- easy things
            can be done easily.  If you want to graph an equation or
            plot some data, and produce postscript output, then you'll
            probably do it faster, from a standing start, than someone
            using one of the beefier packages.  Its weaknesses are
            that it can't easily do very complicated or fancy
            visualisations (that is, it doesn't try to take over the
            world), and it deals naturally only with ASCII data in
            columns.  It is scriptable, but I wouldn't fancy
            programming anything complicated with it.
          </p>

          <p>Start it up with the simple command <code>gnuplot</code>.
          Once it's started, you can give it commands as simple as 
<verbatim>
gnuplot&gt; plot sin(x)
</verbatim>
            to produce a plot of the sine function with default
            ranges, or you can give it a range and specify a line type
            as follows

<verbatim>
gnuplot&gt; plot [x=0:3.14] sin(x)*cos(x**2)**2 with impulses
</verbatim>
</p>

          <p>Gnuplot can also graph data files.  The example file
            <code>gausssine.dat</code> consists of two columns of <m
            notation="latexmaths">64\times64</m> values.  It can be
            plotted in gnuplot with the commands:

<verbatim>
gnuplot&gt; set output 'gausssine-gnuplot.eps'
gnuplot&gt; set terminal postscript eps
Terminal type set to 'postscript'
Options are 'eps monochrome dashed "Helvetica" 14'
gnuplot&gt; splot 'gausssine.dat' using 1 with lines
gnuplot&gt; set terminal x11    # set the terminal type back to the (default) X
gnuplot&gt; set output          # close the output file
</verbatim>

            This produces the EPS file shown in <ref
            id="f.gausssine-g"/>.  The file has a blank line after
            each block of 64 numbers.  Gnuplot interprets this as a
            signal that this is the end of a `row' of a matrix (a
            standard gnuplot gotcha is that is must be a
            <em>completely</em> blank line, with no whitespace).  You
            can plot the surface represented by the second column,
            with the clause <code>using 2</code> to
            <code>splot</code>.  Gnuplot can read more generally
            formatted data, but that's already stepping towards
            advanced usage.</p>

          <figure float="float" alt="File gausssine.dat, displayed with gnuplot" id="f.gausssine-g">
            <caption><px>File gausssine.dat, displayed with
                gnuplot</px></caption>
            <figurecontent image="gausssine-gnuplot.eps"/>
            <figurecontent image="gausssine-gnuplot.gif"/>
          </figure>

          <p>There is good help within gnuplot, available by typing
          <code>help</code>.</p>

        </subsubsect>

        <subsubsect id="s.vis-idl">
          <subhead><title>IDL</title></subhead>

          <p>IDL is much more powerful and flexible than gnuplot, and
            has a correspondingly longer learning curve.  It's never
            been accused of being elegant, but with only a bit of
            headbanging, I've always managed to get it to do what I
            wanted (I've always seen it as reminiscent of Fortran in
            this respect).
          </p>

          <p>Several missions have used IDL as the language in which
            they have written their data-analysis software, and
            Starlink is currently experimenting with providing IDL
            interfaces to important Starlink applications, which is
            possible because IDL can link to codes written in
            languages such as Fortran or C.  IDL is moving towards
            being a core facility at Starlink sites.
          </p>

          <p>IDL displays data in arrays as part of a generic set of array
            manipulations.  For example, the data in the file
            <code>gausssine.dat</code> was produced by the following
            sequence of IDL commands:
<verbatim>
x=(findgen(64)-32)^2
d=fltarr(64,64)
for i=0,63 do d(i,*)=sqrt(x+(i-32)^2)
a3=exp(-(d/15)^2)
s=sin(findgen(64)/63*5*3.141592657)
s2=s#s
m=s2*a3</verbatim>

            The function <code>findgen(N)</code> returns a float array
            (indexed from 0 to <m notation="latexmaths">N-1</m>) in
            which the value of each element is the same as its index;
            performing an arithmetic operation such as subtraction or
            exponentiation on an array performs it on each element of
            the array; <code>fltarr</code> declares an array of floats
            of the specified dimensions; the array reference
            <code>d(i,*)</code> refers to the entire <code>i</code>'th
            row of <code>d</code>; the operator <code>#</code> forms
            the direct product of the two vectors.  The result of this
            is to set <code>d</code> to be an array where each element
            is the euclidean distance from element
            <code>(32,32)</code><note><px>IDL experts will know that
            the common IDL idiom for this is
            <code>d=shift(dist(64),32,32)</code>, but have you ever
            actually compared <code>dist</code> with its
            documentation?  The documentation for <code>dist</code>
            suggests that this idiom wouldn't work, but the function's
            actual behaviour seems to (substantially) depart from the
            claimed behaviour in exactly the right way.</px></note>.
          </p>

          <p>Once we have the data in the array <code>m</code>, we can
            produce a surface plot with <code>surface,m</code>, and
            then go on to annotate it, rotate it, shade it, contour
            it, with the large collection of options and parameters to
            the <code>surface</code> command.  We can produce
            PostScript output with the following sequence of commands:

<verbatim>
  !p.font=0             ; use postscript fonts rather than IDL outlines
  set_plot, 'ps'        ; use the postscript output driver
  device, /encap, filename='gausssine-idl.eps'
                        ; produce encapsulated postscript
  surface, m
  device, /close        ; close the file
</verbatim>

            This produces the EPS file shown in <ref
            id="f.gausssine-i"/>.  A minor, but persistent, irritation
            with IDL is that, although its input and output facilities
            are as flexible as, say, Fortran's (which they closely
            resemble), it doesn't come with a function for dealing
            with the common case of data printed out in columns (the
            only case gnuplot naturally deals with).  Fortunately,
            such a function is not only easy to write, but a useful
            example, too.  See <ref id="a.idl"/>.</p>

          <figure float="float" alt="File gausssine.dat, displayed
            with IDL" id="f.gausssine-i">
            <caption><px>File gausssine.dat, displayed with
                IDL</px></caption>
            <figurecontent image="gausssine-idl.eps"/>
            <figurecontent image="gausssine-idl.gif"/>
          </figure>

          <p>IDL comes with rather good manuals, the reference parts
            of which are available on-line by typing <code>?</code> at
            the IDL prompt.
          </p>

          <p>See appendix B of <docxref doc="SUN/55" text="SUN/55" />
            for a description of how to import data in the Starlink
            NDF format into IDL.
          </p>

        </subsubsect>

        <subsubsect id="s.dx">
          <subhead><title>DX</title></subhead>

          <p>IBM's Data Explorer is also available on some Starlink
            machines.  I don't have personal experience of it, but
            there is a Starlink manual for it in <docxref doc="SUN/203"
            text="SUN/203" />, <cite>SX and DX -- IBM data explorer
            for data visualisation</cite> and a Starlink DX cookbook
            in <docxref doc="SC/2" text="SC/2" />.
          </p>

          <p>In his overview of visualisation systems in <docxref
            doc="SG/8" text="SG/8" />, Clive Davenhall says of DX:
            <blockquote><px>IBM Data Explorer (DX) is a
            general-purpose software package for data visualisation
            and analysis. It employs a data-flow driven client-server
            execution model and provides a comprehensive range of data
            manipulation, visualisation and display functions.
            Visualisations can be generated using a visual programming
            editor or a text-based scripting language. DX is the
            visualisation package recommended by Starlink,
            particularly for three-dimensional scalar and vector
            data. Starlink has produced a set of enhancements to
            DX. If you are using DX at a Starlink site then these
            enhancements should be available automatically. The use of
            DX at Starlink sites and the Starlink enhancements to DX
            are documented in <docxref doc="SUN/203" text="SUN/203"
            />.</px></blockquote>
          </p>

        </subsubsect>

        <subsubsect id="s.pgplot">
          <subhead><title>PGPLOT</title></subhead>

          <p>The above recommendations describe standalone packages
            which work on data produced by your code in a separate
            step.  An alternative route is to incorporate the plotting
            facilities within your program, and the recommended way of
            doing this is by using the PGPLOT library.
          </p>

          <p>The library, which was written to support astronomical
            applications, consists of a collection of high-level
            routines for producing plots, maps and images either
            on-screen or as Postscript to a file.  Refer to <docxref
            doc="SUN/15" text="SUN/15" />, <cite>PGPLOT --- Graphics
            Subroutine Library</cite> for further details, or to the
            PGPLOT home page at &lt;<url></url>&gt;.
          </p>

          <p>Note that there are <em>two</em> versions of PGPLOT
            currently available on Starlink, `native' PGPLOT, and a
            Starlink version which uses GKS.  The latter is being
            deprecated, with a view to being ultimately phased out,
            and this will affect how you link your program against the
            library.  At the time of writing (December 1998), the way
            in which the dual versions will be supported has not been
            finalised; ask your system manager for advice.
          </p>

        </subsubsect>

      </subsect>

      <subsect id="s.im" export="export">

        <subhead><title>Producing images</title></subhead>

        <p>If you wish to include images in your LaTeX output, do so
          using the standard graphics package.  That is, include in
          your file the command <code>\usepackage{graphics}</code> (if
          you're obliged to use the old LaTeX2.09, you can use the
          <code>epsf</code> option to the document style).  Include
          the graphics with the command
          <code>\starincludegraphics{file.eps}</code>.  So how do you
          produce the postscript?
        </p>

        <p>An important point is that the postscript should be
          <em>encapsulated</em> postscript.  This is postscript intended to be
          incorporated within another document: it has a <code>BoundingBox</code>
          comment at the top of the file, and typically has the extension
          <code>.eps</code>.
        </p>

        <p>See <ref id="s.visualisation"/> for details of how to produce EPS
          plots from gnuplot and IDL.
        </p>

        <p>If it's diagrams you want to produce, then <code>xfig</code> has its adherents.
          There's a <em>large</em> manual page for <code>xfig</code>, but you can do pretty
          well just starting it up, and pointing and clicking.
        </p>

        <p>If point and click isn't your style, try <webref
          url="http://cm.bell-labs.com/who/hobby/MetaPost.html">MetaPost</webref>.
          This is a variant of Knuth's MetaFont (which is used for
          designing TeX fonts), which produces postscript instead.  To
          produce a document using MetaPost, you produce a text file
          specifying the objects you want to draw and their spatial
          relationships.  It can be hard work, but the results can
          look very good.  If you wished to automate producing
          diagrams, perhaps because you want to produce a set of
          diagrams which are systematically different, then MetaPost
          could very well help you with this.  See
          <code>.../texmf/doc/metapost</code> under the (Starlink) TeX
          tree for further details.</p>

      </subsect>

    </sect>

    <sect id="s.astro" export="export">
      <subhead><title>Astrophysical and other libraries</title></subhead>

      <subsect id="s.models" export="export">
        <subhead>
          <title>Astrophysical modelling codes</title>
          <update versionid="v2-0"><px>Expanded this section
          considerably, with several more links.</px></update>
          <update versionid="v2-2"><px>Reworking of this section after
          comments from BS; added VALD and Dusty links.</px></update>
        </subhead>

        <p>This section aims to be no more than a set of pointers to more
          complete information and resources.  I'm no expert in this field,
          myself, so if I've missed some important resource, or
          miscontextualised something, please do let me know.</p>

        <p>Stellar atmosphere codes:
          <ul>
            <li>
              <p><webref url="http://ccp7.dur.ac.uk/">CCP7</webref>
                was a <webref
                url="http://www.dci.clrc.ac.uk/ListActivities.asp?Class=5;Classtype=21;">Collaborative
                Computational Project</webref>, `concerned with the
                calculation of theoretical models suitable for the
                interpretation of stellar and interstellar spectra'.
                As well as promoting the use of advanced computers in
                astronomy, it developed a library of
                stellar-atmosphere and spectroscopy codes.  The
                project finished in April 2001, but the resources it
                produced are still useful.</p>
            </li>

            <li><p><webref url="http://star.arm.ac.uk/~csj/">Simon
                  Jeffery</webref> makes available a number of tools
                  for stellar atmosphere calculations.</p></li>

            <li><p>At <webref url="http://kurucz.harvard.edu/">Robert
                  Kurucz's home page</webref> you can obtain copies of
                  his ATLAS and other codes, along with grids of model
                  atmospheres.</p></li>

            <li><p><webref
                url="http://phoenix.physast.uga.edu/">PHOENIX</webref>:
                state-of-the-art M-star model atmospheres.</p></li>

          </ul>
        </p>

        <p>Atomic and molecular data:

          <ul>
            <li><p>The <webref
                  url="http://vizier.u-strasbg.fr/OP.html">Opacity
                  Project</webref> is a collaborative project to
                  produce the atomic data required for stellar
                  envelope calculations.  The project makes the
                  results generally available both through a database
                  called `TOPbase', and by anonymous FTP.</p></li>

            <li><p>Other opacity data is available from the <webref
                url="http://www-phys.llnl.gov/V_Div/OPAL/">OPAL
                code</webref>.  As well as making precalculated
                opacity tables available, you can make requests for
                new tables to be generated.</p></li>

            <li><p>Atomic data at <webref
                url="http://www.pa.uky.edu/~verner/atom.html">Kentucky</webref>
                and <webref
                url="http://cfa-www.harvard.edu/amdata/ampdata/amdata.html">Harvard</webref></p></li>

            <li><p><webref url="http://spec.jpl.nasa.gov/">JPL Molecular
                  Spectroscopy</webref></p></li>

            <li><p>The <webref
                  url="http://www.astro.univie.ac.at/~vald/">Vienna
                  Atomic Line Database (VALD)</webref> is an excellent
                  site with up-to-date atomic data needed for spectrum
                  synthesis.</p></li>

          </ul></p>

        <p>Astronomical chemistry (loosely) -- dust, clouds and the
        interstellar medium:
          
          <ul>
            <li><p><webref
                url="http://www.pa.uky.edu/~gary/cloudy/">Cloudy</webref>
                is a arge-scale plasma simulation code that is widely
                used across the astronomical community as an aid in
                the interpretation of spectroscopic data.</p></li>
            
            <li><p><webref
                url="http://www.pa.uky.edu/~moshe/dusty/">DUSTY</webref>
                is a dust-shell modelling code, also originating at
                Kentucky.</p></li>

          </ul></p>

        <p>A number of <webref
          url="http://www.fges.demon.co.uk/cfd/CFD_codes.html">CFD
          codes</webref> are available to buy or download.  This is a
          collection of pointers and notes about a large number of CFD
          codes, from a variety of sources.
        </p>

        <p>Thanks to [<ref id="ta.sj">SJ</ref>], [<ref id="ta.bs">BS</ref>] and
          [<ref id="ta.as">AS</ref>] for
          much of the content of this section.
        </p>

      </subsect>

      <subsect id="s.lib" export="export">
        <subhead>
          <title>General-purpose and numerical libraries</title>
          <update versionid="v2-0"><px>Longer discussion of the GPL
              and other free licences.</px></update></subhead>

        <p>There are numerous software libraries available.  Many of
          these are free, many are public domain.  The difference
          between the two is that `public-domain software' is in some
          sense `ownerless': it's yours to play with, or modify, or
          exploit, as you wish, with only good manners requiring you
          to acknowledge the source (this is not an authoritative
          statement of copyright law, by the way...).  `Free'
          software, on the other hand, is still copyrighted, but you
          may have a free licence to use it for certain purposes.  One
          of the best known of these licences is the <webref
          url="http://www.gnu.org/copyleft/gpl.html">GNU General
          Public Licence</webref>, which gives you very good access to
          the code, limited only by the requirement that programs
          produced using GPL'd code are themselves made as freely
          availale.  Other licences might make the code available to
          academic users only, or only for non-commercial use.  The
          GNU project have a useful collection of <webref
          url="http://www.gnu.org/licenses/license-list.html">free and
          not-so-free licences</webref>, which is useful even though
          they are sometimes a little fervent about the issues.  The
          type of licence makes a difference if you plan to
          redistribute your code.  See also the observations about
          libraries, and thoughtless use of them, in <ref
          id="s.na"/>.</p>

        <p>Probably the most commonly used numerical library is the
          <webref url="http://www.nag.co.uk">NAG library</webref>.
          This is a long-established, and very highly thought-of,
          library, which contains codes to deal with a broad range of
          numerical problems.  The routines tend to come in several
          versions, typically a highly general, and highly
          configurable, one, accompanied by easy-to-use drivers.  The
          NAG library is expensive, but Starlink's size allows it to
          negotiate with NAG to provide the library at all Starlink
          sites.  The routines are generally in Fortran, but C
          versions of some of them are becoming available.
        </p>

        <p>The PDA library is a collection of public-domain and free routines,
          assembled by Starlink, and intended to replace the NAG library in
          Starlink application code.  The collection was assembled using GAMS,
          with routines drawn from FFTPACK, SLATEC,
          NMS, OPT, plus other isolated sources.  If you need
          to use one of the available algorithms, then the
          advantage of using the library version is that the (possibly
          non-trivial) work of building it for your architecture has already
          been done, leaving you able to simply link against the library.  The
          collection is fully documented in
          <docxref doc="SUN/194" text="SUN/194" />.
        </p>

        <p>The remaining libraries are typically free.</p>

        <p>In your search for codes, you would do well to start at
          <webref url="http://gams.nist.gov">GAMS</webref>: Guide to
          Available Mathematical Software.  This describes itself as
          `A cross-index and virtual repository of mathematical and
          statistical software components of use in computational
          science and engineering'.  You can either search for the
          code you need by keyword, or work through their
          classification of problems (a classification which is
          occasionally used more widely) to find references.  They
          point to both free and commercial software.
        </p>

        <p>The first collection to be aware of is Netlib.  The archive
          is based at <url>http://www.netlib.org</url>, but there are
          <webref url="http://www.netlib.org/bib/mirrors.html">UK
          mirrors</webref> Although there are some facilities which
          are primarily available at Netlib, it also mirrors several
          other archives.
        </p>

        <p><webref url="http://www.nhse.org/">NHSE</webref>, the (US) National
          High-Performance Software Exchange, is `a distributed
          collection of software, documents, data, and information of interest
          to the high performance and parallel computing community'.
          NHSE is part of Netlib, and incorporates software repositories
          <webref url="http://www.nhse.org/hpc-netlib/">HPC-netlib</webref>
          for
          high-performance software, 
          <webref url="http://www.nhse.org/ptlib/">PTlib</webref>
          for parallel tools, 
          and <webref url="http://www.csir.org/">CSIR</webref>
          for chemistry software.
        </p>

        <p>The <webref
          url="http://wwwinfo.cern.ch/asd/index.html">CERN program
          library</webref> includes <webref
          url="http://wwwinfo.cern.ch/asd/cernlib/overview.html">CERNLIB</webref>,
          which consists of a number of <webref
          url="http://wwwinfo.cern.ch/asd/cernlib/libraries.html">component
          libraries</webref>.  This is a long-standing and well-known
          library of general-purpose Fortran (typically) numerical
          routines with, obviously, some bias towards particle
          physics.  The service is free to all HEP users, and to
          physics departments in CERN member states, with separate
          non-commercial and commercial rates available.  There is a
          <webref
          url="http://wwwinfo.cern.ch/asdcgi/listcernlibfaqs.pl">FAQ</webref>.
        </p>

        <p>JPL has a <webref
          url="http://math.jpl.nasa.gov/">Computational Mathematics
          Library</webref>.  These appear to be free, but no longer
          formally supported by JPL.
        </p>

        <p>The <webref
          url="http://math.nist.gov/toms/Overview.html">ACM
          Transactions on Mathematical Software</webref> (TOMS) is a
          journal produced by the ACM.  The software discussed in
          there is available at GAMS, and mirrored at <webref
          url="http://www.hensa.ac.uk/netlib/toms/">HENSA</webref>.
        </p>

        <p>The <webref url="http://www.scd.ucar.edu/">Scientific
          Computing Division</webref> of the (US) <webref
          url="http://www.ncar.ucar.edu/">National Center for
          Atmospheric Research</webref>, has an overview of <webref
          url="http://www.scd.ucar.edu/softlib/mathlib.html">mathematical
          and statistical packages</webref>.  Not all the packages
          reviewed there are freely available, but the discussions are
          useful.
        </p>

        <p><webref url="http://www.bell-labs.com/project/PORT/">PORT</webref>
          is a collection of general maths subroutines.  Its description of
          itself is on the front page: `The
          PORT Mathematical Subroutine Library (third edition) is a
          collection of Fortran 77 routines that address many
          traditional areas of mathematical software, including
          approximation, ordinary and partial differential equations,
          linear algebra and eigensystems, optimization, quadrature,
          root finding, special functions, and Fourier transforms, but
          excluding statistical calculations. PORT stands for Portable,
          Outstanding, Reliable, and Tested.'
          Some routines are public-domain when, for example, they are
          developments of public routines, others have a
          non-commercial-use licence condition.
        </p>

        <p><webref
          url="http://www.hensa.ac.uk/netlib/slatec/index.html">Slatec</webref>
          is `a comprehensive software library containing over 1400
          general purpose mathematical and statistical routines
          written in Fortran 77.'
        </p>

        <p>Specifically concerned with minimisation, <webref
          url="http://www.hensa.ac.uk/netlib/minpack/">minpack</webref>
          (or at <webref
          url="http://www.netlib.org/minpack/">netlib</webref>), is a
          library for solving linear and nonlinear minimisation
          problems.  It has documentation within the source code.

        </p>

        <subsubsect id="s.rwdata">
          <subhead>
            <title>Reading and writing data</title>
            <update versionid="v2-0"><px>Added CONVERT example, and
                added pointers to FITS and cfitsio.</px></update>
          </subhead>

          <p>The codes you write do not exist in isolation, and at
            some point you will have to read data from, or write it
            to, files.  You might, therefore, need to read or write
            one of a number of standard data formats.  Clive Davenhall
            wrote an article on this in the September 1998 issue of
            the <webref
            url="http://www.starlink.ac.uk/bulletin/98sep/node12.html">Starlink
            Bulletin</webref>.  This covered reading and writing using
            the IMG library (<docxref doc="SUN/160" text="SUN/160" />),
            using NDF files and the HDS files they are a special case
            of (<docxref doc="SUN/33" text="SUN/33" /> and <docxref
            doc="SUN/92" text="SUN/92" /> respectively), and reading
            and writing FITS files (<docxref doc="SUN/136"
            text="SUN/136" />).</p>

          <p>You can convert between different data formats using the
            CONVERT package, documented in <docxref doc="SUN/55"
            text="SUN/55" />.  CONVERT is extremely easy to use, and
            converting a FITS file, say, to an NDF is as easy as
            <verbatim>fits2ndf myfile.fits myfile</verbatim></p>

          <p>If you have to read or write FITS files, then visit the
            <webref url="http://fits.gsfc.nasa.gov/">FITS home
            page</webref> for the FITS users guide and the <webref
            url="http://heasarc.gsfc.nasa.gov/docs/software/fitsio/fitsio.html"><code>cfitsio</code></webref>
            library.  Although FITS files have a very simple format,
            there are enough ways of getting things wrong that you
            will, as usual, save yourself time in the long run by
            taking the trouble to use the <code>cfitsio</code>
            library.  It's easier than you might think: the Quick
            Start Guide contains most of what you'll ever need to
            know.  Note that, although the library is called
            <em>c</em>fitsio, it's designed to be used with Fortran as
            well, and the programmer's reference guide comes in two
            flavours.</p>

          <p>Once the data is there, you will need to visualise it.  See
            <ref id="s.im"/> for some pointers to suitable
            software.</p>

        </subsubsect>

      </subsect>

      <subsect id="s.link.libs" export="export">
        <subhead><title>Link farms</title></subhead>

        <p><url>http://cdsweb.u-strasbg.fr/astroweb.html</url>:
          AstroWeb is one of the most useful link collection, because
          it has been developed by the astronomy community.
        </p>

        <p><url>http://math.nist.gov/toms/Resources.html</url>: The
          TOMS list of web resources for mathematical software is a
          collection of pointers maths software on the web.
        </p>

        <p>Yahoo has managed to assemble a respectable collection of
          pointers to Scientific software at
          <url>http://uk.yahoo.com/Computers_and_Internet/Software/Scientific/</url>,
          as well as more specific pointers to maths
          (<url>http://uk.yahoo.com/Science/Mathematics/Software/</url>),
          physics
          (<url>http://uk.yahoo.com/Science/Physics/Software/</url>)
          and astronomy
          (<url>http://uk.yahoo.com/Computers_and_Internet/Software/Scientific/Astronomy/</url>)
          resources.

        </p>

      </subsect>

    </sect>

    <sect id="s.paper" export="export">
      <subhead><title>Paper production</title></subhead>

<subsect id="s.latex" export="export">
        <subhead>
          <title>TeX and LaTeX</title>
          <update versionid="v2-0"><px>Pointers to the LaTeX project, other tutorials, and the TeX FAQ.
Some reorganisation.</px></update>
          <update versionid="v2-3"><px>Added a
              reference to the Adam Lewenberg book
              pointers</px></update>
          <update versionid="v2-5"><px>Added
              a pointer to Peter Flynn's Beginner's
              LaTeX</px></update>
        </subhead>

        <p>Starlink supports LaTeX and TeX users by maintaining and
packaging for release a TeX distribution.  This is typically based
on one of the standard TeX distributions, plus an effort to ensure
that the distribution includes packages of interest to astronomers,
particularly some of the relevant journal style files.  See the 
<webref url="http://www.starlink.ac.uk/%7eacc/tex/tex.html">Starlink LaTeX page</webref>
for details.
</p>

        <p><webref url="http://www.latex-project.org/">LaTeX</webref> is
nominally (though not actually)
re-released every six months, in June and December, with
each release incorporating bugfixes, but no significant development.
New features are being incorporated into LaTeX3, which is a major
upgrade, still being developed.  Versions more than a year old (that
is, more than two releases ago) are formally `obsolete', and bug reports
won't be accepted for them.</p>

        <p>The current version of LaTeX is also known as LaTeX2e, to
distinguish it from the by now completely obsolete LaTeX2.09, which
is the version of LaTeX described in the first edition of Lamport's
book.  LaTeX2e has significant internal differences from
LaTeX2.09, but was intended to appear much the same to the user.
The most prominent difference is that LaTeX2e files start with the
declaration <code>\documentclass[options]{classname}</code>, and
invoke further packages using <code>\usepackage{packagename}</code>,
whilst LaTeX2.09 files start
<code>\documentstyle[options]{stylename}</code>, with the options list
being a mixture of style file options and package names.  LaTeX2e
will attempt to go into a `compatibility mode' if it sees a file start
with <code>\documentstyle</code>, but this isn't terribly reliable,
and you <em>certainly</em> shouldn't create new files like this,
unless some primitive publisher (which used to include MNRAS until
rather recently) absolutely insists on it.</p>

        <p>Other LaTeX resources you might want to examine are the
          <webref url="&ctan;/faq">UK TeX FAQ</webref> (this is
          <em>very</em> good), <webref
          url="http://wwwinfo.cern.ch/asdoc/textproc.html">CERN's
          TeXpages</webref>, and the <webref
          url="&ctan;/tex-archive/help/Catalogue/catalogue.html">catalogue</webref>
          at <webref url="&ctan;">CTAN</webref> (the
          `Comprehensive TeX Archive Network', hosted on three peer
          machines in the UK, Germany and the US, and mirrored
          worldwide; all TeX is there).</p>

        <p>All this, of course, assumes that you're already a LaTeX user.
If you're just starting with LaTeX, then the canonical place to
start is with Leslie Lamport's <cite>LaTeX: a Document Preparation
System, 2nd edition</cite> <citation>lamport</citation>.  I think this is a good
introduction, because it concentrates on the basics, and leaves the
elaborate details to others.  The bulk of the book is an accessible
introduction to LaTeX (and note that you really ought to avoid asking
LaTeX questions until you've read chapter 2); appendix C is
a reference manual.</p>

        <p>If it's the elaborate details you
want, then you'll need to supplement Lamport.  Victor Eijkhout's
<webref url="http://www.eijkhout.net/tbt/">TeX by Topic</webref> is
well spoken-of, though I haven't examined it myself (the book is now out
of print, but the author has made it available for free, for a donation).
Two other good books to
examine are <cite>A Guide to LaTeX</cite>
<citation>kopka</citation>, and <cite>LaTeX Line by Line</cite>
<citation>diller</citation>.  Both are substantially more advanced than Lamport,
and cover a lot of material densely but reasonably clearly.  If forced
to choose, I would go for Kopka and Daly over Diller, partly because
they have produced a second edition covering LaTeX2e, but also
because Diller seems to try to pack in too much, including some
material (such as the intricacies of maths typesetting) which, if
you're going to learn, you should probably learn from Knuth's TeXbook.
Having said that, the advantage is a narrow one, and you'd be
well-advised to choose based on whose writing style you prefer, and
which one happens to be in the bookshop on the right day<note><px>It's
unfortunate that neither book is much of an advert for TeX's
potentially beautiful typesetting -- both seem to be produced using a
practically unmodified LaTeX <code>book</code> style.</px></note>.
Both of the last two should be kept away from anyone not already convinced of
LaTeX's virtues, since they both make LaTeX seem much
more forbidding than it actually is.
Finally, Goossens,
Mittelback and Samarin's <cite>The LaTeX 
Companion</cite> <citation>goossens</citation> is useful, but intended as a reference, not as an
introduction.  For other print books, and details of these ones, see the
TeX FAQ's bibliography at 
<url>&ctan;/cgi-bin/texfaq2html?label=books</url>, and Adam
Lewenberg's collection of <webref url="http://www.macrotex.net/texbooks/">TeX and LaTeX print
resources</webref>.</p>

        <p>There are a number of <webref url="&ctan;/cgi-bin/texfaq2html?label=tutorials">online
tutorials</webref>.  Both the `<webref url="&ctan;/tex-archive/info/gentle/">Gentle Introduction</webref>'
and the `<webref url="&ctan;/tex-archive/info/lshort/english/">Not so
Short Introduction</webref>' are available at CTAN.  Peter Flynn's
`<webref url="http://www.silmaril.ie/downloads/documents/beginlatex.pdf">Beginner's LaTeX</webref>' is well written and informative, and
spends a good deal more time on the preliminary technicalities than
others; but -- since it grew out of a two-day introduction to LaTeX
aimed primarily at humanities users -- it does not cover maths.</p>

        <!--XXX: possibly include pointers to
     http://www-h.eng.cam.ac.uk/help/tpl/textprocessing/
     http://www.latex-project.org/
     -->

        <p>If you prefer learning by example, take a look at the standard sample
files, <code>small2e.tex</code> and <code>sample2e.tex</code>.  These will be
somewhere in your LaTeX distribution, typically with a path ending
in <code>.../tex/latex/base/small2e.tex</code> (try <code>echo
$TEXINPUTS</code> or <code>kpsepath tex</code> to help locate the TeX
distribution on your local machine).</p>

        <p><em>The</em> book on TeX is Knuth's original, <cite>The
TeXbook</cite> <citation>knuth</citation>.  As well as describing
the underlying TeX engine, this also 
describes Knuth's very basic macro package, <code>plain</code>.  You need
the TeXbook if you're writing a LaTeX macro package, if you
demand complete control over positioning (tricky in TeX, but an
out-and-out hassle in LaTeX), or if you just don't like the way
LaTeX lays things out and want to do it all yourself.  If you don't
fall into any of those categories, <code>plain</code> TeX is probably
not where to start (and I speak as a lapsed TeXie who has spluttered
furiously at Leslie Lamport's failure to impose a satisfactorily
rigourous line on even such fundamental doctrinal matters as how the
word `LaTeX' is to be pronounced).</p>

        <p>You should be aware of <code>pdflatex</code>, which is a version of 
TeX which produces PDF files directly rather than DVI files (though
note that versions before <code>1.0-prerelease</code> produce bad PDF
which breaks Windows Acroread 5 at least).</p>

        <p>Starlink has produced several documents concerned with LaTeX.
The LaTeX user's guide,
<docxref doc="SUN/9" text="SUN/9" />,
concentrates on the practical details of LaTeXing your document and
ultimately transforming it into PostScript.  You should also refer to
<docxref doc="SC/9" text="SC/9" />, the LaTeX cookbook.
However, <docxref doc="SGP/28" text="SGP/28" />, <cite>How to write good
documents for 
Starlink</cite>, <docxref doc="SUN/199" text="SUN/199" />, <em>Star2HTML</em> and
<docxref doc="SGP/50" text="SGP/50" />, <cite>Starlink Document Styles</cite> are
primarily intended for those writing Starlink
          documentation.</p>

      </subsect>

      <subsect id="s.lanl" export="export">
        <subhead><title>The LANL archive</title></subhead>

        <p>The LANL preprint archive is based, in the UK, at
          <url>http://xxx.soton.ac.uk</url> which is a mirror of the
          <webref url="http://xxx.lanl.gov">master archive</webref> at
          LANL.  The archive is easy to use as a reader but not,
          unfortunately, transparently easy to use as an author (not
          helped by the rather snide error messages that come back if
          you slip up...).
        </p>

        <p>The <webref url="http://xxx.soton.ac.uk/help/">full
            instructions</webref> are comprehensive, but boil down to
            the following:
          <ul><li><p>The first time you submit
            anything to the archive, you need to register as an
            author.  That registers your email address with them and
            sets a few preferences (such as the default archive you'll
            submit to).</p></li>

            <li><p>Bundle up the LaTeX source for
            your paper in a <code>.tar.gz</code> archive.  The
            automatic-processing software at LANL seems to LaTeX every
            <code>.tex</code> file in sight, so if your submission
            isn't in the canonical format of one TeX file plus a bunch
            of PostScript figures, you'd probably best read the
            instructions one more time.  It follows from this that it
            doesn't matter what you call your TeX file: the processing
            software will still TeX it.  </p><p>LANL has copies of
            journal styles such as the A&amp;A one -- when they
            process your paper it'll be formatted according to that
            style file.  They suggest that the PostScript figures in
            the article be numbered something like
            <code>figure1.ps</code>, <code>figure2.ps</code>, so that
            they alphabetise correctly.  See <webref
            url="http://xxx.soton.ac.uk/help/submit_tex"><cite>Considerations
            for TeX submissions</cite></webref> for the gory
            details.</p></li>

            <li><p>Read the uploads help again,
            particularly the information on the information fields
            you'll have to fill in, then go to the uploads page at
            <url>http://xxx.lanl.gov/uploads</url>.</p></li>

            <li><p>The
            uploads page gives you a form to type in the various
            details of author and title and the like, and to type in
            the abstract.  You give the name of your tar file, press
            the button and wait.  After a pause you can check if the
            automatic processing succeeded.  At this stage, you'll be
            given a password for this paper.  This allows you and your
            co-authors to retrieve the paper before it's put in the
            public archive, and will be needed to make alterations, or
            update the journal publication details, in
            future.</p></li>

            <li><p>Now, you need a drink.</p></li>

          </ul>
        </p>

      </subsect>

    </sect>

    <sect id="s.astro.general" export="export">
      <subhead>
        <title>General astronomical and astrophysical resources</title>
      </subhead>

      <p>The <webref url="http://cdsads.u-strasbg.fr/">Astrophysics
        Data System</webref> (ADS) is a NASA project, providing an
        abstract service, along with a subsidiary data service.
        Further to this, <docxref doc="SUN/174" text="SUN/174" />,
        <cite>An Astronomer's Guide to On-line Bibliographic Databases
        and Information Services</cite>, describes bibliographic and
        other resources of interest to astronomers.

      </p>

      <subsect id="s.obs" export="export">
        <subhead><title>Observations</title></subhead>

        <p><webref
          url="http://simbad.u-strasbg.fr/Simbad">SIMBAD</webref> is a
          `Set of Identifications, Measurements and Bibliography for
          Astronomical Data'.  It's a large database (5,416,970
          objects in November 1998) of astronomical objects, which you
          can search by identifier, coordinates, or other sampling
          criteria.  As well as basic data for the objects, it
          includes some observational data from, and journal
          references to, the object.  You have to register before you
          can use it; it's not free, but if you're in the US or in an
          ESO or ESA member state, the costs are covered for you.
          Also at CDS is the <webref
          url="http://cdsweb.u-strasbg.fr/Cats.html">CDS catalogue
          service</webref>, which allows you to search a list of
          almost 3000 catalogues, plus the contents of tables
          published in A&amp;A.
        </p>

        <p>If you're using such catalogues, you might want to take a
          look at CAT, the Starlink <cite>Catalogue and table
          manipulation library</cite>, documented in <docxref
          doc="SUN/181" text="SUN/181" />.  This is a subroutine
          library for manipulating astronomical catalogues and similar
          tabular datasets.  See also <docxref doc="SUN/127"
          text="SUN/127" />, <cite>The EXOSAT Database System</cite>,
          and more generally <docxref doc="SUN/162" text="SUN/162" />,
          <cite>A Guide to Astronomical Catalogues, Databases and
          Archives available through Starlink</cite>.
        </p>

      </subsect>
</sect>

    <sect id="s.acknowledgements" export="export">
      <subhead><title>Acknowledgements</title>
      </subhead>

      <p>A number of people have contributed to this document, either
with helpful general remarks or corrections or amplifications on
points of detail.  Where their contribution was precisely localisable
-- in particular where I have merely sub-edited their comments into
place -- they are also acknowledged at the appropriate specific points
in the text.

        <ul>
          <li id="ta.sg"><p>SG: Sergio Gelato
          (<code>Sergio.Gelato@Durham.ac.uk</code>) added remarks
          about optimizing C, and compiler switches.</p></li>

          <li id="ta.sj"><p>SJ: Simon Jeffery
          (<code>csj@star.arm.ac.uk</code>) added pointers to model
          atmosphere codes.</p></li>

          <li id="ta.jl"><p>JL: Jon Lockley
              (<code>jjl@astro.soton.ac.uk</code>)</p></li>

          <li id="ta.as"><p>AS: Anne Sansom
              (<code>aesansom@uclan.ac.uk</code>).</p></li>

          <li id="ta.bs"><p>BS: Barry Smalley
          (<code>bs@astro.keele.ac.uk</code>). Pointers to model
          atmospheres.</p></li> 

          <li id="ta.mbt"><p>MBT: Mark Taylor
              (<code>mbt@ast.cam.ac.uk</code>) made a number of points
              about my coverage of Fortran, and several insightful
              remarks about numerical programming.</p></li>

          <li id="ta.rfws"><p>RFWS: Rodney Warren-Smith made many
              comments on an early draft of the text, which made it
              much better than it otherwise might have been.</p></li>

          <li id="ta.rw"><p>RW: Robin Williams
          (<code>Robin.Williams@astro.cf.ac.uk</code>) general
          comments, and information about Alpha switches.</p></li>

        </ul>
      </p>

    </sect>

    <appendices>

      <sect id="s.examples" export="export">
        <subhead>
          <title>Example programs</title>
          <update versionid="v2-0"><px>Added islittleendian example
          program</px></update>
          <update versionid="v2-1"><px>Added download
          URL</px></update>
        </subhead>

        <p>This section contains several example programs.  These are also
distributed with the source of this document.  Look in <code type="fspath">/star/examples/sc13*</code>.  The examples are available
for download from 
<url>&sc13webpage;sc13-examples.tar.gz</url>.</p>

        <subsect id="a.islittleendian.c" export="export">
          <subhead><title>islittlendian.c</title></subhead>

          <p>If you want to find out, possibly as part of a script,
            whether a particular platform is big- or little-endian,
            the information will probably be squirrelled away
            somewhere in the headers for the compiler you're using,
            unfortunately not in any standard way.  However, a
            portable way of doing this (which incidentally illustrates
            the contrast between the two systems) is to use this
            little program.  It isn't bullet-proof, but if it fails,
            this is probably the least of your cross-platform
            problems.  You can use the program as follows:

<verbatim>
% echo '#define BIGENDIAN' \
    `if ./islittleendian; then echo 0; else echo 1; fi` &gt;bytesex.h
</verbatim>

to create a file <code>bytesex.h</code> with either <code>#define
BIGENDIAN 1</code> or <code>#define BIGENDIAN 0</code> in it.

<verbatim>
&ex-islittleendian-c;
</verbatim></p>
        </subsect>

        <subsect id="a.fpp.c" export="export"><subhead><title>fpp.c</title><update versionid="v2-0"><px>Replaced with expanded/corrected program, which also deals with
doubles.</px></update></subhead><p>The first <code>fpp.c</code>, allows you to explore the representation of
floating-point numbers on your machine.  Note that machines may have
either `big-endian' or `little-endian' addressing schemes (referring
to the order in which integers and floating-point numbers are stored
in memory).  Alpha and Intel chips are little-endian, Sparcs, the
Motorola 68k family used in Macs, and Motorola PowerPC chips, are
big-endian.  On the latter machines, you'll need to compile these
programs with the <code>-DBIGENDIAN</code> option to the C compiler.

<verbatim>
&ex-fpp-c;
</verbatim>
          </p>
        </subsect>

        <subsect id="a.fpdemo.c" export="export">
          <subhead><title>fpdemo.c</title></subhead>

          <p>The program <code>fpdemo.c</code> is discussed in
section <ref id="s.accuracy"/>, and shows the effects of catastrophic
cancellation.

<verbatim>
&ex-fpdemo-c;
</verbatim>
            </p></subsect>

        <subsect id="a.profiling" export="export">
          <subhead><title>Profiling</title></subhead>
          
          <p>The fortran files <code>p?.f</code> are example files for
            <ref id="s.profiling"/>, on profiling.  These are drawn
            from <citation>sunf77</citation>. </p>

          <subsubsect>
            <subhead><title>p1.f</title></subhead>

<p>
<verbatim>
&ex-p1-f;
</verbatim>
</p></subsubsect>

          <subsubsect>
            <subhead><title>p2.f</title></subhead>
<p>
<verbatim>
&ex-p2-f;
</verbatim>
</p></subsubsect>

          <subsubsect>
            <subhead><title>p3.f</title></subhead>

<p>
<verbatim>
&ex-p3-f;
</verbatim>
</p></subsubsect>

        </subsect>

        <subsect id="a.crash.c" export="export">
          <subhead><title>crash.c</title></subhead>
          <p>The program <code>crash.c</code> crashes and dumps core.
          See <ref id="s.debugging"/> for discussion.

<verbatim>
&ex-crash-c;
</verbatim>
</p></subsect>

        <subsect id="a.mixed" export="export">
          <subhead><title>Mixed language programming</title></subhead>

          <p>The files <code>mixed-c.c</code> and <code>mixed-f.f</code>
            illustrate some of 
            the techniques involved in calling C from Fortran and <em>vice
              versa</em>, as described in <ref id="s.candf"/>.
          </p><p>On a Sun, compile and link them as follows:
<verbatim>
f77 -c mixed-f.f -ext_names=plain
cc -c mixed-c.c
f77 -o mixed mixed-c.o mixed-f.o
</verbatim>

            The extra option to the first <code>f77</code> command
            tells the compiler not to add an underscore to function
            names; different compilers will have different switches
            for accomplishing the same thing.  See <ref
            id="s.compilingcf"/> for discussion.</p>

          <subsubsect>
            <subhead><title>mixed-c.c</title></subhead>

<p>
<verbatim>
&ex-mixed-c-c;
</verbatim>
</p></subsubsect>

          <subsubsect>
            <subhead><title>mixed-f.f</title></subhead>

            <p>
<verbatim>
&ex-mixed-f-f;
</verbatim>
</p></subsubsect>
</subsect>

        <subsect id="a.maple" export="export">
          <subhead><title>maple.ms</title></subhead>

          <p>This example Maple file gives a slightly fuller example
            of Maple use than given in <ref id="s.maple"/>.
<verbatim>
&ex-maple-ms;
</verbatim>
</p></subsect>

        <subsect id="a.idl" export="export">
          <subhead><title>idl-functions.pro</title></subhead>

          <p>Here is an example of IDL programming, dealing with the common
            situation of reading in columns of data.  See also
            <ref id="s.vis-idl"/>.
<verbatim>
&ex-idl-functions-pro;
</verbatim>
</p></subsect>

      </sect>

      <sect id="s.refs" export="export">
        <subhead><title>References: Starlink documents</title></subhead>

        <p>This section contains a (non-exhaustive!) selection of Starlink
documents which should intersect with the interests of this cookbook's
audience.  Where possible, I have included a reference to a relevant
section of this document.
</p>

        <p>An overall reference for all Starlink users is the
<docxref doc="sug/" text="Starlink User's Guide" />.
</p>

        <p>
          <tabular frame="top">
            <tgroup cols="3">
              <colspec colname="col0"/>
              <colspec colname="col1" colwidth="4in"/>
              <colspec colname="col2" align="right"/>

              <tbody>
                <row rowsep="1">
                  <entry namest="col0" nameend="col2"
                    colsep="1"
                    align="center">Starlink User Notes </entry>

                </row>

                <row
                                               rowsep="1"><entry>Code</entry><entry>Title</entry><entry>Sect. </entry></row>

                <row><entry><docxref
                      doc="SUN/1" text="SUN/1"
                      /></entry><entry>Starlink software collection
                  </entry></row>

                <row><entry><docxref doc="SUN/9"
                      text="SUN/9" /></entry><entry>LaTeX -- Document
                    preparation system v2e User's
                    Guide</entry><entry><ref id="s.latex"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/11"
                      text="SUN/11" /></entry><entry>ARY --
                    Subroutines for accessing ARRAY data structures
                  </entry></row>

                <row><entry><docxref doc="SUN/12"
                      text="SUN/12" /></entry><entry>LaTeX --
                    Cook-book</entry><entry><ref id="s.latex"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/15"
                      text="SUN/15" /></entry><entry>PGPLOT --
                    Graphics subroutine library</entry><entry><ref
                      id="s.pgplot"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/28"
                      text="SUN/28" /></entry><entry>NAG -- Numerical
                    and Graphical Libraries Mk 16/4
                    UG</entry><entry><ref id="s.lib"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/33"
                      text="SUN/33" /></entry><entry>NDF -- Routines
                    for accessing extensible n-D data
                    1.3</entry><entry><ref id="s.rwdata"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/55"
                      text="SUN/55" /></entry><entry>CONVERT -- A
                    format-conversion package 1.1,
                    UM</entry><entry><ref id="s.vis-idl"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/73"
                      text="SUN/73" /></entry><entry>FORCHECK --
                    Fortran verifier and programming
                    aid</entry><entry><ref id="s.fortran77"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/92"
                      text="SUN/92" /></entry><entry>HDS --
                    Hierarchical data system 4.2,
                    PG</entry><entry><ref id="s.rwdata"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/93"
                      text="SUN/93" /></entry><entry>TeX -- Superior
                    document preparation system</entry><entry><ref
                      id="s.latex"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/107"
                      text="SUN/107" /></entry><entry>MAPLE --
                    Mathematical manipulation
                    language</entry><entry><ref id="s.maple"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/127"
                      text="SUN/127" /></entry><entry>EXOSAT database
                    system</entry><entry><ref id="s.obs"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/136"
                      text="SUN/136" /></entry><entry>FITSIO -- Disk
                    FITS I/O routines 5.03</entry><entry><ref
                      id="s.rwdata"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/145"
                      text="SUN/145" /></entry><entry>UNIX -- An
                    introduction</entry><entry><ref id="s.unix"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/160"
                      text="SUN/160" /></entry><entry>IMG -- Simple
                    image data access 1.2</entry><entry><ref
                      id="s.rwdata"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/162"
                      text="SUN/162" /></entry><entry>A guide to
                    astronomical
                    catalogues/databases/archives</entry><entry><ref
                      id="s.obs"/> </entry></row>

                <row><entry><docxref
                      doc="SUN/167" text="SUN/167"
                      /></entry><entry>PERIOD -- A time-series
                    analysis package
                  </entry></row>

                <row><entry><docxref doc="SUN/170"
                      text="SUN/170" /></entry><entry>Editors on
                    Unix</entry><entry><ref id="s.unix"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/172"
                      text="SUN/172" /></entry><entry>FTNCHEK -- A
                    Fortran 77 source-code checker</entry><entry><ref
                      id="s.fortran77"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/174"
                      text="SUN/174" /></entry><entry>Guide to on-line
                    bibliographies and information
                  </entry></row>

                <row><entry><docxref doc="SUN/181"
                      text="SUN/181" /></entry><entry>CAT -- Catalogue
                    and table manipulation library
                    5.1</entry><entry><ref id="s.obs"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/193"
                      text="SUN/193" /></entry><entry>PERL --
                    Practical Extraction and Report
                    Language</entry><entry><ref id="s.otherlang"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/194"
                      text="SUN/194" /></entry><entry>PDA -- Public
                    domain algorithms library 0.4,
                    PM</entry><entry><ref id="s.lib"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/203"
                      text="SUN/203" /></entry><entry>SX and DX -- IBM
                    data explorer for data
                    visualisation</entry><entry><ref id="s.dx"/>
                  </entry></row>

                <row><entry><docxref doc="SUN/209"
                      text="SUN/209" /></entry><entry>CNF and F77
                    Mixed Language Programming v3.1:
                    PM.</entry><entry><ref
                      id="s.candf"/></entry></row>

              </tbody></tgroup></tabular></p>

        <p>

          <tabular frame="top">

            <tgroup cols="3">
              <colspec colname="col0"/>
              <colspec colname="col1" colwidth="4in"/>
              <colspec colname="col2" align="right"/>
              <thead>
                <row rowsep="1">
                  <entry namest="col0" nameend="col2"
                colsep="1" align="center">Starlink General Papers </entry>
                </row>
              </thead>

              <tbody>
                <row>
                  <entry><docxref doc="SGP/4"
                      text="SGP/4" /></entry>
                  <entry>Starlink C
                    programming standard</entry>
                  <entry><ref id="s.c"/>
                  </entry>
                </row>
                <row><entry><docxref doc="SGP/16"
                      text="SGP/16" /></entry><entry>Starlink
                    application programming
                    standard</entry><entry><ref id="s.fortran77"/>
                  </entry></row>

                <row><entry><docxref doc="SGP/47"
                      text="SGP/47" /></entry><entry>Computer Algebra
                    Software</entry><entry><ref
                      id="s.maple"/></entry></row>

              </tbody></tgroup>

          </tabular>
        </p>

        <p>
          <tabular frame="top">
            <tgroup cols="3">
              <colspec colname="col0"/>
              <colspec colname="col1" colwidth="4in"/>
              <colspec colname="col2" align="right"/>
              <thead><row rowsep="1"><entry namest="col0" nameend="col2" colsep="1" align="center">Starlink Cookbooks
</entry></row></thead>

              <tbody><row><entry><docxref doc="SC/2"
                      text="SC/2" /></entry><entry>The DX
                    cookbook</entry><entry><ref id="s.dx"/>
                  </entry></row><row><entry><docxref doc="SC/9"
                      text="SC/9" /></entry><entry>LaTeX
                    Cookbook</entry><entry><ref id="s.latex"/>
                  </entry></row><row><entry><docxref doc="SC/12"
                      text="SC/12" /></entry><entry>Writing your own
                    data reduction
                    software</entry></row></tbody>
            </tgroup>
</tabular></p>

        <p>
          <tabular frame="top">
            <tgroup cols="3">
              <colspec colname="col0"/>
              <colspec colname="col1" colwidth="4in"/>
              <colspec colname="col2" align="right"/>
              <thead>
                <row rowsep="1"><entry namest="col0" nameend="col2" colsep="1" align="center">Starlink Guides
                  </entry></row>
              </thead>

              <tbody><row><entry><docxref doc="SG/6" text="SG/6"
              /></entry><entry>ADAM -- Programmer's facilities and
              documentation guide </entry></row><row><entry><docxref
              doc="SG/8" text="SG/8" /></entry><entry>Introduction to
              Visualisation Software for Astronomy</entry><entry><ref
              id="s.visualisation"/></entry></row></tbody>
            </tgroup>
          </tabular></p>

        <p>Miscellaneous User Documents are documents which are not
          originated by Starlink, which are held at RAL for the
          Starlink project. Copies may be available at other Starlink
          nodes. Ask your Site Manager if you want one.</p>

        <p>
          <tabular frame="top">
            <tgroup cols="3">
              <colspec colname="col0"/>
              <colspec colname="col1" colwidth="4in"/>
              <colspec colname="col2" align="right"/>
              <thead>
                <row rowsep="1"><entry namest="col0" nameend="col2" colsep="1" align="center">Miscellaneous User Documents
                  </entry></row>
              </thead>

              <tbody>
                <row>
                  <entry><docxref doc="MUD/30" text="MUD/30" /></entry>
                  <entry>IDL -- User's guide</entry>
                  <entry><ref id="s.vis-idl"/> </entry>

                </row>

                <row><entry><docxref doc="MUD/48" text="MUD/48"
                      /></entry><entry>LATEX -- User's guide and
                    reference manual</entry><entry><ref id="s.latex"/>
                  </entry></row>

                <row><entry><docxref doc="MUD/52" text="MUD/52"
                      /></entry><entry>MAPLE --
                    Introduction</entry><entry><ref id="s.maple"/>
                  </entry></row>

                <row><entry><docxref doc="MUD/55" text="MUD/55"
                      /></entry><entry>NAG -- Fortran library manual:
                    Mk 15 (10 vols)</entry><entry><ref id="s.lib"/>
                  </entry></row>

                <row><entry><docxref doc="MUD/56" text="MUD/56"
                      /></entry><entry>NAG -- A beginners guide
                    (Book)</entry><entry><ref id="s.lib"/>
                  </entry></row>

                <row><entry><docxref doc="MUD/57" text="MUD/57"
                      /></entry><entry>NAG -- Newsletters, Error
                    bulletins</entry><entry><ref id="s.lib"/>
                  </entry></row>

                <row><entry><docxref doc="MUD/58" text="MUD/58"
                      /></entry><entry>NAG -- Graphical library
                    supplement: Mk 3 (2 vols</entry><entry><ref
                      id="s.lib"/> </entry></row>

                <row><entry><docxref doc="MUD/72" text="MUD/72"
                      /></entry><entry>TEX -- The TeXbook
                    (Book)</entry><entry><ref id="s.latex"/>
                  </entry></row>

                <row><entry><docxref doc="MUD/121" text="MUD/121"
                      /></entry><entry>Unix for
                    beginners</entry><entry><ref id="s.unix"/>
                  </entry></row>

                <row><entry><docxref doc="MUD/122" text="MUD/122"
                      /></entry><entry>An introduction to display
                    editing with Vi</entry><entry><ref
                      id="s.editors"/> </entry></row>

                <row><entry><docxref doc="MUD/123" text="MUD/123"
                      /></entry><entry>Vi -- Quick reference
                    card</entry><entry><ref id="s.editors"/>
                  </entry></row>

                <row><entry><docxref doc="MUD/128" text="MUD/128"
                      /></entry><entry>NAG -- Fortran Library,
                    Introductory Guide (Mk 15)</entry><entry><ref
                      id="s.lib"/> </entry></row>

                <row><entry><docxref doc="MUD/137" text="MUD/137"
                      /></entry><entry>MAPLE V -- Language reference
                    manual</entry><entry><ref id="s.maple"/>
                  </entry></row>

                <row><entry><docxref doc="MUD/138" text="MUD/138"
                      /></entry><entry>MAPLE V -- Library reference
                    manual</entry><entry><ref id="s.maple"/>
                  </entry></row>

                <row><entry><docxref doc="MUD/139" text="MUD/139"
                      /></entry><entry>MAPLE V -- A tutorial
                    introduction</entry><entry><ref id="s.maple"/>
                  </entry></row>

                <row><entry><docxref doc="MUD/159" text="MUD/159"
                      /></entry><entry>SM -- Interactive plotting
                    program 2.3.1</entry><entry><ref
                      id="s.visualisation"/> </entry></row>

                <row><entry><docxref doc="MUD/160" text="MUD/160"
                      /></entry><entry>SM -- The SM
                    tutorial</entry><entry><ref
                      id="s.visualisation"/></entry></row>
              </tbody>
            </tgroup>
          </tabular>
        </p>
      </sect>

<sect id="s.relnotes" export="export">
<subhead><title>Release notes</title></subhead>
        
<subsect id="rel-2.2" export="export">
<subhead><title>Release 2.2</title></subhead>

<p><ul>
<li><p>Enhanced the coverage of Java (though it's still rather brief).</p></li>
<li><p>Added pointers to stellar atmosphere codes (thanks to Barry
Smalley, Ann Sansom, Simon Jeffery).</p></li>
<li><p>A few additions to the TeX/LaTeX coverage.</p></li>
</ul></p>
</subsect>

<subsect id="rel-2.1" export="export">
<subhead><title>Release 2.1</title></subhead>

<p>More detail about NaNs, compilers, largely incorporating the suggestions
I received after the previous edition.  Packaged set of examples.</p>
</subsect>

<subsect id="rel-2.0" export="export">
<subhead><title>Version 2</title></subhead>

<p>Assorted enhancements and additions.  Expanded the section on model
atmospheres.  Links checked, and a couple of broken ones restored.</p>

<p>I haven't been able to incorporate all the suggestions I received
after the previous edition.</p>
</subsect>

<subsect id="rel-1.2" export="export">
<subhead><title>Release 1.2</title></subhead>

<p>No significant changes as yet.  Merely a conversion from the
original &latex; source.</p>
</subsect>

</sect>

</appendices>

<backmatter bibliography="sc13"/>


<!--
Link checking by doing:

SGML_CATALOG_FILES=/home/norman/s/src/docs/document-summaries/CATALOG:/home/norman/s/src/sgml/w/sgml/dtd/CATALOG \
    nsgmls -wall $STARLINK_SGML_DIR/dtd/starlink.decl sc13.xml >sc13.parse
grep 'Aurl ' sc13.parse |awk '{print $3}'>sc13.urllist
sed -n '/^(url/ {n;s/^[^-]*- *\(.*\)/\1/p;}' sc13.parse >>sc13.urllist 
mkdir testres
cat sc13.urllist|while read f; do lynx -dump -head $f|head -1 >testres/`echo $f|tr '/' '_'`;done

-->

  </docbody>
</sc>
